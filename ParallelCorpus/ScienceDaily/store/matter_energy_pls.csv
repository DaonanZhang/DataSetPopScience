pls,fk_score,ari_score,reference,abstract
"
A study published in Nature Nanotechnology presents an innovative graphene-based neurotechnology with the potential for a transformative impact in neuroscience and medical applications. This research, spearheaded by the Catalan Institute of Nanoscience and Nanotechnology (ICN2) together with the Universitat Autònoma de Barcelona (UAB) and other national and international partners, is currently being developed for therapeutic applications through the spin-off INBRAIN Neuroelectronics.

Key Features of Graphene Technology
Following years of research under the European Graphene Flagship project, ICN2 spearheaded in collaboration with the University of Manchester the development of EGNITE (Engineered Graphene for Neural Interfaces), a novel class of flexible, high-resolution, high-precision graphene-based implantable neurotechnology. The results published today in Nature Neurotechnology aim to contribute with innovative technologies to the blooming landscape of neuroelectronics and brain-computer interfaces.
EGNITE builds on the vast experience of its inventors in fabrication and medical translation of carbon nanomaterials. This innovative technology based on nanoporous graphene integrates fabrication processes standard in the semiconductor industry to assemble graphene microelectrodes of a mere 25 µm in diameter. The graphene microelectrodes exhibit low impedance and high charge injection, essential attributes for flexible and efficient neural interfaces.
Preclinical Validation of Functionality
Preclinical studies by various neuroscience and biomedical experts that partnered with ICN2, using different models for both the central and peripheral nervous system, demonstrated the capacity of EGNITE in recording high-fidelity neural signals with exceptional clarity and precision and, more importantly, afford highly targeted nerve modulation. The unique combination of high-fidelity signal recording and precise nerve stimulation offered by EGNITE technology represents a potentially critical advancement in neuroelectronic therapeutics.
This innovative approach addresses a critical gap in neurotechnology, which has seen little advancement in materials over the last two decades. The development of EGNITE electrodes has the capacity to place graphene at the forefront of neurotechnological materials.

International Collaboration and Scientific Leadership
The technology presented today builds on the legacy of the Graphene Flagship, a European initiative that during the last decade strived to advance European strategic leadership in technologies that rely on graphene and other 2D materials. Behind this scientific breakthrough is a collaborative effort led by ICN2 researchers Damià Viana (now at INBRAIN Neuroelectronics), Steven T. Walston (now at University of Southern California), and Eduard Masvidal-Codina, under the guidance of ICREA Jose A. Garrido, leader of the ICN2Advanced Electronic Materials and Devices Group, and ICREA Kostas Kostarelos, leader of the ICN2Nanomedicine Lab and the Faculty of Biology, Medicine & Health at the University of Manchester (UK). The research has had the participation of Xavier Navarro, Natàlia de la Oliva, Bruno Rodríguez-Meana and Jaume del Valle, from the Institute of Neurosciences and the Department of Cellular Biology, Physiology and Immunology of the Universitat Autònoma de Barcelona (UAB).
The collaboration includes the contribution from leading national and international institutions, such as the Institut de Microelectrònica de Barcelona -- IMB-CNM (CSIC), the National Graphene Institute in Manchester (UK), and the Grenoble Institut des Neurosciences -- Université Grenoble Alpes (France) and the University of Barcelona. The technology integration into the standard semiconductor fabrication processes has been performed at the Micro and Nanofabrication cleanroom of the IMB-CNM (CSIC), under the supervision of CIBER researcher Dr Xavi Illa.
Clinical Translation: Next Steps
The EGNITE technology described in the Nature Nanotechnology article has been patented and licensed to INBRAIN Neuroelectronics, a spin-off based in Barcelona from ICN2 and ICREA, with support from IMB-CNM (CSIC). The company, also a partner in the Graphene Flagship project, is leading the translation of the technology into clinical applications and products. Under the direction of CEO Carolina Aguilar, INBRAIN Neuroelectronics is gearing up for the first-in-human clinical trials of this innovative graphene technology.
The industrial and innovation landscape on semiconductor engineering in Catalonia, where ambitious national strategies plan to build state-of-the-art facilities to produce semiconductor technologies based on emerging materials, offer an unprecedented opportunity to accelerate the translation of such results presented today into clinical applications.
Closing Remarks
The Nature Nanotechnology article describes an innovative graphene-based neurotechnology that can be upscaled using established semiconductor fabrication processes, holding the potential for a transformative impact. ICN2 and its partners continue to advance and mature the described technology with the aim to translate it into a real efficacious and innovative therapeutic neurotechnology.

","score: 22.597485493230177, grade_level: '23'","score: 24.402684719535777, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41565-023-01570-5,"One of the critical factors determining the performance of neural interfaces is the electrode material used to establish electrical communication with the neural tissue, which needs to meet strict electrical, electrochemical, mechanical, biological and microfabrication compatibility requirements. This work presents a nanoporous graphene-based thin-film technology and its engineering to form flexible neural interfaces. The developed technology allows the fabrication of small microelectrodes (25 µm diameter) while achieving low impedance (∼25 kΩ) and high charge injection (3–5 mC cm−2). In vivo brain recording performance assessed in rodents reveals high-fidelity recordings (signal-to-noise ratio >10 dB for local field potentials), while stimulation performance assessed with an intrafascicular implant demonstrates low current thresholds (<100 µA) and high selectivity (>0.8) for activating subsets of axons within the rat sciatic nerve innervating tibialis anterior and plantar interosseous muscles. Furthermore, the tissue biocompatibility of the devices was validated by chronic epicortical (12 week) and intraneural (8 week) implantation. This work describes a graphene-based thin-film microelectrode technology and demonstrates its potential for high-precision and high-resolution neural interfacing."
"
When you go running in the woods in your running tights, elastane is the reason they fit you so comfortably. Elastane is an elastic material that allows the fabric to stretch and adapt to your body.

But when elastane fibres are mixed with cotton, wool, nylon or other fibres, as is the case in many clothes today, the clothes become almost impossible to recycle. It is extremely difficult to separate out the different fibres, and therefore the materials in the clothes cannot be recycled.
For this reason, clothes and other textiles are among the materials that we are the worst at recycling. Only about six per cent of clothes thrown away by Danish households are recycled. In comparison, 32 per cent of all plastic packaging is recycled in Denmark.
But this may change, says Assistant Professor Steffan Kvist Kristensen from the Interdisciplinary Nanoscience Center at Aarhus University. Together with a number of colleagues, he is behind a new technology that can separate out fibres in mixed fabrics.
""We've developed a method to remove elastane completely from nylon. We're not quite there yet with cotton, because some of the cotton fibres are broken down in the process. But we believe that, with some minor adjustments, we can solve this problem,"" he says and continues:
""In other words, we can disassemble the fabric so that we can recycle far more textiles in the future.""
Heating clothes in a large pressure cooker
It is not easy to separate elastane and other fibres once they have been woven together. Clothes are made by winding the main fibres, such as nylon or cotton, around the elastane fibres, which consist of long chains of molecules.

The fibres only break apart if we break the long chains of molecules, explains Steffan Kvist Kristensen.
""The many links in the elastane chain are bound together by a small molecule called a diamine. By heating the clothes to 225 degrees Celsius and adding a specific alcohol, we have found a method to break down the bonds in elastane. When this happens, the chains fall apart and the materials separate.
The whole process takes place in what is in effect a large pressure cooker that we feed the textiles into. We then add a little alcohol and some base and heat it up. Then we let it cook for just over four hours, and when we open the lid again, the different fibres will have been separated.""
The secret ingredient is drain cleaner
Because most of the fibres in the clothes need to be recyclable, using harsh chemicals is not an option for Steffan Kvist Kristensen and his colleagues. Instead they use alcohol and add a potassium hydroxide base.
""Potassium hydroxide is one of the main ingredients in ordinary drain cleaner. We found that adding this accelerated the process. It simply increases the speed of the chemical reaction,"" he says.

He doesn't know why this happens exactly, but it does break the bonds in the elastane.
""We're pretty sure that potassium hydroxide increases the reactivity of our alcohol. Either that, or the bonds are broken down slightly by the potassium hydroxide, so it is easier for the alcohol to break them completely,"" he says.
Hopes the clothing industry will embrace the technology
So far, Steffan Kvist Kristensen and his colleagues have only experimented with two nylon stockings at a time. The technology is therefore not yet ready for implementation at industrial scale. This will require being able to decompose much larger amounts of clothing.
""We can only scale things up a little because of the limitations in our equipment. So it's up to industry to embrace the technology and scale it up in earnest,"" he says.
However, according to Steffan Kvist Kristensen, Denmark does not currently have the facilities to exploit the technology at large scale. You'll have to look south of the border for this.
""The chemical industry in Denmark is small, but Germany has some of the largest plants in the world. They will most likely be able to use our method to recycle large amounts of fibres from elastane-containing clothes.
If we're to succeed with this, we need to get the large chemical plants on board. But they must see a business model in buying recycled materials and using them in the production of new fibres. If they don't, the technology will never take off.""

","score: 9.559046443500872, grade_level: '10'","score: 9.618366742371876, grade_levels: ['10'], ages: [15, 16]",10.1039/D3GC02994H,"Solvolysis of elastane in blended fabrics using tert-amyl alcohol and KOH (cat.) provides elastane monomers and a fibre matrix. The process is especially useful for polyamide/elastane blends, providing a possibility for fibre-to-fibre recycling."
"
When light goes through a material, it often behaves in unpredictable ways. This phenomenon is the subject of an entire field of study called ""nonlinear optics,"" which is now integral to technological and scientific advances from laser development and optical frequency metrology, to gravitational wave astronomy and quantum information science.

In addition, recent years have seen nonlinear optics applied in optical signal processing, telecommunications, sensing, spectroscopy, light detection and ranging. All these applications involve the miniaturization of devices that manipulate light in nonlinear ways onto a small chip, enabling complex light interactions chip-scale.
Now, a team of scientists at EPFL and the Max Plank Institute has brought nonlinear optical phenomena into a transmission electron microscope (TEM), a type of microscope that uses electrons for imaging instead of light. The study was led by Professor Tobias J. Kippenberg at EPFL and Professor Claus Ropers, Director of the Max Planck Institute for Multidisciplinary Sciences. It is now published in Science.
At the heart of the study are ""Kerr solitons,"" waves of light that hold their shape and energy as they move through a material, like a perfectly formed surf wave traveling across the ocean. This study used a particular type of Kerr solitons called ""dissipative,"" which are stable, localized pulses of light that last tens of femtoseconds (a quadrillionth of a second) and form spontaneously in the microresonator. Dissipative Kerr solitons can also interact with electrons, which made them crucial for this study.
The researchers formed dissipative Kerr solitons inside a photonic microresonator, a tiny chip that traps and circulates light inside a reflective cavity, creating the perfect conditions for these waves. ""We generated various nonlinear spatiotemporal light patterns in the microresonator driven by a continuous-wave laser,"" explains EPFL researcher Yujia Yang, who led the study. ""These light patterns interacted with a beam of electrons passing by the photonic chip, and left fingerprints in the electron spectrum.""
Specifically, the approach demonstrated the coupling between free electrons and dissipative Kerr solitons, which allowed the researchers to probe soliton dynamics in the microresonator cavity and perform ultrafast modulation of electron beams.
""Our ability to generate dissipative Kerr solitons [DKS] in a TEM extends the use of microresonator-base frequency combs to unexplored territories,"" says Kippenberg. ""The electron-DKS interaction could enable high repetition-rate ultrafast electron microscopy and particle accelerators empowered by a small photonic chip.""
Ropers adds: ""Our results show electron microscopy could be a powerful technique for probing nonlinear optical dynamics at the nanoscale. This technique is non-invasive and able to directly access the intracavity field, key to understanding nonlinear optical physics and developing nonlinear photonic devices.""
The photonic chips were fabricated in the Center of MicroNanoTechnology (CMi) and the Institute of Physics cleanroom at EPFL. The experiments were conducted at the Göttingen Ultrafast Transmission Electron Microscopy (UTEM) Lab.

","score: 16.335634854771786, grade_level: '16'","score: 17.052676348547713, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adk2489,"The short de Broglie wavelength and strong interaction empower free electrons to probe structures and excitations in materials and biomolecules. Recently, electron-photon interactions have enabled new optical manipulation schemes for electron beams. In this work, we demonstrate the interaction of electrons with nonlinear optical states inside a photonic chip–based microresonator. Optical parametric processes give rise to spatiotemporal pattern formation corresponding to coherent or incoherent optical frequency combs. We couple such “microcombs” to electron beams, demonstrate their fingerprints in the electron spectra, and achieve ultrafast temporal gating of the electron beam. Our work demonstrates the ability to access solitons inside an electron microscope and extends the use of microcombs to spatiotemporal control of electrons for imaging and spectroscopy."
"
The world is filled with a myriad of sounds and vibrations -- the gentle tones of a piano drifting down the hall, the relaxing purr of a cat laying on your chest, the annoying hum of the office lights. Imagine being able to selectively tune out noises of a certain frequency. Researchers at the University of Illinois Urbana-Champaign have synthesized polymer networks with two distinct architectures and crosslink points capable of dynamically exchanging polymer strands to understand how the network connectivity and bond exchange mechanisms govern the overall damping behavior of the network. The incorporation of dynamic bonds into the polymer network demonstrates excellent damping of sound and vibrations at well-defined frequencies.

""This research is about using polymers to absorb various sounds and vibrations that can occur at different frequencies,"" says materials science and engineering professor Chris Evans, who led this work. ""We want to know how to design the molecular-scale chemistry of the polymer in such a way that we control what sort of energy absorbing ability it has.""
The results of this new research were recently published in Nature Communications.
Being able to tailor polymers to absorb specific frequencies can be beneficial for use in ear plugs and helmets for people near blasts or explosions and in scenarios with repeat exposure to a certain frequency of noise, like a helicopter pilot, where such long-term exposure can lead to hearing problems.
Polymers are long chain molecules composed of many repeating units. Some polymers are not fully linear and have branches, like trees, and other polymers are highly cross-linked where individual polymer chains are connected by covalent bonds to other chains, like a net. The cross-link point is a bond that links one polymer chain to another, and this is where bonds can exchange.
Dynamic bonds within a polymer network allows it to rearrange its structure in response to a change in environment (high temperature, pH, UV light exposure, etc.). Replacing a few covalent bonds in cross-linked polymer structures with dynamic bonds can enhance the properties of the polymer such as the modulus -- the stiffness of the material -- and the viscosity -- how easily the material flows. Dynamic bonds provide materials with unique properties such as self-healing, super-stretchability, adhesive properties and material toughness due to the modification of the viscoelastic properties.
""The key advance here is that we're using dynamic covalent bonds,"" Evans explains. ""They're chemical bonds but they can exchange with each other (the dynamic part) and when two different chemistries are used; they can exchange at very different timescales (the orthogonal part). We're using that process to try and control what frequencies of sound and vibration we're absorbing.""
Incorporating orthogonal bonds, where fast bonds can only exchange with other fast bonds and slow bonds can only exchange with other slow bonds, generates multiple and well-separated relaxation modes, which gives the network excellent damping and improved mechanical properties, like toughness.

The team made a series of polymers that had controlled types of architectures and backbones and they looked at the way that the polymer chains are connected. Evans says that it actually makes a big difference how the polymer chains are connected in order to get the energy dissipating processes at very specific timescales that would correspond to very specific sound waves or vibrations. If the chains are only linked at the ends, this is not as effective as being linked periodically along the chain backbone.
One of the main limitations with the materials used in this research, however, is that they do ultimately flow. For example, rubber bands will retain their shape, but when those dynamic bonds are added in, they'll always eventually flow, like silly putty. This is fine for, say, a soldier's helmet where the material is enclosed within the shell of the helmet, but not so much for an ear plug. Evans says his group is working on ways to get the polymer to be more of a self-standing material, and in the future, they'd like to incorporate more dynamic bonds, so the polymer isn't just tailored for a specific frequency, but for a much wider range of frequencies.
Chris Evans is also an affiliate of the Materials Research Laboratory and the Beckman Institute for Advanced Science and Technology at UIUC.
Other contributors to this work include Sirui Ge (department of materials science and engineering and the Materials Research Laboratory at UIUC) and Yu-Hsuan Tsao (department of materials science and engineering and the Materials Research Laboratory at UIUC).
This research was funded by the Air Force Office of Scientific Research and the National Science Foundation.

","score: 15.078299142111153, grade_level: '15'","score: 16.702448713166724, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43073-w,"Materials with tunable modulus, viscosity, and complex viscoelastic spectra are crucial in applications such as self-healing, additive manufacturing, and energy damping. It is still challenging to predictively design polymer networks with hierarchical relaxation processes, as many competing factors affect dynamics. Here, networks with both pendant and telechelic architecture are synthesized with mixed orthogonal dynamic bonds to understand how the network connectivity and bond exchange mechanisms govern the overall relaxation spectrum. A hydrogen-bonding group and a vitrimeric dynamic crosslinker are combined into the same network, and multimodal relaxation is observed in both pendant and telechelic networks. This is in stark contrast to similar networks where two dynamic bonds share the same exchange mechanism. With the incorporation of orthogonal dynamic bonds, the mixed network also demonstrates excellent damping and improved mechanical properties. In addition, two relaxation processes arise when only hydrogen-bond exchange is present, and both modes are retained in the mixed dynamic networks. This work provides molecular insights for the predictive design of hierarchical dynamics in soft materials."
"
In a new study, environmentally benign inverse-perovskites with high energy conversion efficiency have been reported by Tokyo Tech scientists with potential for practical application as thermoelectric materials (TEMs). Addressing the limitations typically faced with TEMs, such as insufficient energy conversion efficiency and environmental toxicity due to heavy elements, the new TEMs provide a suitable alternative to TEMs based on toxic elements with better thermoelectric properties than conventional eco-friendly TEMs.

Thermoelectric materials (TEMs) capable of converting thermal energy to electrical energy and vice versa have become an essential part of our world, which needs better waste-energy harvesting systems and cooling systems for electronic gadgets.
The energy conversion efficiency of TEMs depends on a dimensionless figure of merit (ZT), which is a product of two different factors: the inverse of thermal conductivity (k) and the power factor (PF).
A high-performance TEM exhibits a high ZT if it possesses low k and high PF. Over the years, scientists developed several high-performance heavy metal chalcogenide-based TEMs, such as Bi2Te3 and PbTe, that fulfill these criteria. While these materials were ideal for energy conversion, they were toxic to the environment and the health of living organisms -- they contained toxic heavy elements, such as lead (Pb) and tellurium (Te), which limited their practical applications. On the other hand, although oxide-based TEMs, such as SrTiO3, have several advantages of non-toxicity and abundant natural resources, their ZT has been limited due to their high k.
To address this, a research team led by Associate Professor Takayoshi Katase from Tokyo Institute of Technology explored efficient yet environmentally benign toxic-element-free TEMs. In their recent study published in Advanced Science, the researchers presented ""inverse""-perovskite-based high ZT TEMs with the chemical formula Ba3BO, where B refers to silicon (Si) and germanium (Ge).
""Unlike normal perovskites, such as SrTiO3, the positions of cation and anion sites are inverted in inverse-perovskites Ba3BO. So, they contain a large amount of the heavy element, Ba, and their crystal structure is formed by a soft flamework made up of weak O-Ba bonds. These characteristics realize the low k in inverse-perovskites,"" says Dr. Katase, elaborating on the standout properties of the materials.
The research team clarified the synthesized bulk polycrystals of Ba3BO possess extremely low k of 1.0-0.4 W/mK at a T of 300-600 K, which is lower than those of Bi2Te3 and PbTe bulks. As a result, the Ba3BO bulks exhibit rather high ZT of 0.16-0.84 at T = 300-623 K. Additionally to the promising experimental results, the team carried out theoretical calculations which predicted a potential maximum ZT of 2.14 for Ba3SiO and 1.21 for Ba3GeO at T = 600 K by optimizing hole concentration. The maximum ZT of these non-toxic TEMs is much higher than that of other eco-friendly TEMs and comparable to the toxic heavy element ones in the same temperature range.
In addition, the team clarified that the high ZT of Ba3BO is due not only to its low k but also its high PF: B ion, which usually behaves as a positively charged cation but as a negatively charged anion in Ba3BO. The B anions are responsible for the carrier transport, which achieves high PF.
In summary, this study validates the potential of the newly designed Ba3BO as a high-performing and eco-friendly alternative to conventional toxic, heavy element-based TEMs. The results establish inverse-perovskites as a promising option for developing advanced environmentally benign TEMs. In this regard, Dr. Katase concludes, ""We believe that our unique insight into designing high ZT materials without using toxic elements would have a strong impact on the materials science and chemistry communities as well as among innovators looking to expand the horizon of thermoelectric material applications beyond laboratories into our everyday life.""

","score: 17.97497435897436, grade_level: '18'","score: 19.267355769230768, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202307058,"High energy‐conversion efficiency (ZT) of thermoelectric materials has been achieved in heavy metal chalcogenides, but the use of toxic Pb or Te is an obstacle for wide applications of thermoelectricity. Here, high ZT is demonstrated in toxic‐element free Ba3BO (B = Si and Ge) with inverse‐perovskite structure. The negatively charged B ion contributes to hole transport with long carrier life time, and their highly dispersive bands with multiple valley degeneracy realize both high p‐type electronic conductivity and high Seebeck coefficient, resulting in high power factor (PF). In addition, extremely low lattice thermal conductivities (κlat) 1.0–0.4 W m−1 K−1 at T = 300–600 K are observed in Ba3BO. Highly distorted O–Ba6 octahedral framework with weak ionic bonds between Ba with large mass and O provides low phonon velocities and strong phonon scattering in Ba3BO. As a consequence of high PF and low κlat, Ba3SiO (Ba3GeO) exhibits rather high ZT = 0.16–0.84 (0.35–0.65) at T = 300–623 K (300–523 K). Finally, based on first‐principles carrier and phonon transport calculations, maximum ZT is predicted to be 2.14 for Ba3SiO and 1.21 for Ba3GeO at T = 600 K by optimizing hole concentration. Present results propose that inverse‐perovskites would be a new platform of environmentally‐benign high‐ZT thermoelectric materials."
"
Soft robots, medical devices, and wearable devices have permeated our daily lives. KAIST researchers have developed a fluid switch using ionic polymer artificial muscles that operates at ultra-low power and produces a force 34 times greater than its weight. Fluid switches control fluid flow, causing the fluid to flow in a specific direction to invoke various movements.

KAIST (President Kwang-Hyung Lee) announced on the 4th of January that a research team under Professor IlKwon Oh from the Department of Mechanical Engineering has developed a soft fluidic switch that operates at ultra-low voltage and can be used in narrow spaces.
Artificial muscles imitate human muscles and provide flexible and natural movements compared to traditional motors, making them one of the basic elements used in soft robots, medical devices, and wearable devices. These artificial muscles create movements in response to external stimuli such as electricity, air pressure, and temperature changes, and in order to utilize artificial muscles, it is important to control these movements precisely.
Switches based on existing motors were difficult to use within limited spaces due to their rigidity and large size. In order to address these issues, the research team developed an electro-ionic soft actuator that can control fluid flow while producing large amounts of force, even in a narrow pipe, and used it as a soft fluidic switch.
The ionic polymer artificial muscle developed by the research team is composed of metal electrodes and ionic polymers, and it generates force and movement in response to electricity. A polysulfonated covalent organic framework (pS-COF) made by combining organic molecules on the surface of the artificial muscle electrode was used to generate an impressive amount of force relative to its weight with ultra-low power (~0.01V).
As a result, the artificial muscle, which was manufactured to be as thin as a hair with a thickness of 180 µm, produced a force more than 34 times greater than its light weight of 10 mg to initiate smooth movement. Through this, the research team was able to precisely control the direction of fluid flow with low power.
Professor IlKwon Oh, who led this research, said, ""The electrochemical soft fluidic switch that operate at ultra-low power can open up many possibilities in the fields of soft robots, soft electronics, and microfluidics based on fluid control."" He added, ""From smart fibers to biomedical devices, this technology has the potential to be immediately put to use in a variety of industrial settings as it can be easily applied to ultra-small electronic systems in our daily lives.""
The results of this study, in which Dr. Manmatha Mahato, a research professor in the Department of Mechanical Engineering at KAIST, participated as the first author, were published in the international academic journal Science Advances on December 13, 2023. (Paper title: Polysulfonated Covalent Organic Framework as Active Electrode Host for Mobile Cation Guests in Electrochemical Soft Actuator)
This research was conducted with support from the National Research Foundation of Korea's Leader Scientist Support Project (Creative Research Group) and Future Convergence Pioneer Project.

","score: 17.625523715415024, grade_level: '18'","score: 19.272895256916996, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adk9752,"Tailoring transfer dynamics of mobile cations across solid-state electrolyte-electrode interfaces is crucial for high-performance electrochemical soft actuators. In general, actuation performance is directly proportional to the affinity of cations and anions in the electrolyte for the opposite electrode surfaces under an applied field. Herein, to maximize electrochemical actuation, we report an electronically conjugated polysulfonated covalent organic framework ( p S-COF) used as a common electrolyte-electrode host for 1-ethyl-3-methylimidazolium cation embedded into a Nafion membrane. The p S-COF–based electrochemical actuator exhibits remarkable bending deflection at near-zero voltage (~0.01 V) and previously unattainable blocking force, which is 34 times higher than its own weight. The ultrafast step response shows a very short rising time of 1.59 seconds without back-relaxation, and substantial ultralow-voltage actuation at higher frequencies up to 5.0 hertz demonstrates good application prospects of common electrolyte-electrode hosts. A soft fluidic switch is constructed using the proposed soft actuator as a potential engineering application."
"
Traditional cloud computing faces various challenges when processing large amounts of data in real time. ""Edge"" computing is a promising alternative and can benefit from devices known as physical reservoirs. Researchers have now developed a novel memristor device for this purpose. It responds to electrical and optical signals and overcomes real-time processing limitations. When tested, it achieved up to 90.2% accuracy in digit identification, demonstrating its potential for applications in artificial intelligence systems and beyond.

Every day, a significant amount of data related to weather, traffic, and social media undergo real-time processing. In traditional cloud computing, this processing occurs on the cloud, raising concerns about issues such as leaks, communication delays, slow speeds, and higher power consumption. Against this backdrop, ""edge computing"" presents a promising alternative solution. Located near users, it aims to distribute computations, thereby reducing the load and speeding up data processing. Specifically, edge AI, which involves AI processing at the edge, is expected to find applications in, for example, self-driving cars and machine anomaly prediction in factories.
However, for effective edge computing, efficient and computationally cost-effective technology is needed. One promising option is reservoir computing, a computational method designed for processing signals that are recorded over time. It can transform these signals into complex patterns using reservoirs that respond nonlinearly to them. In particular, physical reservoirs, which use the dynamics of physical systems, are both computationally cost-effective and efficient. However, their ability to process signals in real time is limited by the natural relaxation time of the physical system. This limits real-time processing and requires adjustments for best learning performance.
Recently, Professor Kentaro Kinoshita, a member of the Faculty of Advanced Engineering and the Department of Applied Physics at the Tokyo University of Science (TUS), and Mr. Yutaro Yamazaki from the Graduate School of Science and the same department at TUS developed an optical device with features that support physical reservoir computing and allow real-time signal processing across a broad range of timescales within a single device. Their findings were published in Advanced Scienceon 20 November 2023.
Speaking of their motivation for the study, Prof. Kinoshita explains: ""The devices developed in this research will enable a single device to process time-series signals with various timescales generated in our living environment in real time. In particular, we hope to realize an AI device to utilize in the edge domain.""
In their study, the duo created a special device using Sn-doped In2O3 and Nb-doped SrTiO3 (denoted as ITO/Nb:STO), which responds to both electrical and optical signals. They tested the electrical features of the device to confirm that it functions as a memristor (a memory device that can change its electrical resistance). The team also explored the influence of ultraviolet light on ITO/Nb:STO by varying the voltage and observing changes in the current. The results suggested that this device can modify the relaxation time of the photo-induced current according to the voltage, making it a potential candidate for a physical reservoir.
Furthermore, the team tested the effectiveness of ITO/Nb:STO as a physical reservoir by using it for classifying handwritten digit images in the MNIST (Modified National Institute of Standards and Technology) dataset. To their delight, the device achieved a classification accuracy of up to 90.2%. Additionally, to understand the role of the physical reservoir, the team ran experiments without it, which resulted in a relatively lower classification accuracy of 85.1%. These findings show that the ITO/Nb:STO junction device improves classification accuracy while keeping computational costs lower, proving its value as a physical reservoir.
""In the past, our research group has focused on research and development of materials applicable to physical reservoir computing. Accordingly, we fabricated these devices with the aim to realize a physical reservoir in which the relaxation time of photo-induced current can be arbitrarily controlled by voltage,"" says Prof. Kinoshita.
In summary, this study presents a novel memristor device capable of adjusting its response timescale through voltage variation, exhibiting enhanced learning capabilities, which makes it promising for applications at the edge as an AI device for edge computing. This, in turn, could pave the way for single devices that can effectively handle signals of varied durations found in real-world environments.

","score: 15.364212799717915, grade_level: '15'","score: 15.915177186177715, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202304804,"Recent years have witnessed a rising demand for edge computing, and there is a need for methods to decrease the computational cost while maintaining a high learning performance when processing information at arbitrary edges. Reservoir computing using physical dynamics has attracted significant attention. However, currently, the timescale of the input signals that can be processed by physical reservoirs is limited by the transient characteristics inherent to the selected physical system. This study used an Sn‐doped In2O3/Nb‐doped SrTiO3 junction to fabricate a memristor that could respond to both electrical and optical stimuli. The results show that the timescale of the transient current response of the device could be controlled over several orders of magnitude simply by applying a small voltage. The computational performance of the device as a physical reservoir is evaluated in an image classification task, demonstrating that the learning accuracy could be optimized by tuning the device to exhibit appropriate transient characteristics according to the timescale of the input signals. These results are expected to provide deeper insights into the photoconductive properties of strontium titanate, as well as support the physical implementation of computing systems."
"
In a study published in Science Advances, a group of researchers led by Associate Professor Nobuhiro Yanai from Kyushu University's Faculty of Engineering, in collaboration with Associate Professor Kiyoshi Miyata from Kyushu University and Professor Yasuhiro Kobori of Kobe University, reports that they have achieved quantum coherence at room temperature: the ability of a quantum system to maintain a well-defined state over time without getting affected by surrounding disturbances

This breakthrough was made possible by embedding a chromophore, a dye molecule that absorbs light and emits color, in a metal-organic framework, or MOF, a nanoporous crystalline material composed of metal ions and organic ligands.
Their findings mark a crucial advancement for quantum computing and sensing technologies. While quantum computing is positioned as the next major advancement of computing technology, quantum sensing is a sensing technology that utilizes the quantum mechanical properties of qubits (quantum analogs of bits in classical computing that can exist in a superposition of 0 and 1).
Various systems can be employed to implement qubits, with one approach being the utilization of intrinsic spin -- a quantum property related to a particle's magnetic moment -- of an electron. Electrons have two spin states: spin up and spin down. Qubits based on spin can exist in a combination of these states and can be ""entangled,"" allowing the state of one qubit to be inferred from another.
By leveraging the extremely sensitive nature of a quantum entangled state to environmental noise, quantum sensing technology is expected to enable sensing with higher resolution and sensitivity compared to traditional techniques. However, so far, it has been challenging to entangle four electrons and make them respond to external molecules, that is, achieve quantum sensing using a nanoporous MOF.
Notably, chromophores can be used to excite electrons with desirable electron spins at room temperatures through a process called singlet fission. However, at room temperature causes the quantum information stored in qubits to lose quantum superposition and entanglement. As a result, it is usually only possible to achieve quantum coherence at liquid nitrogen level temperatures.
To suppress the molecular motion and achieve room-temperature quantum coherence, the researchers introduced a chromophore based on pentacene (polycyclic aromatic hydrocarbon consisting of five linearly fused benzene rings) in a UiO-type MOF. ""The MOF in this work is a unique system that can densely accumulate chromophores. Additionally, the nanopores inside the crystal enable the chromophore to rotate, but at a very restrained angle,"" says Yanai.
The MOF structure facilitated enough motion in the pentacene units to allow the electrons to transition from the triplet state to a quintet state, while also sufficiently suppressing motion at room temperature to maintain quantum coherence of the quintet multiexciton state. Upon photoexciting electrons with microwave pulses, the researchers could observe the quantum coherence of the state for over 100 nanoseconds at room temperature. ""This is the first room-temperature quantum coherence of entangled quintets,"" remarks an excited Kobori.
While the coherence was observed only for nanoseconds, the findings will pave the way for designing materials for the generation of multiple qubits at room temperatures. ""It will be possible to generate quintet multiexciton state qubits more efficiently in the future by searching for guest molecules that can induce more such suppressed motions and by developing suitable MOF structures,"" speculates Yanai. ""This can open doors to room-temperature molecular quantum computing based on multiple quantum gate control and quantum sensing of various target compounds.""

","score: 18.27830434782609, grade_level: '18'","score: 19.198130434782605, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adi3147,"Singlet fission can generate an exchange-coupled quintet triplet pair state 5 TT, which could lead to the realization of quantum computing and quantum sensing using entangled multiple qubits even at room temperature. However, the observation of the quantum coherence of 5 TT has been limited to cryogenic temperatures, and the fundamental question is what kind of material design will enable its room-temperature quantum coherence. Here, we show that the quantum coherence of singlet fission–derived 5 TT in a chromophore-integrated metal-organic framework can be over hundred nanoseconds at room temperature. The suppressed motion of the chromophores in ordered domains within the metal-organic framework leads to the enough fluctuation of the exchange interaction necessary for 5 TT generation but, at the same time, does not cause severe 5 TT decoherence. Furthermore, the phase and amplitude of quantum beating depend on the molecular motion, opening the way to room-temperature molecular quantum computing based on multiple quantum gate control."
"
Endocrine-disrupting chemicals (EDCs) in plastics pose a serious threat to public health and cost the U.S. an estimated $250 billion in increased health care costs in 2018, according to new research published in the Journal of the Endocrine Society.

Plastics contain many hazardous, endocrine-disrupting chemicals that leach and contaminate humans and the environment. These chemicals disturb the body's hormone systems and can cause cancer, diabetes, reproductive disorders, neurological impairments of developing fetuses and children, and death.
Potential options under discussion as part of a Global Plastics Treaty include interventions to reduce EDC exposure to protect public health and the environment, and data on the health costs of EDCs could help move this initiative forward.
""Our study found plastics contribute substantially to disease and associated social costs in the U.S., about $250 billion in 2018 alone. These costs are equivalent to 1.22% of the Gross Domestic Product. The diseases due to plastics run the entire life course from preterm birth to obesity, heart disease and cancers,"" said study author Leonardo Trasande, M.D., M.P.P., of NYU Grossman School of Medicine and NYU Wagner Graduate School of Public Service in New York, N.Y. Trasande has represented the Society at intergovernmental meetings to address plastic pollution and its health effects.
""Our study drives home the need to address chemicals used in plastic materials as part of the Global Plastics Treaty,"" Trasande said. ""Actions through the Global Plastics Treaty and other policy initiatives will reduce these costs in proportion to the actual reductions in chemical exposures achieved.""
The researchers analyzed existing studies on EDCs to identify how many diseases and disabilities were attributed to chemicals in plastics. The chemicals they studied commonly found in plastics included polybrominated diphenyl ethers (PBDE), phthalates, bisphenols, and poly- and perfluoroalkyl substances (PFAS).
The researchers updated previously published data on disease burden and cost estimates for these chemicals in the United States to 2018. They combined the data and estimated $250 billion in disease burden from plastic exposure in 2018.

""This study shows that preventing plastic pollution can reduce the incidence of disease, disability and early death, and its attendant human suffering and health care costs,"" said co-author Michael Belliveau, Executive Director of Defend Our Health based in Portland, Maine. ""Policymakers and market leaders must detoxify and slash the use of petrochemical plastics and endocrine-disrupting chemicals. We urge negotiators to finalize a Global Plastics Treaty that caps and reduces plastic production and eliminate EDCs as plastics additives.""
Most of the cost burden was from polybrominated diphenyl ethers (PBDE) exposure which is associated with diseases such as cancer. Sixty-seven billion in health costs was due to phthalate exposure which is linked to preterm birth, reduced sperm count and childhood obesity, and $22 billion was due to PFAS exposure which is associated with kidney failure and gestational diabetes.
The other authors of this study are Roopa Krithivasan of Defend Our Health; Kevin Park of NYU Grossman School of Medicine; and Vladislav Obsekov of Children's Hospital of Philadelphia in Philadelphia, Pa.
The study was funded by the National Institutes of Health's National Institute of Environmental Health Sciences and The Passport Foundation.

","score: 15.63689887640449, grade_level: '16'","score: 17.58685393258427, grade_levels: ['college_graduate'], ages: [24, 100]",10.1210/jendso/bvad163,"Chemicals used in plastics have been described to contribute to disease and disability, but attributable fractions have not been quantified to assess specific contributions. Without this information, interventions proposed as part of the Global Plastics Treaty cannot be evaluated for potential benefits. To accurately inform the tradeoffs involved in the ongoing reliance on plastic production as a source of economic productivity in the United States, we calculated the attributable disease burden and cost due to chemicals used in plastic materials in 2018. We first analyzed the existing literature to identify plastic-related fractions (PRF) of disease and disability for specific polybrominated diphenylethers (PBDE), phthalates, bisphenols, and polyfluoroalkyl substances and perfluoroalkyl substances (PFAS). We then updated previously published disease burden and cost estimates for these chemicals in the United States to 2018. By uniting these data, we computed estimates of attributable disease burden and costs due to plastics in the United States. We identified PRFs of 97.5% for bisphenol A (96.25-98.75% for sensitivity analysis), 98% (96%-99%) for di-2-ethylhexylphthalate, 100% (71%-100%) for butyl phthalates and benzyl phthalates, 98% (97%-99%) for PBDE-47, and 93% (16%-96%) for PFAS. In total, we estimate $249 billion (sensitivity analysis: $226 billion-$289 billion) in plastic-attributable disease burden in 2018. The majority of these costs arose as a result of PBDE exposure, though $66.7 billion ($64.7 billion-67.3 billion) was due to phthalate exposure and $22.4 billion was due to PFAS exposure (sensitivity analysis: $3.85-$60.1 billion). Plastics contribute substantially to disease and associated social costs in the United States, accounting for 1.22% of the gross domestic product. The costs of plastic pollution will continue to accumulate as long as exposures continue at current levels. Actions through the Global Plastics Treaty and other policy initiatives will reduce these costs in proportion to the actual reductions in chemical exposures achieved."
"
If you've ever taken a car trip through a rural area, you might already know that livestock, including cows and sheep, can be individually tracked using decidedly old-fashioned methods, such as ear tags or even branding marks. By contrast, many tech-savvy pet owners have opted to have their dog or cat ""chipped"" by having a radio frequency identification (RFID) permanently implanted under the skin. However, all these identification solutions leave something to be desired, as ear tags can become damaged or lost, while RFID chips require an invasive procedure to insert and specialized equipment to read.

In a study recently published in Scientific Reports, researchers from the Institute of Industrial Science, The University of Tokyo demonstrated an alternative ""bio-tagging"" method, in which a unique array of microneedles -- with alphanumeric characters visible to the unaided eye -- is directly inserted into the skin for permanent identification of animals. This approach relies on a patch of dissolvable microneedle arrays to deliver the dye molecules. ""We feel that our method is a simpler, safer, and more humane way to label animals, and is versatile enough to be applied both in pets and industrial situations,"" lead author of the study, Jongho Park says.
The researchers used microneedle array patches (MAPs), in which microneedle arrays, less than 1 mm long, are created in the form of a matrix from customized polydimethylsiloxane molds. By altering the molds, desired symbols can be tattooed into the animal, like the output of dot-matrix printers. The negative molds themselves can be made easily from positive 3D-printed resin plugs. ""Our MAPs approach allows for a very large number of unique identifiers, and does not require much specialized training to apply,"" says senior author, Beomjoon Kim.
Testing showed that the biotags remained clearly legible in the skin over a month after being stamped. This technique can be a useful tool for animal research and management, as well as potentially being extended biomedical applications and other areas such as flexible electronics integration.

","score: 16.405702274975273, grade_level: '16'","score: 16.902408506429275, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41598-023-50343-6,"Properly handling animals and understanding their habits are crucial to establish a society where humans and animals coexist. Thus, identifying individual animals, including their possessions, and adequately managing each animal is necessary. Although several conventional identification methods exist, such as the use of ear punch, tattoos, and radio frequency (RF) chips, they require several processes and external apparatus. In this study, we proposed a new biotagging method using a microneedle array for animal identification. Our approach uses dissolvable microneedle arrays as a single patch to deliver dyes directly into the skin layer. Additionally, we developed a new fabrication method for customised female moulds to realise microneedle array patches (MAPs) with patterns of different characters and number. The characteristics and feasibility of the patterned MAPs were confirmed through basic evaluations and animal experiments. Moreover, we confirmed that patterns formed from biotagging using the developed patterned MAPs lasted over one month with clear readability. Finally, we confirmed that our patterned MAPs successfully realised biotagging on rat skin with the designated patterns including characters and number patterns. The proposed method is expected to enable minimally invasive tagging without external equipment or complex processes. In addition, the developed method could be used to embed various tags into the skin of animals and humans in the future."
"
Researchers have developed a new technology that uses meta-optical devices to perform thermal imaging. The approach provides richer information about imaged objects, which could broaden the use of thermal imaging in fields such as autonomous navigation, security, thermography, medical imaging and remote sensing.

""Our method overcomes the challenges of traditional spectral thermal imagers, which are often bulky and delicate due to their reliance on large filter wheels or interferometers,"" said research team leader Zubin Jacob from Purdue University. ""We combined meta-optical devices and cutting-edge computational imaging algorithms to create a system that is both compact and robust while also having a large field of view.""
In Optica, Optica Publishing Group's journal for high-impact research, the authors describe their new spectro-polarimetric decomposition system, which uses a stack of spinning metasurfaces to break down thermal light into its spectral and polarimetric components. This allows the imaging system to capture the spectral and polarization details of thermal radiation in addition to the intensity information that is acquired with traditional thermal imaging.
The researchers showed that the new system can be used with a commercial thermal camera to successfully classify various materials, a task that is typically challenging for conventional thermal cameras. The method's ability to distinguish temperature variations and identify materials based on spectro-polarimetric signatures could help boost safety and efficiency for a variety of applications, including autonomous navigation.
""Traditional autonomous navigation approaches rely heavily on RGB cameras, which struggle in challenging conditions like low light or bad weather,"" said the paper's first author Xueji Wang, a postdoctoral researcher at Purdue University. ""When integrated with heat-assisted detection and ranging technology, our spectro-polarimetric thermal camera can provide vital information in these difficult scenarios, offering clearer images than RGB or conventional thermal cameras. Once we achieve real-time video capture, the technology could significantly enhance scene perception and overall safety.""
Doing more with a smaller imager
Spectro-polarimetric imaging in the long-wave infrared is crucial for applications such as night vision, machine vision, trace gas sensing and thermography. However, today's spectro-polarimetric long-wave infrared imagers are bulky and limited in spectral resolution and field of view.

To overcome these limitations the researchers turned to large-area metasurfaces -- ultra-thin structured surfaces that can manipulate light in complex ways. After engineering spinning dispersive metasurfaces with tailored infrared responses, they developed a fabrication process that allowed these metasurfaces to be used to create large-area (2.5-cm diameter) spinning devices suitable for imaging applications. The resulting spinning stack measures less than 10 x 10 x 10 cm and can be used with a traditional infrared camera.
""Integrating these large-area meta-optical devices with computational imaging algorithms facilitated the efficient reconstruction of the thermal radiation spectrum,"" said Wang. ""This enabled a more compact, robust and effective spectro-polarimetric thermal imaging system than was previously achievable.""
Classifying materials with thermal imaging
To evaluate their new system, the researchers spelled out ""Purdue"" using various materials and microstructures, each with unique spectro-polarimetric properties. Using the spectro-polarimetric information acquired with the system, they accurately distinguished the different materials and objects. They also demonstrated a three-fold increase in material classification accuracy compared to traditional thermal imaging methods, highlighting the system's effectiveness and versatility.
The researchers say that the new method could be especially useful for applications that require detailed thermal imaging. ""In security, for example, it could revolutionize airport systems by detecting concealed items or substances on people,"" said Wang. ""Moreover, its compact and robust design enhances its suitability for diverse environmental conditions, making it particularly beneficial for applications such as autonomous navigation.""
In addition to working to achieve video capture with the system, the researchers are trying to enhance the technique's spectral resolution, transmission efficiency and speed of image capture and processing. They also plan to improve the metasurface design to enable more complex light manipulation for higher spectral resolution. Additionally, they want to extend the method to room-temperature imaging since the use of metasurface stacks restricted the method to high-temperature objects. They plan to do this using improved materials, metasurface designs and techniques like anti-reflection coatings.

","score: 18.477815432742442, grade_level: '18'","score: 19.715354535974974, grade_levels: ['college_graduate'], ages: [24, 100]",10.1364/OPTICA.506813,"Spectro-polarimetric imaging in the long-wave infrared (LWIR) region plays a crucial role in applications from night vision and machine perception to trace gas sensing and thermography. However, the current generation of spectro-polarimetric LWIR imagers suffers from limitations in size, spectral resolution, and field of view (FOV). While meta-optics-based strategies for spectro-polarimetric imaging have been explored in the visible spectrum, their potential for thermal imaging remains largely unexplored. In this work, we introduce an approach for spectro-polarimetric decomposition by combining large-area stacked meta-optical devices with advanced computational imaging algorithms. The co-design of a stack of spinning dispersive metasurfaces along with compressive sensing and dictionary learning algorithms allows simultaneous spectral and polarimetric resolution without the need for bulky filter wheels or interferometers. Our spinning-metasurface-based spectro-polarimetric stack is compact (<10×10×10cm) and robust, and it offers a wide field of view (20.5°). We show that the spectral resolving power of our system substantially enhances performance in machine learning tasks such as material classification, a challenge for conventional panchromatic thermal cameras. Our approach represents a significant advance in the field of thermal imaging for a wide range of applications including heat-assisted detection and ranging (HADAR)."
"
A Rutgers biophysical chemist and his brother, a political scientist on the West Coast, have joined intellectual forces, realizing a long-standing dream of co-authoring an article that bridges their disciplines involving cells and society.

In their paper, they have proposed that powerful parallels exist between the microscopic, natural world of cells and molecules and the human-forged realm of organizations and political systems.
Taking it a step further, the brothers -- eminent scholars who have served as top leaders of their respective institutions -- have proposed that humankind can draw lessons from what the microscopic and macroscopic worlds have in common. Ideally, they said, their perspective could alert policymakers to strategies for responding adaptively to improve the performance of their institutions and political systems.
Writing in the Proceedings of the National Academies of Science Nexus, Kenneth Breslauer, a Linus C. Pauling Distinguished Professor of Chemistry and Chemical Biology with the Rutgers School of Arts and Sciences (SAS), and his older brother, George Breslauer, a Chancellor's Professor of Political Science at the University of California-Berkeley, have identified and analyzed similarities in rules that apply to both the natural and social realms.
""Our focus is particularly timely given the growing global challenges to various forms of governance and the emergence of history-changing biology,"" said Kenneth, who has been a member of the Rutgers faculty for 50 years and is the university's founding dean of life sciences. ""Many stability-based concepts, characteristics and phenomena within the physical sciences find analogous expression in the influences on the relative stabilities of socio-political systems.""
Kenneth, one the world's foremost authorities on the forces that control the structure and function of biological molecules, was described in 2018 by former SAS Executive Dean Peter March as ""the architect of our outstanding life science programs, which have helped establish Rutgers as a premier institution within the [Association of American Universities.]"" In addition, Kenneth has been the dean of the Division of Life Sciences, the vice president for Health Science Partnerships and the vice president for Research.
His brother George is recognized as a world-renowned expert in Soviet and Russian politics and foreign relations. In his area of expertise, he is the author of 14 books. At UC Berkeley, George has been the chair of the Center for Slavic and East European Studies, dean of the social sciences, executive dean of the College of Letters and Science and executive vice chancellor and provost.

Born 14 months apart, the Breslauers grew up in Jackson Heights, Queens, raised by parents who were refugees from Nazi Germany.
""George and I are each other's best friend,"" Kenneth said.
The brothers have waited years to work together. Their paper, they said, is a ""bucket list"" item for both.
The two used the shared concept of ""stability"" as their prism.
The molecular workings of microscopic systems such as a cell or molecule are generally understood to be subject to the laws of nature, the Breslauers said, while social and political events are thought to be structured by human action and chance. However, both natural, molecular systems and sociopolitical organizations, under the influences of analogous features, they said, exhibit some level of stability, instability and even ""metastability,"" a state of precarious stability.
For example, a chemical system can be metastable for extended periods of time, when it becomes trapped in a high energy state, until outside influences are sufficient to perturb and disrupt the stability of the trapped species. Analogously, isolated social states such as the former country of East Germany can persist in a metastable state for decades until the isolating boundaries are breached by outside influences.

The researchers likened a political science macroscopic concept, known as the ""collective action"" barrier, with the chemical property of cooperativity, which accelerates microscopic molecular transformations from one chemical state to another.
With respect to the societal collective action barrier, individuals who want to change an aspect of their government are less likely to act if they believe they are alone. Rather, they are more likely to advocate collectively for change if they believe they are one of many similarly minded people.
Likewise, in the natural world, when molecules are arranged in an optimal configuration, they can collectively ""snowball,"" accelerating a chemical transformation. This phenomenon is known as a cooperative transition.
The idea for the study arose five years ago when the Breslauer brothers were strolling near Lincoln Center in Manhattan. George mentioned that his latest work had just been published. Kenneth asked George about the theme of his research that shaped the publications.
""He told me it was proposing what features allow certain social institutions to maintain stability for extended periods of time, a characteristic that can be referred to as 'longitudinal persistence,'"" Kenneth said. ""George went on to identify about five characteristics that were necessary. I stopped him at that point and said, 'George, you just described features that are completely analogous to what provides molecules with their stability.'""
Kenneth then realized that the microscopic molecular world he studied exhibited many analogous core features with the macroscopic societal world that his brother studied, particularly in terms of the features that allow systems to form, adapt and persist, or rise and fall like the Roman Empire.
""One can think of a central government as the central nucleus of the cell,"" Kenneth said. ""Imagine regional governments as the embedded mitochondria and other specialized organelles. Carrying the analogy further, a country's borders are analogous to the cell membrane.""
Kenneth added; ""There are so many parallels between nature and society. Identifying and examining such structural, organizational and functional analogues yields a wealth of information that is just waiting to be mined.""

","score: 15.422279792746114, grade_level: '15'","score: 16.374352877011177, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/pnasnexus/pgad401,"A biophysical chemist and a political scientist team up to explore striking parallels between the requisites of “stability” and the causes of instability within both the cellular/molecular world of biophysical chemistry and the world of social and political organization of self-assembled, societal structures, such as sovereign states and institutions. The structure, function, and organizational similarities of such parallelisms are particularly noteworthy, given that human agency introduces greater contingency in the sociopolitical world than do the “laws of Nature” in the natural-scientific world. In this perspective piece, we critically identify and analyze these parallels between the natural and the social realms through the prism of the shared concept of stability, including causal factors that embrace the full “stability spectrum” from instability to stability. This spectrum includes the crucial bridging, time-dependent, intermediate, kinetic state of “metastability.” Our analyses reveal that, in the microscopic/molecular world of the physical sciences, the thermodynamic and kinetic characterizations of the stabilities and transformations between physiochemical “states” exhibit cognate properties and features in the macroscopic world of sociopolitical arenas in ways that reflect a greater than traditionally assumed continuity between Nature and society. Select examples from the natural and social realms are presented and elaborated on to illustrate these parallelisms, while underscoring the striking similarities in their functional consequences."
"
In nature, organic molecules are either left- or right-handed, but synthesizing molecules with a specific ""handedness"" in a lab is hard to do. Make a drug or enzyme with the wrong ""handedness,"" and it just won't work. Now chemists at the University of California, Davis, are getting closer to mimicking nature's chemical efficiency through computational modeling and physical experimentation.

In a study appearing Jan. 10 in Nature, Professor Dean Tantillo, graduate students William DeSnoo and Croix Laconsay, and colleagues at the Max Planck Institute in Germany report the successful synthesis of specific chiral, or ""handed,"" molecules using rearrangements of simple hydrocarbons in the presence of complex organic catalysts. Most biological compounds, including many prescription drugs, are chiral.
Tantillo and colleagues hope the findings will enable scientists to better harness hydrocarbons for a variety of purposes, such as precursors to medicines and materials.
""The novelty of this paper is that this is really the first time, to my knowledge, that someone has been able to get a carbocation shift that makes one of the mirror image products rather than the other with high selectivity,"" Tantillo said.
Little balls of grease
In chemistry, chirality is a property that refers to a pair of molecules that share atomic makeup but are mirror images of each other. Like your left and right hands, they can't be superimposed on each other.
""Synthetic chemists often want to make molecules that come in mirror image forms, but they only want one of them,"" Tantillo said. ""For example, if you want to make a drug molecule, often you need one of the two chiral forms to bind selectively to a protein or enzyme target.""
Achieving this can be difficult in a lab setting because such molecules, according to Tantillo, are often like ""little balls of grease with some positive charge smeared around them.""

The greasy-like nature of these molecules typically makes binding by a chemical catalyst in one orientation over another difficult due to the lack of charged groups for the catalyst to grab on to.
But the researchers found a solution. Using a chiral organic acid, imidodiphosphorimidate, as a catalyst, the team successfully performed rearrangements of achiral alkenyl cycloalkanes, producing chiral molecules of interest called cycloalkenes. Using computational methods, Tantillo and colleagues deduced how the catalyst selectively produces one chiral form over the other.
Similarities to nature
Tantillo said that the resulting reaction is similar to how enzymes that make hydrocarbon products called terpenes behave in nature. Part of Tantillo's research concerns mapping terpene reaction pathways using quantum mechanical methods.
""If there are multiple possible pathways to a product, then every time you stop at an intermediate on that pathway, you have the possibility to get byproducts that come from that intermediate,"" he said. ""So it is important to know when and why a carbocation wants to stop en route to a given terpene if one wants to understand and ultimately re-engineer terpene-forming enzymes.""
The new method published in Naturecould in principle be harnessed to produce both natural molecules and nonnatural molecules.
""Whether these things will ever be done is hard to say, but petroleum is a source of a lot of hydrocarbons, and if you could catalytically turn those into molecules with defined chirality, you've increased the value of those molecules,"" Tantillo said.
The work was supported in part by the Max Planck Society, the Deutsche Forschungsgemeinschaft and the European Research Council, and the U.S. National Science Foundation.

","score: 15.101151843976833, grade_level: '15'","score: 15.559348192682748, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06826-7,"Asymmetric catalysis is an advanced area of chemical synthesis, but the handling of abundantly available, purely aliphatic hydrocarbons has proven to be challenging. Typically, heteroatoms or aromatic substructures are required in the substrates and reagents to facilitate an efficient interaction with the chiral catalyst. Confined acids have recently been introduced as tools for homogenous asymmetric catalysis, specifically to enable the processing of small unbiased substrates1. However, asymmetric reactions in which both substrate and product are purely aliphatic hydrocarbons have not previously been catalysed by such super strong and confined acids. We describe here an imidodiphosphorimidate-catalysed asymmetric Wagner–Meerwein shift of aliphatic alkenyl cycloalkanes to cycloalkenes with excellent regio- and enantioselectivity. Despite their long history and high relevance for chemical synthesis and biosynthesis, Wagner–Meerwein reactions utilizing purely aliphatic hydrocarbons, such as those originally reported by Wagner and Meerwein, had previously eluded asymmetric catalysis."
"
Researchers from the University of Birmingham, U.K., are working on Repoint, a new cutting-edge railway switch (points) technology to improve upon the traditional design, which has been in use for over 200 years.

While conventional railway switches guide trains from one track to another by sliding a pair of tapering rails horizontally, the new design, which is called Repoint, uses a lift and move mechanism, which includes a passive lock for when the points are in place. This is combined with a stub-switch type layout, which offers advantages in many situations. Importantly, the switch is 'fault-tolerant', continuing to work even when two of the three actuators, which control the movement of the points, have failed.
Research published today by the team (now at University of Birmingham, Leeds, Loughborough, and Network Rail) describes the team's development of a digital twin (dynamic simulation model) which has been used to show that the design meets and exceeds requirements for speed and performance.
The research investigated the performance of the switch using a novel method for simulating track system behaviour, which combines rail bending with physics-based models of actuators and control systems. The simulation scenarios included one of power failure to four of the six motors that drive the actuators, and showed that a single actuator is capable lifting and moving the points to the desired position.
Repoint was developed by Professor Roger Dixon, who led a team at Loughborough University until 2018, and is now Professor of Control Systems Engineering at the Birmingham Centre for Railway Research and Education (BRCCE).
The journey to a new railway switch started when Roger, then Head of Loughborough's Control Systems Research Group, responded to a joint call from the Engineering and Physics Research Council (EPSRC) and the UK Rail Safety and Standards Board (RSSB) to look at ways of improving capacity on existing lines. It was clear that one significant limiting factor to growing capacity was the railway track switch, and so a project to re-imagine the switch was proposed and subsequently funded (having ranked 1st in the peer review for the call).
Professor Dixon commented: ""Although switches account for less than 5% of railway track miles, they contribute to 18% of delay minutes, and 17.5% of delay costs in the UK.""
The team engaged with operators, maintainers and designers to understand the limits and issues with existing switch technology.

One of the most significant findings was the 'single point of failure' that is embedded in the traditional switches and their detection systems, so the new switch incorporates fault-tolerant design.
Inspired by aircraft control systems, the team designed a switch that remains operational even when two (out of three) components fail.
Professor Dixon said: ""While railway networks continue to carry more passengers and freight, building new track is always difficult and expensive, and increasing the reliability and exploiting the capacity of existing routes is generally the preferred option.""
Repoint actuation is at Technology Readiness Level (TRL) 4-5. It has been successfully tested at a test track, which demonstrated its compatibility and functionality with conventional switch rail arrangements. The researchers are now seeking partners and funding to design and fully test the full repoint system including the actuators, p-way and interfaces to signaling.

","score: 15.935555555555556, grade_level: '16'","score: 18.36727777777778, grade_levels: ['college_graduate'], ages: [24, 100]",10.1007/s40534-023-00324-2,"The main contribution of this paper is the development and demonstration of a novel methodology that can be followed to develop a simulation twin of a railway track switch system to test the functionality in a digital environment. This is important because, globally, railway track switches are used to allow trains to change routes; they are a key part of all railway networks. However, because track switches are single points of failure and safety-critical, their inability to operate correctly can cause significant delays and concomitant costs. In order to better understand the dynamic behaviour of switches during operation, this paper has developed a full simulation twin of a complete track switch system. The approach fuses finite element for the rail bending and motion, with physics-based models of the electromechanical actuator system and the control system. Hence, it provides researchers and engineers the opportunity to explore and understand the design space around the dynamic operation of new switches and switch machines before they are built. This is useful for looking at the modification or monitoring of existing switches, and it becomes even more important when new switch concepts are being considered and evaluated. The simulation is capable of running in real time or faster meaning designs can be iterated and checked interactively. The paper describes the modelling approach, demonstrates the methodology by developing the system model for a novel “REPOINT” switch system, and evaluates the system level performance against the dynamic performance requirements for the switch. In the context of that case study, it is found that the proposed new actuation system as designed can meet (and exceed) the system performance requirements, and that the fault tolerance built into the actuation ensures continued operation after a single actuator failure."
"
Free charge carriers in perovskite solar cells likely have a special form of protection from recombination, researchers at Forschungszentrum Jülich have discovered by means of innovative photoluminescence measurements.

Highly efficient and relatively inexpensive to produce -- perovskite solar cells have been the subject of repeated surprises in recent years. Scientists at Forschungszentrum Jülich have now discovered another special feature of the cells using a new photoluminescence measurement technique. They found that the loss of charge carriers in this type of cell follows different physical laws than those known for most semiconductors. This may be one of the main reasons for their high level of efficiency. The results were presented in the journal Nature Materials.
Perovskite solar cells are regarded as highly promising for photovoltaics, even if their stability leaves much to be desired. Cells of this type are inexpensive to print and very efficient. In the last decade, their efficiency has doubled to over 25 % and is therefore currently on a par with conventional solar cells made of silicon. Further improvements also appear to be possible in the future.
""An important factor here is the question of how long excited charge carriers remain in the material, in other words their lifetime,"" explains Thomas Kirchartz. ""Understanding the processes is crucial to further improving the efficiency of perovskite-based solar cells."" The electrical engineer is the head of a working group on organic and hybrid solar cells at Forschungszentrum Jülich's Institute of Energy and Climate Research (IEK-5).
It's the lifetime that counts
In a solar cell, electrons are dislodged by photons and raised to a higher energy level from the valence band to the conduction band. Only then can they move more freely and flow through an external circuit. They can only contribute to electrical energy generation if their lifetime is long enough for them to pass through the absorber material to the electrical contact. An excited electron also leaves a hole in the underlying valence band -- a mobile vacancy that can be moved through the material like a positive charge carrier.
It is mainly defects in the crystal lattice which ensure that excited electrons quickly fall back down to lower energy levels again. The electrons affected are then no longer able to contribute to the current flow. ""This mechanism is also known as recombination and is the main loss process of every solar cell,"" says Kirchartz.

Recombination crucial for efficiency
No solar cell is perfect on an atomic level; each one has different types of defects due to the manufacturing process. These defects or foreign atoms in the lattice structure are the collection points where electrons and holes tend to come together. The electrons then fall back into the valence band and become worthless in terms of electricity generation.
""It had previously been assumed that recombination is predominantly triggered by defects that are energetically located in the middle between the valence and conduction bands. This is because these deep defects are similarly accessible to excited electrons and their counterparts, the holes,"" says Kirchartz. Indeed, this is likely true for most types of solar cells.
Shallow defects dominate
However, Kirchartz and his team have now disproved this assumption for perovskite solar cells and shown that the shallow defects are ultimately decisive in terms of their final efficiency. Unlike the deep defects, they are not located in the middle of the band gap, but very close to the valence or conduction band.
""The cause of this unusual behavior has not yet been fully clarified,"" Kirchartz adds. ""It is reasonable to assume that deep defects simply cannot exist in these materials. This restriction may also be one of the reasons for the particularly high efficiency of the cells.""
New HDR measurement technique with extended dynamic range
The observation was only made possible by innovative transient photoluminescence measurements. In previous measurements, it was not possible to distinguish loss processes caused by shallow defects from those caused by other factors.
The new measuring method developed by Thomas Kirchartz and his team at Forschungszentrum Jülich delivers data with a significantly increased dynamic range compared to conventional technology, i.e. data over a larger measuring range and with better fine gradation. The process is based on a similar principle to HDR image in high dynamic range quality. The dynamic range of the camera is increased by superimposing different images or measurements -- in this case signals with different levels of amplification -- to create a data set.

","score: 12.852589969648793, grade_level: '13'","score: 13.285969070674959, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41563-023-01771-2,"Quantifying recombination in halide perovskites is a crucial prerequisite to control and improve the performance of perovskite-based solar cells. While both steady-state and transient photoluminescence are frequently used to assess recombination in perovskite absorbers, quantitative analyses within a consistent model are seldom reported. We use transient photoluminescence measurements with a large dynamic range of more than ten orders of magnitude on triple-cation perovskite films showing long-lived photoluminescence transients featuring continuously changing decay times that range from tens of nanoseconds to hundreds of microseconds. We quantitatively explain both the transient and steady-state photoluminescence with the presence of a high density of shallow defects and consequent high rates of charge carrier trapping, thereby showing that deep defects do not affect the recombination dynamics. The complex carrier kinetics caused by emission and recombination processes via shallow defects imply that the reporting of only single lifetime values, as is routinely done in the literature, is meaningless for such materials. We show that the features indicative for shallow defects seen in the bare films remain dominant in finished devices and are therefore also crucial to understanding the performance of perovskite solar cells."
"
From ""Law and Order"" to ""CSI,"" not to mention real life, investigators have used fingerprints as the gold standard for linking criminals to a crime. But if a perpetrator leaves prints from different fingers in two different crime scenes, these scenes are very difficult to link, and the trace can go cold.

It's a well-accepted fact in the forensics community that fingerprints of different fingers of the same person -- ""intra-person fingerprints"" -- are unique, and therefore unmatchable.
Research led by Columbia Engineering undergraduate
A team led by Columbia Engineering undergraduate senior Gabe Guo challenged this widely held presumption. Guo, who had no prior knowledge of forensics, found a public U.S. government database of some 60,000 fingerprints and fed them in pairs into an artificial intelligence-based system known as a deep contrastive network. Sometimes the pairs belonged to the same person (but different fingers), and sometimes they belonged to different people.
AI has potential to greatly improve forensic accuracy 
Over time, the AI system, which the team designed by modifying a state-of-the-art framework, got better at telling when seemingly unique fingerprints belonged to the same person and when they didn't. The accuracy for a single pair reached 77%. When multiple pairs were presented, the accuracy shot significantly higher, potentially increasing current forensic efficiency by more than tenfold. The project, a collaboration between Hod Lipson's Creative Machines lab at Columbia Engineering and Wenyao Xu's Embedded Sensors and Computing lab at University at Buffalo, SUNY, was published today in Science Advances.
Study findings challenge-and surprise-forensics community
Once the team verified their results, they quickly sent the findings to a well-established forensics journal, only to receive a rejection a few months later. The anonymous expert reviewer and editor concluded that ""It is well known that every fingerprint is unique,"" and therefore it would not be possible to detect similarities even if the fingerprints came from the same person.

The team did not give up. They doubled down on the lead, fed their AI system even more data, and the system kept improving. Aware of the forensics community's skepticism, the team opted to submit their manuscript to a more general audience. The paper was rejected again, but Lipson, who is the James and Sally Scapa Professor of Innovation in the Department of Mechanical Engineering and co-director of the Makerspace Facility, appealed. ""I don't normally argue editorial decisions, but this finding was too important to ignore,"" he said. ""If this information tips the balance, then I imagine that cold cases could be revived, and even that innocent people could be acquitted.""
While the system's accuracy is not sufficient to officially decide a case, it can help prioritize leads in ambiguous situations. After more back and forth, the paper was finally accepted for publication by Science Advances.
Unveiled: a new kind of forensic marker to precisely capture fingerprints
One of the sticking points was the following question: What alternative information was the AI actually using that has evaded decades of forensic analysis? After careful visualizations of the AI system's decision process, the team concluded that the AI was using a new kind of forensic marker.
""The AI was not using 'minutiae,' which are the branchings and endpoints in fingerprint ridges -- the patterns used in traditional fingerprint comparison,"" said Guo, who began the study as a first-year student at Columbia Engineering in 2021. ""Instead, it was using something else, related to the angles and curvatures of the swirls and loops in the center of the fingerprint.""
Columbia Engineering senior Aniv Ray and PhD student Judah Goldfeder, who helped analyze the data, noted that their results are just the beginning. ""Just imagine how well this will perform once it's trained on millions, instead of thousands of fingerprints,"" said Ray.

VIDEO: https://youtu.be/s5esfRbBc18 
A need for broader datasets 
The team is aware of potential biases in the data. The authors present evidence that indicates that the AI performs similarly across genders and races, where samples were available. However, they note, more careful validation needs to be done using datasets with broader coverage if this technique is to be used in practice.
Transformative potential of AI in a well-established field
This discovery is an example of more surprising things to come from AI, notes Lipson, . ""Many people think that AI cannot really make new discoveries-that it just regurgitates knowledge,"" he said. ""But this research is an example of how even a fairly simple AI, given a fairly plain dataset that the research community has had lying around for years, can provide insights that have eluded experts for decades.""
He added, ""Even more exciting is the fact that an undergraduate student, with no background in forensics whatsoever, can use AI to successfully challenge a widely held belief of an entire field. We are about to experience an explosion of AI-led scientific discovery by non-experts, and the expert community, including academia, needs to get ready.""

","score: 14.375299746692935, grade_level: '14'","score: 15.090194202082749, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adi0329,"Fingerprint biometrics are integral to digital authentication and forensic science. However, they are based on the unproven assumption that no two fingerprints, even from different fingers of the same person, are alike. This renders them useless in scenarios where the presented fingerprints are from different fingers than those on record. Contrary to this prevailing assumption, we show above 99.99% confidence that fingerprints from different fingers of the same person share very strong similarities. Using deep twin neural networks to extract fingerprint representation vectors, we find that these similarities hold across all pairs of fingers within the same person, even when controlling for spurious factors like sensor modality. We also find evidence that ridge orientation, especially near the fingerprint center, explains a substantial part of this similarity, whereas minutiae used in traditional methods are almost nonpredictive. Our experiments suggest that, in some situations, this relationship can increase forensic investigation efficiency by almost two orders of magnitude."
"
Researchers at Stockholm University have for the first time been able to study the surface of iron and ruthenium catalysts when ammonia is formed from nitrogen and hydrogen; the results are published in the scientific journal Nature. A better knowledge of the catalytic process and the possibility of finding even more efficient materials opens the door for a green transition in the currently very CO2-intensive chemical industry.

Ammonia, produced in the Haber-Bosch process, is currently one of the most essential base chemicals for the world to produce fertilizers, with an annual production of 110 million tones. The journal Nature proposed in 2001 that the Haber-Bosch process was the most critical scientific invention for humankind during the 20th century, since it has saved around 4 billion people's lives by preventing mass starvation. An estimation of the nitrogen content in our bodies' DNA and proteins shows that half of the atoms can be derived from Haber-Bosch.
""In spite of 3 Nobel Prizes (1918, 1931, and 2007) for the Haber-Bosch process, it has not been possible to experimentally investigate the catalyst surface with surface-sensitive methods under real ammonia production conditions; experimental techniques with surface sensitivity at high enough pressures and temperatures had not been achievable. Consequently, different hypotheses about the state of the iron catalyst as being metallic or in a nitride, as well as the nature of the intermediate species of importance to the reaction mechanism, could not be unambiguously verified,"" says Anders Nilsson, professor of Chemical Physics at Stockholm University.
""What enabled this study is that we have built a photoelectron spectroscopy instrument in Stockholm that allows studies of catalyst surfaces under high pressures. Thereby, we have been able to observe what happens when the reaction occurs directly,"" says David Degerman, Postdoc in Chemical Physics at Stockholm University. ""We have opened a new door into understanding ammonia production catalysis with our new instrument where we now can detect reaction intermediates and provide evidence for the reaction mechanism.""
""To have our Stockholm instrument at one of the brightest x-ray sources in the world at PETRA III in Hamburg has been crucial to conduct the study,"" says Patrick Lömker, Researcher at Stockholm University. ""We can now imagine the future with even brighter sources when the machine upgrades to PETRA IV.""
""We now have the tools to conduct research leading to new catalyst materials for ammonia production that can be used better to fit together with electrolysis-produced hydrogen for the green transition of the chemical industry,"" says Anders Nilsson.
""It is inspiring to conduct research on a topic that is so linked to a scientific success story that has helped humanity tremendously. I am eager to continue research to find new catalysts that can lessen our dependence on fossil sources. The chemical industry alone accounts for 8% of the world-wide CO2 emissions,"" says Bernadette Davies, PhD student in Materials Chemistry at Stockholm University.
""The long-term prospect of carrying out ammonia production through an electrocatalytic alternative that is directly driven by solar, or wind electricity is most appealing, and now we have tools to scientifically assist in this development,"" says Sergey Koroidov, Researcher at Stockholm University.
The study was conducted in collaboration with Deutsches Elektronen-Synchrotron (DESY) in Hamburg and the Montan University in Austria. The study included former employees at the University, Chris Goodwin, Peter Amann, Mikhail Shiplin, Jette Mathiesen and Gabriel Rodrigez.

","score: 17.17052173913044, grade_level: '17'","score: 18.832500686498854, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06844-5,"The large-scale conversion of N2 and H2 into NH3 (refs. 1,2) over Fe and Ru catalysts3 for fertilizer production occurs through the Haber–Bosch process, which has been considered the most important scientific invention of the twentieth century4. The active component of the catalyst enabling the conversion was variously considered to be the oxide5, nitride2, metallic phase or surface nitride6, and the rate-limiting step has been associated with N2 dissociation7–9, reaction of the adsorbed nitrogen10 and also NH3 desorption11. This range of views reflects that the Haber–Bosch process operates at high temperatures and pressures, whereas surface-sensitive techniques that might differentiate between different mechanistic proposals require vacuum conditions. Mechanistic studies have accordingly long been limited to theoretical calculations12. Here we use X-ray photoelectron spectroscopy—capable of revealing the chemical state of catalytic surfaces and recently adapted to operando investigations13 of methanol14 and Fischer–Tropsch synthesis15—to determine the surface composition of Fe and Ru catalysts during NH3 production at pressures up to 1 bar and temperatures as high as 723 K. We find that, although flat and stepped Fe surfaces and Ru single-crystal surfaces all remain metallic, the latter are almost adsorbate free, whereas Fe catalysts retain a small amount of adsorbed N and develop at lower temperatures high amine (NHx) coverages on the stepped surfaces. These observations indicate that the rate-limiting step on Ru is always N2 dissociation. On Fe catalysts, by contrast and as predicted by theory16, hydrogenation of adsorbed N atoms is less efficient to the extent that the rate-limiting step switches following temperature lowering from N2 dissociation to the hydrogenation of surface species."
"
Ions are everywhere, from our daily surroundings to the cosmic expanse. As common table salt (NaCl) dissolves into sodium (Na+) and chloride (Cl-) ions in water, it imparts a salty taste. Once absorbed by the body, these ions regulate nerve impulses and muscle movements. In the sun, plasma -- a gathering of ions in the gaseous state -- undergoes nuclear fusion reactions, transmitting light and energy to Earth. One of the most noteworthy usage ions in everyday life is found in lithium-ion batteries, which power devices like smartphones, laptops, and electric cars.

Consequently, ions play pivotal roles in various facets of our lives, and comprehending the intricate processes, structural attributes, and dynamics of ions remains crucial for advancements in science and technology. However, capturing the ephemeral moments of ion formation and the molecular structural transitions, especially in the challenging gas phase, has proven to be challenging due to experimental complexities.
Led by Director IHEE Hyotcherl, researchers at the Center for Advanced Reaction Dynamics (CARD) in the Institute for Basic Science (IBS) achieved real-time capture of the ionization process and subsequent structural changes in gas-phase molecules through an enhanced megaelectronvolt ultrafast electron diffraction (MeV-UED) technique, enabling observation of faster and finer movements of ions.
Director Ihee's team had a long history of achieving groundbreaking milestones in molecular dynamics, such as the rupture of molecular bonds (Science, 2005), the initiation of molecular birth through chemical bonding (Nature, 2015), and the in-depth exploration of molecular structures at the atomic level across the entirety of a chemical reaction (Nature, 2020). Now for the first time, they successfully conducted real-time observations of the formation and structural evolution of gas-phase ions.
To achieve this objective, the team focused on cations of 1,3-dibromopropane (DBP). Experimental data unveiled a fascinating phenomenon -- the cation persisted in a structurally stable state termed the 'dark state' for approximately 3.6 picoseconds (1 picosecond equals one trillionth of a second) following its formation. Subsequently, the cation underwent a transformation into an unusual intermediate with a ring structure encompassing four atoms, including a loosely bound bromine atom. Eventually, the loosely attached bromine atom disengaged, giving rise to a bromonium ion characterized by a ring structure comprising three atoms.
Given the high reactivity of ions, observing their existence has posed a longstanding significant challenge. The success of this research hinged on the incorporation of a newly devised signal processing technology and a modeling analysis technique for structural changes. Another important element was the application of the resonance-enhanced multiphoton ionization (REMPI) technique, which facilitated the mass production of specific ions while preventing random dissociation of compounds. The experimental findings indicated that the generated gas ions maintained a specific form before undergoing sudden transformations, which allowed the IBS team to ultimately elucidate the formation of chemically stable, ring-shaped molecules.
Then, by leveraging the innovative megaelectronvolt ultrafast electron diffraction (MeV-UED) technique, the research team achieved a precise capture of subtle structural changes in ions within the gas phase. This cutting-edge technology offered high-resolution spatial and temporal resolution required for the needs of this research, and it enabled the meticulous tracking of the entire process from the moment of ion generation to subsequent structural transformations.

Being the first to achieve real-time observation of structural changes in selectively generated ions, this study is hailed as a substantial breakthrough in ion chemistry research. This research represents a groundbreaking achievement in the scientific community, marking the inaugural instance of real-time observation of the structural dynamics of molecular ions.
By advancing our understanding of ions in the gas phase, this research yields fresh perspectives across diverse fields, including the mechanisms of chemical reactions, alterations in material properties, and the realm of astrochemistry. The anticipated impact extends well beyond ion chemistry, influencing various scientific and technological disciplines.
Dr. HEO Jun, the primary author, emphasized, ""This discovery represents a pivotal advancement in our fundamental comprehension of ion chemistry, poised to profoundly influence the design of diverse chemical reactions and future exploration in astrochemistry.""
KIM Doyeong, the first author and a student, shared his aspirations, stating, ""Contributing to a study with the potential to lay the groundwork for advancements in basic science is truly gratifying. I am committed to persistent research efforts to evolve into a proficient scientist.""
Professor IHEE Hyotcherl reflected, ""Despite the remarkable strides in science and technology, numerous captivating mysteries remain in the material world. This research, though unveiling just one more enigma of ions previously undiscovered, underscores the profound secrets awaiting our exploration."" He further remarked, ""The support from the Institute for Basic Science has played a crucial role in achieving this modest yet meaningful milestone. We anticipate sustained, effective backing for R&D budgets in the future.""

","score: 17.364455233706384, grade_level: '17'","score: 18.988541392363395, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06909-5,"Molecular ions are ubiquitous and play pivotal roles1–3 in many reactions, particularly in the context of atmospheric and interstellar chemistry4–6. However, their structures and conformational transitions7,8, particularly in the gas phase, are less explored than those of neutral molecules owing to experimental difficulties. A case in point is the halonium ions9–11, whose highly reactive nature and ring strain make them short-lived intermediates that are readily attacked even by weak nucleophiles and thus challenging to isolate or capture before they undergo further reaction. Here we show that mega-electronvolt ultrafast electron diffraction (MeV-UED)12–14, used in conjunction with resonance-enhanced multiphoton ionization, can monitor the formation of 1,3-dibromopropane (DBP) cations and their subsequent structural dynamics forming a halonium ion. We find that the DBP+ cation remains for a substantial duration of 3.6 ps in aptly named ‘dark states’ that are structurally indistinguishable from the DBP electronic ground state. The structural data, supported by surface-hopping simulations15 and ab initio calculations16, reveal that the cation subsequently decays to iso-DBP+, an unusual intermediate with a four-membered ring containing a loosely bound17,18 bromine atom, and eventually loses the bromine atom and forms a bromonium ion with a three-membered-ring structure19. We anticipate that the approach used here can also be applied to examine the structural dynamics of other molecular ions and thereby deepen our understanding of ion chemistry."
"
Like the Greek mythological beast with a snake's tail and two ferocious heads, a potential Parkinson's medicine created in the lab of chemist Matthew Disney, Ph.D., is also a type of chimera bearing two heads. One seeks out a key piece of Parkinson's-causing RNA, while the other goads the cell to chop it to pieces for recycling.

The research is described in the Jan. 9 issue of the Proceedings of the National Academy of Sciences, or PNAS.
Parkinson's is a frustrating and all too common disease. Slowly, people with Parkinson's lose brain cells and other neurons needed to make the neurotransmitter dopamine. This progressive loss leads them to develop rigid, tense muscles and tremors, and causes difficulties with sleep, mood, speech, eating and movement.
Commonly used treatments include drugs that replace the dopamine. Other treatments, such as deep-brain stimulation, help with movement problems that develop as the disease worsens. But while these types of treatments alleviate symptoms, they are not a cure, come with side effects and do not change the trajectory of the disease. An estimated 500,000 people in the United States live with Parkinson's.
""To change the course of this disease, we need to address its cause. For many Parkinson's patients, that apparent cause is the accumulation of a toxic protein called alpha-synuclein, in and around their neurons,"" said Disney, the endowed Institute Professor and chair of the chemistry department at The Herbert Wertheim UF Scripps Institute for Biomedical Innovation & Technology in Jupiter, Florida.
Unfortunately, alpha-synuclein has proven an especially challenging protein to medicate due to its unruly, disorganized form and lack of clear druggable structures, Disney added.
""In situations like this, we have found that targeting the RNA needed to build the toxic protein may be an optimal strategy to slowing or even stopping disease progression,"" he added.

Disney's lab focuses on interfering with or degrading RNA needed to assemble the proteins implicated in disease. This is a relatively new concept. Most drugs on the market work by binding to proteins to change their function. But not all disease-causing proteins can be successfully targeted with drugs. Some are too changeable, some lack druggable structures, some fold in a way that conceals their active sites.
Disney's approach is to prevent the problematic proteins from being made in the first place. To do that requires targeting their RNA. Here's why: Proteins are assembled in cells through a process that involves the reading and translation of a gene, the transport of that information from the cell nucleus to its cytoplasm via messenger RNA, and the assembly of protein-building factories called ribosomes, also built of RNA, in the cytoplasm. The ribosomes stitch the proteins together one amino acid at a time. Disney's potential Parkinson's drug, which he calls Syn-RiboTAC, binds to a section of messenger RNA that tells a ribosome to start protein assembly. Without the ""start"" signal, the toxic protein isn't built.
Disney's first authors on the PNAS study were graduate students in his lab. Yuquan Tong is a current student of the Skaggs Graduate School of Chemical and Biological Sciences on the Jupiter, Florida campus, and Peiyuan Zhang, Ph.D., is a recent graduate, now a postdoctoral researcher at the Massachusetts Institute of Technology.
""In Parkinson's mouse models, we see that reducing alpha-synuclein by even 25% is therapeutically beneficial,"" Tong said. ""In studies from induced neurons of Parkinson's patients, we see the Syn-RiboTAC strategy reduces alpha-synuclein production by about 50%. We saw that adding the RiboTAC produces a significant gain in potency.""
Disney added that the compound also showed good selectivity, important for avoiding unwanted side effects, and improved brain-barrier penetration relative to other compounds they studied.
Other collaborators on the study included physician-scientist M. Maral Mouradian, M.D., of Rutgers University, whose patients donated tissue to create induced neurons.
Much work lies ahead, as the team works to refine the two-headed drug and improve its drug-like properties, the scientists said. Preparing an experimental compound for clinical trials in humans can sometimes take years, as refinements are made and data are gathered.
""The medical need for a truly disease-modifying treatment is significant, and we know that patients are awaiting better options,"" Disney said. ""We're hopeful that we're on the road to a better days for people living with Parkinson's.""

","score: 12.114639846743298, grade_level: '12'","score: 13.157430651340995, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2306682120,"α-Synuclein is an important drug target for the treatment of Parkinson’s disease (PD), but it is an intrinsically disordered protein lacking typical small-molecule binding pockets. In contrast, the encoding SNCA mRNA has regions of ordered structure in its 5′ untranslated region (UTR). Here, we present an integrated approach to identify small molecules that bind this structured region and inhibit α-synuclein translation. A drug-like, RNA-focused compound collection was studied for binding to the 5′ UTR of SNCA mRNA, affording Synucleozid-2.0, a drug-like small molecule that decreases α-synuclein levels by inhibiting ribosomes from assembling onto SNCA mRNA. This RNA-binding small molecule was converted into a ribonuclease-targeting chimera (RiboTAC) to degrade cellular SNCA mRNA. RNA-seq and proteomics studies demonstrated that the RiboTAC (Syn-RiboTAC) selectively degraded SNCA mRNA to reduce its protein levels, affording a fivefold enhancement of cytoprotective effects as compared to Synucleozid-2.0. As observed in many diseases, transcriptome-wide changes in RNA expression are observed in PD. Syn-RiboTAC also rescued the expression of ~50% of genes that were abnormally expressed in dopaminergic neurons differentiated from PD patient–derived iPSCs. These studies demonstrate that the druggability of the proteome can be expanded greatly by targeting the encoding mRNAs with both small molecule binders and RiboTAC degraders."
"
Researchers at the U.S. Department of Energy's Princeton Plasma Physics Laboratory (PPPL) have developed a new theoretical model explaining one way to make black silicon. The new etching model precisely explains how fluorine gas breaks certain bonds in the silicon more often than others, depending on the orientation of the bond at the surface. Black silicon is an important material used in solar cells, light sensors, antibacterial surfaces and many other applications.

Black silicon is made when the surface of regular silicon is etched to produce tiny nanoscale pits on the surface. These pits change the color of the silicon from gray to black and, critically, trap more light, an essential feature of efficient solar cells.
While there are many ways to make black silicon, including some that use the charged, fourth state of matter known as plasma, the new model focuses on a process that uses only fluorine gas. PPPL Postdoctoral Research Associate Yuri Barsukov said the choice to focus on fluorine was intentional: the team at PPPL wanted to fill a gap in publicly available research. While some papers have been published about the role of charged particles called ions in the production of black silicon, not much has been published about the role of neutral substances, such as fluorine gas.
""We now know -- with great specificity -- the mechanisms that cause these pits to form when fluorine gas is used,"" said Barsukov, one of the authors of a new paper about the work. ""This kind of information, published publicly and openly available, benefits us all, whether we pursue further knowledge into the basic knowledge that underlines such processes or we seek to improve manufacturing processes.""
Model reveals bonds break based on atom orientation at the surface
The new etching model precisely explains how fluorine gas breaks certain bonds in the silicon more often than others, depending on the orientation of the bond at the surface. As silicon is a crystalline material, atoms bond in a rigid pattern. These bonds can be characterized based on the way they are oriented in the pattern, with each type of orientation, or plane, identified by a bracketed number, such as (100), (110) or (111).
""If you etch silicon using fluorine gas, the etching proceeds along (100) and (110) crystal planes but does not etch (111), resulting in a rough surface after the etching,"" explained Barsukov. As the gas etches away at the silicon unevenly, pits are created on the surface of the silicon. The rougher the surface, the more light it can absorb, making rough black silicon ideal for solar cells. Smooth silicon, in contrast, is an ideal surface for creating the atomic-scale patterns necessary for computer chips.
""If you want to etch silicon while leaving a smooth surface, you should use another reactant than fluorine. It should be a reactant that etches uniformly all crystalline planes,"" Barsukov said.

","score: 13.311069958847739, grade_level: '13'","score: 14.289226770630279, grade_levels: ['college_graduate'], ages: [24, 100]",10.1116/6.0002841,"Anisotropic etching is a widely used process in semiconductor manufacturing, in particular, for micro- and nanoscale texturing of silicon surfaces for black silicon production. The typical process of plasma-assisted etching uses energetic ions to remove materials in the vertical direction, creating anisotropic etch profiles. Plasmaless anisotropic etching, considered here, is a less common process that does not use ions and plasma. The anisotropy is caused by the unequal etching rates of different crystal planes; the etching process, thus, proceeds in a preferred direction. In this paper, we have performed quantum chemistry modeling of gas-surface reactions involved in the etching of silicon surfaces by molecular fluorine. The results confirm that orientation-dependent etch rates are the reason for anisotropy. The modeling of F2 dissociative chemisorption on F-terminated silicon surfaces shows that Si–Si bond breaking is slow for the Si(111) surface, while it is fast for Si(100) and Si(110) surfaces. Both Si(100) and Si(110) surfaces incorporate a larger number of fluorine atoms resulting in Si–Si bonds having a larger amount of positive charge, which lowers the reaction barrier of F2 dissociative chemisorption, yielding a higher etch rate for Si(100) and Si(110) surfaces compared to Si(111) surfaces. Molecular dynamics modeling of the same reactions has shown that the chosen reactive bond order potential does not accurately reproduce the lower reaction barriers for F2 dissociative chemisorption on Si(100) and Si(100) surfaces. Thus, reparameterization is necessary to model the anisotropic etching process that occurs at lower temperatures."
"
UCLA-led research finds that scooter injuries nearly tripled across the U.S. from 2016 to 2020, with a concurrent increase in severe injuries requiring orthopedic and plastic surgery over the same period.

The study, which compared national trends in scooter and bicycle injuries during the period, also found that costs to treat those injuries rose five-fold, highlighting the financial strain these injuries pose to the healthcare system -- a finding that ""underscores a critical juncture for discerning the underlying causes of injuries and informing policies for injury prevention,"" the researchers note.
The study will be published January 9 in the peer-reviewed Journal of the American College of Surgeons.
""Considering the rise in the number of hospitalizations and major operations for scooter-related injuries, it's crucial to elevate safety standards for riders,"" said lead author Nam Yong Cho, a third-year medical student at UCLA and a research associate at the UCLA Cardiovascular Outcomes Research Laboratories. ""Advocating for improved infrastructure, including enforced speed limits and dedicated lanes, is also vital to minimize risks for vehicles, scooter riders, and pedestrians alike.""
The researchers used the 2016-2020 National Inpatient Sample, a database maintained by the Agency for Healthcare Research and Quality, to compare trends and outcomes for scooter-related and bicycle-related injuries. The database does not, however, differentiate between electric and non-electric scooters. Of nearly 93,000 patients who were hospitalized for injuries, about 6,100 (6.6%) resulted from scooter injuries.
Overall, about 27% of people in the scooter cohort were under age 18 compared with 16% for the bicycle group. In addition, injuries were most frequent in the winter months (24% vs 20%), patients were insured by Medicaid (27% vs 24%); and scooter injuries led to more major operative interventions (56% vs 48%), which mainly included orthopedic and plastic surgery (89% vs 85%) and operations to the head (5% vs 4%).
Scooter riders also had higher odds of experiencing long bone fractures and paralysis than their bicycle riding counterparts, though both groups were similarly likely to suffer traumatic brain injuries.

Finally, the annual healthcare burden of treating scooter-related injuries jumped from about $6.6 million in 2016 to $35.5 million in 2020. For bicycle injuries, the price tag increased from $307 million to $434 million.
The study has some limitations. They include a limited amount of granular data such as helmet use, presence of multiple riders on the vehicles, and use of intoxicants; and an inability to account for objects and other vehicles that might have been involved in the injury incidents, or to determine the kind of terrain where they happened, and speed, time of day and total distance traveled when they occurred. The researchers also could not ascertain the type of scooter or bicycle models involved in the injuries.
Still, the findings indicate a worrisome increase in patient injury, hospitalization and financial burden, the researchers note.
""The progressive exacerbation of injury severity in scooter-related incidents manifested in a substantial proportion of patients necessitating surgical intervention and potentially having long-term morbidity,"" the researchers write. ""Our findings are a call to action for healthcare leaders to empower themselves in promoting scooter-related injury prevention and greater safety in the community.""
Study co-authors are Shineui Kim, Dr. Zachary Tran, Dr. Joseph Hadaya; Konmal Ali, Elsa Kronen and Dr. Peyman Benharash of UCLA, and Dr. Sigrid Burruss of Loma Linda University Health. Tran is also affiliated with Loma Linda University Health.

","score: 16.58581352681178, grade_level: '17'","score: 17.703171545325667, grade_levels: ['college_graduate'], ages: [24, 100]",10.1097/XCS.0000000000000918,"In recent years, the adoption of electric scooters has been accompanied by a surge of scooter-related injuries in the US, raising concerns for their severity and associated healthcare costs. The present study aimed to assess temporal trends and outcomes of scooter-related hospital admissions compared to bicycle-related hospitalizations. This was a retrospective cohort study utilizing the 2016-2020 National Inpatient Sample for patients younger than 65 years old who were hospitalized following bicycle and scooter injuries. The Trauma Mortality Prediction Model (TMPM) was used to quantify injury severity. The primary outcome of interest was temporal trends of micromobility injuries. In-hospital mortality, rates of long bone fracture, traumatic brain injury (TBI), paralysis, length of stay, hospitalization costs, and non-home discharge were secondarily assessed. Among 92,815 patients included in the study, 6,125 (6.6%) were scooter injuries. Compared to those with bicycle injuries, patients with scooter injuries were more commonly younger than 18 years (26.7 vs 16.4%, P<0.001) and frequently underwent major operations (55.8 vs 48.1%, P<0.001). After risk adjustment, scooter injuries were associated with greater risks of long bone fracture (AOR 1.40, 95%CI 1.15-1.70) and paralysis (AOR 2.06, 95%CI 1.16-3.69) compared to bicycle injuries. Additionally, patients with bicycle or scooter injuries had comparable index hospitalization durations of stay and costs. The prevalence and severity of scooter-related injuries have significantly increased in the US, thereby attributing to a substantial cost burden on the healthcare system. Multidisciplinary efforts to inform safety policies and enact targeted interventions are warranted to reduce scooter-related injuries."
"
Transmitting an effect known as a domino reaction using redox chemistry has been achieved for the first time.

Domino reactions occur when the transformation of one chemical group stimulates the reaction of another attached group, or other molecule, leading to a rapid knock-on effect through the system like a row of falling dominoes. Researchers at Hokkaido University have now achieved the first example of a domino reaction in the branch of chemistry called redox chemistry.
The term redox comes from 'reduction,' referring to the gain of electrons, and 'oxidation,' referring to the loss of electrons. Redox reactions are therefore electron transfer processes.
""The problem with achieving domino reactions in redox processes is that the electron transfer, especially multi-electron transfer, produces electrically charged species whose electrostatic interactions can inhibit further change,"" says chemist Yusuke Ishigaki of the Hokkaido team.
To overcome the obstacles the researchers designed a two-part molecule that undergoes a significant structural change when one part is converted between its electrically neutral (reduced) and positively charged (oxidized) states. This structural change transmits a chemical effect to the other part of the molecule that makes its own oxidation more likely.
The molecule they designed consists of two relatively large redox-active units connected by a non-planar flexible link formed by sulfur atoms. When one of the paired units loses electrons (is oxidized), it acquires two positive charges which acts as the trigger causing the other part of the molecule to twist around the core. A change in the state of the electrons in this twisted form from the initial folded form then facilitates the oxidation process to occur in the neighboring group, achieving the domino effect.
The initial triggering of the reaction can be initiated by a temperature rise, offering a means of control. Although this effect has only so far been demonstrated within a two-part molecule, the researchers suggest it might eventually be used to transmit wave-like redox transformations in much larger molecules with many of the 'domino' units linked together.
Applications of the discovery might be far in the future but there are clearly some general possibilities. Electrical and structural transformations traveling through molecular chains could become the nano-scale moving parts of chemical computation systems and sensors, for example. There are also possible applications in the new battery systems needed to support the ongoing transition to renewable electrical energy technologies.
""The control offered by heating and cooling could be used in many fields to make novel materials with switchable electronic properties, especially those involving multi-electron transfer,"" says Ishigaki.
""It was very challenging, but also very satisfying, to demonstrate what nobody had achieved before, and we now hope to move into larger and more complex systems involving increased electron transfer,"" Ishigaki concludes.

","score: 16.54526443474042, grade_level: '17'","score: 17.423466763706934, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/anie.202316753,"The concept of a domino‐type reaction has been applied in a wide range of fields such as synthetic organic chemistry, material engineering, and life science. To extend the domino concept to redox chemistry, we designed and synthesized a dimeric quinodimethane (QD) with a nonplanar dithiin spacer. The domino‐redox properties can be activated by raising the temperature, based on a thermally equilibrated twisted conformation of QD, which has a higher HOMO level that is more readily oxidized. After one QD unit is oxidized (trigger), steric repulsion and electronic interaction between electrophores make the neighboring QD unit adopt a twisted conformation (domino process), which facilitates the following oxidation. Thus, a domino‐redox reaction was achieved for the first time by a change in the HOMO level due to a drastic change in the molecular conformation."
"
A study published today in IOP Publishing's journal Environmental Research: Infrastructure and Sustainability has found that green ammonia could be used to fulfil the fuel demands of over 60% of global shipping by targeting just the top 10 regional fuel ports. Researchers at the University of Oxford looked at the production costs of ammonia which are similar to very low sulphur fuels, and concluded that the fuel could be a viable option to help decarbonise international shipping by 2050.

Around USD 2 trillion will be needed to transition to a green ammonia fuel supply chain by 2050, primarily to finance supply infrastructure. The study shows that the greatest investment need is in Australia, to supply the Asian markets, with large production clusters also predicted in Chile (to supply South America), California (to supply Western U.S.A.), North-West Africa (to meet European demand), and the southern Arabian Peninsula (to meet local demand and parts of south Asia).
90% of world's physical goods trade is transported by ships which burn heavy fuel oil and emit toxic pollutants. This accounts for nearly 3% of the global greenhouse gas (GHG) emissions. As a result of this, the International Maritime Organization (IMO) committed to decarbonising international shipping in 2018, aiming to halve GHG emissions by 2050. These targets have been recently revised to net zero emissions by 2050.
After investigating the viability of diesel vessel exhaust scrubbers, green ammonia, made by electrolysing water with renewable electricity, was proposed as an alternative fuel source to quickly decarbonise the shipping industry. However, historically there has been great uncertainty as to how and where to invest to create the necessary infrastructure to deliver an efficient, viable fuel supply chain.
René Bañares-Alcántara, Professor of Chemical Engineering in the Department of Engineering Science at the University of Oxford, says: ""Shipping is one of the most challenging sectors to decarbonize because of the need for fuel with high energy density and the difficulty of coordinating different groups to produce, utilize and finance alternative (green) fuel supplies.""
To guide investors, the team at the University of Oxford developed a modelling framework to create viable scenarios for how to establish a global green ammonia fuel supply chain. The framework combines a fuel demand model, future trade scenarios and a spatial optimisation model for green ammonia production, storage, and transport, to find the best locations to meet future demand for shipping fuel.
Professor Bañares-Alcántara continues: ""The implications of this work are striking. Under the proposed model, current dependence upon oil-producing nations would be replaced by a more regionalised industry; green ammonia will be produced near the equator in countries with abundant land and high solar potential then transported to regional centres of shipping fuel demand.""

","score: 17.28480701754386, grade_level: '17'","score: 19.01394736842105, grade_levels: ['college_graduate'], ages: [24, 100]",10.1088/2634-4505/ad097a,"Green ammonia has been proposed as a technologically viable solution to decarbonise global shipping, yet there are conflicting ambitions for where global production, transport and fuelling infrastructure will be located. Here, we develop a spatial modelling framework to quantify the cost-optimal fuel supply to decarbonise shipping in 2050 using green ammonia. We find that the demand for green ammonia by 2050 could be three to four times the current (grey) ammonia production, requiring major new investments in infrastructure. Our model predicts a regionalisation of supply, entailing a few large supply clusters that will serve regional demand centres, with limited long-distance shipping of green ammonia fuel. In this cost-efficient model, practically all green ammonia production is predicted to lie within 40° latitudes North/South. To facilitate this transformation, investments worth USD 2 trillion would be needed, half of which will be required in low- and middle-income countries."
"
Badminton traces its roots back more than a millennium, but the modern version of the racket game originated in the late 19th century in England. Today, it is the second most popular sport in the world behind soccer, with an estimated 220 million people who enjoy playing. For the last three decades, badminton has been a competitive Olympic sport, and with ""bird"" speeds topping 300 mph in ""smash"" shots, it certainly makes for exciting spectator sport.

Shuttlecocks, also known as birdies or birds, are traditionally made from duck feathers, but nylon shuttlecocks have become more widely used because of their superior durability. Their flight behavior, however, is far different from that of traditional feather birdies.
In Physics of Fluids, by AIP Publishing, a trio of scientists in India explored the aerodynamic performance of nylon shuttlecocks at various flight speeds. Through computational analyses based on two-way fluid-structure interactions, the team coupled equations governing air flow with equations determining skirt deformation of a shuttlecock in flight.
""We studied the flow by examining aerodynamic forces on the shuttlecock as well as its deformations at each flight speed,"" said author Sanjay Mittal. ""The pressure on the skirt causes it to deform inwards and this deformation increases with speed.""
The team identified four distinct regimes of deformation. At speeds less than 40 meters per second (89 mph), the skirt maintains circularity despite cross-sectional deformation; at higher speeds, it buckles and deforms into a square before it then vibrates radially. Eventually, it undergoes a low frequency wavelike circumferential deformation.
""The cross-sectional area of the shuttlecock decreases with speed, which lowers the air flow rate through the shuttlecock,"" said Mittal. ""The vortex structures that form inside the shuttlecock weaken when it deforms. As a result of these effects, the deformed shuttlecock offers a much lower air resistance compared to its rigid counterpart.""
The study's computational results confirm experimental measurements, explaining the phenomenology of why a duck feather shuttlecock does not deform as much as a nylon shuttlecock -- and why the flight of each at high speed is quite different. From the perspective of a player on the receiving end of a smash shot, the nylon shuttlecock, which travels faster, is harder to return.
Ultimately, the research may represent a new arc in the history of the beloved sport.
""Our study opens up the possibility for improved designs that make the nylon shuttlecock structurally stiffer so that it more closely mimics the aerodynamic performance of feather shuttlecocks,"" said Mittal. ""This could be a game-changer, literally.""

","score: 12.911760368663597, grade_level: '13'","score: 13.979285714285716, grade_levels: ['college_graduate'], ages: [24, 100]",10.1063/5.0182411,"Fluid–structure interactions of a synthetic badminton shuttlecock at various flight speeds are investigated computationally. The cork of the shuttlecock is held fixed and its skirt is free to deform. The cross-sectional area of the skirt decreases with an increase in flight speed leading to a significant reduction in the drag compared to that for an undeformed shuttlecock. Four regimes of deformation, with an increase in speed, are identified. The deformation is steady and axisymmetric in regime 1. Beyond a certain speed, which is referred to as “buckling speed,” the deformation is in regime 2. The skirt assumes a non-axisymmetric shape with a significant increase in its rate of deformation with speed. It undergoes vibration in regime 3. The amplitude of vibration increases with increased speed. In regime 4, the vibrations are modulated atop a lower frequency wave that travels circumferentially along the skirt. Compared to a rigid shuttlecock at the same flow speed, the streamwise vortex structures inside the skirt are weaker in a deformed shuttlecock. The decrease in the drag coefficient with an increase in speed is due to a decrease in the cross-sectional area of the skirt as well as a reduction in the entrainment of the flow through the gaps in the skirt area. The computational results are in good agreement with the available experimental measurements. The effect of the elastic modulus of the material and various structural reinforcements is studied."
"
In recent years, there has been rising concern that tiny particles known as microplastics are showing up basically everywhere on Earth, from polar ice to soil, drinking water and food. Formed when plastics break down into progressively smaller bits, these particles are being consumed by humans and other creatures, with unknown potential health and ecosystem effects. One big focus of research: bottled water, which has been shown to contain tens of thousands of identifiable fragments in each container.

Now, using newly refined technology, researchers have entered a whole new plastic world: the poorly known realm of nanoplastics, the spawn of microplastics that have broken down even further. For the first time, they counted and identified these minute particles in bottled water. They found that on average, a liter contained some 240,000 detectable plastic fragments -- 10 to 100 times greater than previous estimates, which were based mainly on larger sizes.
The study was just published in the journal Proceedings of the National Academy of Sciences.
Nanoplastics are so tiny that, unlike microplastics, they can pass through intestines and lungs directly into the bloodstream and travel from there to organs including the heart and brain. They can invade individual cells, and cross through the placenta to the bodies of unborn babies. Medical scientists are racing to study the possible effects on a wide variety of biological systems.
""Previously this was just a dark area, uncharted. Toxicity studies were just guessing what's in there,"" said study coauthor Beizhan Yan, an environmental chemist at Columbia University's Lamont-Doherty Earth Observatory. ""This opens a window where we can look into a world that was not exposed to us before.""
Worldwide plastic production is approaching 400 million metric tons a year. More than 30 million tons are dumped yearly in water or on land, and many products made with plastics including synthetic textiles shed particles while still in use. Unlike natural organic matter, most plastics do not break down into relatively benign substances; they simply divide and redivide into smaller and smaller particles of the same chemical composition. Beyond single molecules, there is no theoretical limit to how small they can get.
Microplastics are defined as fragments ranging from 5 millimeters (less than a quarter inch) down to 1 micrometer, which is 1 millionth of a meter, or 1/25,000th of an inch. (A human hair is about 70 micrometers across.) Nanoplastics, which are particles below 1 micrometer, are measured in billionths of a meter.

Plastics in bottled water became a public issue largely after a 2018 study detected an average of 325 particles per liter; later studies multiplied that number many times over. Scientists suspected there were even more than they had yet counted, but good estimates stopped at sizes below 1 micrometer -- the boundary of the nano world.
""People developed methods to see nano particles, but they didn't know what they were looking at,"" said the new study's lead author, Naixin Qian, a Columbia graduate student in chemistry. She noted that previous studies could provide bulk estimates of nano mass, but for the most part could not count individual particles, nor identify which were plastics or something else.
The new study uses a technique called stimulated Raman scattering microscopy, which was co-invented by study coauthor Wei Min, a Columbia biophysicist. This involves probing samples with two simultaneous lasers that are tuned to make specific molecules resonate. Targeting seven common plastics, the researchers created a data-driven algorithm to interpret the results. ""It is one thing to detect, but another to know what you are detecting,"" said Min.
The researchers tested three popular brands of bottled water sold in the United States (they declined to name which ones), analyzing plastic particles down to just 100 nanometers in size. They spotted 110,000 to 370,000 particles in each liter, 90% of which were nanoplastics; the rest were microplastics. They also determined which of the seven specific plastics they were, and charted their shapes -- qualities that could be valuable in biomedical research.
One common one was polyethylene terephthalate or PET. This was not surprising, since that is what many water bottles are made of. (It is also used for bottled sodas, sports drinks and products such as ketchup and mayonnaise.) It probably gets into the water as bits slough off when the bottle is squeezed or gets exposed to heat. One recent study suggests that many particles enter the water when you repeatedly open or close the cap, and tiny bits abrade.
However, PET was outnumbered by polyamide, a type of nylon. Ironically, said Beizhan Yan, that probably comes from plastic filters used to supposedly purify the water before it is bottled. Other common plastics the researchers found: polystyrene, polyvinyl chloride and polymethyl methacrylate, all used in various industrial processes.

A somewhat disturbing thought: the seven plastic types the researchers searched for accounted for only about 10% of all the nanoparticles they found in samples; they have no idea what the rest are. If they are all nanoplastics, that means they could number in the tens of millions per liter. But they could be almost anything, ""indicating the complicated particle composition inside the seemingly simple water sample,"" the authors write. ""The common existence of natural organic matter certainly requires prudent distinguishment.""
The researchers are now reaching beyond bottled water. ""There is a huge world of nanoplastics to be studied,"" said Min. He noted that by mass, nanoplastics comprise far less than microplastics, but ""it's not size that matters. It's the numbers, because the smaller things are, the more easily they can get inside us.""
Among other things, the team plans to look at tap water, which also has been shown to contain microplastics, though far less than bottled water. Beizhan Yan is running a project to study microplastics and nanoplastics that end up in wastewater when people do laundry -- by his count so far, millions per 10-pound load, coming off synthetic materials that comprise many items. (He and colleagues are designing filters to reduce the pollution from commercial and residential washing machines.) The team will soon identify particles in snow that British collaborators trekking by foot across western Antarctica are currently collecting. They also are collaborating with environmental health experts to measure nanoplastics in various human tissues and examine their developmental and neurologic effects.
""It is not totally unexpected to find so much of this stuff,"" said Qian. ""The idea is that the smaller things get, the more of them there are.""
The study was coauthored by Xin Gao and Xiaoqi Lang of the Columbia chemistry department; Huipeng Deng and Teodora Maria Bratu of Lamont-Doherty; Qixuan Chen of Columbia's Mailman School of Public Health; and Phoebe Stapleton of Rutgers University.

","score: 12.224712322160599, grade_level: '12'","score: 12.95985531709669, grade_levels: ['college'], ages: [18, 24]",10.1073/pnas.2300582121,"Plastics are now omnipresent in our daily lives. The existence of microplastics (1 µm to 5 mm in length) and possibly even nanoplastics (<1 μm) has recently raised health concerns. In particular, nanoplastics are believed to be more toxic since their smaller size renders them much more amenable, compared to microplastics, to enter the human body. However, detecting nanoplastics imposes tremendous analytical challenges on both the nano-level sensitivity and the plastic-identifying specificity, leading to a knowledge gap in this mysterious nanoworld surrounding us. To address these challenges, we developed a hyperspectral stimulated Raman scattering (SRS) imaging platform with an automated plastic identification algorithm that allows micro-nano plastic analysis at the single-particle level with high chemical specificity and throughput. We first validated the sensitivity enhancement of the narrow band of SRS to enable high-speed single nanoplastic detection below 100 nm. We then devised a data-driven spectral matching algorithm to address spectral identification challenges imposed by sensitive narrow-band hyperspectral imaging and achieve robust determination of common plastic polymers. With the established technique, we studied the micro-nano plastics from bottled water as a model system. We successfully detected and identified nanoplastics from major plastic types. Micro-nano plastics concentrations were estimated to be about 2.4 ± 1.3 × 10 5 particles per liter of bottled water, about 90% of which are nanoplastics. This is orders of magnitude more than the microplastic abundance reported previously in bottled water. High-throughput single-particle counting revealed extraordinary particle heterogeneity and nonorthogonality between plastic composition and morphologies; the resulting multidimensional profiling sheds light on the science of nanoplastics."
"
Hydrogen energy has emerged as a promising alternative to fossil fuels, offering a clean and sustainable energy source. However, the development of low-cost and efficient catalysts for hydrogen evolution reaction remains a crucial challenge. A research team led by scientists from City University of Hong Kong (CityU) has recently developed a novel strategy to engineer stable and efficient ultrathin nanosheet catalysts by forming Turing structures with multiple nanotwin crystals. This innovative discovery paves the way for enhanced catalyst performance for green hydrogen production.

Producing hydrogen through the process of water electrolysis with net-zero carbon emissions is one of the clean hydrogen production processes. While low-dimensional nanomaterials with controllable defects or strain modifications have emerged as active electrocatalysts for hydrogen-energy conversion and utilization, the insufficient stability in these materials due to spontaneous structural degradation and strain relaxation leads to their catalytic performance degradation.
To addressing this issue, a research team led by Professor Lu Jian, Dean of the College of Engineering at CityU and Director of Hong Kong Branch of National Precious Metal Material Engineering Research Center, has recently developed a pioneering Turing structuring strategy which not only activates but also stabilizes catalysts through the introduction of high-density nanotwin crystals. This approach effectively resolves the instability problem associated with low-dimensional materials in catalytic systems, enabling efficient and long-lasting hydrogen production.
Turing patterns, known as spatiotemporal stationary patterns, are widely observed in biological and chemical systems, such as the regular surface colouring on sea-shells. The mechanism of these pattern formations is related to the reaction-diffusion theory proposed by Alan Turing, a famous English mathematician regarded as one of the fathers of modern computing, in which the activator with a smaller diffusion coefficient induces local preferential growth.
""In previous research, the fabrication of low-dimensional materials has mainly focused on structural controls for functional purposes, with few considerations on spatiotemporal controls,"" Professor Lu explained the background of this research. ""However, the Turing patterns in nanomaterials may be achieved by the anisotropic growth of nanograins of the materials. Such broken lattice symmetry has crucial crystallographic implications for the growth of specific configurations, such as two-dimensional (2D) materials with twinning and intrinsic broken symmetry. So we wanted to explore the application of Turing theory on nanocatalyst growth and the relations with crystallographic defects.""
In this research, the team used two-step approach to create superthin platinum-nickel-niobium (PtNiNb) nanosheets with strips topologically resemble Turing patterns. These Turing structures on nanosheets were formed through the constrained orientation attachment of nanograins, resulting in an intrinsically stable, high-density nanotwin network which acted as structural stabilizers which prevented spontaneous structural degradation and strain relaxation.
Moreover, the Turing patterns generated lattice straining effects which reduce the energy barrier of water dissociation and optimize the hydrogen adsorption free energy for hydrogen evolution reaction, enhancing the activity of the catalysts and providing exceptional stability. The surface of the nano-scale Turing structure exhibits a large number of twins interfaces, also rendering it an exceptionally well-suited materials for interface-dominated applications, particularly electrochemical catalysis.
In the experiments, the researchers demonstrated the potential of the newly invented Turing PtNiNb nano-catalyst as a stable hydrogen evolution catalyst with superb efficiency. It achieved 23.5 and 3.1 times increase in mass activity and stability index, respectively, compared with commercial 20% Pt/C. The Turing PtNiNb-based anion-exchange-membrane water electrolyser with a low platinum (Pt) mass loading of 0.05 mg cm−2 was also extremely reliable, as it could achieve 500 hours of stability at 1,000 mAcm−2.
""Our key findings provide valuable insights into the activation and stabilization of catalytic materials with low dimensions. It presents a fresh paradigm for enhancing catalyst performance,"" said Professor Lu. ""The Turing structure optimization strategy not only addresses the issue of stability degradation in low-dimensional materials but also serves as a versatile material optimization approach applicable to other alloying and catalytic systems, ultimately enhancing catalytic performance.""

","score: 20.067651515151514, grade_level: '20'","score: 21.570062917308682, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-40972-w,"Low-dimensional nanocrystals with controllable defects or strain modifications are newly emerging active electrocatalysts for hydrogen-energy conversion and utilization; however, a crucial challenge remains in insufficient stability due to spontaneous structural degradation and strain relaxation. Here we report a Turing structuring strategy to activate and stabilize superthin metal nanosheets by incorporating high-density nanotwins. Turing configuration, realized by constrained orientation attachment of nanograins, yields intrinsically stable nanotwin network and straining effects, which synergistically reduce the energy barrier of water dissociation and optimize the hydrogen adsorption free energy for hydrogen evolution reaction. Turing PtNiNb nanocatalyst achieves 23.5 and 3.1 times increase in mass activity and stability index, respectively, compared against commercial 20% Pt/C. The Turing PtNiNb-based anion-exchange-membrane water electrolyser with a low Pt mass loading of 0.05 mg cm−2 demonstrates at least 500 h stability at 1000 mA cm−2, disclosing the stable catalysis. Besides, this new paradigm can be extended to Ir/Pd/Ag-based nanocatalysts, illustrating the universality of Turing-type catalysts."
"
Using a new technology developed at MIT, diagnosing lung cancer could become as easy as inhaling nanoparticle sensors and then taking a urine test that reveals whether a tumor is present.

The new diagnostic is based on nanosensors that can be delivered by an inhaler or a nebulizer. If the sensors encounter cancer-linked proteins in the lungs, they produce a signal that accumulates in the urine, where it can be detected with a simple paper test strip.
This approach could potentially replace or supplement the current gold standard for diagnosing lung cancer, low-dose computed tomography (CT). It could have an especially significant impact in low- and middle-income countries that don't have widespread availability of CT scanners, the researchers say.
""Around the world, cancer is going to become more and more prevalent in low- and middle-income countries. The epidemiology of lung cancer globally is that it's driven by pollution and smoking, so we know that those are settings where accessibility to this kind of technology could have a big impact,"" says Sangeeta Bhatia, the John and Dorothy Wilson Professor of Health Sciences and Technology and of Electrical Engineering and Computer Science at MIT, and a member of MIT's Koch Institute for Integrative Cancer Research and the Institute for Medical Engineering and Science.
Bhatia is the senior author of the paper, which appears today in Science Advances. Qian Zhong, an MIT research scientist, and Edward Tan, a former MIT postdoc, are the lead authors of the study.
Inhalable particles
To help diagnose lung cancer as early as possible, the U.S. Preventive Services Task Force recommends that heavy smokers over the age of 50 undergo annual CT scans. However, not everyone in this target group receives these scans, and the high false-positive rate of the scans can lead to unnecessary, invasive tests.

Bhatia has spent the last decade developing nanosensors for use in diagnosing cancer and other diseases, and in this study, she and her colleagues explored the possibility of using them as a more accessible alternative to CT screening for lung cancer.
These sensors consist of polymer nanoparticles coated with a reporter, such as a DNA barcode, that is cleaved from the particle when the sensor encounters enzymes called proteases, which are often overactive in tumors. Those reporters eventually accumulate in the urine and are excreted from the body.
Previous versions of the sensors, which targeted other cancer sites such as the liver and ovaries, were designed to be given intravenously. For lung cancer diagnosis, the researchers wanted to create a version that could be inhaled, which could make it easier to deploy in lower resource settings.
""When we developed this technology, our goal was to provide a method that can detect cancer with high specificity and sensitivity, and also lower the threshold for accessibility, so that hopefully we can improve the resource disparity and inequity in early detection of lung cancer,"" Zhong says.
To achieve that, the researchers created two formulations of their particles: a solution that can be aerosolized and delivered with a nebulizer, and a dry powder that can be delivered using an inhaler.
Once the particles reach the lungs, they are absorbed into the tissue, where they encounter any proteases that may be present. Human cells can express hundreds of different proteases, and some of them are overactive in tumors, where they help cancer cells to escape their original locations by cutting through proteins of the extracellular matrix. These cancerous proteases cleave DNA barcodes from the sensors, allowing the barcodes to circulate in the bloodstream until they are excreted in the urine.

In the earlier versions of this technology, the researchers used mass spectrometry to analyze the urine sample and detect DNA barcodes. However, mass spectrometry requires equipment that might not be available in low-resource areas, so for this version, the researchers created a lateral flow assay, which allows the barcodes to be detected using a paper test strip.
The researchers designed the strip to detect up to four different DNA barcodes, each of which indicates the presence of a different protease. No pre-treatment or processing of the urine sample is required, and the results can be read about 20 minutes after the sample is obtained.
""We were really pushing this assay to be point-of-care available in a low-resource setting, so the idea was to not do any sample processing, not do any amplification, just to be able to put the sample right on the paper and read it out in 20 minutes,"" Bhatia says.
Accurate diagnosis
The researchers tested their diagnostic system in mice that are genetically engineered to develop lung tumors similar to those seen in humans. The sensors were administered 7.5 weeks after the tumors started to form, a time point that would likely correlate with stage 1 or 2 cancer in humans.
In their first set of experiments in the mice, the researchers measured the levels of 20 different sensors designed to detect different proteases. Using a machine learning algorithm to analyze those results, the researchers identified a combination of just four sensors that was predicted to give accurate diagnostic results. They then tested that combination in the mouse model and found that it could accurately detect early-stage lung tumors.
For use in humans, it's possible that more sensors might be needed to make an accurate diagnosis, but that could be achieved by using multiple paper strips, each of which detects four different DNA barcodes, the researchers say.
The researchers now plan to analyze human biopsy samples to see if the sensor panels they are using would also work to detect human cancers. In the longer term, they hope to perform clinical trials in human patients. A company called Sunbird Bio has already run phase 1 trials on a similar sensor developed by Bhatia's lab, for use in diagnosing liver cancer and a form of hepatitis known as nonalcoholic steatohepatitis (NASH).
In parts of the world where there is limited access to CT scanning, this technology could offer a dramatic improvement in lung cancer screening, especially since the results can be obtained during a single visit.
""The idea would be you come in and then you get an answer about whether you need a follow-up test or not, and we could get patients who have early lesions into the system so that they could get curative surgery or lifesaving medicines,"" Bhatia says.
The research was funded by the Johnson & Johnson Lung Cancer Initiative, the Howard Hughes Medical Institute, the Koch Institute Support (core) Grant from the National Cancer Institute, and the National Institute of Environmental Health Sciences.

","score: 15.38934664246824, grade_level: '15'","score: 16.79950998185118, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adj9591,"Although low-dose computed tomography screening improves lung cancer survival in at-risk groups, inequality remains in lung cancer diagnosis due to limited access to and high costs of medical imaging infrastructure. We designed a needleless and imaging-free platform, termed PATROL (point-of-care aerosolizable nanosensors with tumor-responsive oligonucleotide barcodes), to reduce resource disparities for early detection of lung cancer. PATROL formulates a set of DNA-barcoded, activity-based nanosensors (ABNs) into an inhalable format. Lung cancer–associated proteases selectively cleave the ABNs, releasing synthetic DNA reporters that are eventually excreted via the urine. The urinary signatures of barcoded nanosensors are quantified within 20 min at room temperature using a multiplexable paper-based lateral flow assay. PATROL detects early-stage tumors in an autochthonous lung adenocarcinoma mouse model with high sensitivity and specificity. Tailoring the library of ABNs may enable not only the modular PATROL platform to lower the resource threshold for lung cancer early detection tools but also the rapid detection of chronic pulmonary disorders and infections."
"
Spintronic devices are electronic devices that utilize the spin of electrons (an intrinsic form of angular momentum possessed by the electron) to achieve high-speed processing and low-cost data storage. In this regard, spin-transfer torque is a key phenomenon that enables ultrafast and low-power spintronic devices. Recently, however, spin-orbit torque (SOT) has emerged as a promising alternative to spin-transfer torque.

Many studies have investigated the origin of SOT, showing that in non-magnetic materials, a phenomenon called the spin Hall effect (SHE) is key to achieving SOT. In these materials, the existence of a ""Dirac band"" structure, a specific arrangement of electrons in terms of their energy, is important to achieving large SHE. This is because the Dirac band structure contains ""hot spots"" for the Berry phase, a quantum phase factor responsible for the intrinsic SHE. Thus, materials with suitable Berry phase hot spots are key to engineering the SHE.
In this context, the material tantalum silicide (TaSi2) is of great interest as it has several Dirac points near the Fermi level in its band structure, suitable for practicing Berry phase engineering. To demonstrate this, a team of researchers, led by Associate Professor Pham Nam Hai from the Department of Electrical and Electronic Engineering at Tokyo Institute of Technology (Tokyo Tech), Japan, recently investigated the influence of Dirac band hot spots on the temperature dependence of SHE in TaSi2. ""Berry phase monopole engineering is an interesting avenue of research as it can give rise to efficient high-temperature SOT spintronic devices such as the magneto-resistive random-access memory,"" explains Dr. Hai about the importance of their study. Their findings were published in the journal Applied Physics Letters.
Through various experiments, the team observed that the SOT efficiency of TaSi2 remained almost unchanged from 62 K to 288 K, which was similar to the behavior of conventional heavy metals. However, upon increasing the temperature further, the SOT efficiency suddenly increased and nearly doubled at 346 K. Moreover, the corresponding SHE also increased in a similar fashion. Notably, this was quite different from the behavior of conventional heavy metals and their alloys. Upon further analysis, the researchers attributed this sudden increase in SHE at high temperatures to Berry phase monopoles.
""These results provide a strategy to enhance the SOT efficiency at high temperatures via Berry phase monopole engineering,"" highlights Dr. Hai.
Indeed, their study highlights the potential of Berry phase monopole engineering to effectively use the SHE in non-magnetic materials, and provides a new pathway for the development of high-temperature, ultrafast, and low-power SOT spintronic devices.

","score: 16.0014262317456, grade_level: '16'","score: 16.57774669032346, grade_levels: ['college_graduate'], ages: [24, 100]",10.1063/5.0165333,"We demonstrate the concept of Berry phase monopole engineering of the spin Hall effect in non-centrosymmetric silicide TaSi2. We show that while the effective damping-like spin–orbit torque (SOT) efficiency θDLeff of TaSi2 is nearly unchanged from 62 to 288 K (−0.049 to −0.069), θDLeff suddenly increases at high temperatures and becomes nearly double (−0.12) at 346 K. The corresponding intrinsic spin Hall conductivity σDLeff significantly increases at high temperatures, which can be attributed to the increasing contribution from the four degenerate points near the Fermi level via thermal excitation. Our results provide a strategy to enhance θDLeff at high temperatures via Berry phase monopole engineering and pave the way for SOT spintronic devices working at high temperatures."
"
With a split-second muscle contraction, the greater blue-ringed octopus can change the size and color of the namesake patterns on its skin for purposes of deception, camouflage and signaling. Researchers at the University of California, Irvine have drawn inspiration from this natural wonder to develop a technological platform with similar capabilities for use in a variety of fields, including the military, medicine, robotics and sustainable energy.

According to its inventors, new devices made possible by this innovation will benefit from dynamically adjustable fluorescent and spectroscopic properties, ease of manufacturing, and potential for scaling to areas large enough to cover vehicles, billboards and even buildings. The bio-inspired creation is the subject of a study published recently in Nature Communications.
Hapalochlaena lunulata is a species of octopus native to the Western Pacific Ocean and Indian Ocean. It uses a neurotoxin venom to stun its prey and can ward off predators with a flash of its blue rings. These iridescent circles on a brown background on the creature's skin are what drew the attention of the UCI researchers.
""We are fascinated by the mechanisms underpinning the blue-ringed octopus' ability to rapidly switch its skin markings between hidden and exposed states,"" said senior co-author Alon Gorodetsky, UCI professor of chemical and biomolecular engineering. ""For this project, we worked to mimic the octopus' natural abilities with devices from unique materials we synthesized in our laboratory, and the result is an octopus-inspired deception and signaling system that is straightforward to fabricate, functions for a long time when operated continuously, and can even repair itself when damaged.""
The architecture of the innovation calls for a thin film consisting of wrinkled blue rings surrounding brown circles -- much like those on the octopus -- sandwiched between a topmost transparent proton-conducting electrode and an underlying acrylic membrane, with another identical electrode underneath.
Further technical creativity by the researchers occurs at the molecular level as they explored the use of acenes, which are organic compounds made up of linearly fused benzene rings. Designer nonacene-like molecules (with nine linearly fused rings) used by the team help give the platform some of its outstanding capabilities, according to Gorodetsky.
""For our devices, we conceptualized and designed a nonacene-like molecule with a unique architecture,"" said co-lead author Preeta Pratakshya, who recently received her Ph.D. in UCI's Department of Chemistry. ""Acenes are organic hydrocarbon molecules with a host of advantageous characteristics, including ease of synthesis, tunable electronic characteristics, and controllable optical properties.""
She added, ""Our nonacene-like molecules are exceptional among acenes because they can survive years of storage in air and over a day of continuous irradiation with bright light in air. No other expanded acene displays this combined long-term stability under such harsh conditions.""

According to Gorodetsky, the type of molecules used to fabricate the colored blue ring layer are what endow the devices with their most favorable features, including adjustable spectroscopic properties, the facilitation of straightforward benchtop manufacturing and ambient-atmosphere stability under illumination.
""Our co-author Sahar Sharifzadeh, a Boston University professor of electrical and computer engineering, demonstrated that the stimuli-responsive properties of the molecules can be computationally predicted, which opens paths for the in silico design of other camouflage technologies,"" Gorodetsky said.
In their laboratory tests, many of which happened in UCI's California Institute for Telecommunications and Information Technology, the team found that the bioinspired devices could change their visible appearance over 500 times with little or no degradation, and they also could autonomously self-repair without user intervention.
The invention was demonstrated to possess a desirable combination of capabilities in the ultraviolet, visible light, and near-infrared parts of the electromagnetic spectrum, according to Gorodetsky. This would enable the devices to disguise other objects from detection or to clandestinely signal observers.
""The photophysical robustness and general processability of our nonacene-like molecule -- and presumably its variants -- opens opportunities for future investigation of these compounds within the context of traditional optoelectronic systems such as light-emitting diodes and solar cells,"" added Gorodetsky.
Joining Gorodetsky and Pratakshya in this study were Chengyi Xu, Panyiming Liu, Reina Kurakake, and Robert Lopez in UCI's Department of Materials Science and Engineering; David Josh Dibble and Anthony Burke in UCI's Department of Chemical and Biomolecular Engineering; Philip Denison in UCI's Department of Chemistry; and Aliya Mukazhanova and Sharifzadeh of Boston University. The Office of Naval Research, the Defense Advanced Research Projects Agency, and the National Science Foundation provided funding support.

","score: 20.36355263157895, grade_level: '20'","score: 21.625516194331986, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-40163-7,"Multifunctional platforms that can dynamically modulate their color and appearance have attracted attention for applications as varied as displays, signaling, camouflage, anti-counterfeiting, sensing, biomedical imaging, energy conservation, and robotics. Within this context, the development of camouflage systems with tunable spectroscopic and fluorescent properties that span the ultraviolet, visible, and near-infrared spectral regions has remained exceedingly challenging because of frequently competing materials and device design requirements. Herein, we draw inspiration from the unique blue rings of the Hapalochlaena lunulata octopus for the development of deception and signaling systems that resolve these critical challenges. As the active material, our actuator-type systems incorporate a readily-prepared and easily-processable nonacene-like molecule with an ambient-atmosphere stability that exceeds the state-of-the-art for comparable acenes by orders of magnitude. Devices from this active material feature a powerful and unique combination of advantages, including straightforward benchtop fabrication, competitive baseline performance metrics, robustness during cycling with the capacity for autonomous self-repair, and multiple dynamic multispectral operating modes. When considered together, the described exciting discoveries point to new scientific and technological opportunities in the areas of functional organic materials, reconfigurable soft actuators, and adaptive photonic systems."
"
Mass spectrometers, devices that identify chemical substances, are widely used in applications like crime scene analysis, toxicology testing, and geological surveying. But these machines are bulky, expensive, and easy to damage, which limits where they can be effectively deployed.

Using additive manufacturing, MIT researchers produced a mass filter, which is the core component of a mass spectrometer, that is far lighter and cheaper than the same type of filter made with traditional techniques and materials.
Their miniaturized filter, known as a quadrupole, can be completely fabricated in a matter of hours for a few dollars. The 3D-printed device is as precise as some commercial-grade mass filters that can cost more than $100,000 and take weeks to manufacture.
Built from durable and heat-resistant glass-ceramic resin, the filter is 3D printed in one step, so no assembly is required. Assembly often introduces defects that can hamper the performance of quadrupoles.
This lightweight, cheap, yet precise quadrupole is one important step in Luis Fernando Velásquez-García's 20-year quest to produce a 3D-printed, portable mass spectrometer.
""We are not the first ones to try to do this. But we are the first ones who succeeded at doing this. There are other miniaturized quadrupole filters, but they are not comparable with professional-grade mass filters. There are a lot of possibilities for this hardware if the size and cost could be smaller without adversely affecting the performance,"" says Velásquez-García, a principal research scientist in MIT's Microsystems Technology Laboratories (MTL) and senior author of a paper detailing the miniaturized quadrupole.
For instance, a scientist could bring a portable mass spectrometer to remote areas of the rainforest, using it to rapidly analyze potential pollutants without shipping samples back to a lab. And a lightweight device would be cheaper and easier to send into space, where it could monitor chemicals in Earth's atmosphere or on those of distant planets.

Velásquez-García is joined on the paper by lead author Colin Eckhoff, an MIT graduate student in electrical engineering and computer science (EECS); Nicholas Lubinsky, a former MIT postdoc; and Luke Metzler and Randall Pedder of Ardara Technologies. The research is published in Advanced Science.
Size matters
At the heart of a mass spectrometer is the mass filter. This component uses electric or magnetic fields to sort charged particles based on their mass-to-charge ratio. In this way, the device can measure the chemical components in a sample to identify an unknown substance.
A quadrupole, a common type of mass filter, is composed of four metallic rods surrounding an axis. Voltages are applied to the rods, which produce an electromagnetic field. Depending on the properties of the electromagnetic field, ions with a specific mass-to-charge ratio will swirl around through the middle of the filter, while other particles escape out the sides. By varying the mix of voltages, one can target ions with different mass-to-charge ratios.
While fairly simple in design, a typical stainless-steel quadrupole might weigh several kilograms. But miniaturizing a quadrupole is no easy task. Making the filter smaller usually introduces errors during the manufacturing process. Plus, smaller filters collect fewer ions, which makes chemical analysis less sensitive.
""You can't make quadrupoles arbitrarily smaller -- there is a tradeoff,"" Velásquez-García adds.

His team balanced this tradeoff by leveraging additive manufacturing to make miniaturized quadrupoles with the ideal size and shape to maximize precision and sensitivity.
They fabricate the filter from a glass-ceramic resin, which is a relatively new printable material that can withstand temperatures up to 900 degrees Celsius and performs well in a vacuum.
The device is produced using vat photopolymerization, a process where a piston pushes into a vat of liquid resin until it nearly touches an array of LEDs at the bottom. These illuminate, curing the resin that remains in the minuscule gap between the piston and the LEDs. A tiny layer of cured polymer is then stuck to the piston, which rises up and repeats the cycle, building the device one tiny layer at a time.
""This is a relatively new technology for printing ceramics that allows you to make very precise 3D objects. And one key advantage of additive manufacturing is that you can aggressively iterate the designs,"" Velásquez-García says.
Since the 3D printer can form practically any shape, the researchers designed a quadrupole with hyperbolic rods. This shape is ideal for mass filtering but difficult to make with conventional methods. Many commercial filters employ rounded rods instead, which can reduce performance.
They also printed an intricate network of triangular lattices surrounding the rods, which provides durability while ensuring the rods remain positioned correctly if the device is moved or shaken.
To finish the quadrupole, the researchers used a technique called electroless plating to coat the rods with a thin metal film, which makes them electrically conductive. They cover everything but the rods with a masking chemical and then submerge the quadrupole in a chemical bath heated to a precise temperature and stirring conditions. This deposits a thin metal film on the rods uniformly without damaging the rest of the device or shorting the rods.
""In the end, we made quadrupoles that were the most compact but also the most precise that could be made, given the constraints of our 3D printer,"" Velásquez-García says.
Maximizing performance
To test their 3D-printed quadrupoles, the team swapped them into a commercial system and found that they could attain higher resolutions than other types of miniature filters. Their quadrupoles, which are about 12 centimeters in length, are one-quarter the density of comparable stainless-steel filters.
In addition, further experiments suggest that their 3D-printed quadrupoles could achieve precision that is on par with that of largescale commercial filters.
In the future, the researchers plan to boost the quadrupole's performance by making the filters longer. A longer filter can enable more precise measurements since more ions that are supposed to be filtered out will escape as the chemical travels along its length. They also intend to explore different ceramic materials that could better transfer heat.
""Our vision is to make a mass spectrometer where all the key components can be 3D printed, contributing to a device with much less weight and cost without sacrificing performance. There is still a lot of work to do, but this is a great start,"" Velásquez-Garcia adds.
This work was funded by Empiriko Corporation.

","score: 12.783889695210448, grade_level: '13'","score: 13.538685050798257, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202307665,"This study reports novel, compact, and additively manufactured quadrupole mass filters (QMFs) with adequate filtering performance for practical mass spectrometry applications. The QMFs are monolithically fabricated via vat photopolymerization of glass‐ceramic resin using 57 µm × 57 µm × 100 µm voxels, and selective electroless plating of nickel‐boron. Experimental characterization of QMF prototypes at 1.74 MHz using FC‐43 yields 131 Da peaks with 0.50 Da full width at half maximum (260 resolution), surpassing the resolution of reported miniaturized counterparts under similar conditions, and being on par with commercial, non‐miniaturized, heavier devices. The sensitivity of the 3D‐printed devices is estimated at 0.13 mA Torr−1 (comparable to that of optimized, commercial counterparts), while the devices attained up to 250 Da of mass range (limited by the driving electronics). The work is of interest to low‐cost, capable mass spectrometry, 3D‐printed instruments, and in‐space manufacturing of complex instrumentation."
"
The integration of mechanical memory in the form of springs has for hundreds of years proven to be a key enabling technology for mechanical devices (like clocks), achieving advanced functionality through complex autonomous movements. In our times, the integration of springs in silicon-based microtechnology has opened the world of planar mass-producible mechatronic devices from which we all benefit, via air-bag sensors for example. For a new generation of minimally and even non-invasive biomedical applications however, mobile devices which can safely interact mechanically with cells must be achieved at much smaller scales (10 microns) and with much softer forces (pico Newton scale i. e. lifting weights less than one millionth of a mg) and in customized three-dimensional shapes.

Researchers at the Chemnitz University of Technology, the Shenzhen Institute of Advanced Technology of the Chinese Academy of Sciences and the Leibniz IFW Dresden, in a recent publication in Nature Nanotechnology, have now demonstrated that controllable springs can be integrated at arbitrary chosen locations within soft three-dimensional structures using confocal photolithographic manufacturing (with nanoscale precision) of a novel magnetically active material in the form of a photoresist impregnated with customizable densities of magnetic nanoparticles.
These ""picosprings"" have remarkably large and tuneable compliancy and can be controlled remotely through magnetic fields (even deep within the human body) allowing articulated motion in microrobots as well as micromanipulations well beyond the state of the art.
Moreover, the extension of the picosprings can also be used visually to measure forces, for example propulsion or grasping forces, in interaction with other objects like cells. For example, these picosprings have been used to measure the locomotive propulsion force of sperm cells. The publication showcases these capabilities by demonstrating several microbots (including a micropenguin) containing picosprings at multiple locations that can do these tasks at cellular scales: propel themselves, grasp and release cells and measure the minute forces needed to do this safely.
Dr. Haifeng Yu, first author of the study and group leader at the Chinese Academy of Sciences in Shenzhen (China), says: ""Programmable elasticity at the micrometer scale offers a feasible strategy for producing 3D devices and finely structured 'micro-surgeons' capable of performing complex medical tasks.""
Dr. Mariana Medina-Sanchez, group leader at the Leibniz IFW and BCUBE- TU Dresden, co-author and co-supervisor of this work, adds: ""These picospring-based micromachines with programmable elasticity and magnetism, crafted through monolithic fabrication, open numerous possibilities for localized force sensing and actuation in low Reynolds number environments. This versatility underscores their significance across a spectrum of biomedical applications.""
Prof. Oliver Schmidt, who is last author of the paper and supervised this work, sees this as another important step in the transition towards life-ready soft and smart modular microrobotics. ""Remotely controlled microdevices using magnetic fields form a particularly promising technology for non-invasive medical applications -- and now this extends to mechanical mechanisms inside these remote microdevices,"" says Schmidt.
""Being able to incorporate designer springs will also add a new tool to the growing capability at TU Chemnitz towards microelectronic morphogenesis and artificial life,"" adds Prof. John McCaskill, co-author of the study, member of the Research Center MAIN, and Founding Director of the European Centre for Living Technology.
This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreements No 835268, and No. 853609).

","score: 21.141428571428573, grade_level: '21'","score: 23.556214285714283, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41565-023-01567-0,"Microscale organisms and specialized motile cells use protein-based spring-like responsive structures to sense, grasp and move. Rendering this biomechanical transduction functionality in an artificial micromachine for applications in single-cell manipulations is challenging due to the need for a bio-applicable nanoscale spring system with a large and programmable strain response to piconewton-scale forces. Here we present three-dimensional nanofabrication and monolithic integration, based on an acrylic elastomer photoresist, of a magnetic spring system with quantifiable compliance sensitive to 0.5 pN, constructed with customized elasticity and magnetization distributions at the nanoscale. We demonstrate the effective design programmability of these ‘picospring’ ensembles as energy transduction mechanisms for the integrated construction of customized soft micromachines, with onboard sensing and actuation functions at the single-cell scale for microrobotic grasping and locomotion. The integration of active soft springs into three-dimensional nanofabrication offers an avenue to create biocompatible soft microrobots for non-disruptive interactions with biological entities."
"
When water vapor meets metal, the resulting corrosion can lead to mechanical problems that harm a machine's performance. Through a process called passivation, it also can form a thin inert layer that acts as a barrier against further deterioration.

Either way, the exact chemical reaction is not well understood on an atomic level, but that is changing thanks to a technique called environmental transmission electron microscopy (TEM), which allows researchers to directly view molecules interacting on the tiniest possible scale.
Professor Guangwen Zhou -- a faculty member at Binghamton University, State University of New York's Thomas J. Watson College of Engineering and Applied Science -- has been probing the secrets of atomic reactions since joining the Department of Mechanical Engineering in 2007. Along with collaborators from the University of Pittsburgh and the Brookhaven National Laboratory, he has studied the structural and functional properties of metals and the process of making ""green"" steel.
Their latest research, ""Atomistic mechanisms of water vapor induced surface passivation,"" was published in November in the journal Science Advances. Co-authors included Binghamton PhD students Xiaobo Chen, Dongxiang Wu, Chaoran Li, Shuonan Ye and Shyam Bharatkumar Patel, MS '21; Na Cai, PhD '12; Zhao Liu, PhD '20; Weitao Shan, MS '16, and Guofeng Wang from the University of Pittsburgh; and Sooyeon Hwang, Dmitri N. Zakharov and Jorge Anibal Boscoboinik from the Brookhaven National Laboratory.
In the paper, Zhou and his team introduced water vapor to clean aluminum samples and observed the surface reactions.
""This phenomenon is well-known because it happens in our daily lives,"" he said. ""But how do water molecules react with aluminum to form this passivation layer? If you look at the [research] literature, there's not much work about how this happens at an atomic scale. If we want to use it for good, we must know, because then we will have some way to control it.""
They discovered something that had never been observed before: In addition to the aluminum hydroxide layer that formed on the surface, a second amorphous layer developed underneath it, which indicates there is a transport mechanism that diffuses oxygen into the substrate.

""Most corrosion studies focus on the growth of the passivation layer and how it slows down the corrosion process,"" Zhou said. ""To look at it from an atomic scale, we feel we can bridge the knowledge gap.""
The cost of repairing corrosion worldwide is estimated at $2.5 trillion a year, which is more than 3% of the global GDP -- so developing better ways to manage oxidation would be an economic boon.
Additionally, understanding how a water molecule's hydrogen and oxygen atoms break apart to interact with metals could lead to clean-energy solutions, which is why the U.S. Department of Energy funded this research and Zhou's similar projects in the past.
""If you break water into oxygen and hydrogen, when you recombine it, it's just water again,"" he said. ""It doesn't have the contamination of fossil fuels, and it doesn't produce carbon dioxide.""
Because of the clean-energy implications, the DOE regularly has renewed Zhou's grant funding over the past 15 years.
""I greatly appreciate the long-term support for this research,"" Zhou said. ""It's a very important issue for energy devices or energy systems, because you have a lot of metallic alloys that are used as structural material.""

","score: 14.439665071770339, grade_level: '14'","score: 14.86796650717703, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adh5565,"The microscopic mechanisms underpinning the spontaneous surface passivation of metals from ubiquitous water have remained largely elusive. Here, using in situ environmental electron microscopy to atomically monitor the reaction dynamics between aluminum surfaces and water vapor, we provide direct experimental evidence that the surface passivation results in a bilayer oxide film consisting of a crystalline-like Al(OH) 3 top layer and an inner layer of amorphous Al 2 O 3 . The Al(OH) 3 layer maintains a constant thickness of ~5.0 Å, while the inner Al 2 O 3 layer grows at the Al 2 O 3 /Al interface to a limiting thickness. On the basis of experimental data and atomistic modeling, we show the tunability of the dissociation pathways of H 2 O molecules with the Al, Al 2 O 3 , and Al(OH) 3 surface terminations. The fundamental insights may have practical significance for the design of materials and reactions for two seemingly disparate but fundamentally related disciplines of surface passivation and catalytic H 2 production from water."
"
Perovskite nanosheets show distinctive characteristics with significant applications in science and technology. In a recent study, researchers from Korea and UK achieved enhanced signal amplification in CsPbBr3 perovskite nanosheets with a unique waveguide pattern, which enhanced both gain and thermal stability. These advancements carry wide-ranging implications for laser, sensor, and solar cell applications, and can potentially influence areas like environmental monitoring, industrial processes, and healthcare.

Perovskite materials are still attracting a lot of interest in solar cell applications. Now, the nanostructures of perovskite materials are being considered as a new laser medium. Over the years, light amplification in perovskite quantum dots has been reported, but most of the works present inadequate quantitative analysis. To assess the light amplification ability, ""gain coefficient"" is necessary, whereby the essential characteristic of a laser medium is revealed. An efficient laser medium is one that has a large gain.
Scientists have been exploring ways to boost this gain. Now, in a recent study, a team of researchers, led by Professor Kwangseuk Kyhm from the Department of Optics & Mechatronics at Pusan National University in Korea, has managed to enhance signal amplification in perovskite nanosheets of CsPbBr3 with a unique waveguide pattern. Their study was published in the journal Light: Science & Applications on 24 November 2023.
Perovskite nanosheets are two-dimensional structures arranged in sheet-like configurations on the nanoscale and possess characteristics that make them valuable for various applications. Their achievement overcomes the shortcomings of CsPbBr3 quantum dots, whose gain is inherently limited due to the Auger process, which essentially shortens the decay time for population inversion (a state in which more members of the system are in higher, excited states than in lower, unexcited energy states). Prof. Kyhm explains: ""Perovskite nanosheets can be a new laser medium, and this work has demonstrated that light amplification can be achieved based on tiny perovskite nanosheets that are synthesized chemically.""
The researchers also proposed a new gain analysis of ""gain contour"" to overcome the limit of earlier gain analysis. While the old method provides a gain spectrum, it is unable to analyze the gain saturation for long optical stripe lengths. Because the ""gain contour"" illustrates the variation of the gain with respect to spectrum energy and optical stripe length, it is very convenient to analyze the local gain variation along spectrum energy and optical stripe length.
The researchers also studied the excitation and temperature dependence of the gain contour and the patterned waveguide, based on polyurethane-acrylate, which boosted both the gain and thermal stability of perovskite nanosheets. This enhancement was attributed to improved optical confinement and heat dissipation, which was facilitated by the two-dimensional center-of-mass confined excitons and localized states arising from the inhomogeneous sheet thickness and the defect states.
The implementation of such a patterned waveguide is promising for efficient and controlled signal amplification and can contribute to the development of more reliable and versatile devices based on perovskite nanosheets, including lasers, sensors, and solar cells. In addition, it could also impact industries related to encryption and decryption of information, neuromorphic computing, and visible light communication. Furthermore, enhanced amplification and increased efficiencies can help perovskite solar cells compete better with traditional silicon-based solar cells.
The study is also poised to significantly influence optics and photonics. The insights gained can help optimize laser operation, enhance signal transmission in optical communication, and improve sensitivity in photodetectors. This, in turn, could allow devices to operate more reliably.
In the long term, when intense light is needed at the nanoscale, perovskite nanosheets can be combined with other nanostructures, allowing the amplified light to serve as an optical probe. However, the successful application of perovskite nanosheets in diverse areas, including consumer products like smartphones and lighting, would depend on overcoming challenges related to their stability, scalability, and toxicity.
""So far, perovskite quantum dots have been studied for lasers, but such zero-dimensional structures have fundamental limits. In this regard, our work suggests that the two-dimensional structure of perovskite nanosheets can be an alternative solution,"" concludes Prof. Kyhm.

","score: 16.45275351213282, grade_level: '16'","score: 17.686419923371652, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41377-023-01313-0,"Optical gain enhancement of two-dimensional CsPbBr3 nanosheets was studied when the amplified spontaneous emission is guided by a patterned structure of polyurethane-acrylate. Given the uncertainties and pitfalls in retrieving a gain coefficient from the variable stripe length method, a gain contour $$g(\hslash \omega ,x)$$ g ( ℏ ω , x ) was obtained in the plane of spectrum energy (ℏω) and stripe length (x), whereby an average gain was obtained, and gain saturation was analysed. Excitation and temperature dependence of the gain contour show that the waveguide enhances both gain and thermal stability due to the increased optical confinement and heat dissipation, and the gain origins were attributed to the two-dimensional excitons and the localized states."
"
Scientific researchers draw inspiration from nature's brilliance as they seek to develop transformative solutions to unresolved challenges. Prof. WANG Zuankai, Associate Vice President (Research and Innovation) and Chair Professor of the Department of Mechanical Engineering of The Hong Kong Polytechnic University (PolyU), has meticulously explored the intricacies of nature and made remarkable findings with very significant real-world applications. His recently published research on cooling ceramic successfully translates novel discovery into sustainable applications.

Findings from his research project ""Hierarchically structured passive radiative cooling ceramic with high solar reflectivity"" were published in the journal Science. Together with Prof. Christopher CHAO, Vice President (Research and Innovation), Chair Professor of Thermal and Environmental Engineering of PolyU and co-author of the paper, Prof. Wang collaborated with a research team from the City University of Hong Kong on this innovation.
With unwavering commitment to transformative research, the research team led by Prof. Chao and Prof. Wang has developed a passive radiative cooling ceramic (cooling ceramic) that can achieve highly efficient light scattering and a near-perfect solar reflectivity of 99.6%. This passive radiative cooling material demonstrates promising energy-saving potential with weather resistance and high mechanic strength, reducing the cooling demand of an indoor environment.
""Our work on cooling ceramic exemplifies the power of learning from nature. It addresses a significant research gap in passive radiative cooling, specifically high solar reflectivity. Taking inspiration from the bio-whiteness observed in the whitest beetle, the researchers optimised the design of the scattering system, leading to a significant increase in solar reflectivity,"" said Prof. Wang.
Beetle-inspired material to achieve 99.6% solar reflectivity
This innovation was derived from the intricate biological structure of Cyphochilus, the whitest known beetle. Based on investigation of the scattering system found in the beetle's scales, the cooling ceramic was engineered with a hierarchically porous structure. This nature-inspired system is easily fabricated and boasts excellent daytime cooling performance, thus reducing energy consumption for indoor cooling.
""Nature offers us an abundance of intricate designs, efficient systems and sustainable solutions that have evolved over millions of years. Through careful study of these natural phenomena, we can uncover innovative ideas and principles that can be translated into practical applications,"" said Prof. Wang.

This cooling ceramic also exemplifies Prof. Wang's pioneering structured thermal amour (STA), which has the potential to enable efficient water cooling at ultra-high solid temperatures -- an uncharted property. His previous research project, ""Inhibiting the Leidenfrost effect above 1,000°C for sustained thermal cooling,"" tackled the longstanding challenges posed by the Leidenfrost effect.
When the temperature surpasses the Leidenfrost point, a continuous vapour layer forms between a solid and a liquid, resulting in a decrease in heat transfer due to increased thermal resistance. Prof. Wang's innovative STA holds the potential to implement efficient liquid cooling at extremely high temperatures.
First-time investigation into the Leidenfrost effect
In applications involving evaporative cooling, the interaction between water and surfaces at high temperatures is a critical yet frequently overlooked phenomenon. Therefore, the suppression of the Leidenfrost effect is a major milestone in the successful development of this cooling ceramic, in addition to the bio-inspired whiteness and high solar reflectivity.
The cooling ceramic exhibits super-hydrophilicity, enabling immediate droplet spreading and facilitating rapid impregnation of the droplets through its interconnected porous structure. As a result, the cooling ceramic inhibits the Leidenfrost effect at temperatures above 800°C during the evaporative cooling process.
""One of the key factors contributing to the success of the cooling ceramic is its hierarchical porous structure, akin to the porous membrane used in the STA design. It is this intricate structure that enables the ceramic to effectively draw in and evaporate liquid, thereby efficiently inhibiting the Leidenfrost effect,"" said Prof. Wang.

It is the first time that the Leidenfrost effect has been investigated within the realm of passive radiative cooling materials. This novel exploration broadens the horizons of passive radiative cooling material design and also provides new insights for STA development and application.
The cooling ceramic's ingenuity lies in its ability to achieve multiple functionalities through simple fabrication and manipulation. Its key features, including high weather resistance, mechanical robustness, the ability to depress the Leidenfrost effect, favorable recyclability and its colour, contribute to its practical applications in diverse scenarios and building constructions. With its suitability for commercialisation and long-term outdoor applications, it also possesses advantages in terms of cost-effectiveness, durability and versatility.
Nature inspires scientific discovery and drives the development of impactful solutions through new materials, devices and systems. This is also the vision of the Research Centre for Nature-Inspired Science and Engineering at PolyU, led by Prof. Wang. The Centre is envisioned as a dynamic hub for innovation and collaboration, leveraging nature's brilliance to create transformative solutions for societal and environmental challenges.
""This cooling ceramic research breakthrough illustrates the practicality and versatility of our approach. The cooling ceramic not only exhibits exceptional cooling performance through its bio-inspired structure from the white beetle but also possess valuable features such as self-cleaning properties, robust mechanical strength and Leidenfrost effect depression. All these characteristics make it ready for real-world applications,"" said Prof. Wang.

","score: 17.668122065727704, grade_level: '18'","score: 19.27696009389671, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adi4725,"Passive radiative cooling using nanophotonic structures is limited by its high cost and poor compatibility with existing end uses, whereas polymeric photonic alternatives lack weather resistance and effective solar reflection. We developed a cellular ceramic that can achieve highly efficient light scattering and a near-perfect solar reflectivity of 99.6%. These qualities, coupled with high thermal emissivity, allow the ceramic to provide continuous subambient cooling in an outdoor setting with a cooling power of >130 watts per square meter at noon, demonstrating energy-saving potential on a worldwide scale. The color, weather resistance, mechanical robustness, and ability to depress the Leidenfrost effect are key features ensuring the durable and versatile nature of the cooling ceramic, thereby facilitating its commercialization in various applications, particularly building construction."
"
Coal is an abundant resource in the United States that has, unfortunately, contributed to climate change through its use as a fossil fuel. As the country transitions to other means of energy production, it will be important to consider and reevaluate coal's economic role. A joint research effort from the University of Illinois Urbana-Champaign, the National Energy Technology Laboratory, Oak Ridge National Laboratory and the Taiwan Semiconductor Manufacturing Company has shown how coal can play a vital role in next-generation electronic devices.

""Coal is usually thought of as something bulky and dirty, but the processing techniques we've developed can transform it into high-purity materials just a couple of atoms thick,"" said Qing Cao, a U. of I. materials science & engineering professor and a co-lead of the collaboration. ""Their unique atomic structures and properties are ideal for making some of the smallest possible electronics with performance superior to state-of-the art.""
A process developed by the NETL first converts coal char into nanoscale carbon disks called ""carbon dots"" that the U. of I. research group demonstrated can be connected to form atomically thin membranes for applications in both two-dimensional transistors and memristors, technologies that will be critical to constructing more advanced electronics. These results are reported in the journal Communications Engineering.
Perfect for 2D electronics
In the ongoing search for smaller, faster and more efficient electronics, the final step will be devices made with materials just one or two atoms thick. It is impossible for devices to be smaller than this limit, and their small scale often makes them operate much quicker and consume far less energy. While ultrathin semiconductors have been extensively studied, it is also necessary to have atomically thin insulators -- materials that block electric currents -- to construct working electronic devices like transistors and memristors.
Atomically thin layers of carbon with disordered atomic structures can function as an excellent insulator for constructing two-dimensional devices. The researchers in the collaboration have shown that such carbon layers can be formed from carbon dots derived from coal char. To demonstrate their capabilities, the U. of I. group led by Cao developed two examples of two-dimensional devices.
""It's really quite exciting, because this is the first time that coal, something we normally see as low-tech, has been directly linked to the cutting edge of microelectronics,"" Cao said.

Transistor dielectric
Cao's group used coal-derived carbon layers as the gate dielectric in two-dimensional transistors built on the semimetal graphene or semiconductor molybdenum disulfide to enable more than two times faster device operating speed with lower energy consumption. Like other atomically thin materials, the coal-derived carbon layers do not possess ""dangling bonds,"" or electrons that are not associated with a chemical bond. These sites, which are abundant on the surface of conventional three-dimensional insulators, alter their electrical properties by effectively functioning as ""traps,"" slowing down the transport of mobile charges and thus the transistor switching speed.
However, unlike other atomically thin materials, the new coal-derived carbon layers are amorphous, meaning that they do not possess a regular, crystalline structure. They therefore do not have boundaries between different crystalline regions that serve as conduction pathways leading to ""leakage,"" where undesired electrical currents flow through the insulator and cause substantial additional power consumption during device operations.
Memristor filament
Another application Cao's group considered is memristors -- electronic components capable of both storing and operating on data to greatly enhance the implementation of AI technology. These devices store and represent data by modulating a conductive filament formed by electrochemical reactions between a pair of electrodes with the insulator sandwiched in between.
The researchers found that the adoption of ultrathin coal-derived carbon layers as the insulator allows the fast formation of such filament with low energy consumption to enable high device operating speed with low power. Moreover, atomic size rings in these coal-derived carbon layers confine the filament to enhance the reproducible device operations for enhanced data storage fidelity and reliability.
From research to production
The new devices developed by the Cao group provide proof-of-principle for the use of coal-derived carbon layers in two-dimensional devices. What remains is to show that such devices can be manufactured on large scales.
""The semiconductor industry, including our collaborators at Taiwan Semiconductor, is very interested in the capabilities of two-dimensional devices, and we're trying to fulfill that promise,"" Cao said. ""Over the next few years, the U. of I. will continue to collaborate with NETL to develop a fabrication process for coal-based carbon insulators that can be implemented in industrial settings.""

","score: 17.789671860589298, grade_level: '18'","score: 19.212670258725304, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s44172-023-00141-9,"Materials keeping thickness in atomic scale but extending primarily in lateral dimensions offer properties attractive for many emerging applications. However, compared to crystalline counterparts, synthesis of atomically thin films in the highly disordered amorphous form, which avoids nonuniformity and defects associated with grain boundaries, is challenging due to their metastable nature. Here we present a scalable and solution-based strategy to prepare large-area, freestanding quasi-2D amorphous carbon nanomembranes with predominant sp2 bonding and thickness down to 1–2 atomic layers, from coal-derived carbon dots as precursors. These atomically thin amorphous carbon films are mechanically strong with modulus of 400 ± 100 GPa and demonstrate robust dielectric properties with high dielectric strength above 20 MV cm−1 and low leakage current density below 10−4 A cm−2 through a scaled thickness of three-atomic layers. They can be implemented as solution-deposited ultrathin gate dielectrics in transistors or ion-transport media in memristors, enabling exceptional device performance and spatiotemporal uniformity."
"
If you have a deep-seated, nagging worry over dropping your phone in molten lava, you're in luck.

A research team led by materials scientists at Duke University has developed a method for rapidly discovering a new class of materials with heat and electronic tolerances so rugged that they that could enable devices to function at lava-like temperatures above several thousands of degrees Fahrenheit.
Harder than steel and stable in chemically corrosive environments, these materials could also form the basis of new wear- and corrosion-resistant coatings, thermoelectrics, batteries, catalysts and radiation-resistant devices.
The recipes for these materials -- ceramics made using transition metals carbonitrides or borides -- were discovered through a new computational method called Disordered Enthalpy-Entropy Descriptor (DEED). In its first demonstration, the program predicted the synthesizability of 900 new formulations of high-performance materials, 17 of which were then tested and successfully produced in laboratories.
The results appear online January 3 in the journal Nature and include contributions from collaborators at Penn State University, Missouri University of Science and Technology, North Carolina State University, and State University of New York at Buffalo.
""The capability of rapidly discovering synthesizable compositions will allow researchers to focus on optimizing their industry-disrupting properties,"" said Stefano Curtarolo, the Edmund T. Pratt Jr. School Distinguished Professor of Mechanical Engineering and Materials Science at Duke.
The Curtarolo group maintains the Duke Automatic-FLOW for Materials Database (AFLOW) -- an enormous reservoir of material properties data connected to many online tools for materials optimization. This wealth of information allows algorithms to accurately predict the properties of unexplored mixtures without having to attempt to simulate the complexities of atomic dynamics or make them in the laboratory.

For the past several years, the Curtarolo group has been working to develop predictive powers for ""high-entropy"" materials that derive enhanced stability from a chaotic mixture of atoms rather than relying solely on the orderly atomic structure of conventional materials. In 2018, they discovered high-entropy carbides, which were a simpler, special-case scenario.
""The high-entropy carbides all had a relatively uniform amount of enthalpy, so we could ignore part of the equation,"" Curtarolo said. ""But to predict new ceramic recipes with other transition metals, we had to address the enthalpy.""
To better understand the concepts of entropy and enthalpy in this application, think of a 10-year-old trying to construct a doghouse out of a giant pile of Legos. Even with limited types of building blocks, there would be many possible design outcomes.
In simple terms, enthalpy is a measure of how sturdy each design is, and entropy a measure of the number of possible designs that all have similar strength. The first promotes ordered configurations, like those that might be found in instruction booklets. The latter captures the unavoidable chaos that would occur as the child puts more time and energy into the increasingly confusing construction effort. Both are a measure of the amount of energy and heat that end up being absorbed into the final product.
""To rapidly quantify both enthalpy and entropy, we had to calculate the energy contained within the hundreds of thousands of various combinations of ingredients that we could potentially create instead of the ceramics we're looking for,"" Curtarolo said. ""It was a mammoth undertaking.""
Besides predicting new recipes for stable disordered ceramics, DEED also helps direct their further analysis to discover their inherent properties. To find the optimal ceramics for various applications, researchers will need to refine these calculations and physically test them in laboratories.

DEED is specifically tailored to a production method called hot-pressed sintering. This involves taking powdered forms of the constituent compounds and heating them in a vacuum to as high as 4000 degrees Fahrenheit while applying pressure for times that can be as long as a few hours. Between all the preparation, reaction and cooling times, the entire process takes more than eight hours.
""The final step in synthesis, called spark plasma sintering, is an emerging method in materials science that is common in research labs,"" said William Fahrenholtz, the Curators' Distinguished Professor of Ceramic Engineering at Missouri S&T.
The finished ceramics have a metallic appearance and look dark grey or black. They feel like metal alloys such as stainless steel and have a similar density, but they are much darker in appearance. And even though they appear metallic, they are hard and brittle like conventional ceramics.
Moving forward, the group expects other researchers to begin using DEED to synthesize and test the properties of new ceramic materials for various applications. Given the incredible array of potential properties and uses, they believe it's only a matter of time before some of them enter commercial production.
""Spark plasma sintering or field assisted sintering technology (FAST) is not a common technique in industry yet,"" added Doug Wolfe, professor of materials science and engineering and associate vice president for research at Penn State. ""However, current ceramic manufacturers could pivot to making these materials by making small adjustments to existing processes and facilities.""
This research was primarily supported by a five-year, $7.5 million grant through the US Department of Defense's Multidisciplinary University Research Initiative (MURI) competition led by Curtarolo (N00014-21-1-2515, N00014-23-1-2615) and the Department of Defense High Performance Computing Modernization Program (HPC-Frontier).

","score: 16.005904330963155, grade_level: '16'","score: 17.3007094376212, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06786-y,"The need for improved functionalities in extreme environments is fuelling interest in high-entropy ceramics1–3. Except for the computational discovery of high-entropy carbides, performed with the entropy-forming-ability descriptor4, most innovation has been slowly driven by experimental means1–3. Hence, advancement in the field needs more theoretical contributions. Here we introduce disordered enthalpy–entropy descriptor (DEED), a descriptor that captures the balance between entropy gains and enthalpy costs, allowing the correct classification of functional synthesizability of multicomponent ceramics, regardless of chemistry and structure. To make our calculations possible, we have developed a convolutional algorithm that drastically reduces computational resources. Moreover, DEED guides the experimental discovery of new single-phase high-entropy carbonitrides and borides. This work, integrated into the AFLOW computational ecosystem, provides an array of potential new candidates, ripe for experimental discoveries."
"
Aptamers, nucleic acids1 capable of selectively binding to viruses, proteins, ions, small molecules, and various other targets, are garnering attention in drug development as potential antibody substitutes for their thermal and chemical stability as well as ability to inhibit specific enzymes or target proteins through three-dimensional binding. They also hold promise for swift diagnoses of colon cancer and other challenging diseases by targeting elusive biomarkers.2 Despite their utility, these aptamers are susceptible to easy degradation by multiple enzymes, presenting a significant challenge.

Professor Seung Soo Oh and his team from the Department of Materials Science and Engineering at Pohang University of Science and Technology (POSTECH), including Dr. Byunghwa Kang, and Dr. Soyeon V Park, have introduced a breakthrough approach using ionic liquids to address the challenges in functional nucleic acid research, paving the way for diverse applied research. Their findings have been published in Nucleic Acids Research.
Functional nucleic acids are termed as such for their versatility in not only storing and transmitting genetic information in living organisms but also in performing varied functions, such as detecting target molecules or catalyzing biochemical reactions similar to aptamers. However, these nucleic acids face obstacles in research applications due to vulnerability to degradation by hydrolases.3 Conventional preservation methods such as ultra-low-temperature cryogenic storage or chemical modification of nucleic acids fail to inhibit a wide array of enzymes, resulting in significant impairment of the nucleic acids' useful functions.
The team shifted away from the conventional belief that ""water is essential."" Although nucleic acids serve various roles and exhibit multiple functions in water, enzymes that break them down remain active in this medium. Hence, water acts as both the ""home"" and the ""graveyard"" for nucleic acids. The research team marked a significant milestone by globally validating the capability of nucleic acids to retain multiple functions in a choline dihydrogen phosphate-based ionic liquid. This ionic liquid, also present in our bodies, exhibits exceptional biocompatibility. The choline cation within the liquid effectively shields the negative charge of nucleic acids, preventing their contact with water and thereby fundamentally impeding hydrolysis.
In experiments, this liquid created an environment where nucleic acids resisted degradation regardless of the enzyme type, extending their half-life up to 6.5 million times. Even in extreme environments with a mix of seven different hydrolases, the nucleic acids remained completely intact and functional.
Furthermore, the team applied this innovation to enable aptamer-based biomolecular diagnostics within biological solutions for the first time. Previously, saliva containing numerous nucleic acid hydrolases made it impossible to use functional nucleic acids for biomarker detection. However, the team shielded the aptamers with an ionic liquid added to the saliva sample to achieve simple molecular diagnostics.
Professor Seung Soo Oh emphasized, ""By demonstrating that nucleic acids can maintain functionality even in unexplored or contaminated samples and body fluids, we've demonstrated their limitless application potential."" Dr. Byunghwa Kang expressed hope, stating, ""This research will significantly benefit the application of not only nucleic acids but also other molecules susceptible to hydrolysis.""
This research was conducted with support from various institutions, including grants from the National Research Foundation of Korea funded by the Ministry of Science and ICT, the Korea Evaluation Institute of Industrial Technology, the Institute of Civil Military Technology Cooperation funded by the Defense Acquisition Program Administration and the Ministry of Trade, Industry & Energy, the Korea Basic Science Institute, and the Brain Korea 21 FOUR project.

1. Nucleic acids Polymers composed of units called nucleotides. These are two types: DNA and RNA.
2. Biomarker An indicator that can objectively measure the normal or pathological state of an organism, the degree of response to a drug, etc., using proteins, DNA, RNA, metabolites, etc.
3. Hydrolase An enzyme that catalyzes a reaction that breaks down chemical bonds using water

","score: 16.798375619714204, grade_level: '17'","score: 17.587920676582094, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/nar/gkad1093,"Beyond storage and transmission of genetic information in cellular life, nucleic acids can perform diverse interesting functions, including specific target recognition and biochemical reaction acceleration; the versatile biopolymers, however, are acutely vulnerable to hydrolysis-driven degradation. Here, we demonstrate that the cage effect of choline dihydrogen phosphate permits active folding of nucleic acids like water, but prevents their phosphodiester hydrolysis unlike water. The choline-based ionic liquid not only serves as a universal inhibitor of nucleases, exceptionally extending half-lives of nucleic acids up to 6 500 000 times, but highly useful tasks of nucleic acids (e.g. mRNA detection of molecular beacons, ligand recognition of aptamers, and transesterification reaction of ribozymes) can be also conducted with well-conserved affinities and specificities. As liberated from the function loss and degradation risk, the presence of undesired and unknown nucleases does not undermine desired molecular functions of nucleic acids without hydrolysis artifacts even in nuclease cocktails and human saliva."
"
A team of researchers led by Professor Young S. Park at UNIST's Department of Chemistry has achieved a significant breakthrough in the field of organic semiconductors. Their successful synthesis and characterization of a novel molecule called ""BNBN anthracene"" has opened up new possibilities for the development of advanced electronic devices.

Organic semiconductors play a crucial role in improving the movement and light properties of electrons in carbon-centered organic electronic devices. The team's research focused on enhancing the chemical diversity of these semiconductors by replacing carbon-carbon (C−C) bonds with isoelectronic boron-nitrogen (B−N) bonds. This substitution allows for precise modulation of the electronic properties without significant structural changes.
The researchers successfully synthesized the BNBN anthracene derivative, which contains a continuous BNBN unit formed by converting the BOBN unit at the zigzag edge. Compared to conventional anthracene derivatives composed solely of carbon, the BNBN anthracene exhibited significant variations in the C−C bond length and a larger highest occupied molecular orbital-lowest unoccupied molecular orbital energy gap.
In addition to its unique properties, the BNBN anthracene derivative demonstrated promising potential for application in organic electronics. When used as the blue host in an organic light-emitting diode (OLED), the BOBN anthracene exhibited a remarkably low driving voltage of 3.1V, along with higher efficiency in terms of current utilization, energy efficiency, and light emission.
The research team further confirmed the properties of the BNBN anthracene derivative by studying its crystal structure using an X-ray diffractometer. This analysis revealed structural changes, such as bonding length and angle, resulting from the boron-nitrogen (BN) bonding.
""Our study on anthracene, a type of acene widely recognized as an organic semiconductor, has laid the groundwork for future advancements in the field,"" commented Songhua Jeong (Combined MS/Ph.D. Program of Chemistry, UNIST), the first author of this study. ""The continuous BN bonding synthesized through this research holds great potential for applications in organic semiconductors.""
Professor Park emphasized the significance of this breakthrough, stating, ""The synthesis and characterization of compounds with continuous boron-nitrogen (BN) bonds contribute to fundamental research in chemistry. It provides a valuable tool for synthesizing new compounds and controlling their electronic properties.""
The research findings, which also involve the contributions of Professor Joonghan Kim's team from the Catholic University of Korea, Professor Wonyoung Choe's team from the Department of Chemistry at UNIST, and a research team from SFC Co., Ltd., were published online on December 11 in the journal, Angewande Chemie International Edition. The study received support from the mid-sized research enterprise SFC and was promoted by the National Research Foundation (NRF) of the Ministry of Science and ICT, under the projects of the Ministry of Trade, Industry, and Energy.

","score: 17.40808302808303, grade_level: '17'","score: 18.475130647130648, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/anie.202314148,"Increasing the chemical diversity of organic semiconductors is essential to develop efficient electronic devices. In particular, the replacement of carbon‐carbon (C−C) bonds with isoelectronic boron‐nitrogen (B−N) bonds allows precise modulation of the electronic properties of semiconductors without significant structural changes. Although some researchers have reported the preparation of B2N2 anthracene derivatives with two B−N bonds, no compounds with continuous multiple BN units have been prepared yet. Herein, we report the synthesis and characterization of a B2N2 anthracene derivative with a BNBN unit formed by converting the BOBN unit at the zigzag edge. Compared to the all‐carbon analogue 2‐phenylanthracene, BNBN anthracene exhibits significant variations in the C−C bond length and a larger highest occupied molecular orbital–lowest unoccupied molecular orbital energy gap. The experimentally determined bond lengths and electronic properties of BNBN anthracene are confirmed through theoretical calculations. The BOBN anthracene organic light‐emitting diode, used as a blue host, exhibits a low driving voltage. The findings of this study may facilitate the development of larger acenes with multiple BN units and potential applications in organic electronics."
"
A research group has developed a high-speed, high-sensitivity terahertz-wave detector operating at room temperature, paving the way for advancements in the development of next generation 6G/7G technology.

Details of their breakthrough were published in the journal Nanophotonics on November 9, 2023.
The enhancement of current communications speeds will rely on terahertz (THz) waves. THz waves are electromagnetic waves within the THz range, which falls between the microwave and infrared portions of the electromagnetic spectrum, typically spanning frequencies from 300 gigahertz to 3 THz.
Still, the fast and sensitive detection of THz waves at room temperature is challenging for conventional electronic- or photonic-based semiconductor devices.
This is where two-dimensional plasmons come in. In a semiconductor field-effect transistor, there is a two-dimensional electron channel where a collective charge-density quanta, i.e., two-dimensional plasmons, exist. These plasmons are excited states of electrons exhibiting fluid-like behaviors. Their nonlinear rectification effects, originating from these fluid-like behaviors, and their rapid response (not constrained by electron transit time) make them a promising means to detect THz waves at room temperature.
""We discovered a 3D plasmonic rectification effect in THz wave detector,"" says Akira Satou, leader of the research group and associate professor at Tohoku University's Research Institute for Electrical Communication (RIEC). ""The detector was based on an indium-phosphide high-electron mobility transistor and it enabled us to enhance the detection sensitivity more than one order of magnitude higher than conventional detectors based on 2D plasmons.""
The new detection method combined the traditional vertical hydrodynamic nonlinear rectification effect of 2D plasmons with the addition of a vertical diode-current nonlinearity.
It also dramatically resolved the waveform distortion caused by multiple reflections of high-speed modulated signals -- a critical issue in conventional detectors based on 2D plasmons.
Leading the group alongside Satou was Specially Appointed Professor Tetsuya Suemitsu from Tohoku University's New Industry Creation Hatchery Center and Hiroaki Minamide from RIKEN Center for Advanced Photonics.
""Our new detection mechanism overcomes most of the bottlenecks in conventional terahertz-wave detectors,"" adds Satou. ""Looking ahead, we hope to build on our achievement by improving the device performance.""

","score: 17.119469373219378, grade_level: '17'","score: 17.919519230769232, grade_levels: ['college_graduate'], ages: [24, 100]",10.1515/nanoph-2023-0256,"We experimentally investigated the asymmetric dual-grating-gate plasmonic terahertz (THz) detector based on an InGaAs-channel high-electron-mobility transistor (HEMT) in the gate-readout configuration. Throughout the THz pulse detection measurement on the fabricated device, we discovered a new detection mechanism called the “3D rectification effect” at the positive gate bias application, which is a cooperative effect of the plasmonic nonlinearities in the channel with the diode nonlinearity in the heterobarrier between the InGaAs channel layer and the InAlAs spacer/carrier-supply/barrier layers, resulting in a giant enhancement of the detector responsivity. We also found that an undesired long-tail waveform observed on the temporal pulse photoresponse of the device is due to trapping of carriers to the donor levels in the silicon δ-doped carrier-supply layer when they tunnel through the barrier to the gate and can be eliminated completely by introducing the so-called inverted-HEMT structure. The internal current responsivity and noise-equivalent power are estimated to be 0.49 A/W (with the equivalent voltage responsivity of 4.9 kV/W with a high output impedance of 10 kΩ) and 196 pW/√Hz at 0.8 THz. These results pave the way towards the application of the plasmonic THz detectors to beyond-5G THz wireless communication systems."
"
An international research group has engineered a novel high-strength flexible device by combining piezoelectric composites with unidirectional carbon fiber (UDCF), an anisotropic material that provides strength only in the direction of the fibers. The new device transforms kinetic energy from the human motion into electricity, providing an efficient and reliable means for high-strength and self-powered sensors.

Details of the group's research were published in the journal Small on Dec.14, 2023.
Motion diction involves converting energy from the human motion into measurable electrical signals and is something crucial for ensuring a sustainable future.
""Everyday items, from protective gears to sports equipment, are connected to the internet as part of the Internet of Things (IoT), and many of them are equipped with sensors that collect data,"" says Fumio Narita, co-author of the study and professor at Tohoku University's Graduate School of Environmental Studies. ""And effective integration of these IoT devices into personal gear requires innovative solutions in power management and material design to ensure durability, flexibility.""
Mechanical energy can be utilized thanks to piezoelectric materials' ability to generate electricity when physically stressed. Meanwhile, carbon fiber lends itself to applications in the aerospace and automotive industries, sports equipment, and medical equipment because of its durability and lightness.
""We wondered if personal protective equipment, made flexible using a combination of carbon fiber and a piezoelectric composite, could offer comfort, more durability, and sensing capabilities,"" says Narita.
The group fabricated the device using a combination of unidirectional carbon fiber fabric (UDCF) and potassium sodium niobate (KNN) nanoparticles mixed with epoxy (EP) resin. The UDCF served as both an electrode and a directional reinforcement.
The so-called UDCF/KNN-EP device lived up to its expectations. Tests revealed that it could maintain high performance even after being stretched more than 1000 times. It has been proven that it can withstand a much higher load when pulled along the fiber direction compared to other flexible materials. Additionally, when subjected to impacts and stretching perpendicular to the fiber direction, it surpasses other piezoelectric polymers in terms of energy output density. Notably, the mechanical and piezoelectric responses of UDCF/KNN-EP were analyzed using multiscale simulations in collaboration with Professor Uetsuji's group at the Osaka Institute of Technology.
The UDCF/KNN-EP will help propel the development of flexible self-powered IoT sensors, leading to advanced multifunctional IoT devices.
Narita and his colleagues are also excited about the technological advancements of their breakthrough. ""CF/KNN-EP was integrated into sports equipment and accurately detected the impact from catching a baseball and a person's step frequency. In our work, the high strength of CFs was leveraged to improve the sustainability and reliability of battery-free sensors while maintaining their directional stretchability and provides valuable insights and guidance for future research in the field of motion detection.""

","score: 16.876786324786327, grade_level: '17'","score: 17.533653846153847, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/smll.202307689,"Piezoelectric composite materials can convert mechanical energy into electrical energy, thus promoting battery‐free motion‐sensing systems. However, their substandard mechanical performance limits the capability of sensors developed using flexible piezoelectric materials. This study introduces a novel design strategy for preparing high‐strength flexible piezoelectric composite materials comprising unidirectional carbon fiber–reinforced potassium sodium niobate (K0.5Na0.5NbO3) nanoparticle–filled epoxy resin (UDCF/KNN–EP). The fibers significantly improve the Young's modulus of UDCF/KNN–EP along the fiber direction, which reaches 282.5 MPa. Moreover, the composite exhibits excellent stretchability and piezoelectric response () in the cross‐fiber direction under cyclic tensile loading. Multiscale finite element analysis is performed via simulation, which allows theoretical examination of the experimental results and the material's mechanical response mechanism. Finally, UDCF/KNN–EP is seamlessly incorporated into athletic gear and used to measure the impact caused by baseball catching and track footfall patterns. This study harnesses the superior strength of carbon fibers to enhance the durability and dependability of self‐powered sensors without compromising flexibility in specific directions."
"
Of the world's various weather phenomena, fog is perhaps the most mysterious, forming and dissipating near the ground with fluctuations in air temperature and humidity interacting with the terrain itself.

While fog presents a major hazard to transportation safety, meteorologists have yet to figure out how to forecast it with the precision they have achieved for precipitation, wind and other stormy events.
This is because the physical processes resulting in fog formation are extremely complex, according to Zhaoxia Pu, a professor of atmospheric sciences at the University of Utah.
""Our understanding is limited. In order to accurately forecast fog we should better understand the process that controls fog formation,"" said Pu, who led a fog study focusing on a northern Utah valley.
Now, in a recent paper published by the American Meteorological Society, Pu and her colleagues have reported their findings from the Cold Fog Amongst Complex Terrain (CFACT) project, conceived to investigate the life cycle of cold fog in mountain valleys.
Also working on the project, funded by a $1.17 million grant from the National Science Foundation, were several other members of the U Department of Atmospheric Sciences, including Gannet Hallar and Sebastian Hoch, along with Eric Pardyjak of the Department of Mechanical Engineering, a group of scientists from the National Center for Atmospheric Research (NCAR), and Dr. Ismail Gultepe from Ontario Tech University, Canada.
Because it reduces visibility, fog poses serious hazards to the traveling public. For example, fog is the second leading cause of aircraft accidents after high winds. It leads to automobile crashes and disrupts ferry operations.

Between 1995 and 2004 in the United States, 13,720 have died in fog-related accidents.
Improving fog forecasting would make traveling more safe, Pu said.
Today, most forecasting uses a computer model known as Numerical Weather Prediction (NWP), which processes massive meteorological observations with computer models to output predictions for precipitation, temperature, and all sorts of other elements of the weather. However the current computer model doesn't work well for fog, and Pu's team hopes that improvements can be made using the masses of data they gathered over seven weeks in the winter of 2022 at several sites in the Heber Valley.
""Fog involves a lot of physics processes so it requires a computer model that can better represent all these processes,"" Pu said. ""Because fog is clouds near the ground, it requires a high-resolution model to resolve it, so we need models at a very fine scale, which are computationally very expensive. The current models (relatively coarser in resolution) are not capable of resolving the fog processes, and we need to improve the models for better fog prediction.""
Located bout 50 miles southeast of Salt Lake City, Heber Valley is nestled behind the Wasatch Mountains and framed by two major reservoirs on the Provo River.
This scenic basin is a typical mountain valley, hemmed by Mt. Timpanogos and other high peaks, with the reservoirs serving as a moisture source. The seven-week study window covered the time of year when Heber Valley is the foggiest.

Valley fog is a perfect example of how topography and atmospheric processes converge to create a distinctive weather phenomenon.
The ground is cooling overnight while denser, cooler air drops from mountain tops collecting in the valleys, in a phenomenon known as ""cold air drainage."" Cooled by the ground, the dropping air temperature can approach the dew point, and if there is sufficient moisture in the air, fog begins to form, becoming the most dense around sunrise when surface temperatures are lowest.
Winter nights create favorable conditions for different forms of fog, such as cold-air pool fog, ephemeral mountain valley fog and radiative ice fog.
The Heber Valley project homed in on cold-air fog which forms in freezing temperatures below zero degrees Celsius, according to Pu. However by observing how these varying kinds of fog form and dissipate, the researchers are continuing to learn about the meteorological conditions and physical processes governing the formation of fog.
For the CFACT study, the NCAR and U team set up two major data-collecting stations, one near Deer Creek Reservoir and another a few miles up the Provo River. These are low spots in the valley, about 5,450 feet above sea level, that see the densest fog. These sites were equipped with 100-foot towers to support an array of instruments that captured various meteorological data associated with humidity, wind, visibility, temperature, even snow depths, and soil moisture. The recordings were made from both in situ and remote-sensing platforms.
Additionally, the team recorded a lesser array of data points at nine satellite sites.
During the seven-week CFACT field campaign, nine intensive observation periods (IOPs), each conducted over 24-hour periods, yielded a dataset that included high-frequency radiosonde profiles, tethered balloon profiles, remotely sensed thermodynamic and wind profiles, surface meteorological observations and microphysical and aerosol measurements.
Besides fog IOPs, the variety of non-fog IOPs provided valuable observations for understanding near-surface inversion, ice crystal formation, moisture advection and transportation, and stable boundary layers over complex terrain, all of which are essential factors related to fog formation. Comprehensive studies are ongoing for an improved understanding of cold fog over complex terrain.
The study appeared Nov. 15 in the Bulletin of the American Meteorological Society. U researchers involved with the study included Zhaoxia Pu, Sebastian Hoch, A. Gannet Hallar, Rebecca Beal, Geraldo Carrillo-Cardenas, Xin Li and Maria Garcia of the Department of Atmospheric Sciences and Eric Pardyjak and Alexei Perelet of the Department of Mechanical Engineering.

","score: 14.98321386603995, grade_level: '15'","score: 16.078062867215046, grade_levels: ['college_graduate'], ages: [24, 100]",10.1175/BAMS-D-22-0030.1,"Cold fog forms via various thermodynamic, dynamic, and microphysical processes when the air temperature is less than 0°C. It occurs frequently during the cold season in the western United States yet is challenging to detect using standard observations and is very difficult to predict. The Cold Fog Amongst Complex Terrain (CFACT) project was conceived to investigate the life cycle of cold fog in mountain valleys. The overarching goals of the CFACT project are to 1) investigate the life cycle of cold-fog events over complex terrain with the latest observation technology, 2) improve microphysical parameterizations and visibility algorithms used in numerical weather prediction (NWP) models, and 3) develop data assimilation and analysis methods for current and next-generation (e.g., subkilometer scale) NWP models. The CFACT field campaign took place in Heber Valley, Utah, during January and February 2022, with support from NSF’s Lower Atmospheric Observing Facilities (managed by NCAR’s Earth Observing Laboratory), the University of Utah, and Ontario Technical University. A network of ground-based and aerial in situ instruments and remote sensing platforms were used to obtain comprehensive measurements of thermodynamic profiles, cloud microphysics, aerosol properties, and environmental dynamics. Nine intensive observation periods (IOPs) explored various mountainous weather and cold-fog conditions. Field observations, NWP forecasts, and large-eddy simulations provided unprecedented data sources to help understand the mechanisms associated with cold-fog weather and to identify and mitigate numerical model deficiencies in simulating winter weather over mountainous terrain. This article summarizes the CFACT field campaign, its observations, and challenges during the field campaign, including real-time fog prediction issues and future analysis."
"
Writing in Nature Communicationson November 24, engineers at Columbia and theoretical collaborators at the Max Planck for the Structure and Dynamics of Matter find that pairing laser light to crystal lattice vibrations can enhance the nonlinear optical properties of a layered 2D material.

Cecilia Chen, a Columbia Engineering PhD student and co-author of the recent paper, and her colleagues from Alexander Gaeta's Quantum and Nonlinear Photonics group used hexagonal boron nitride (hBN). hBN is a 2D material similar to graphene: its atoms are arranged in a honey-combed-shaped repeating pattern and can be peeled into thin layers with unique quantum properties. Chen noted that hBN is stable at room temperature, and its constituent elements -- boron and nitrogen -- are very light. That means they vibrate very quickly.
Atomic vibrations occur in all materials above absolute zero. That movement can be quantized into quasiparticles called phonons with particular resonances; in hBN's case, the team was interested in the optical phonon mode vibrating at 41 THz, corresponding to a wavelength of 7.3 μm, which is in the mid-infrared regime of the electromagnetic spectrum. While mid-IR wavelengths are considered short, and thus, high energy, in the picture of crystal vibrations, they are considered very long and low energy in most optics research with lasers, where the overwhelming majority of experiments and studies are performed in the visible to near-IR range of approximately 400 nm to 2 um.
When they tuned their laser system to hBN's frequency corresponding to 7.3 μm, Chen, along with fellow PhD student Jared Ginsberg (now a data scientist at Bank of America) and postdoc Mehdi Jadidi (now a Team Lead at quantum computing company PsiQuantum), were able to coherently and simultaneously drive the phonons and electrons of the hBN crystal to efficiently generate new optical frequencies from the medium -- an essential goal of nonlinear optics. Theoretical work led by Professor Angel Rubio's group at Max Planck helped the experimental team understand their results.
Using commercially available, table-top mid-infrared lasers, they explored the phonon-mediated nonlinear optical process of four-wave mixing to generate light close to even harmonics of an optical signal. They also observed greater than a 30-fold increase in third-harmonic generation over what is achieved without exciting the phonons.
""We're excited to show that amplifying the natural phonon motion with laser driving can enhance nonlinear optical effects and generate new frequencies,"" said Chen. The team plans to explore how they might be able to modify hBN and materials like it using light in future work.

","score: 17.489242891401165, grade_level: '17'","score: 18.69580678314491, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43501-x,"Polar crystals can be driven into collective oscillations by optical fields tuned to precise resonance frequencies. As the amplitude of the excited phonon modes increases, novel processes scaling non-linearly with the applied fields begin to contribute to the dynamics of the atomic system. Here we show two such optical nonlinearities that are induced and enhanced by the strong phonon resonance in the van der Waals crystal hexagonal boron nitride (hBN). We predict and observe large sub-picosecond duration signals due to four-wave mixing (FWM) during resonant excitation. The resulting FWM signal allows for time-resolved observation of the crystal motion. In addition, we observe enhancements of third-harmonic generation with resonant pumping at the hBN transverse optical phonon. Phonon-induced nonlinear enhancements are also predicted to yield large increases in high-harmonic efficiencies beyond the third."
"
Researchers led by Genki Kobayashi at the RIKEN Cluster for Pioneering Research in Japan have developed a solid electrolyte for transporting hydride ions (H?) at room temperature. This breakthrough means that the advantages of hydrogen-based solid-state batteries and fuel cells are within practical reach, including improved safety, efficiency, and energy density, which are essential for advancing towards a practical hydrogen-based energy economy.The study was published in the scientific journal Advanced Energy Materials.

For hydrogen-based energy storage and fuel to become more widespread, it needs to be safe, very efficient, and as simple as possible. Current hydrogen-based fuel cells used in electric cars work by allowing hydrogen protons to pass from one end of the fuel cell to the other through a polymer membrane when generating energy. Efficient, high-speed hydrogen movement in these fuel cells requires water, meaning that the membrane must be continually hydrated so that it does not dry out. This constraint adds an additional layer of complexity and cost to battery and fuel cell design that limits the practicality of a next-generation hydrogen-based energy economy. To overcome this problem, scientists have been struggling to find a way to conduct negative hydride ions through solid materials, particularly at room temperature.
The wait is over. ""We have achieved a true milestone,"" says Kobayashi. ""Our result is the first demonstration of a hydride ion-conducting solid electrolyte at room temperature.""
The team had been experimenting with lanthanum hydrides (LaH3-?) for several reasons; the hydrogen can be released and captured relatively easily, hydride ion conduction is very high, they can work below 100°C, and have a crystal structure. But, at room temperature, the number of hydrogens attached to lanthanum fluctuates between 2 and 3, making it impossible to have efficient conduction. This problem is called hydrogen non-stoichiometry, and was the biggest obstacle overcome in the new study. When the researchers replaced some of the lanthanum with strontium (Sr) and added just a pinch of oxygen -- for a basic formula of La1-xSrxH3-x-2yOy, they got the results they were hoping for.
The team prepared crystalline samples of the material using a process called ball-milling, followed by annealing. They studied the samples at room temperature and found that they could conduct hydride ions at a high rate. Then, they tested its performance in a solid-state fuel cell made from the new material and titanium, varying the amounts of strontium and oxygen in the formula. With an optimal value of at least 0.2 strontium, they observed complete 100% conversion of titanium to titanium hydride, or TiH2. This means that almost zero hydride ions were wasted.
""In the short-term, our results provide material design guidelines for hydride ion-conducting solid electrolytes,"" says Kobayashi. ""In the long-term, we believe this is an inflection point in the development of batteries, fuel cells, and electrolytic cells that operate by using hydrogen."" The next step will be to improve performance and create electrode materials that can reversibly absorb and release hydrogen. This would allow batteries to be recharged, as well as make it possible to place hydrogen in storage and easily release it when needed, which is a requirement for hydrogen-based energy use.

","score: 13.467897397769516, grade_level: '13'","score: 13.9042936802974, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/aenm.202301993,"Hydride ion conductors have made remarkable progress in recent years; in particular, the fluorite‐type LaH3‐δ series exhibits high conductivity around room temperature. However, its intrinsic character of hydrogen non‐stoichiometry still makes its application as a solid electrolyte challenging, for which high electronic insulation is essential. Here, Sr‐substituted LaH3‐δ with slight O2− incorporation, represented as La1‐xSrxH3‐x‐2yOy (0.1 ≤ x ≤ 0.6, y ≤ 0.171), is synthesized, which exhibits H− conductivity of 10−4 – 10−5 S cm−1 at room temperature. The galvanostatic discharge reaction using an all‐solid‐state cell composed of Ti|La1‐xSrxH3‐x‐2yOy|LaH3‐δ shows that the Ti electrode is completely hydrogenated to TiH2 for x ≥ 0.2, whereas a short circuit occurs for x = 0.1. These experimental observations, together with calculation studies on the density of states and the defect formation energy, provide clear evidence that electropositive cation, such as Sr, doping critically suppresses the electron conduction in LaH3‐δ. Achieving a superior H− conducting solid electrolyte is a novel milestone in the development of electrochemical devices that utilize its strong reducing ability (E°(H−/H2) = −2.25 V vs SHE), such as batteries with high energy density and electrolysis/fuel cells with high efficiency."
"
A pancake stack of radioactivity-sensitive films carried through the sky by a balloon was able to take the world's most accurate picture of a neutron star's gamma ray beam. To achieve this, Kobe University researchers combined the oldest method of capturing radioactive radiation with the newest data capturing techniques and a clever time-recording device.

The stars shine their light on us in the full range of the spectrum of light, from infra-red to gamma rays. For each of these bands, different sensing equipment is needed. The most challenging one is gamma rays, famous for being a high-energy product of nuclear fission, because their very short wavelength means that they don't interact with matter in the same way as other forms of light and thus can't be deflected with lenses or detected by standard sensors. Thus, there is a gap in our ability to detect the light coming from fascinating stellar objects such as supernovae and their remnants.
To resolve this issue, Kobe University astrophysicist AOKI Shigeki and his team turned to the very first material that was used to detect radioactivity, photographic films. ""Our group has been focusing on the excellent capability of emulsion film to trace gamma rays with high precision and proposed that it could become an excellent gamma-ray telescope by introducing several modern data capture and analysis features,"" explains Aoki. Based on the high sensitivity of these films and a novel, automated, high-speed process of extracting data from them, the physicists' idea was to stack up a few of them to accurately capture the trajectory of the particles that the gamma ray produces on impact, just like a single pancake may capture where you poke a straw into it, but it takes a whole stack to record the straw's direction.
To reduce atmospheric interference, they then mounted the stack of films onto a scientific observation balloon to lift it to a height between 35 and 40 kilometers. However, since a balloon is swaying and twisting in the wind, the direction of the ""telescope"" is not stable, so they added a set of cameras to record the gondola's orientation relative to the stars at any time. But this created another issue, because as anybody who has ever taken a photograph with long exposure knows, photographic film does not record the passage of time and so it is not directly possible to know at what time any given gamma ray impact occurred. To overcome this problem, they made the bottom three layers of film move back and forth at regular but different speeds, just like the hands of a clock. From the relative dislocation of the traces in those lower plates they could then calculate the precise time of the impact and thus correlate it with the cameras' footage.
They have now published the first image resulting from this setup in the journal The Astrophysical Journal. It is the most accurate image ever produced of the Vela pulsar, a fast-spinning neutron star that projects a beam of gamma rays into the sky like a lighthouse at night. ""We captured a total of several trillion tracks with an accuracy of 1/10,000 millimeters. By adding time information and combining it with attitude monitoring information, we were able to determine 'when' and 'where' the events originated with such precision that the resulting resolution was more than 40 times higher than that of conventional gamma-ray telescopes,"" Aoki summarizes his group's achievements.
While these results are impressive already, the new technique opens the possibility of capturing more details in this frequency band of light than ever before. The Kobe University researcher explains, ""By means of scientific balloon-borne experiments, we can attempt to contribute to many areas of astrophysics, and in particular to open up gamma-ray telescopy to 'multi-messenger astronomy' where simultaneous measurements of the same event captured through different techniques are required. Based on the success of the 2018 balloon experiment these data were generated with, we will expand the observation area and time in upcoming balloon flights and are looking forward to scientific breakthroughs in the field of gamma-ray astronomy.""
This work was supported by JSPS KAKENHI grants 17H06132, 18H01228 and 18K13562. It was conducted in collaboration with researchers from Okayama University of Science, Aichi University of Education, Nagoya University and Gifu University.

","score: 16.360618612807645, grade_level: '16'","score: 17.992813085807583, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/ad0973,"We are developing the Gamma-Ray Astro-Imager with Nuclear Emulsion project, designed for 10 MeV–100 GeV cosmic γ-ray observations with a high angular resolution (5′/0.°08 at 1–2 GeV) and a polarization-sensitive large-aperture (∼10 m2) emulsion telescope for repeated long-duration balloon flights. In 2018, a balloon-borne experiment was carried out in Australia with a 0.38 m2 sensitive area and a flight duration of 17.4 hr, including 6.7 hr of Vela observations. Significant improvements compared with the 2015 balloon-borne experiment were achieved by a factor of 5, including both an increase in effective area × time and a reduction in the background contribution. We aimed to demonstrate the telescope’s overall performance based on detection and imaging of a known γ-ray source, the Vela pulsar. A robust detection of the Vela pulsar was achieved with a 68% containment radius of 0.°42, at a significance of 6σ, at energies above 80 MeV. The resulting angular profile is consistent with that of a pointlike source. We achieved the current best imaging performance of the Vela pulsar using an emulsion γ-ray telescope with the highest angular resolution of any γ-ray telescope to date."
"
A research team at Osaka Metropolitan University has fabricated a gallium nitride (GaN) transistor using diamond, which of all natural materials has the highest thermal conductivity on earth, as a substrate, and they succeeded in increasing heat dissipation by more than two times compared with conventional transistors. The transistor is expected to be useful not only in the fields of 5G communication base stations, weather radar, and satellite communications, but also in microwave heating and plasma processing.

Researchers at Osaka Metropolitan University are proving that diamonds are so much more than just a 'girl's best friend.' Their groundbreaking research focuses on gallium nitride (GaN) transistors, which are high-power, high-frequency semiconductor devices used in mobile data and satellite communication systems.
With the increasing miniaturization of semiconductor devices, problems arise such as increases in power density and heat generation that can affect the performance, reliability, and lifetime of these devices. Therefore, effective thermal management is crucial. Diamond, which has the highest thermal conductivity of all natural materials, is an ideal substrate material but has not yet been put to practical use due to the difficulties of bonding diamond to GaN elements.
A research team led by Associate Professor Jianbo Liang and Professor Naoteru Shigekawa of the Graduate School of Engineering at Osaka Metropolitan University has successfully fabricated GaN High Electron Mobility Transistors using diamond as a substrate. This novel technology has more than twice the heat dissipation performance of transistors of the same shape fabricated on a silicon carbide (SiC) substrate. To maximize the high thermal conductivity of diamond, the researchers integrated a 3C-SiC layer, a cubic polytype of silicon carbide, between GaN and diamond. This technique significantly reduces the thermal resistance of the interface and improves heat dissipation.
""This new technology has the potential to significantly reduce CO2 emissions and potentially revolutionize the development of power and radio frequency electronics with improved thermal management capabilities,"" said Professor Liang.

","score: 18.106458333333332, grade_level: '18'","score: 19.294927083333334, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/smll.202305574,"Thermal management is critical in contemporary electronic systems, and integrating diamond with semiconductors offers the most promising solution to improve heat dissipation. However, developing a technique that can fully exploit the high thermal conductivity of diamond, withstand high‐temperature annealing processes, and enable mass production is a significant challenge. In this study, the successful transfer of AlGaN/GaN/3C‐SiC layers grown on Si to a large‐size diamond substrate is demonstrated, followed by the fabrication of GaN high electron mobility transistors (HEMTs) on the diamond. Notably, no exfoliation of 3C‐SiC/diamond bonding interfaces is observed even after annealing at 1100 °C, which is essential for high‐quality GaN crystal growth on the diamond. The thermal boundary conductance of the 3C‐SiC‐diamond interface reaches ≈55 MW m−2 K−1, which is efficient for device cooling. GaN HEMTs fabricated on the diamond substrate exhibit the highest maximum drain current and the lowest surface temperature compared to those on Si and SiC substrates. Furthermore, the device thermal resistance of GaN HEMTs on the diamond substrate is significantly reduced compared to those on SiC substrates. These results indicate that the GaN/3C‐SiC on diamond technique has the potential to revolutionize the development of power and radio‐frequency electronics with improved thermal management capabilities."
"
Researchers at the University of Sussex have discovered the transformative potential of Martian nanomaterials, potentially opening the door to sustainable habitation on the red planet.

Using resources and techniques currently applied on the International Space Station and by NASA, Dr Conor Boland, a Lecturer in Materials Physics at the University of Sussex, led a research group that investigated the potential of nanomaterials -- incredibly tiny components thousands of times smaller than a human hair -- for clean energy production and building materials on Mars.
Taking what was considered a waste product by NASA and applying only sustainable production methods, including water-based chemistry and low-energy processes, the researchers have successfully identified electrical properties within gypsum nanomaterials -- opening the door to potential clean energy and sustainable technology production on Mars.
Dr Conor Boland, said:
""This study shows that the potential is quite literally out of this world for nanomaterials. Our study builds off recent research performed by NASA and takes what was considered waste, essentially lumps of rock, and turns it into transformative nanomaterials for a range of applications from creating clean hydrogen fuel to developing an electronic device similar to a transistor, to creating an additive to textiles to increase their robustness.
""This opens avenues for sustainable technology -- and building -- on Mars but also highlights the broader potential for eco-friendly breakthroughs here on Earth.""
To make the breakthrough the researchers used NASA's innovative method for extracting water from Martian gypsum, which is dehydrated by the agency to get water for human consumption. This produces a byproduct called anhydrite -- considered waste material by NASA, but now shown to be hugely valuable.

The Sussex researchers processed anhydrite into nanobelts -- essentially tagliatelle-shaped materials -- demonstrating their potential to provide clean energy and sustainable electronics. Furthermore, at every step of their process, water could be continuously collected and recycled.
Dr Boland added:
""We are optimistic of the feasibility of this process on Mars, as it requires only naturally occurring materials -- everything we used could, in theory, be replicated on the red planet. Arguably this is the most important goal in making the Martian colony sustainable from the outset.""
While full-scale electronics production may be impractical on Mars due to the lack of clean rooms and sterile conditions, the anhydrite nanobelts hold promise for clean energy production on Earth, and could, later down the line, still have a profound effect on sustainable energy production on Mars.

","score: 19.08564485265978, grade_level: '19'","score: 20.709822043628016, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adfm.202310600,"The sky is the limit with regards to the societal impact nanomaterials can have on the lives. However, in this study, it is shown that their potential is out of this world. The planet Mars has an abundant source of calcium sulfate minerals and in this work, it is shown that these deposits can be the basis of transformative nanomaterials to potentially support future space endeavors. Vitally, the methods applied are low cost and require no specialized instruments of great expertise, strengthening the potential involvement of nanotechnology in sustaining Martian inhabitation. Through a scalable eco‐friendly liquid processing technique performed on two common terrestrial gypsum, this simple method presented a cost‐efficient procedure to yield suspensions of large aspect ratio anhydrite nanobelts with long‐term stability that are characterized through scanning electron microscopy and Raman spectroscopy. Transmission electron microscopy shows nanobelts to have a mesocrystal structure, with distinct nanoparticle constituents making up the lattice. Unexpectedly, anhydrite nanobelts have remarkable electronic properties, namely a bandgap that is easily tuned between semiconducting (≈2.2 eV) and insulating (≈4 eV) behaviors through dimensional control measured via atomic force microscopy. To demonstrate the application potential of the nanobelts; optoelectronic, electrochemical, and nanocomposite measurements are made."
"
Researchers have developed an augmented reality head-up display that could improve road safety by displaying potential hazards as high-resolution three-dimensional holograms directly in a driver's field of vision in real time.

Current head-up display systems are limited to two-dimensional projections onto the windscreen of a vehicle, but researchers from the Universities of Cambridge, Oxford and University College London (UCL) developed a system using 3D laser scanner and LiDAR data to create a fully 3D representation of London streets.
The system they developed can effectively 'see through' objects to project holographic representations of road obstacles that are hidden from the driver's field of view, aligned with the real object in both size and distance. For example, a road sign blocked from view by a large truck would appear as a 3D hologram so that the driver knows exactly where the sign is and what information it displays.
The 3D holographic projection technology keeps the driver's focus on the road instead of the windscreen, and could improve road safety by projecting road obstacles and potential hazards in real time from any angle. The results are reported in the journal Advanced Optical Materials.
Every day, around 16,000 people are killed in traffic accidents caused by human error. Technology could be used to reduce this number and improve road safety, in part by providing information to drivers about potential hazards. Currently, this is mostly done using head-up displays, which can provide information such as current speed or driving directions.
""The idea behind a head-up display is that it keeps the driver's eyes up, because even a fraction of a second not looking at the road is enough time for a crash to happen,"" said Jana Skirnewskaja from Cambridge's Department of Engineering, the study's first author. ""However, because these are two-dimensional images, projected onto a small area of the windscreen, the driver can be looking at the image, and not actually looking at the road ahead of them.""
For several years, Skirnewskaja and her colleagues have been working to develop alternatives to head-up displays (HUDs) that could improve road safety by providing more accurate information to drivers while keeping their eyes on the road.

""We want to project information anywhere in the driver's field of view, but in a way that isn't overwhelming or distracting,"" said Skirnewskaja. ""We don't want to provide any information that isn't directly related to the driving task at hand.""
The team developed an augmented reality holographic point cloud video projection system to display objects aligned with real-life objects in size and distance within the driver's field of view. The system combines data from a 3D holographic setup with LiDAR (light detection and ranging) data. LiDAR uses a pulsed light source to illuminate an object and the reflected light pulses are then measured to calculate how far the object is from the light source.
The researchers tested the system by scanning Malet Street on the UCL campus in central London. Information from the LiDAR point cloud was transformed into layered 3D holograms, consisting of as many as 400,000 data points. The concept of projecting a 360° obstacle assessment for drivers stemmed from meticulous data processing, ensuring clear visibility of each object's depth.
The researchers sped up the scanning process so that the holograms were generated and projected in real-time. Importantly, the scans can provide dynamic information, since busy streets change from one moment to the next.
""The data we collected can be shared and stored in the cloud, so that any drivers passing by would have access to it -- it's like a more sophisticated version of the navigation apps we use every day to provide real-time traffic information,"" said Skirnewskaja. ""This way, the system is dynamic and can adapt to changing conditions, as hazards or obstacles move on or off the street.""
While more data collection from diverse locations enhances accuracy, the researchers say the unique contribution of their study lies in enabling a 360° view by judiciously choosing data points from single scans of specific objects, such as trucks or buildings, enabling a comprehensive assessment of road hazards.

""We can scan up to 400,000 data points for a single object, but obviously that is quite data-heavy and makes it more challenging to scan, extract and project data about that object in real time,"" said Skirnewskaja. ""With as little as 100 data points, we can know what the object is and how big it is. We need to get just enough information so that the driver knows what's around them.""
Earlier this year, Skirnewskaja and her colleagues conducted a virtual demonstration with virtual reality headsets loaded with the LiDAR data of the system at the Science Museum in London. User feedback from the sessions helped the researchers improve the system to make the design more inclusive and user-friendly. For example, they have fine-tuned the system to reduce eye strain, and have accounted for visual impairments.
""We want a system that is accessible and inclusive, so that end users are comfortable with it,"" said Skirnewskaja. ""If the system is a distraction, then it doesn't work. We want something that is useful to drivers, and improves safety for all road users, including pedestrians and cyclists.""
The researchers are currently collaborating with Google to develop the technology so that it can be tested in real cars. They are hoping to carry out road tests, either on public or private roads, in 2024.
The research was supported in part by Stiftung der Deutschen Wirtschaft and the Engineering and Physical Sciences Research Council (EPSRC), part of UK Research and Innovation (UKRI).

","score: 13.736157139187764, grade_level: '14'","score: 15.016769314192757, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adom.202301772,"Identifying road obstacles hidden from the driver's field of view can ensure road safety in transportation. Current driver assistance systems such as 2D head‐up displays are limited to the projection area on the windshield of the car. An augmented reality holographic point cloud video projection system is developed to display objects aligned with real‐life objects in size and distance within the driver's field of view. Light Detection and Ranging (LiDAR) point cloud data collected with a 3D laser scanner is transformed into layered 3D replay field objects consisting of 400 k points. GPU‐accelerated computing generated real‐time holograms 16.6 times faster than the CPU processing time. The holographic projections are obtained with a Spatial Light Modulator (SLM) (3840×2160 px) and virtual Fresnel lenses, which enlarged the driver's eye box to 25 mm × 36 mm. Real‐time scanned road obstacles from different perspectives provide the driver a full view of risk factors such as generated depth in 3D mode and the ability to project any scanned object from different angles in 360°. The 3D holographic projection technology allows for maintaining the driver's focus on the road instead of the windshield and enables assistance by projecting road obstacles hidden from the driver's field of view."
"
High-frequency terahertz waves have great potential for a number of applications including next-generation medical imaging and communication. Researchers at Linköping University, Sweden, have shown, in a study published in the journal Advanced Science, that the transmission of terahertz light through an aerogel made of cellulose and a conducting polymer can be tuned. This is an important step to unlock more applications for terahertz waves.

The terahertz range covers wavelengths that lie between microwaves and infrared light on the electromagnetic spectrum. It has a very high frequency. Thanks to this, many researchers believe that the terahertz range has great potential for use in space exploration, security technology and communication systems, among other things. In medical imaging, it can also be an interesting substitute for X-ray examinations as the waves can pass through most non-conductive materials without damaging any tissue.
However, there are several technological barriers to overcome before terahertz signals can be widely used. For example, it is difficult to create terahertz radiation in an efficient way and materials that can receive and adjust the transmission of terahertz waves are needed.
Researchers at Linköping University have now developed a material whose absorption of terahertz signals can be turned on and off through a redox reaction. The material is an aerogel, which is one of the world's lightest solid materials.
""It's like an adjustable filter for terahertz light. In one state, the electromagnetic signal will not be absorbed and in the other state it can. That property can be useful for long-range signals from space or radar signals,"" says Shangzhi Chen, postdoc at the Laboratory of Organic Electronics, LOE, at Linköping University.
The Linköping researchers used a conducting polymer, PEDOT:PSS, and cellulose to create their aerogel. They also designed the aerogel with outdoor applications in mind. It is both water-repellent (hydrophobic) and can be naturally defrosted via heating by sunlight.
Conducting polymers have many advantages over other materials used to create tunable materials. Among other things, they are biocompatible, durable, and have a great ability to be tuned. The tunability comes from the ability to change the charge density in the material. The great advantages of cellulose are the relatively low production cost compared to other similar materials and that it is a renewable material which is key for sustainable applications.
""The transmission of terahertz waves in a broad frequency range could be regulated between around 13 % and 91 %, which is a very large modulation range,"" says Chaoyang Kuang, postdoc at LOE.

","score: 13.323339160839158, grade_level: '13'","score: 13.431372377622381, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202305898,"Terahertz (THz) technologies provide opportunities ranging from calibration targets for satellites and telescopes to communication devices and biomedical imaging systems. A main component will be broadband THz absorbers with switchability. However, optically switchable materials in THz are scarce and their modulation is mostly available at narrow bandwidths. Realizing materials with large and broadband modulation in absorption or transmission forms a critical challenge. This study demonstrates that conducting polymer‐cellulose aerogels can provide modulation of broadband THz light with large modulation range from ≈ 13% to 91% absolute transmission, while maintaining specular reflection loss < −30 dB. The exceptional THz modulation is associated with the anomalous optical conductivity peak of conducting polymers, which enhances the absorption in its oxidized state. The study also demonstrates the possibility to reduce the surface hydrophilicity by simple chemical modifications, and shows that broadband absorption of the aerogels at optical frequencies enables de‐frosting by solar‐induced heating. These low‐cost, aqueous solution‐processable, sustainable, and bio‐friendly aerogels may find use in next‐generation intelligent THz devices."
"
People who received gentle electric currents on the back of their heads learned to maneuver a robotic surgery tool in virtual reality and then in a real setting much more easily than people who didn't receive those nudges, a new study shows.

The findings offer the first glimpse of how stimulating a specific part of the brain called the cerebellum could help health care professionals take what they learn in virtual reality to real operating rooms, a much-needed transition in a field that increasingly relies on digital simulation training, said author and Johns Hopkins University roboticist Jeremy D. Brown.
""Training in virtual reality is not the same as training in a real setting, and we've shown with previous research that it can be difficult to transfer a skill learned in a simulation into the real world,"" said Brown, the John C. Malone Associate Professor of Mechanical Engineering. ""It's very hard to claim statistical exactness, but we concluded people in the study were able to transfer skills from virtual reality to the real world much more easily when they had this stimulation.""
The work appears today in Nature Scientific Reports.
Participants drove a surgical needle through three small holes, first in a virtual simulation and then in a real scenario using the da Vinci Research Kit, an open-source research robot. The exercises mimicked moves needed during surgical procedures on organs in the belly, the researchers said.
Participants received a subtle flow of electricity through electrodes or small pads placed on their scalps meant to stimulate their brain's cerebellum. While half the group received steady flows of electricity during the entire test, the rest of the participants received a brief stimulation only at the beginning and nothing at all for the rest of the tests.
People who received the steady currents showed a notable boost in dexterity. None of them had prior training in surgery or robotics.

""The group that didn't receive stimulation struggled a bit more to apply the skills they learned in virtual reality to the actual robot, especially the most complex moves involving quick motions,"" said Guido Caccianiga, a former Johns Hopkins roboticist, now at Max Planck Institute for Intelligent Systems, who designed and led the experiments. ""The groups that received brain stimulation were better at those tasks.""
Noninvasive brain stimulation is a way to influence certain parts of the brain from outside the body, and scientists have shown how it can benefit motor learning in rehabilitation therapy, the researchers said. With their work, the team is taking the research to a new level by testing how stimulating the brain can help surgeons gain skills they might need in real-world situations, said co-author Gabriela Cantarero, a former assistant professor of physical medicine and rehabilitation at Johns Hopkins.
""It was really cool that we were actually able to influence behavior using this setup, where we could really quantify every little aspect of people's movements, deviations, and errors,"" Cantarero said.
Robotic surgery systems provide significant benefits for clinicians by enhancing human skill. They can help surgeons minimize hand tremors and perform fine and precise tasks with enhanced vision.
Besides influencing how surgeons of the future might learn new skills, this type of brain stimulation also offers promise for skill acquisition in other industries that rely on virtual reality training, particularly work in robotics.
Even outside of virtual reality, the stimulation can also likely help people learn more generally, the researchers said.
""What if we could show that with brain stimulation you can learn new skills in half the time?"" Caccianiga said. ""That's a huge margin on the costs because you'd be training people faster; you could save a lot of resources to train more surgeons or engineers who will deal with these technologies frequently in the future.""
Other authors include Ronan A. Mooney of the Johns Hopkins University School of Medicine, and Pablo A. Celnik of the Shirley Ryan AbilityLab.

","score: 14.702550200803213, grade_level: '15'","score: 16.357655622489958, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41598-023-47404-1,"The cerebellum has demonstrated a critical role during adaptation in motor learning. However, the extent to which it can contribute to the skill acquisition of complex real-world tasks remains unclear. One particularly challenging application in terms of motor activities is robotic surgery, which requires surgeons to complete complex multidimensional visuomotor tasks through a remotely operated robot. Given the need for high skill proficiency and the lack of haptic feedback, there is a pressing need for understanding and improving skill development. We investigated the effect of cerebellar transcranial direct current stimulation applied during the execution of a robotic surgery training task. Study participants received either real or sham stimulation while performing a needle driving task in a virtual (simulated) and a real-world (actual surgical robot) setting. We found that cerebellar stimulation significantly improved performance compared to sham stimulation at fast (more demanding) execution speeds in both virtual and real-world training settings. Furthermore, participants that received cerebellar stimulation more effectively transferred the skills they acquired during virtual training to the real world. Our findings underline the potential of non-invasive brain stimulation to enhance skill learning and transfer in real-world relevant tasks and, more broadly, its potential for improving complex motor learning."
"
Researchers at Nagoya University in Japan have used artificial intelligence to discover a new method for understanding small defects called dislocations in polycrystalline materials, materials widely used in information equipment, solar cells, and electronic devices, that can reduce the efficiency of such devices. The findings were published in the journal Advanced Materials.

Almost every device that we use in our modern lives has a polycrystal component. From your smartphone to your computer to the metals and ceramics in your car. Despite this, polycrystalline materials are tough to utilize because of their complex structures. Along with their composition, the performance of a polycrystalline material is affected by its complex microstructure, dislocations, and impurities.
A major problem for using polycrystals in industry is the formation of tiny crystal defects caused by stress and temperature changes. These are known as dislocations and can disrupt the regular arrangement of atoms in the lattice, affecting electrical conduction and overall performance. To reduce the chances of failure in devices that use polycrystalline materials, it is important to understand the formation of these dislocations.
A team of researchers at Nagoya University, led by Professor Noritaka Usami and including Lecturer Tatsuya Yokoi and Associate Professor Hiroaki Kudo and collaborators, used a new AI to analyse image data of a material widely used in solar panels, called polycrystalline silicon. The AI created a 3D model in virtual space, helping the team to identify the areas where dislocation clusters were affecting the material's performance.
After identifying the areas of the dislocation clusters, the researchers used electron microscopy and theoretical calculations to understand how these areas formed. They revealed stress distribution in the crystal lattice and found staircase-like structures at the boundaries between the crystal grains. These structures appear to cause dislocations during crystal growth. ""We found a special nanostructure in the crystals associated with dislocations in polycrystalline structures,"" Usami said.
Along with its practical implications, this study may have important implications for the science of crystal growth and deformation as well. The Haasen-Alexander-Sumino (HAS) model is an influential theoretical framework used to understand the behavior of dislocations in materials. But Usami believes that they have discovered dislocations that the Haasen-Alexander-Sumino model missed.
Another surprise was to follow soon after, as when the team calculated the arrangement of the atoms in these structures, they found unexpectedly large tensile bond strains along the edge of the staircase-like structures that triggered dislocation generation.
As explained by Usami, ""As experts who have been studying this for years, we were amazed and excited to finally see proof of the presence of dislocations in these structures. It suggests that we can control the formation of dislocation clusters by controlling the direction in which the boundary spreads.""
""By extracting and analyzing the nanoscale regions through polycrystalline materials informatics, which combines experiment, theory, and AI, we made this clarification of phenomena in complex polycrystalline materials possible for the first time,"" Usami continued. ""This research illuminates the path towards establishing universal guidelines for high-performance materials and is expected to contribute to the creation of innovative polycrystalline materials. The potential impact of this research extends beyond solar cells to everything from ceramics to semiconductors. Polycrystalline materials are widely used in society, and the improved performance of these materials has the potential to revolutionize society.""

","score: 16.29351594202899, grade_level: '16'","score: 17.119130434782612, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adma.202308599,"A comprehensive analysis of optical and photoluminescence images obtained from practical multicrystalline silicon wafers is conducted, utilizing various machine learning models for dislocation cluster region extraction, grain segmentation, and crystal orientation prediction. As a result, a realistic 3D model that includes the generation point of dislocation clusters is built. Finite element stress analysis on the 3D model coupled with crystal growth simulation reveals inhomogeneous and complex stress distribution and that dislocation clusters are frequently formed along the slip plane with the highest shear stress among twelve equivalents, concentrated along bending grain boundaries (GBs). Multiscale analysis of the extracted GBs near the generation point of dislocation clusters combined with ab initio calculations has shown that the dislocation generation due to the concentration of shear stress is caused by the nanofacet formation associated with GB bending. This mechanism cannot be captured by the Haasen‐Alexander‐Sumino model. Thus, this research method reveals the existence of a dislocation generation mechanism unique to the multicrystalline structure. Multicrystalline informatics linking experimental, theoretical, computational, and data science on multicrystalline materials at multiple scales is expected to contribute to the advancement of materials science by unraveling complex phenomena in various multicrystalline materials."
"
A team of UK scientists has got a step closer to making several different types of plastic much easier to recycle, using a method that could be applied to a whole range of difficult-to-recycle polymers, including rubbers, gels and adhesives.

Thermoplastics and thermosets are two types of plastics that both consist of long chains of molecules called polymers but behave differently when heated.
Thermoplastics can be heated to high temperatures, poured into a mould then cooled to make the desired shape. They can subsequently be melted and reformed into other shapes when they are recycled, however they can break when stretched or stressed.
In contrast, the polymer chains in thermoset plastics are crosslinked to form a network which makes them incredibly strong and flexible. They are often used in composite materials, paints, coatings, rubbers and gels. Unfortunately, however, the crosslinks mean that the materials burn rather than melt when heated, making them much harder to break down and recycle.
Now, researchers at the University of Bath and University of Surrey have developed a way of introducing degradable bonds into thermoset polymers to make them more easily recyclable.
Publishing in Polymer Chemistry, they made a series of polymer gels with breakable bonds incorporated into different parts of the structure, and tested whether the properties changed after the gel was degraded and reformed.
They found that whilst all the gels could be degraded to some extent, gels with breakable bonds in the polymer chains (B in the attached diagram) retained their properties much better when reformed, compared with the polymers that were broken down via the cross-linked bonds (A).

The researchers hope this model system can be applied to other types of polymers, including adhesives, sealants and elastomers.
Dr Maciek Kope?, from the University of Bath's Department of Chemistry, said: ""Thermosets are used widely in the commercial sector, in materials like resins and adhesives.
""Being able to make bonds reversible in these materials will increase their applications as well as making them more recyclable.""
The researchers aim to create a general road map of the best locations for these breakable bonds, to understand better why some bonds break more easily than others, and plan to optimise the system using other commercially used polymers.
The researchers are also looking at other applications of the work, including using crosslinked polymers as vehicles for controlled drug delivery systems.
The work was funded by the Engineering and Physical Sciences Research Council (EPSRC).

","score: 14.610426829268295, grade_level: '15'","score: 16.092768292682926, grade_levels: ['college_graduate'], ages: [24, 100]",10.1039/D3PY01008B,The influence of the cleavable bond location on degradation and reformation of poly(n-butyl acrylate) networks synthesised by RAFT polymerisation was investigated and revealed that cleavable backbones lead to more efficient network reversibility.
"
Scientists from the University of Rochester say deep learning can supercharge a technique that is already the gold standard for characterizing new materials. In an npj Computational Materials paper, the interdisciplinary team describes models they developed to better leverage the massive amounts of data that X-ray diffraction experiments produce.

During X-ray diffraction experiments, bright lasers shine on a sample, producing diffracted images that contain important information about the material's structure and properties. Project lead Niaz Abdolrahim, an associate professor in the Department of Mechanical Engineering and a scientist at the Laboratory for Laser Energetics (LLE), says conventional methods of analyzing these images can be contentious, time-consuming, and often ineffective.
""There is a lot of materials science and physics hidden in each one of these images and terabytes of data are being produced every day at facilities and labs worldwide,"" says Abdolrahim. ""Developing a good model to analyze this data can really help expedite materials innovation, understand materials at extreme conditions, and develop materials for different technological applications.""
The study, led by Jerardo Salgado '23 MS (materials science), holds particular promise for high-energy-density experiments like those conducted at LLE by researchers from the Center for Matter at Atomic Pressures. By examining the precise moment when materials under extreme conditions change phases, scientists can discover ways to create new materials and learn about the formation of stars and planets.
Abdolrahim says the project, funded by the US Department of Energy's National Nuclear Security Administration and the National Science Foundation, improves upon previous attempts to develop machine learning models for X-ray diffraction analysis that were trained and evaluated primarily with synthetic data. Abdolrahim, Associate Professor Chenliang Xu from the Department of Computer Science, and their students incorporated real-world data from experiments with inorganic materials to train their deep-learning models.
More X-ray diffraction analysis experimental data needs to be publicly available to help refine the models, according to Abdolrahim. She says the team is working on creating platforms for others to share data that can help train and evaluate the system, making it even more effective.

","score: 18.59152215799615, grade_level: '19'","score: 20.525192678227356, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41524-023-01164-8,"In current in situ X-ray diffraction (XRD) techniques, data generation surpasses human analytical capabilities, potentially leading to the loss of insights. Automated techniques require human intervention, and lack the performance and adaptability required for material exploration. Given the critical need for high-throughput automated XRD pattern analysis, we present a generalized deep learning model to classify a diverse set of materials’ crystal systems and space groups. In our approach, we generate training data with a holistic representation of patterns that emerge from varying experimental conditions and crystal properties. We also employ an expedited learning technique to refine our model’s expertise to experimental conditions. In addition, we optimize model architecture to elicit classification based on Bragg’s Law and use evaluation data to interpret our model’s decision-making. We evaluate our models using experimental data, materials unseen in training, and altered cubic crystals, where we observe state-of-the-art performance and even greater advances in space group classification."
"
A winter wonderland calls to mind piles of fluffy, glistening snow. But to reach the ground, snowflakes are swept into the turbulent atmosphere, swirling through the air instead of plummeting directly to the ground.

The path of precipitation is complex but important to more than just skiers assessing the potential powder on their alpine vacation or school children hoping for a snow day. Determining snowflake fall speed is crucial for predicting weather patterns and measuring climate change.
In Physics of Fluids, from AIP Publishing, researchers from the University of Utah report snowflake accelerations in atmospheric turbulence. They found that regardless of turbulence or snowflake type, acceleration follows a universal statistical pattern that can be described as an exponential distribution.
""Even in the tropics, precipitation often starts its lifetime as snow,"" said author Timothy Garrett. ""How fast precipitation falls greatly affects storm lifetimes and trajectories and the extent of cloud cover that may amplify or diminish climate change. Just small tweaks in model representations of snowflake fall speed can have important impacts on both storm forecasting and how fast climate can be expected to warm for a given level of elevated greenhouse gas concentrations.""
Set up in a ski area near Salt Lake City, the team battled an unprecedented 900 inches of snow. They simultaneously filmed snowfall and measured atmospheric turbulence. Using a device they invented that employs a laser light sheet, they gathered information about snowflake mass, size, and density.
""Generally, as expected, we find that low-density 'fluffy' snowflakes are most responsive to surrounding turbulent eddies,"" said Garrett.
Despite the system's complexity, the team found that snowflake accelerations follow an exponential frequency distribution with an exponent of three halves. In analyzing their data, they also discovered that fluctuations in the terminal velocity frequency distribution followed the same pattern.
""Snowflakes are complicated, and turbulence is irregular. The simplicity of the problem is actually quite mysterious, particularly given there is this correspondence between the variability of terminal velocities -- something ostensibly independent of turbulence -- and accelerations of the snowflakes as they are locally buffeted by turbulence,"" said Garrett.
Because size determines terminal velocity, a possible explanation is that the turbulence in clouds that influences snowflake size is related to the turbulence measured at the ground. Yet the factor of three halves remains a mystery.
The researchers will revisit their experiment this winter, using a mist of oil droplets to obtain a closer look at turbulence and its impact on snowflakes.

","score: 13.989939759036144, grade_level: '14'","score: 15.173457831325301, grade_levels: ['college_graduate'], ages: [24, 100]",10.1063/5.0173359,"We use a novel experimental setup to obtain the vertical velocity and acceleration statistics of snowflakes settling in atmospheric surface-layer turbulence, for Taylor microscale Reynolds numbers (Reλ) between 400 and 67 000, Stokes numbers (St) between 0.12 and 3.50, and a broad range of snowflake habits. Despite the complexity of snowflake structures and the non-uniform nature of the turbulence, we find that mean snowflake acceleration distributions can be uniquely determined from the value of St. Ensemble-averaged snowflake root mean square (rms) accelerations scale nearly linearly with St. Normalized by the rms value, the acceleration distribution is nearly exponential, with a scaling factor for the (exponent) of −3/2 that is independent of Reλ and St; kurtosis scales with Reλ, albeit weakly compared to fluid tracers in turbulence; gravitational drift with sweeping is observed for St &lt; 1. Surprisingly, the same exponential distribution describes a pseudo-acceleration calculated from fluctuations of snowflake terminal fall speed in still air. This equivalence suggests an underlying connection between how turbulence determines the trajectories of particles and the microphysics determining the evolution of their shapes and sizes."
"
X-ray imaging visualizes hidden structures and processes in living cells and organisms. The radiation that consists of highly energy-rich electromagnetic waves, however, has an ionizing effect and may damage the genetic material. This limits the possible observation period. While conventional X-ray images of soft tissue are of low contrast, phase contrast methods produce far better image contrasts at a reduced radiation dose. With higher resolution, however, gentle imaging becomes increasingly difficult, as a higher dose is required. Moreover, the efficiency of the usually applied high-resolution detectors decreases, as a result of which radiation exposure is further increased. So far, high-resolution X-ray phase contrast imaging of living biological specimens has been possible for a few seconds to minutes only, before severe damage is caused by the radiation.

Researchers from KIT's Laboratory for Applications of Synchrotron Radiation (LAS), Institute for Photon Science and Synchrotron Radiation, and Physikalisches Institut have now developed a method that uses radiation more efficiently and produces images of micrometer resolution. The method is suited for both living specimens and sensitive materials and opens up new opportunities in biology, biomedicine, and materials sciences. The new system combines X-ray phase contrast with a so-called Bragg magnifier and a photon-counting detector.
Directly Enlarged X-ray Image
""Instead of converting the X-ray image into an image with visible light and enlarging it afterwards, we enlarge it directly,"" LAS doctoral researcher Rebecca Spiecker says. ""Thanks to this approach, we can use highly efficient large-area detectors."" The researchers use a photon-counting detector with a pixel size of 55 micrometers. Before, the X-ray image of the specimen is enlarged with a so-called Bragg magnifier, as a result of which the resolution of the specimen proper reaches about 1 micrometer. The Bragg magnifier consists of two perfect silicon crystals, whose enlarging effect results from asymmetric diffraction in the silicon crystal lattice. Another big advantage of the Bragg magnifier is the very good optical image transmission. It allows for the nearly loss-free reproduction of all spatial frequencies up to the resolution limit.
Parasitic Wasps Observed for 30 Minutes
Thanks to the combination of propagation-based X-ray phase contrast with a Bragg magnifier and a photon-counting detector, all of which are optimized for an X-ray energy of 30 kiloelectron-volts (keV), the method reaches about the maximum possible dose efficiency for X-ray phase contrast. This allows for far longer observation times of small living organisms with micrometer resolution. Together with scientists from all over Germany, the researchers demonstrated the method in a pilot study of smallest parasitic wasps. For more than 30 minutes, they observed the wasps in their host eggs and how they emerged from them. ""The method is also suited for biomedical applications, an example being the gentle three-dimensional histological investigation of biopsy samples,"" Spiecker says. The researchers now plan to further improve the setup, to enlarge the field of view, and to increase mechanical stability for even longer measurements.

","score: 14.723438085885189, grade_level: '15'","score: 15.647079725024554, grade_levels: ['college_graduate'], ages: [24, 100]",10.1364/OPTICA.500978,"X-ray imaging enables the study of morphodynamic and physiological processes in living organisms. However, the required photon flux increases with the desired spatial resolution and with it the requirements for dose efficiency. We realize full-field imaging at micrometer resolution close to the highest possible dose efficiency. This is achieved by combining propagation-based phase contrast with Bragg crystal optics and a high-Z single-photon-counting detector, all designed for X-ray energies that allow minimal dose for a given image quality. We prove the superior imaging performance compared to conventional systems and, in particular, show a substantial increase in dose efficiency for high spatial frequencies that comprise the relevant high-resolution components of the image. We demonstrate the potential of the technique by a behavioral in vivo study of submillimeter-sized parasitoid chalcid wasps within their host eggs before and during emergence. The findings show that the technique opens up new possibilities for dose-sensitive studies at micrometer resolution, not only in life sciences but also in materials research."
"
In quantum mechanics, particles can exist in multiple states at the same time, defying the logic of everyday experiences. This property, known as quantum superposition, is the basis for emerging quantum technologies that promise to transform computing, communication, and sensing. But quantum superpositions face a significant challenge: quantum decoherence. During this process, the delicate superposition of quantum states breaks down when interacting with its surrounding environment.

To unlock the power of chemistry to build complex molecular architectures for practical quantum applications, scientists need to understand and control quantum decoherence so that they can design molecules with specific quantum coherence properties. Doing so requires knowing how to rationally modify a molecule's chemical structure to modulate or mitigate quantum decoherence. To that end, scientists need to know the ""spectral density,"" the quantity which summarizes how fast the environment moves and how strongly it interacts with the quantum system.
Until now, quantifying this spectral density in a way that it accurately reflects the intricacies of molecules has remained elusive to theory and experimentation. But a team of scientists has developed a method to extract the spectral density for molecules in solvent using simple resonance Raman experiments -- a method that captures the full complexity of chemical environments. Led by Ignacio Franco, an associate professor of chemistry and of physics at the University of Rochester, the team published their findings in the Proceedings of the National Academy of Sciences.
Using the extracted spectral density, it is possible not only to understand how fast the decoherence happens but also to determine which part of the chemical environment is mostly responsible for it. As a result, scientists can now map decoherence pathways to connect molecular structure with quantum decoherence.
""Chemistry builds up from the idea that molecular structure determines the chemical and physical properties of matter. This principle guides the modern design of molecules for medicine, agriculture, and energy applications. Using this strategy, we can finally start to develop chemical design principles for emerging quantum technologies,"" says Ignacio Gustin, a chemistry graduate student at Rochester and the first author of the study.
The breakthrough came when the team recognized that resonance Raman experiments yielded all the information needed to study decoherence with full chemical complexity. Such experiments are routinely used to investigate photophysics and photochemistry, but their utility for quantum decoherence had not been appreciated. The key insights emerged from discussions with David McCamant, an associate professor in the chemistry department at Rochester and an expert in Raman spectroscopy, and with Chang Woo Kim, now on the faculty at Chonnam National University in Korea and an expert in quantum decoherence, while he was a postdoctoral researcher at Rochester.
The team used their method to show, for the first time, how electronic superpositions in thymine, one of the building blocks of DNA, unravel in just 30 femtoseconds (one femtosecond is one millionth of one billionth of a second) following its absorption of UV light. They found that a few vibrations in the molecule dominate the initial steps in the decoherence process, while solvent dominates the later stages. In addition, they discovered that chemical modifications to thymine can significantly alter the decoherence rate, with hydrogen-bond interactions near the thymine ring leading to more rapid decoherence.
Ultimately, the team's research opens the way toward understanding the chemical principles that govern quantum decoherence. ""We are excited to use this strategy to finally understand quantum decoherence in molecules with full chemical complexity and use it to develop molecules with robust coherence properties,"" says Franco.

","score: 16.98226560189293, grade_level: '17'","score: 17.994547471162377, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2309987120,"Establishing the fundamental chemical principles that govern molecular electronic quantum decoherence has remained an outstanding challenge. Fundamental questions such as how solvent and intramolecular vibrations or chemical functionalization contribute to the decoherence remain unanswered and are beyond the reach of state-of-the-art theoretical and experimental approaches. Here we address this challenge by developing a strategy to isolate electronic decoherence pathways for molecular chromophores immersed in condensed phase environments that enables elucidating how electronic quantum coherence is lost. For this, we first identify resonance Raman spectroscopy as a general experimental method to reconstruct molecular spectral densities with full chemical complexity at room temperature, in solvent, and for fluorescent and non-fluorescent molecules. We then show how to quantitatively capture the decoherence dynamics from the spectral density and identify decoherence pathways by decomposing the overall coherence loss into contributions due to individual molecular vibrations and solvent modes. We illustrate the utility of the strategy by analyzing the electronic decoherence pathways of the DNA base thymine in water. Its electronic coherences decay in ∼ 30 fs. The early-time decoherence is determined by intramolecular vibrations while the overall decay by solvent. Chemical substitution of thymine modulates the decoherence with hydrogen-bond interactions of the thymine ring with water leading to the fastest decoherence. Increasing temperature leads to faster decoherence as it enhances the importance of solvent contributions but leaves the early-time decoherence dynamics intact. The developed strategy opens key opportunities to establish the connection between molecular structure and quantum decoherence as needed to develop chemical strategies to rationally modulate it."
"
Origami, traditionally associated with paper folding, has transcended its craft origins to influence a diverse range of fields, including art, science, engineering, and architecture. Recently, origami principles have extended to technology, with applications spanning solar cells to biomedical devices. While origami-inspired materials have been explored at various scales, the challenge of creating molecular materials based on origami tessellations has remained. Addressing this challenge, a team of researchers, led by Professor Wonyoung Choe in the Department of Chemistry at Ulsan National Institute of Science and Technology (UNIST), South Korea, has unveiled a remarkable breakthrough in the form of a two-dimensional (2D) Metal Organic Framework (MOF) that showcases unprecedented origami-like movement at the molecular level.

Metal-Organic Frameworks (MOFs) have long been recognized for their structural flexibility, making them an ideal platform for origami tessellation-based materials. However, their application in this context is still in its early stages. Through the development of a 2D MOF based on the origami tessellation, the research team has achieved a significant milestone. The researchers utilized temperature-dependent synchrotron single-crystal X-ray diffraction to demonstrate the origami-like folding behavior of the 2D MOF in response to temperature changes. This behavior showcases negative thermal expansion and reveals a unique origami tessellation pattern, previously unseen at the molecular level.
The key to this breakthrough lies in the choice of MOFs, which incorporate flexible structural building blocks. The inherent flexibility enables the origami-like movement, observed in the 2D MOF. The study highlights the deformable net topology of the materials. Additionally, the role of solvents in maintaining the packing between 2D framework in MOFs is emphasized, as it directly affects the degree of folding.
""This groundbreaking research opens new avenues for origami-inspired materials at the molecular level, introducing the concept of origamic MOFs. The findings not only contribute to the understanding of dynamic behavior in MOFs, but also offer potential applications in mechanical metamaterials."" noted Professor Wonyoung Choe. He further highlighted the potential of molecular level control over origami movement, as a platform for designing advanced materials with unique mechanical properties. The study also suggests exciting possibilities for tailoring origamic MOFs for specific applications, including advancements in molecular quantum computing.
The findings of this research have been published in Nature Communications, a sister journal to Nature, on December 01, 2023. This study has been supported by the National Research Foundation (NRF) of Korea via the Mid-Career Researcher Program, Hydrogen Energy Innovation Technology Development Project, Science Research Center (SRC), and Global Ph.D. Fellowship (GPF), as well as Korea Environment Industry & Technology Institute (KEITI) through Public Technology Program based on Environmental Policy Program, funded by Korea Ministry of Environment (MOE).

","score: 17.717118993135013, grade_level: '18'","score: 18.08911899313501, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43647-8,"Origami, known as paper folding has become a fascinating research topic recently. Origami-inspired materials often establish mechanical properties that are difficult to achieve in conventional materials. However, the materials based on origami tessellation at the molecular level have been significantly underexplored. Herein, we report a two-dimensional (2D) porphyrinic metal-organic framework (MOF), self-assembled from Zn nodes and flexible porphyrin linkers, displaying folding motions based on origami tessellation. A combined experimental and theoretical investigation demonstrated the origami mechanism of the 2D porphyrinic MOF, whereby the flexible linker acts as a pivoting point. The discovery of the 2D tessellation hidden in the 2D MOF unveils origami mechanics at the molecular level."
"
A collaborative team of experimental and computational physical chemists from South Korea and the United States have made an important discovery in the field of electrochemistry, shedding light on the movement of water molecules near metal electrodes. This research holds profound implications for the advancement of next-generation batteries utilizing aqueous electrolytes.

In the nanoscale realm, chemists typically utilize laser light to illuminate molecules and measure spectroscopic properties to visualize molecules. However, studying the behavior of water molecules near metal electrodes proved challenging due to the overwhelming interference from metal atoms in the electrode itself. Additionally, water molecules distant from the electrode surface also contribute to the response of the applied light, complicating the selective observation of molecules at the liquid-metal electrode interface.
Led by Professor Martin Zanni from the University of Wisconsin at Madison and Director CHO Minhaeng from the Center for Molecular Spectroscopy and Dynamics within the Institute for Basic Science (IBS) addressed this challenge with newly developed spectroscopic techniques coupled with computer simulations. In order to minimize the interference from the metals, the authors coated the surface of the electrode with specially designed organic molecules. Then, surface-enhanced femtosecond (10-15 second) two-dimensional vibrational spectroscopy was employed to observe the changes in the movement of water molecules near the metal electrode.
Depending on the magnitude and polarity of the applied voltage on the metal electrode, the researchers observed, for the first time, either a deceleration or acceleration of the motion of water molecules near the electrode. ""When a positive voltage is applied to the electrode, the movement of nearby water molecules slows down. Conversely, when a negative voltage is applied, the opposite is observed both in femtosecond vibrational spectroscopy and in computer simulations,"" explains Dr. Kwac.
""The results of this study provide crucial information for understanding electrochemical reactions, offering essential physical insights necessary for the research and development of aqueous electrolyte batteries in the future,"" comments Director CHO Minhaeng of the IBS Center for Molecular Spectroscopy and Dynamics, a corresponding author of the study.
This outcome implies a close relationship between electrochemical reactions involving water on the surface of electrodes and the dynamics of interfacial water molecules. It is expected to not only advance our understanding of fundamental electrochemical processes but also pave the way for the design of more efficient and sustainable battery technologies.
This research was published in the Proceedings of the National Academy of Sciences (PNAS) on December 18, 2023.

","score: 19.219438165438167, grade_level: '19'","score: 20.188361998361998, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2314998120,"We report the hydrogen-bonding dynamics of water to a nitrile-functionalized and plasmonic electrode surface as a function of applied voltage. The surface-enhanced two-dimensional infrared spectra exhibit hydrogen-bonded and non-hydrogen-bonded nitrile features in similar proportions, plus cross peaks between the two. Isotopic dilution experiments show that the cross peaks arise predominantly from chemical exchange between hydrogen-bonded and non-hydrogen-bonded nitriles. The chemical exchange rate depends upon voltage, with the hydrogen bond of the water to the nitriles breaking 2 to 3 times slower (>63 vs. 25 ps) under a positive as compared to a negative potential. Spectral diffusion created by hydrogen-bond fluctuations occurs on a ~1 ps timescale and is moderately potential-dependent. Timescales from molecular dynamics simulations agree qualitatively with the experiment and show that a negative voltage causes a small net displacement of water away from the surface. These results show that the voltage applied to an electrode can alter the timescales of solvent motion at its interface, which has implications for electrochemically driven reactions."
"
Drones flying along miles of rivers in the steep, mountainous terrain of central Taiwan and mapping the rock properties have revealed new clues about how water helps shape mountains over geological time, according to a team led by Penn State scientists.

The researchers found a link between the size of boulders in the rivers and the steepness of the rivers. The link shows how rock properties can influence the relationship between tectonic processes happening deep underground and how mountainous landscapes change shape. They reported in the journal Science Advances.
""Over the course of a mountain belt developing, we're seeing differences in how rivers incise, or cut down into the bedrock, in the younger and older sections,"" said Julia Carr, lead author of the study who earned her doctorate in geosciences from Penn State in 2022. ""It means that as a mountain belt evolves, erosion is changing at the surface.""
As tectonic plates collide and form mountain ranges, rocks that were previously buried in the Earth's crust are pushed to the surface in a process called uplift. The temperature and pressure that these rocks experience leads to variability in rock properties -- like rock hardness or the spacing and orientation of fractures -- that then affect how easily they are eroded by elements at the surface, the scientists said.
In Taiwan, the scientists found the main signature of rock strength of the mountains was the size of boulders in rivers, which were larger and stronger in locations where rocks had been buried deeper in Earth's crust. And the size of boulders correlated with the steepness of the rivers, which must be powerful enough to move these boulders downstream before eroding the mountain, the scientists said.
""When the boulders in the channels are larger, the river needs to steepen to be able to erode at the same rate,"" said Roman DiBiase, associate professor of geosciences at Penn State and co-author of the study. ""This is because in order to erode rock, the sediment covering a river channel needs to move out of the way. The larger the boulders in the channel, the steeper the channel needs to be to move them.""
Models can account for how things like storms and floods impact erosion rates, but it's harder to factor the role of rock strength on the process, the scientists said.

""Determining the controls on river incision into rock is important for understanding how mountain ranges evolve over geologic time,"" DiBiase said. ""But some key parameters for testing models of river incision, such as flow depth and sediment cover, are difficult to measure at large scales.""
The researchers turned to drones to avoid obstacles like hazardous river crossings and waterfalls to collect data. During these surveys, the scientists collected hundreds of thousands of measurements of river channel morphology and more than 22,000 measurements of boulders along roughly 18 miles of rivers.
""That's where it's really unprecedented -- something of this scale is really unusual,"" said Carr, who conducted the research at Penn State and is now a postdoctoral fellow at Simon Fraser University in British Columbia. ""It's exciting to be able to survey at this scale -- it helps us see patterns we really would otherwise never see. If you just went into the field and surveyed the few spots you could get to easily, you would not observe this pattern.""
Taiwan's central mountain range is one of the steepest landscapes on Earth and has one of the highest erosion rates of any place outside glaciated or human-influenced areas, Carr said. In addition, the tectonic setting of Taiwan is well known and has systematic burial depth patterns that can be used to evaluate the connection between subsurface history of rocks and their current condition at the surface.
""It's this great unique place because unlike somewhere like the Himalayas or the Alps, where there's so many complex tectonic histories, Taiwan can be a relatively simple landscape to study because the same collision forces that created it millions of years ago are still active today,"" Carr said. ""And these lessons learned from Taiwan can help inform erosion models that are applied to other mountain ranges with fewer constraints.""
Because of how the range formed, younger rocks are found in the south and west, while older rocks that were buried deeper -- up to 24 miles underground -- are found further east and north, the scientists said.

In the younger sections, rivers have fewer, smaller boulders that cover less of the area of the channels. And as you travel toward the older sections, the boulders increase to a median size of more than six feet, the scientists said.
These boulders aren't sitting in the rivers waiting to be broken down over time, according to the researchers. Instead, boulders in each of the sections of rivers were close to the threshold of mobility -- meaning the water was nearly powerful enough to move them downstream. During high flows after storms, these boulders may be fully mobile, and as they move, they help incise the river.
""One way you can think about how rivers incise long term -- you need to be able to move sediment, and once you cross over some threshold, you can incise the river,"" Carr said. ""If we apply this, it implies this primary rock strength signal controlling boulder size is setting river incision in the landscape. And that matches with the local steepness of the rivers.""
Also contributing were Donald Fisher, professor of geosciences at Penn State; En-Chao Yeh, associate professor at National Taiwan Normal University; and Eric Kirby, professor at University of North Carolina at Chapel Hill.
The National Science Foundation supported this work.
Link to drone video footage: https://youtu.be/uER7H-zm1yE 

","score: 12.500167096557139, grade_level: '13'","score: 14.555834080968935, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adg6794,"Feedbacks between surface and deep Earth processes in collisional mountain belts depend on how erosion and topographic relief vary in space and time. One outstanding unknown lies in how rock strength influences bedrock river morphology and thus mountain relief. Here, we quantify boulder cover and channel morphology using uncrewed aerial vehicle surveys along 30 kilometers of bedrock-bound river corridors throughout the Taiwan Central Range where regional gradients in rock properties relate to tectonic history. We find that boulder size systematically increases with increasing metamorphic grade and depth of exhumation. Boulder size correlates with reach-scale channel steepness but does not explain observations of highly variable channel width. Transport thresholds indicate that rivers are adjusted to mobilize boulders and are well in excess of the threshold to transport gravel and cobbles, as previously assumed. The linkage between metamorphic history, boulder size, and channel steepness reveals how rock properties can influence feedbacks between tectonics and topography throughout the life span of a mountain range."
"
University of Wisconsin-Madison engineers have used a spray coating technology to produce a new workhorse material that can withstand the harsh conditions inside a fusion reactor.

The advance, detailed in a paper published recently in the journal Physica Scripta, could enable more efficient compact fusion reactors that are easier to repair and maintain.
""The fusion community is urgently looking for new manufacturing approaches to economically produce large plasma-facing components in fusion reactors,"" says Mykola Ialovega, a postdoctoral researcher in nuclear engineering and engineering physics at UW-Madison and lead author on the paper. ""Our technology shows considerable improvements over current approaches. With this research, we are the first to demonstrate the benefits of using cold spray coating technology for fusion applications.""
The researchers used a cold spray process to deposit a coating of tantalum, a metal that can withstand high temperatures, on stainless steel. They tested their cold spray tantalum coating in the extreme conditions relevant to a fusion reactor and found that it performed very well. Importantly, they discovered the material is exceptionally good at trapping hydrogen particles, which is beneficial for compact fusion devices.
""We discovered that the cold spray tantalum coating absorbs much more hydrogen than bulk tantalum because of the unique microstructure of the coating,"" says Kumar Sridharan, a professor of nuclear engineering and engineering physics and materials science and engineering. Over the last decade, Sridharan's research group has introduced cold spray technology to the nuclear energy community by implementing it for multiple applications related to fission reactors.
""The simplicity of the cold spray process makes it very practical for applications,"" Sridharan says.
In fusion devices, plasma -- an ionized hydrogen gas -- is heated to extremely high temperatures, and atomic nuclei in the plasma collide and fuse. That fusion process produces energy. However, some hydrogen ions may get neutralized and escape from the plasma.

""These hydrogen neutral particles cause power losses in the plasma, which makes it very challenging to sustain a hot plasma and have an effective small fusion reactor,"" says Ialovega, who works in the research group of Oliver Schmitz, a professor of nuclear engineering and engineering physics.
That's why the researchers set out to create a new surface for plasma-facing reactor walls that could trap hydrogen particles as they collide with the walls.
Tantalum is inherently good at absorbing hydrogen -- and the researchers suspected that creating a tantalum coating using a cold spray process would boost its hydrogen-trapping abilities even more.
Creating a cold sprayed coating is somewhat like using a can of spray paint. It consists of propelling particles of the coating material at supersonic velocities onto a surface. Upon impact, the particles flatten like pancakes and coat the entire surface, while preserving nanoscale boundaries between the coating particles. The researchers discovered that those tiny boundaries facilitate trapping of hydrogen particles.
Ialovega conducted experiments on the coated material at facilities at Aix Marseille University in France and Forschungszentrum Jülich GmbH in Germany. During these experiments, he found that when he heated the material to a higher temperature, it expelled the trapped hydrogen particles without modifying the coatings -- a process that essentially regenerates the material so it can be used again.
""Another big benefit of the cold spray method is that it allows us to repair reactor components on site by applying a new coating,"" Ialovega says. ""Currently, damaged reactor components often need to be removed and replaced with a completely new part, which is costly and time consuming.""
The researchers plan to use their new material in the Wisconsin HTS Axisymmetric Mirror (WHAM). The experimental device is under construction near Madison, Wis., and will serve as a prototype for a future next-generation fusion power plant that UW-Madison spinoff Realta Fusion aims to develop. Housed in the Physical Sciences Laboratory, the WHAM experiment is a partnership between UW-Madison, Massachusetts Institute of Technology and Commonwealth Fusion Systems.

""Creating a refractory metal composite with these features of well-controlled hydrogen handling combined with erosion resistance and general material resilience is a breakthrough for the design of plasma devices and fusion energy systems,"" Schmitz says. ""The prospect of changing the alloy and including other refractory metals to enhance the composite for nuclear applications is particularly exciting.""
The researchers are patenting their technology through the Wisconsin Alumni Research Foundation.
Oliver Schmitz is the Thomas and Suzanne Werner Professor, associate dean for research innovation in the UW-Madison College of Engineering, and director of the Grainger Institute of Engineering. Sridharan is a Grainger Professor.
Additional co-authors on the paper from UW-Madison include: Tyler Dabney, Marcos Navarro Gonzalez, Hwasung Yeom, Danah Velez, Evan Willing, Jay Anderson, and Cary Forest. Thierry Angot and Régis Bisson from Aix Marseille University in France, and Arkadi Kreter from Forschungszentrum Jülich GmbH in Germany are also co-authors on the paper.
Seed funding for this research came in part from UW-Madison's Research Forward program. This research was also supported by grants from the Advanced Research Projects Agency-Energy (ARPA-E) and the U.S. Department of Energy.

","score: 15.307965928013324, grade_level: '15'","score: 16.226400666068912, grade_levels: ['college_graduate'], ages: [24, 100]",10.1088/1402-4896/ad0098,"Removal of neutral hydrogen atoms in the plasma edge reduces the number of charge exchange events and thus, the net energy losses in the plasma, significantly improving performance of fusion devices. Effective control of the residual pressure of hydrogen isotopes (HIs) in the plasma edge may be achieved by utilizing a hydrogen absorbing first wall interface capable of withstanding the harsh fusion environment. In this study, we have investigated tantalum (Ta) coating deposited by cold spray technology on 316L stainless steel substrate as a potential plasma-facing material surface. High fluence low energy deuterium plasma irradiation experiments and subsequent thermal annealing cycles associated with thermal desorption spectrometry (TDS) demonstrated superior structural stability of the Ta coating. TDS experiments revealed the outgassing of deuterium (as measure of its retention) for cold spray Ta coatings to be three times higher than bulk Ta and two orders of magnitude greater than bulk polycrystalline W. X-ray photoelectron spectroscopy revealed evolution of oxidation states upon deuterium irradiation and a partial recovery of the metallic signature of Ta after the thermal treatment at 1100 K."
"
Researchers at North Carolina State University have now identified a welding technique that can be used to join composite metal foam (CMF) components together without impairing the properties that make CMF desirable. CMFs hold promise for a wide array of applications because the pockets of air they contain make them light, strong and effective at insulating against high temperatures.

CMFs are foams that consist of hollow, metallic spheres -- made of materials such as stainless steel or titanium -- embedded in a metallic matrix made of steel, titanium, aluminum or other metallic alloys. The resulting material is both lightweight and remarkably strong, with potential applications ranging from aircraft wings to vehicle armor and body armor.
In addition, CMF is better at insulating against high heat than conventional metals and alloys, such as steel. The combination of weight, strength and thermal insulation means that CMF also holds promise for use in storing and transporting nuclear material, hazardous materials, explosives and other heat-sensitive materials.
However, in order to realize many of these applications, manufacturers would need to weld multiple CMF components together. And that has posed a problem.
""Traditional fusion welding uses a filler to connect two pieces of metal,"" says Afsaneh Rabiei, corresponding author of a paper on the new research and professor of mechanical and aerospace engineering at NC State. ""This is problematic, because the metal being melted to fuse two pieces of CMF is solid, so it lacks the desirable properties of the CMF on either side of it. In addition, any type of welding that uses direct heat to melt the metal results in some of the porosity in the CMF being filled in, which impairs its properties. In short, that means that most forms of traditional welding don't work well with metal foams.""
However, the researchers have now identified a form of welding that works very well. It's called induction welding, and it uses an induction coil to create an electromagnetic field that heats the metal for welding.
""Because CMF is only 30-35% metal, the electromagnetic field is able to penetrate deeply into the material -- allowing for a good weld,"" Rabiei says. ""The air pockets that make up the remaining 65-70% of the CMF serve to insulate the material against the heat. This allows induction welding to heat up the targeted area for joining two pieces of CMF, but prevents the heat from spreading out from the site of the join. That helps to preserve the CMF's properties.
""This is an important step forward, because CMF's properties make it attractive for a wide range of applications, but it's essential to have a means of welding the CMF components without impairing the properties that make it attractive in the first place.""
The paper, ""A Study on Welding of Porous Metals and Metallic Foams,"" is published in the journal Advanced Engineering Materials. The paper was co-authored by John Cance and Zubin Chacko, Ph.D. students at NC State. The work was done with support from the U.S. Department of Transportation's Pipeline and Hazardous Materials Safety Administration, under grant number PH957-20-0075.

","score: 12.686133751306166, grade_level: '13'","score: 13.893406478578889, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adem.202301430,"Metal foams are lightweight materials with exceptional impact energy absorption and unique thermal properties. Integrating these novel materials into large structural components requires developing appropriate welding techniques that preserve their bulk performance. Traditional fusion welding methods are ill‐suited for metal foams due to their porous structure, which tends to be filled during welding, compromising performance. This study focuses on solid‐state welding techniques, including friction stir welding (FSW) and induction welding, to join metal foams without adversely affecting their cellular structure. The results reveal challenges with FSW; it generates excessive heat during welding, filling the foam's porosities and disrupting its cellular structure. In contrast, induction welding is an effective method for joining composite metal foam (CMF) panels without compromising their structural integrity. The matrix between the porosities in CMF facilitates the penetration of eddy current, promoting the induction welding process. The mechanical properties of the weldments are studied through uniaxial tensile tests, while microstructural characterization of the weldment is evaluated using scanning electron microscopy. The results provide insight into the effect of various welding parameters (e.g., welding temperature, workpiece thickness, and welding environment) as well as the suitability and restrictions of such welding methods in joining CMFs."
"
Neuroengineer Silvestro Micera develops advanced technological solutions to help people regain sensory and motor functions that have been lost due to traumatic events or neurological disorders. Until now, he had never before worked on enhancing the human body and cognition with the help of technology.

Now in a study published in Science Robotics, Micera and his team report on how diaphragm movement can be monitored for successful control of an extra arm, essentially augmenting a healthy individual with a third -- robotic -- arm.
""This study opens up new and exciting opportunities, showing that extra arms can be extensively controlled and that simultaneous control with both natural arms is possible,"" says Micera, Bertarelli Foundation Chair in Translational Neuroengineering at EPFL, and professor of Bioelectronics at Scuola Superiore Sant'Anna.
The study is part of the Third-Arm project, previously funded by the Swiss National Science Foundation (NCCR Robotics), that aims to provide a wearable robotic arm to assist in daily tasks or to help in search and rescue. Micera believes that exploring the cognitive limitations of third-arm control may actually provide gateways towards better understanding of the human brain.
Micera continues, ""The main motivation of this third arm control is to understand the nervous system. If you challenge the brain to do something that is completely new, you can learn if the brain has the capacity to do it and if it's possible to facilitate this learning. We can then transfer this knowledge to develop, for example, assistive devices for people with disabilities, or rehabilitation protocols after stroke.""
""We want to understand if our brains are hardwired to control what nature has given us, and we've shown that the human brain can adapt to coordinate new limbs in tandem with our biological ones,"" explains Solaiman Shokur, co-PI of the study and EPFL Senior Scientist at the Neuro-X Institute. ""It's about acquiring new motor functions, enhancement beyond the existing functions of a given user, be it a healthy individual or a disabled one. From a nervous system perspective, it's a continuum between rehabilitation and augmentation.""
To explore the cognitive constraints of augmentation, the researchers first built a virtual environment to test a healthy user's capacity to control a virtual arm using movement of his or her diaphragm. They found that diaphragm control does not interfere with actions like controlling one's physiological arms, one's speech or gaze.

In this virtual reality setup, the user is equipped with a belt that measures diaphragm movement. Wearing a virtual reality headset, the user sees three arms: the right arm and hand, the left arm and hand, and a third arm between the two with a symmetric, six-fingered hand.
""We made this hand symmetric to avoid any bias towards either the left or the right hand,"" explains Giulia Dominijanni, PhD student at EPFL's Neuro-X Institute.
In the virtual environment, the user is then prompted to reach out with either the left hand, the right hand, or in the middle with the symmetric hand. In the real environment, the user holds onto an exoskeleton with both arms, which allows for control of the virtual left and right arms. Movement detected by the belt around the diaphragm is used for controlling the virtual middle, symmetric arm. The setup was tested on 61 healthy subjects in over 150 sessions.
""Diaphragm control of the third arm is actually very intuitive, with participants learning to control the extra limb very quickly,"" explains Dominijanni. ""Moreover, our control strategy is inherently independent from the biological limbs and we show that diaphragm control does not impact a user's ability to speak coherently.""
The researchers also successfully tested diaphragm control with an actual robotic arm, a simplified one that consists of a rod that can be extended out, and back in. When the user contracts the diaphragm, the rod is extended out. In an experiment similar to the VR environment, the user is asked to reach and hover over target circles with her left or right hand, or with the robotic rod.
Besides the diaphragm, but not reported in the study, vestigial ear muscles have also been tested for feasibility in performing new tasks. In this approach, a user is equipped with ear sensors and trained to use fine ear muscle movement to control the displacement of a computer mouse.
""Users could potentially use these ear muscles to control an extra limb,"" says Shokur, emphasizing that these alternative control strategies may help one day for the development of rehabilitation protocols for people with motor deficiencies.
Part of the third arm project, previous studies regarding the control of robotic arms have been focused on helping amputees. The latest Science Robotics study is a step beyond repairing the human body towards augmentation.
""Our next step is to explore the use of more complex robotic devices using our various control strategies, to perform real-life tasks, both inside and outside of the laboratory. Only then will we be able to grasp the real potential of this approach,"" concludes Micera.

","score: 14.205565129972712, grade_level: '14'","score: 15.052973574608643, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/scirobotics.adh1438,"Extra robotic arms (XRAs) are gaining interest in neuroscience and robotics, offering potential tools for daily activities. However, this compelling opportunity poses new challenges for sensorimotor control strategies and human-machine interfaces (HMIs). A key unsolved challenge is allowing users to proficiently control XRAs without hindering their existing functions. To address this, we propose a pipeline to identify suitable HMIs given a defined task to accomplish with the XRA. Following such a scheme, we assessed a multimodal motor HMI based on gaze detection and diaphragmatic respiration in a purposely designed modular neurorobotic platform integrating virtual reality and a bilateral upper limb exoskeleton. Our results show that the proposed HMI does not interfere with speaking or visual exploration and that it can be used to control an extra virtual arm independently from the biological ones or in coordination with them. Participants showed significant improvements in performance with daily training and retention of learning, with no further improvements when artificial haptic feedback was provided. As a final proof of concept, naïve and experienced participants used a simplified version of the HMI to control a wearable XRA. Our analysis indicates how the presented HMI can be effectively used to control XRAs. The observation that experienced users achieved a success rate 22.2% higher than that of naïve users, combined with the result that naïve users showed average success rates of 74% when they first engaged with the system, endorses the viability of both the virtual reality–based testing and training and the proposed pipeline."
"
For the first time, researchers have shown that 3D-printed polymer-based micro-optics can withstand the heat and power levels that occur inside a laser. The advance enables inexpensive compact and stable laser sources that would be useful in a variety of applications, including the lidar systems used for autonomous vehicles.

""We significantly reduced the size of a laser by using 3D printing to fabricate high-quality micro-optics directly on glass fibers used inside of lasers,"" said research team leader Simon Angstenberger from the 4th Physics Institute at University of Stuttgart in Germany. ""This is the first implementation of such 3D-printed optics in a real-world laser, highlighting their high damage threshold and stability.""
In the Optica Publishing Group journal Optics Letters, the researchers describe how they 3D printed microscale optics directly onto optical fibers to combine fibers and laser crystals inside a single laser oscillator in a compact way. The resulting hybrid laser exhibited stable operation at output powers of over 20 mW at 1063.4 nm and had a maximum output power of 37 mW.
The new laser combines the compactness, robustness and low cost of fiber-based lasers with the advantages of crystal-based solid-state lasers, which can have a broad range of properties such as different powers and colors.
""Until now, 3D-printed optics have primarily been used for low power applications such as endoscopy,"" said Angstenberger. ""The ability to use them with high power applications could be useful for lithography and laser marking, for example. We showed that these 3D micro-optics printed onto fibers can be used to focus large amounts of light down to a single point, which could be useful for medical applications such as precisely destroying cancerous tissue.""
Taking the heat
The 4th Physics Institute at University of Stuttgart has a long history of developing 3D-printed micro-optics, especially the ability to print them directly on fibers. They use a 3D printing approach known as two-photon polymerization, which focuses an infrared laser into a UV sensitive photoresist. In the laser's focal region, two infrared photons will be absorbed simultaneously, which hardens the UV resist. Moving the focus around allows various shapes to be created with high precision. This method use can be used to create miniaturized optics and also allows novel functionalities such as the creation of free-form optics or complex lens systems.

""Because these 3D-printed elements are made of polymers, it was unclear whether they could withstand the significant amount of heat load and optical power that occurs inside a laser cavity,"" said Angstenberger. ""We found that they are surprisingly stable, and we were not able to observe any kind of damage on the lenses even after several hours of running the laser.""
For the new study, the researchers used a 3D printer made by Nanoscribe to fabricate lenses with a 0.25 mm diameter and height of 80 microns onto the end of a fiber with the same diameter using two-photon polymerization. This involved designing an optical element with commercial software, inserting the fiber into the 3D printer, and then printing the small structure on the end of the fiber. This process must be extremely precise in terms of aligning the printing to the fiber and the accuracy of the printing itself.
Creating a hybrid laser
After the printing was complete, the researchers assembled the laser and the laser cavity. Rather than using a crystal inside a laser cavity made of bulky and costly mirrors, they used fibers to form part of the cavity, creating a hybrid fiber-crystal laser. The lenses printed at the end of the fibers focus and collect -- or couple -- the light into and out of the laser crystal. They then glued the fibers into a mount to make the laser system more stable and less susceptible to air turbulence. The crystal and the printed lenses measured just 5 X 5 cm2.
Continuously recording the laser power over several hours verified that the printed optics inside the system did not deteriorate or affect the long-term properties of the laser. Additionally, scanning electron microscopy images of the optics after use in the laser cavity did not show any visible damage. ""Interestingly, we found that the printed optics were more stable than the commercial fiber Bragg grating we used, which ended up limiting our maximum power,"" said Angstenberger.
The researchers are now working to optimize the efficiency of the printed optics. Larger fibers with optimized freeform and aspherical lens designs or a combination of lenses printed directly onto the fiber could help improve the output power. They would also like to demonstrate different crystals in the laser, which could allow the output to be customized for specific applications.

","score: 14.539659407237597, grade_level: '15'","score: 15.008992140167024, grade_levels: ['college_graduate'], ages: [24, 100]",10.1364/OL.504940,"Microscale 3D-printing has revolutionized micro-optical applications ranging from endoscopy, imaging, to quantum technologies. In all these applications, miniaturization is key, and in combination with the nearly unlimited design space, it is opening novel, to the best of our knowledge, avenues. Here, we push the limits of miniaturization and durability by realizing the first fiber laser system with intra-cavity on-fiber 3D-printed optics. We demonstrate stable laser operation at over 20 mW output power at 1063.4 nm with a full width half maximum (FWHM) bandwidth of 0.11 nm and a maximum output power of 37 mW. Furthermore, we investigate the power stability and degradation of 3D-printed optics at Watt power levels. The intriguing possibilities afforded by free-form microscale 3D-printed optics allow us to combine the gain in a solid-state crystal with fiber guidance in a hybrid laser concept. Therefore, our novel ansatz enables the compact integration of a bulk active media in fiber platforms at substantial power levels."
"
Protein-splitting enzymes play an important role in many physiological processes. Such proteases are generally present in an inactive state, only becoming activated under certain conditions. Some are linked to diseases like infections or cancer, making it important to have methods that can selectively detect active proteases. In the journal Angewandte Chemie, scientists have introduced a new class of protease-activity sensors: gold nanoparticles equipped with peptide DNA.

Led by Devleena Samanta and Anna Capasso (The University of Texas at Austin, USA), the team has shown that these nanoprobes can sense multiple active proteases in parallel (multiplexed measurement). The method works at room temperature and does not require complicated sample preparation or elaborate instruments.
At the core of the novel probes are gold nanoparticles equipped with chains made of a peptide and a DNA fragment. The peptide structure is designed to be one that is split by the protease being detected. The DNA acts as a unique barcode for identifying the peptide and also amplifies the signal. If the desired protease is present in its active form in the sample, the peptide splits it. This releases the DNA barcode into the solution, where it can be detected based on its sequence.
To carry out this detection, the team uses a CRISPR/Cas12a test: the enzyme Cas12a is bound to a guide RNA (gRNA) to form an inactive complex. The gRNA contains a segment that specifically binds to the barcode DNA. This activates the Cas12a, so that it can now ""cut up"" single-stranded DNA (ssDNA). For the test, the researchers add ssDNA molecules with a fluorescing group (fluorophore) at one end and a quencher, which ""switches off"" the fluorescence of the fluorophore (as long as they are close enough), at the other. If the ssDNA is cut up, the fluorophore and quencher move further apart. This results in strong fluorescence that indicates that the protease being tested for is present (detection limit of about 58 pM).
If no instruments are available on site and the test must go fast, detection is possible with the naked eye: if the protease splits the peptide on the probe, the surface charge of the gold nanoparticles changes and they aggregate. The color of these so-called ""plasmonic nanostructures"" depends significantly on their degree of aggregation. It is possible to detect nanomolar protease concentrations based on the color change in the test solution.
Multiplexed detection of the proteases 3CL and caspase3 allowed the team to demonstrate the high sensitivity and selectivity of their new method. 3CL is a marker for active coronavirus infection and COVID patients often also have elevated activity of the apoptosis marker caspase3. The clinical potential of this test was also demonstrated by the detection of cathepsin B, a protease related to colorectal cancer, in three different tumor cell lines obtained from patients.
These nanoprobes yield 100-fold higher fluorescence signals compared to commercial fluorescence-based protease sensors. Moreover, virtually any protease can be detected if the peptide it splits is known. Taken together, these nanoprobes can potentially enable early disease detection and improve the precision and reliability of diagnostic tests through multiplexing.

","score: 12.331283024376003, grade_level: '12'","score: 12.96066851554518, grade_levels: ['college'], ages: [18, 24]",10.1002/anie.202310964,"We report the development of a new class of protease activity sensors called DNA‐barcoded plasmonic nanostructures. These probes are comprised of gold nanoparticles functionalized with peptide‐DNA conjugates (GPDs), where the peptide is a substrate of the protease of interest. The DNA acts as a barcode identifying the peptide and facilitates signal amplification. Protease‐mediated peptide cleavage frees the DNA from the nanoparticle surface, which is subsequently measured via a CRISPR/Cas12a‐based assay as a proxy for protease activity. As proof‐of‐concept, we show activity‐based, multiplexed detection of the SARS‐CoV‐2‐associated protease, 3CL, and the apoptosis marker, caspase 3, with high sensitivity and selectivity. GPDs yield >25‐fold turn‐on signals, 100‐fold improved response compared to commercial probes, and detection limits as low as 58 pM at room temperature. Moreover, nanomolar concentrations of proteases can be detected visually by leveraging the aggregation‐dependent color change of the gold nanoparticles. We showcase the clinical potential of GPDs by detecting a colorectal cancer‐associated protease, cathepsin B, in three different patient‐derived cell lines. Taken together, GPDs detect physiologically relevant concentrations of active proteases in challenging biological samples, require minimal sample processing, and offer unmatched multiplexing capabilities (mediated by DNA), making them powerful chemical tools for biosensing and disease diagnostics."
"
The transition to a society without fossil fuels means that the need for batteries is increasing at a rapid pace. At the same time, the increase will mean a shortage of the metals lithium and cobalt, which are key components in the most common battery types. One option is a sodium-ion battery, where table salt and biomass from the forest industry make up the main raw materials. Now, researchers from Chalmers University of Technology, Sweden, show that these sodium-ion batteries have an equivalent climate impact as their lithium-ion counterparts -- without the risk of running out of raw materials.

""The materials we use in the batteries of the future will be important in order to be able to switch to renewable energy and a fossil-free vehicle fleet,"" says Rickard Arvidsson, Associate Professor of Environmental Systems Analysis at Chalmers.
According to the European Commission's Critical Raw Materials Act, the demand for critical raw battery materials is expected to increase exponentially as EU countries transition to renewable energy systems and electric vehicles. The green transition will also require more local production of batteries and other new fossil-free technologies, and a steady supply of raw materials is needed to meet demand. At the same time, such production carries a high risk of supply disruptions, due to the limited number of sources for raw materials. ""Lithium-ion batteries are becoming a dominant technology in the world and they are better for the climate than fossil-based technology is, especially when it comes to transport. But lithium poses a bottleneck. You can't produce lithium-based batteries at the same rate as you want to produce electric cars, and the deposits risk being depleted in the long term,"" says Rickard Arvidsson. In addition to this, critical battery materials, such as lithium and cobalt, are largely mined in just a few places in the world, posing a risk to the supply.
Sodium-ion batteries offer promising technology
The development of new battery technologies is moving fast in the quest for the next generation of sustainable energy storage -- which should preferably have a long lifetime, have a high energy density and be easy to produce. The research team at Chalmers chose to look at sodium-ion batteries, which contain sodium -- a very common substance found in common sodium chloride -- instead of lithium. In a new study, they have carried out a so-called life cycle assessment of the batteries, where they have examined their total environmental and resource impact during raw material extraction and manufacturing. ""We came to the conclusion that sodium-ion batteries are much better than lithium-ion batteries in terms of impact on mineral resource scarcity, and equivalent in terms of climate impact. Depending on which scenario you look at, they end up at between 60 and just over 100 kilogrammes of carbon dioxide equivalents per kilowatt hour theoretical electricity storage capacity, which is lower than previously reported for this type of sodium-ion battery. It's clearly a promising technology,"" says Rickard Arvidsson.
The researchers also identified a number of measures with the potential to further reduce climate impact, such as developing an environmentally better electrolyte, as it accounted for a large part of the battery's total impact.
Green energy requires energy storage
Today's sodium-ion batteries are already expected to be used for stationary energy storage in the electricity grid, and with continued development, they will probably also be used in electric vehicles in the future. ""Energy storage is a prerequisite for the expansion of wind and solar power. Given that the storage is done predominantly with batteries, the question is what those batteries will be made from? Increased demand for lithium and cobalt could be an obstacle to this development,"" says Rickard Arvidsson.

The major advantage of the technology is that the materials in the sodium-ion batteries are abundant and can be found all over the world. One electrode in the batteries -- the cathode -- has sodium ions as a charge carrier, and the other electrode -- the anode -- consists of hard carbon, which in one of the examples the Chalmers researchers have investigated can be produced from biomass from the forest industry. In terms of production processes and geopolitics, sodium-ion batteries are also an alternative that can accelerate the transition to a fossil-free society. ""Batteries based on abundant raw materials could reduce geopolitical risks and dependencies on specific regions, both for battery manufacturers and countries,"" says Rickard Arvidsson.
More about the study
The study is a prospective life cycle assessment of two different sodium-ion battery cells where the environmental and resource impact is calculated from cradle to gate, i.e. from raw material extraction to the manufacture of a battery cell. The functional unit of the study is 1 kWh theoretical electricity storage capacity at the cell level. Both types of battery cells are mainly based on abundant raw materials. The anode is made up of hard carbon from either bio-based lignin or fossil raw materials, and the cathode is made up of so-called ""Prussian white"" (consisting of sodium, iron, carbon and nitrogen). The electrolyte contains a sodium salt. The production is modelled to correspond to a future, large-scale production. For example, the actual production of the battery cell is based on today's large-scale production of lithium-ion batteries in gigafactories.
Two different electricity mixes were tested, as well as two different types of so-called allocation methods -- that is, allocation of resources and emissions. One where the climate and resource impact is distributed between coproducts based on mass, and one method where all impact is allocated to the main product (the sodium-ion battery and its components and materials).
The study was funded by the Swedish Energy Agency through the Battery Fund Program.

","score: 14.92613277133825, grade_level: '15'","score: 15.604429038877491, grade_levels: ['college_graduate'], ages: [24, 100]",10.1111/jiec.13452,"Batteries are enablers for reducing fossil‐fuel dependency and climate‐change impacts. In this study, a prospective life cycle assessment (LCA) of large‐scale production of two different sodium‐ion battery (SIB) cells is performed with a cradle‐to‐gate system boundary. The SIB cells modeled have Prussian white cathodes and hard carbon anodes based only on abundant elements and thus constitute potentially preferable options to current lithium‐ion battery (LIB) cells from a mineral resource scarcity point of view. The functional unit was 1 kWh theoretical electricity storage capacity, and the specific energy density of the cells was 160 Wh/kg. Data for the cathode active material come from a large‐scale facility under construction and data for the SIB cell production is based on a large‐scale LIB cell gigafactory. For other SIB cell materials, prospective inventory data was obtained from a generic eight‐step procedure developed, which can be used by other LCA practitioners. The results show that both SIB cells indeed have considerably lower mineral resource scarcity impacts than nickel‐manganese‐cobalt (NMC)‐type LIB cells in a cradle‐to‐gate perspective, while their global warming impacts are on par. Main recommendations to SIB manufacturers are to source fossil‐free electricity for cell production and use hard carbon anodes based on lignin instead of phenolic resin. Additionally, since none of the assessed electrolytes had clearly lower cradle‐to‐gate impacts than any other, more research into SIB electrolyte materials with low environmental and resource impacts should be prioritized. An improvement of the SIB cell production model would be to obtain large‐scale production data specific to SIB cells."
"
A verdant forest is one of the most iconic symbols of the power of nature, from the abundance of plant and animal life that shelters among its thick vegetation to the positive impact it has on Earth's climate, thanks in part to photosynthesis, which removes carbon dioxide from the air, thereby mitigating the effects of global warming. Cutting down tropical evergreen forests has played a significant role in exacerbating the climate crisis, and many environmental initiatives focus on rehabilitating destroyed forests or planting new trees. The problem is that, even if we were to cover the entire surface of the planet with trees, the resultant massive photosynthetic force would still not suffice to absorb the huge surplus of carbon dioxide -- the major greenhouse gas -- that has been pumped into the atmosphere during the past 150 years of human activity.

There is another way of dealing with the climate crisis, which, unlike the forests, is neither natural nor green, at least not in the literal sense of the word. This artificial solution consists of erecting fields of dark-colored solar panels. Obviously, the production of electricity from solar power has a positive impact on climate balance, since it replaces power stations that use fossil fuels such as coal and gas, thereby reducing harmful emissions of greenhouse gases that accumulate at increasing concentrations in the atmosphere.
But both the green, natural forest and the artificial, dark ""solar forest"" produce other effects, some of which can be problematic from a climate perspective. They are both relatively dark, which means that they absorb a large proportion of the radiation from the Sun (making them ""low albedo"" surfaces in the professional jargon) and, as a result, they heat up. Some of this energy is used for photosynthesis in natural forests or to produce electricity in solar ""forests"" -- but most returns to the atmosphere as fluxes of energy, heating it up. In contrast, the light-colored desert soil, for example, reflects a significant portion of the sunlight back into space, which does not add to the accumulated heat in the atmosphere. (Such soil is known as a surface with a ""high albedo."")
What, then, would be the most effective use of a certain plot of land in terms of the climate crisis: planting a forest, which is a natural means of absorbing carbon dioxide from the atmosphere, or erecting fields of solar panels, which reduce the emission of carbon dioxide into the atmosphere? This dilemma has long been debated by decision-makers around the world.
Now, for the first time -- based on findings from arid areas and on comprehensive measurements of the energy flow exchanged between the ground and the atmosphere -- we may have an answer to this question, thanks to a new study led by Dr. Rafael Stern, Dr. Jonathan Muller and Dr. Eyal Rotenberg from Prof. Dan Yakir's lab at the Earth and Planetary Sciences Department of the Weizmann Institute of Science. The study, published today in PNAS Nexus, was coauthored by Madi Amer, also from Prof. Yakir's lab, and Dr. Lior Segev of Weizmann's Physics Core Facilities Department.
A century of photosynthesis
The first stage of the study involved comparing the impact of a forest situated on the border of an arid area to that of a field of solar panels, or a solar farm, in an arid environment. Arid areas are characterized by a large amount of sunlight and a relative paucity of plant diversity and biomass, which makes them especially suited for large solar farms. Such fields already exist in Israel in the Arava and the Negev, and the government has plans to erect more in Jordan through an international collaboration. Elsewhere in the world, huge solar projects are under way, for example, in the deserts of China, and the European Union has long discussed plans to build solar farms in the Sahara. The Weizmann researchers traveled down to the Arava in a truck carrying a mobile measuring station, specially designed by Yakir and Rotenberg. They began by placing this measuring station close to the solar panel field to measure the flux of energy between the ground and the atmosphere -- as it occurs in an arid area without solar panels. Then they placed the station inside the solar panel field itself; this required overcoming operational and safety challenges stemming from the sensitivity of the panels, which had interfered with such measurements in the past. At both locations, the experiments were repeated during different seasons of the year. Finally, to compare their results to the similar process occurring in a forest, the scientists relied on data that Yakir and Rotenberg had collected over the past 20 years in Yatir Forest -- the largest of the forests planted in Israel by the Jewish National Fund -- on the northern edge of the arid Negev Desert.

The researchers discovered that the albedo effect of both of these ""forests"" was similar, but the absorption or prevention of carbon emissions was very different, favoring the solar forest. To complete the comparison, they calculated the equilibrium points at which the opposing effects on the Earth's climate -- heating from both forests' dark color and cooling from reduced atmospheric carbon dioxide -- balance out one another, ultimately lowering the concentration of greenhouse gases in the atmosphere as a result of the natural forest's photosynthesis or the solar forest's reduced electricity-production emissions. It turns out that it takes two and a half years for the heat emitted by solar farms to be offset by the carbon emissions that are averted thanks to the energy they generate. This even takes into account the carbon emissions from the manufacture, transportation and operation of the panels, as well as of batteries used for electricity storage. In the case of a forest of similar size, it would take more than 100 years of photosynthesis to offset its heating effect.
The researchers also wanted to establish how the heating and cooling ratio changed in other climates. Using data from similar measurements collected from satellites and databases, they found that in more humid environments such as the tropics or in temperate grassland regions like Europe, the heating effect of planting large numbers of trees is smaller. This is because the ground there is darker to begin with, which means that the albedo-related effect is smaller, and the carbon capture rate by trees is higher, so the break-even point is reached within 15 to 18 years. With that, they note, it must be kept in mind that less open space is available in these areas for planting new forests.
Stern and Muller explain: ""Our study unequivocally shows that in arid environments, where most of the open land reserves exist, building solar farms is far more effective than planting forests when it comes to dealing with the climate crisis. In this environment, erecting solar panels on areas that are far smaller than forests (up to one hundredth of the size) will offset exactly the same quantity of carbon emissions. Having said that, forests currently absorb close to one-third of humanity's annual carbon emissions, so it's of paramount importance to safeguard this capability and prevent the kind of widescale deforestation that takes place in tropical regions. Moreover, forests play a vital role in the global rain cycle, in maintaining biodiversity and in many other environmental and social contexts. Therefore, the conclusion from our study is that we must protect the Earth's forests, and that the most appropriate solution to the climate crisis is to combine the planting and rehabilitation of forests in humid regions with erecting fields of solar panels in arid regions.""
Prof. Dan Yakir's research is supported by the Helen Kimmel Center for Planetary Science and the Schwartz Reisman Collaborative Science Program. 
Prof. Yakir is the incumbent of the Hilda and Cecil Lewis Professorial Chair.

","score: 16.555545977011494, grade_level: '17'","score: 18.24482183908046, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/pnasnexus/pgad352,"Suppression of carbon emissions through photovoltaic (PV) energy and carbon sequestration through afforestation provides complementary climate change mitigation (CCM) strategies. However, a quantification of the “break-even time” (BET) required to offset the warming impacts of the reduced surface reflectivity of incoming solar radiation (albedo effect) is needed, though seldom accounted for in CCM strategies. Here, we quantify the CCM potential of PV fields and afforestation, considering atmospheric carbon reductions, solar panel life cycle analysis (LCA), surface energy balance, and land area required across different climatic zones, with a focus on drylands, which offer the main remaining land area reserves for forestation aiming climate change mitigation (Rohatyn S, Yakir D, Rotenberg E, Carmel Y. Limited climate change mitigation potential through forestation of the vast dryland regions. 2022. Science 377:1436–1439). Results indicate a BET of PV fields of ∼2.5 years but &gt;50× longer for dryland afforestation, even though the latter is more efficient at surface heat dissipation and local surface cooling. Furthermore, PV is ∼100× more efficient in atmospheric carbon mitigation. While the relative efficiency of afforestation compared with PV fields significantly increases in more mesic climates, PV field BET is still ∼20× faster than in afforestation, and land area required greatly exceeds availability for tree planting in a sufficient scale. Although this analysis focusing purely on the climatic radiative forcing perspective quantified an unambiguous advantage for the PV strategy over afforestation, both approaches must be combined and complementary, depending on climate zone, since forests provide crucial ecosystem, climate regulation, and even social services."
"
Various molecular systems have been developed by researchers for photoinduced (i.e., light-driven) electron transfer, including supramolecules, hybrid materials, and organic polymeric systems. While these systems fulfill the distance criterion required by the electron donor and acceptor for efficient electron transfer, they frequently fall short in accommodating molecular motion, especially in fluid environments. Is there a viable approach to design a system that facilitates electron transfer without succumbing to these limitations?

This issue has been specifically addressed in a recent study. A team of researchers from the Japan Advanced Institute of Science and Technology (JAIST), led by Associate Professor Kosuke Okeyoshi and including Associate Professor Shun Nishimura and Graduate course Student Reina Hagiwara, has now developed a copolymer-conjugated nanocatalytic system to enhance active electron transfer for increased photoinduced hydrogen generation.
Their study, published in Chemical Communications, aims to overcome the limitations of current photoinduced electron transfer systems. The objective of the researchers was to establish an efficient catalyst system capable of promoting electron transfer with only a minimum number of side reactions. Dr. Okeyoshi explains: ""This system has potential real-life applications for the hydrogen economy. By integrating the system with an oxygen-generating system, photoinduced water splitting (artificial photosynthesis) is anticipated.""
In this regard, viologen is a well-known molecule that is both an efficient electron donor and acceptor. The researchers had previously exploited this property of viologen to develop an electron transfer system, which included the copolymer poly(N-isopropylacrylamide-co-Viologen) (PNV) and modified platinum nanoparticles (Pt NPs). In this system, the temperature-dependent phase transition in PNV responds to viologen's redox changes, allowing for a cyclical electron transfer process for continuous hydrogen generation. However, while the PNVs near the Pt NPs participated in the electron transfer process, free PNV molecules situated farther away could also accept electrons.
To address this issue, the researchers have now designed a copolymer-conjugated nanocatalytic system using the ternary random copolymer poly(NIPAAm-co-Acrylamide-co-Viologen) or PNAV, which was synthesized by precisely controlling the molecular weight and introduction ratio of the polymeric units.
A notable characteristic of PNAV is its temperature-responsive behavior, marked by a phase transition dependent on temperature. This unique copolymer exhibits a discernible shift, oscillating between a swollen state in its oxidized form (PNAV2+) and a shrunken state in its reduced form (PNAV+). Additionally, the connection of PNAV to Pt NPs involves a reduction process, providing control over the distance between the viologen and the Pt NPs. Specifically, the precise swelling/shrinking of PNAV on the Pt NPs proves crucial to the success of the proposed cyclic electron transfer process at a given distance.
The present innovation leverages the advantages of a stimuli-responsive polymer chain to achieve dynamic electron transfer. The copolymer-conjugated nanocatalytic system not only holds promise for facilitating active electron transfer in photoinduced hydrogen generation but also demonstrates potential utility in artificial photosynthetic reactions, such as photoinduced water splitting. Moreover, this innovative approach is anticipated to have broader applications beyond photochemical reactions to encompass various domains, including electrochemical reactions and macromolecular recognition.
The sustainable cyclic electron transfer process enabled by this technology thus presents opportunities for advancements across diverse scientific disciplines. ""The long-term implications include the promotion of a hydrogen energy society powered by sunlight and the manufacturing of bio-inspired soft materials as products,"" concludes Dr. Okeyoshi.

","score: 19.509214381880103, grade_level: '20'","score: 19.965875504870517, grade_levels: ['college_graduate'], ages: [24, 100]",10.1039/d3cc05242g,"To enhance photoinduced H2 generation, we precisely synthesize ternary random copolymers capable of transferring electrons through phase transitions in response to viologen's redox changes within 2 nm distance from the surface of the Pt nanoparticle."
"
Scientists have solved a decades-long puzzle and unveiled a near unbreakable substance that could rival diamond, as the hardest material on earth, a study says.

Researchers found that when carbon and nitrogen precursors were subjected to extreme heat and pressure, the resulting materials -- known as carbon nitrides -- were tougher than cubic boron nitride, the second hardest material after diamond.
The breakthrough opens doors for multifunctional materials to be used for industrial purposes including protective coatings for cars and spaceships, high-endurance cutting tools, solar panels and photodetectors, experts say.
Materials researchers have attempted to unlock the potential of carbon nitrides since the 1980s, when scientists first noticed their exceptional properties, including high resistance to heat.
Yet after more than three decades of research and multiple attempts to synthesize them, no credible results were reported.
Now, an international team of scientists -- led by researchers from the Centre for Science at Extreme Conditions at the University of Edinburgh and experts from the University of Bayreuth, Germany and the University of Linköping, Sweden -- have finally achieved a breakthrough.
The team subjected various forms of carbon nitrogen precursors to pressures of between 70 and 135 gigapascals -- around one million times our atmospheric pressure -- while heating it to temperatures of more than one and a half thousand degrees celsius.

To identify the atomic arrangement of the compounds under these conditions, the samples were illuminated by an intense X-ray beam at three particle accelerators -- the European Synchrotron Research Facility in France, the Deutsches Elektronen-Synchrotron in Germany and the Advanced Photon Source based in the United States.
Researchers discovered that three carbon nitride compounds were found to have the necessary building blocks for super-hardness.
Remarkably, all three compounds retained their diamond-like qualities when they returned to ambient pressure and temperature conditions.
Further calculations and experiments suggest the new materials contain additional properties including photoluminescence and high energy density, where a large amount of energy can be stored in a small amount of mass.
Researchers say the potential applications of these ultra-incompressible carbon nitrides is vast, potentially positioning them as ultimate engineering materials to rival diamonds.
The research, published in Advanced Materials, was funded by the UKRI FLF scheme and European research grants.
Dr Dominique Laniel, Future Leaders Fellow, Institute for Condensed Matter Physics and Complex Systems, School of Physics and Astronomy, University of Edinburgh, said: ""Upon the discovery of the first of these new carbon nitride materials, we were incredulous to have produced materials researchers have been dreaming of for the last three decades. These materials provide strong incentive to bridge the gap between high pressure materials synthesis and industrial applications.""
Dr Florian Trybel, Assistant Professor, Department of Physics, Chemistry and Biology, University of Linköping, said: ""These materials are not only outstanding in their multi-functionality, but show that technologically relevant phases can be recovered from a synthesis pressure equivalent to the conditions found thousands of kilometres in the Earth's interior. We strongly believe this collaborative research will open up new possibilities for the field.""

","score: 18.030070588235294, grade_level: '18'","score: 20.980102352941174, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adma.202308030,"Carbon nitrides featuring three‐dimensional frameworks of CN4 tetrahedra are one of the great aspirations of materials science, expected to have a hardness greater than or comparable to diamond. After more than three decades of efforts to synthesize them, no unambiguous evidence of their existence has been delivered. Here, the high‐pressure high‐temperature synthesis of three carbon‐nitrogen compounds, tI14‐C3N4, hP126‐C3N4, and tI24‐CN2, in laser‐heated diamond anvil cells, is reported. Their structures are solved and refined using synchrotron single‐crystal X‐ray diffraction. Physical properties investigations show that these strongly covalently bonded materials, ultra‐incompressible and superhard, also possess high energy density, piezoelectric, and photoluminescence properties. The novel carbon nitrides are unique among high‐pressure materials, as being produced above 100 GPa they are recoverable in air at ambient conditions."
"
Self-propelled nanoparticles could potentially advance drug delivery and lab-on-a-chip systems -- but they are prone to go rogue with random, directionless movements. Now, an international team of researchers has developed an approach to rein in the synthetic particles.

Led by Igor Aronson, the Dorothy Foehr Huck and J. Lloyd Huck Chair Professor of Biomedical Engineering, Chemistry and Mathematics at Penn State, the team redesigned the nanoparticles into a propeller shape to better control their movements and increase their functionality. They published their results in the journal Small.
Due to fabrication challenges, the shape of nanoparticles has previously been limited to rods and donuts, according to Ashlee McGovern, doctoral student in chemistry at Penn State and first author on the paper. With a nanoscribe machine that can 3D print at the nanoscale in Penn State's Materials Research Institute, McGovern experimented to optimize the nanoparticle shape. She redesigned the shape of the particles to a propeller, which can spin efficiently when triggered by a chemical reaction or magnetic field.
The propeller shape employs chirality, akin to a screw or spiral staircase, where the top face is mirrored by the bottom face.
""Shape predetermines how a particle is going to move,"" McGovern said. ""Chirality, or handedness, as a design feature has not been utilized enough in nanoparticle research and is a way to make the particles move in more and more complex ways.""
The chiral shape allows the particles to move in a prescribed direction, and, depending on the tilt of the blades, spin clockwise or counterclockwise in place, fueled by a chemical reaction between the metals in the nanoparticles and hydrogen peroxide.
After experimenting with different numbers and angles of fins, as well as different thicknesses, researchers found that using four or more fins at a 20-degree tilt and 3.3-micron thickness allowed for the greatest amount of stability. With three or fewer fins, the propellers exhibit uncontrolled movement.

The increased control allowed researchers to manipulate the particles to capture and transport polymer cargo particles.
""Using a magnetic field, we can steer the micropropellers to hunt down and collect cargo particles,"" McGovern said. ""Our lab's rod- and donut-shaped nanoparticles would accidentally pick up cargo, but not in any controlled fashion.""
To further control the movements of the particles, researchers manipulated the rotational direction of the micropropellers.
""With the built-in flows that the particles create, we can control the particle-to-particle interactions between the two propellers,"" McGovern said. ""Switching the rotational direction from counterclockwise to clockwise and vice versa allows two propellers to attract or repel each other.""
Aronson, who heads the Active Biomaterials Lab in which McGovern works, emphasized the future reach of this research.
""Using tailored mechanical, magnetic and chemical responses, we can exert more control than ever before on these nanoparticles,"" Aronson said. ""In the future, we can leverage this control to apply this technology to design concepts for microscale devices or microrobotics.""
In addition to McGovern and Aronson, the co-authors include Mu-Jie Huang and Raymond Kapral from the University of Toronto and Jiyuan Wang from the Heilongjiang University of Science and Technology, who contributed simulation work to support the experimental research. The U.S. Department of Energy and the Natural Sciences and Engineering Research Council of Canada partially funded this work.
Video URL: https://vimeo.com/892258599 

","score: 14.288428571428572, grade_level: '14'","score: 15.237642857142859, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/smll.202304773,"Practical applications of synthetic self‐propelled nano and microparticles for microrobotics, targeted drug delivery, and manipulation at the nanoscale are rapidly expanding. However, fabrication limitations often hinder progress, resulting in relatively simple shapes and limited functionality. Here, taking advantage of 3D nanoscale printing, chiral micropropellers powered by the hydrogen peroxide reduction reaction are fabricated. Due to their chirality, the propellers exhibit multifunctional behavior controlled by an applied magnetic field: spinning in place (loitering), directed migration in the prescribed direction, capture, and transport of polymer cargo particles. Design parameters of the propellers are optimized by computation modeling based on mesoscale molecular dynamics. It is predicted by computer simulations, and confirmed experimentally, that clockwise rotating propellers attract each other and counterclockwise repel. These results shed light on how chirality and shape optimization enhance the functionality of synthetic autonomous micromachines."
"
Researchers from Osaka University and collaborating partners have  developed a new means of manipulating Mie scattering from  nanostructures. By judicious choice of the laser illumination position  with respect to the center of a nanostructure, one can strongly enhance  optical responses that would not have been otherwise possible. This work  is an important milestone in modern meta-photonics and will benefit  computing and communication technologies.

When you look up at the sky and see clouds of wondrous shapes, or struggle to peer through dense, hazy fog, you're seeing the results of 'Mie scattering', which is what happens with light interacts with particles of a certain size. There is a growing body of research that aims to manipulate this phenomenon and make possible an array of exciting technologies.
Now, in a study recently published in Nature Communications, a multi-institutional research team including Osaka University has overcome what were thought to be fundamental limitations of how to enhance the efficiency of Mie scattering.
Researchers in the field of meta-photonics use phenomena like Mie scattering to generate device outputs that are not possible with conventional nanomaterials, for example, low-power surveillance technology. For many years, though, researchers have thought that Mie scattering can only be manipulated by changing the wavelength of the light or the size of the nanostructure it interacts with. Overcoming this limitation -by expanding on recent studies that focused on the alignment between the laser and the nanostructures -- was the goal of the present work.
""In our approach, we misalign the incident laser,"" explains Yu-Lung Tang, lead author of the study. ""In other words, we displace the illumination position on a nanometer scale from the center of the target nanostructure.""
By doing so, the researchers found that the scattering exhibited by the silicon nanostructures depended on the extent of the misalignment of the tightly focused laser with the center of the nanostructure. A misalignment of only 100 nanometers could induce the maximized Mie resonant scattering that were previously obscured because conventional microscopy uses plane wave light illumination. These findings could increase the efficiency of optical technologies. For example, the team's work could help researchers develop all-optical transistors, i.e., transistors that use light instead of electricity and exceed the performance of their conventional electronic counterparts.
""We're excited because we've expanded upon the fundamentals of the century-old light theory of Mie scattering,"" says Junichi Takahara, senior author. ""Applications are wide ranging and currently underway in our laboratory.""
This work is an important step forward in our understanding of light-matter interactions. Furthermore, these results are not limited to silicon and the incident laser does not need to be a visible wavelength, encouraging exciting advancements in meta-photonics and bringing fantastical technologies like cloaking devices one step closer to reality.

","score: 16.05255965292842, grade_level: '16'","score: 17.03058111656582, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43063-y,"The canonical studies on Mie scattering unravel strong electric/magnetic optical responses in nanostructures, laying foundation for emerging meta-photonic applications. Conventionally, the morphology-sensitive resonances hinge on the normalized frequency, i.e. particle size over wavelength, but non-paraxial incidence symmetry is overlooked. Here, through confocal reflection microscopy with a tight focus scanning over silicon nanostructures, the scattering point spread functions unveil distinctive spatial patterns featuring that linear scattering efficiency is maximal when the focus is misaligned. The underlying physical mechanism is the excitation of higher-order multipolar modes, not accessible by plane wave irradiation, via displacement resonance, which showcases a significant reduction of nonlinear response threshold, sign flip in all-optical switching, and spatial resolution enhancement. Our result fundamentally extends the century-old light scattering theory, and suggests new dimensions to tailor Mie resonances."
"
Until the early morning of February 24th, 2022, Ukrainian scientist Olena Iarmosh did not believe there would be a Russian invasion of Ukraine. Iarmosh grew up and had settled in Kharkiv, her beloved city in Eastern Ukraine and only 40 km away from the Russian border, where she worked for more than 16 years as a lecturer in higher education before fleeing to Switzerland. At approximately 5AM, she awoke to the sounds of bombing, hoping that they were merely the loud sounds of technical maintenance at the local power plant.

""My city looks worse now after the bombing than after two occupations by German troops,"" says Iarmosh. Iarmosh remained steadfast in her apartment throughout the bombardment for nine days before fleeing westward, first in western Ukraine, until the bombing started there too. She then fled to Switzerland, all the while ensuring her teaching duties online, and eventually landed a temporary position at EPFL with Gaétan de Rassenfosse.
In the meantime, de Rassenfosse and his team set out to quantify the impact of the war's influence on Ukrainian research, with one of the most extensive surveys yet, analyzing the responses from roughly 2500 Ukrainian scientists in autumn 2022. The results are published in Humanities and Social Sciences Communications.
""Our survey shows that Ukraine has lost almost 20% of top scientists, like Olena,"" explains de Rassenfosse of EPFL's College of Management of Technology, who was able to hire Iarmosh to work in his lab as a visting professor.
""Many of these emigrant scientists are under precarious contracts at their host institutions. Of the scientists who stay in Ukraine, if still alive, about 15% have left research, and others have little time to devote to research given the circumstances of war.""
The EPFL researchers found that research capacity in Ukraine, that is time directly devoted to research activity, is down 20%. The study reports that 23.5% of scientists still in Ukraine have lost access to critical input for their research, and 20.8% cannot physically access their institution. de Rassenfosse and his colleagues highlight in the study that ""the provision of more and longer scholarships emerges as a paramount concern"" for migrant scientists. As for scientists still in Ukraine, the study suggests that ""institutions across Europe and beyond can offer a host of support programs, such as remote visiting programs, access to digital libraries and computing resources, as well as collaborative research grants.""
""From a purely academic perspective, moving abroad may actually be an opportunity to improve as a scientist, as our survey shows that being abroad means exposure to novelty,"" continues de Rassenfosse.

Now at UNIL on a temporary contract, Iarmosh is living day-to-day in Switzerland, trying to juggle constraints imposed by employer contracts and her temporary Swiss permit. ""In Ukraine, with my level of education, there were many more options that I could choose from. In Switzerland, I am less picky about the job and know that each opportunity will be a positive experience for me.""
Iarmosh continues, ""Despite the war, Ukraine is doing a lot to keep researchers and scientists employed. Education in eastern and southern Ukraine is fully online. Ukrainian universities still want to keep us. They invite us to activities, ask us to supervise and continue research. It is a great privilege for all lecturers and researchers. They are trying to maintain a university education for youth.""
""More generally, our study shows that Ukrainian scientists are getting more and more disconnected from the Ukrainian scientific community, and this is dangerous for the future of Ukraine and Ukrainian research,"" warns de Rassenfosse. ""Policymakers must anticipate the renewal of the Ukrainian research system in order for scientists to return, and to train the next generation of Ukrainian scientists.""
""I am the biggest patriot of my city,"" concludes Iarmosh. ""Kharkiv is beautiful, the people, the mentality, the architecture, it is clean. I love Kharkiv. But the human loss has been colossal. Physically and mentally strong, patriotic, open-minded men stayed behind, fighting to protect Ukraine. We can rebuild buildings. It takes many years to build a new generation.""

","score: 11.737088277371036, grade_level: '12'","score: 12.439840949255235, grade_levels: ['college'], ages: [18, 24]",10.1057/s41599-023-02346-x,"The ongoing war in Ukraine has profoundly impacted the Ukrainian scientific community. Numerous researchers have either emigrated or transitioned to alternate professions. For those who remain in research, the destruction of civil infrastructure and psychological stress may dramatically slow down research progress. There is limited knowledge concerning the war’s influence on Ukrainian research. This study presents the results of a representative survey of over 2500 Ukrainian scientists. The data suggest that by the Fall of 2022, about 18.5% of the population of Ukrainian scientists fled the country. Notably, these emigrant scientists were amongst the most research-active in Ukraine. However, a significant portion of these migrant scientists are under precarious contracts at their host institutions. Of the scientists who stayed in Ukraine, about 15% have left research, and the others experience a marked reduction in research time. A large number of stayers have lost access to critical input for their research (23.5%) or cannot physically access their institution (20.8%). Finally, should the war stop today, it seems that Ukraine has already lost about seven percent of its scientists. These observations bear significant policy implications. In light of the vulnerable position of migrant scientists, the provision of more and longer scholarships emerges as a paramount concern for this group of scientists. Concerning stayers, institutions across Europe and beyond can offer a host of support programs, such as remote visiting programs, access to digital libraries and computing resources, as well as collaborative research grants."
"
McGill University researchers have made a breakthrough in diagnostic technology, inventing a 'lab on a chip' that can be 3D-printed in just 30 minutes. The chip has the potential to make on-the-spot testing widely accessible.

As part of a recent study, the results of which were published in the journal Advanced Materials, the McGill team developed capillaric chips that act as miniature laboratories. Unlike other computer microprocessors, these chips are single-use and require no external power source -- a simple paper strip suffices. They function through capillary action -- the very phenomena by which a spilled liquid on the kitchen table spontaneously wicks into the paper towel used to wipe it up.
""Traditional diagnostics require peripherals, while ours can circumvent them. Our diagnostics are a bit what the cell phone was to traditional desktop computers that required a separate monitor, keyboard and power supply to operate,"" explains Prof. David Juncker, Chair of the Department of Biomedical Engineering at McGill and senior author on the study.
At-home testing became crucial during the COVID-19 pandemic. But rapid tests have limited availability and can only drive one liquid across the strip, meaning most diagnostics are still done in central labs. Notably, the capillaric chips can be 3D-printed for various tests, including COVID-19 antibody quantification.
The study brings 3D-printed home diagnostics one step closer to reality, though some challenges remain, such as regulatory approvals and securing necessary test materials. The team is actively working to make their technology more accessible, adapting it for use with affordable 3D printers. The innovation aims to speed up diagnoses, enhance patient care, and usher in a new era of accessible testing.
""This advancement has the capacity to empower individuals, researchers, and industries to explore new possibilities and applications in a more cost-effective and user-friendly manner,"" says Prof. Juncker. ""This innovation also holds the potential to eventually empower health professionals with the ability to rapidly create tailored solutions for specific needs right at the point-of-care.""

","score: 14.524129353233835, grade_level: '15'","score: 15.128487562189058, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adma.202303867,"Digital manufacturing (DM) holds great potential for microfluidics, but requirements for embedded conduits and high resolution beyond the capability of common manufacturing equipment, and microfluidic systems' dependence on peripheralshave limited its adoption. Capillaric circuits (CCs) are structurally encoded, self‐contained microfluidic systems that operate and self‐fill via precisely tailored hydrophilicity. CCs are heretofore hydrophilized in a plasma chamber, but which offers only transient hydrophilicity, lacks reproducibility, and limits CC design to open surface channels subsequently sealed with tape. Here, the additive DM of monolithic, fully functional, and intrinsically hydrophilic CCs is reported. CCs are 3D printed with commonly available light‐engine‐based 3D printers using poly(ethylene glycol)diacrylate‐based ink co‐polymerized with hydrophilic acrylic acid crosslinkers and optimized for hydrophilicity and printability. A new, robust capillary valve design and embedded conduits with circular cross‐sections that prevent bubble trapping are presented, interwoven circuit architectures created, and CC use illustrated with an immunoassay. Finally, the external paper capillary pumps are eliminated by directly embedding the capillary pump in the chip as a porous gyroid structure, realizing fully functional, monolithic CCs. Thence, a digital file can be made into a CC by commonly available 3D printers in less than 30 min enabling low‐cost, distributed DM of fully functional ready‐to‐use microfluidic systems."
"
Train accidents could be caused by solar storms switching signalling from red to green according to new research examining the impact of space weather.

Solar storms can trigger powerful magnetic disturbances on Earth, creating geomagnetically induced currents (GICs) which could potentially interfere with electricity transmission and distribution grids.
A team led by PhD researcher Cameron Patterson and Professor Jim Wild from Lancaster University modelled how GICs flowed through the track circuits of AC electrified lines powered with overhead cables.
Using two routes -- the Preston to Lancaster section of the West Coast Main Line, and the Glasgow to Edinburgh line -- the team modelled how GICs induced in the rails could cause rail signalling to malfunction.
There are more than 50,000 signalling track circuits in the UK, where the signal is controlled by an electrical circuit between the rails.
Physics PhD researcher Cameron Patterson said: ""Crucially, our research suggests that space weather is able to flip a signal in either direction, turning a red signal green or a green signal red. This is obviously very significant from a safety perspective.
""By building a computer model of the signalling track circuits using realistic specifications for the various components of the system, we found that space weather events capable of triggering faults in these track circuits are expected in the UK every few decades.""
Cameron's earlier research in the journal Space Weather explored what is known in the industry as ""right side"" failures, where the signal is switched from green to red.

This is a fail-safe scenario but the converse ""wrong side"" failures -- when the signal goes from red to green -- are much more hazardous.
This latest study, also in Space Weather, shows that ""wrong side"" failures could occur at a lower geoelectric field strength than for ""right side"" failures, meaning a weaker geomagnetic storm could more easily trigger ""wrong side"" failures.
It was estimated that, for the lines studied, ""wrong side"" failures could occur due to a geomagnetic storm with a frequency of about one or two decades.
The analysis was also performed for once-in-a-century extreme event, and it was shown that it could potentially cause many malfunctions of both typs throughout the lines in both directions of travel, depending on the number of trains on the line at that time.
Cameron said: ""When we experience severe space weather which happens every few decades or extreme space weather seen every century or two, then there is a potential for significant signalling misoperation, which has an obvious safety impact.""
There have been several examples of space weather impacting power grids in the last few decades, including power outages affecting millions across the Canadian province of Quebec in 1989 and the Swedish city of Malmo in 2003.

There are also historic examples of space weather interfering with railway signalling as far back as the nineteenth century. And in 1859, a massive solar eruption triggered a geomagnetic storm that disrupted telegraph lines across the world. The team also assessed the impact of a solar storm of the size of the 1859 event, predicting that it would cause widespread problems with signalling on both lines studied.
Cameron said: ""Our research shows that space weather poses a serious, if relatively rare, risk to the rail signalling system, which could cause delays or even have more critical, safety implications. This natural hazard needs to be taken seriously. By their nature, high-impact, low-frequency events are hard to plan for, but ignoring them is rarely the best way forward.
Jim Wild, Professor of Space Physics at Lancaster University said: ""Other industries such as aviation, electricity generation and transmission, and the space sector are considering the risks to their operations, and exploring how these might be mitigated. It's important that the rail sector is included in this planning.""
""As our understanding of the space weather hazard improves, it's possible to consider how to reduce the risks. In future, we could see space weather forecasting being used make decisions about limiting railway operations if an extreme event is expected, just as meteorological forecasts are used currently.
Severe space weather is included in the UK Government's National Risk Register for Civil Emergencies which lists the risk posed to the UK's economy and society as ""significant.""

","score: 14.64733956651084, grade_level: '15'","score: 16.420397365065874, grade_levels: ['college_graduate'], ages: [24, 100]",10.1029/2023SW003625,"The majority of studies into space weather impacts on ground‐based systems focus on power supply networks and oil and gas pipelines. The effects on railway signaling infrastructure remain a sparsely covered aspect even though these systems are known to have experienced adverse effects in the past as a result of geomagnetic activity. This study extends recent modeling of geomagnetic effects on DC signaling for AC‐electrified railways in the UK that analyzed “right side” failures in which green signals are turned to red. The extended model reported here allows the study of “wrong side” failures where red signals are turned green: a failure mode that is potentially more dangerous. Railway lines using track circuit signaling, like those modeled in this study, are separated into a number of individual blocks. This study shows that a relay is most susceptible to “wrong side” failure when a train is at the end of a track circuit block. Assuming that each train is positioned at the end of the block it is occupying, the results show that the geoelectric field threshold at which “wrong side” failures can occur is lower than for “right side” failures. This misoperation field level occurs on a timescale of once every 10 or 20 years. We also show that the estimated electric field caused by a 1‐in‐100 years event could cause a significant number of “wrong side” failures at multiple points along the railway lines studied, although this depends on the number of trains on the line at that time."
"
The electrical properties of cancer cells can provide information on their cancer type, state, and drug resistance. However, conventional platforms to measure these properties are complex and can only analyze a few cells. Researchers from the Tokyo University of Science have successfully developed a high-throughput device that measures the electrical properties of cancer cells through continuous flow electrorotation. The new platform offers a high degree of automation and can simultaneously analyze several cells.

Monitoring cancer cells effectively can help physicians with treatment and management, thus reducing cancer-related mortality. Can non-invasive technologies pave the way for improved monitoring to reduce cancer mortality rates? Diagnostic platforms that non-invasively measure the electrical properties of cancer cells offer promise in the early detection of cancer drug resistance and metastasis. Research has shown that it is possible to understand a cancer type and its drug resistance status from cellular permittivity and conductivity data. In fact, there is an increasing demand for analytical methods that can rapidly measure a cell's electrical properties.
Electrorotation (ROT) offers one such route to capture cellular properties by inferring permittivity and conductivity from a cell's movement in an electric field. This allows the characterization of the cell type and state by profiling its frequency-dependent rotational movement under a modulated electric field. However, there are limitations. The challenge is that the capture, measurement, and replacement of cells is quite cumbersome and lowers the throughput of ROT platforms, where throughput refers to the number of cells that a given technology can analyze at any given time.
Recently, researchers from Tokyo University of Science (TUS) developed a continuous flow ROT (cROT) to address conventional ROT's drawbacks. The new platform leverages microfluidics to continuously measure cellular dynamics and simultaneously capture cells to collect measurements on one device. The group's validated findings were recently published in Lab on a Chip on 23 October 2023.
""I discovered that cancer cells had vastly different responses to electric fields while they looked similar. This implied a certain degree of individuality, and the idea of discerning the differences using ROT intrigued me,"" explains Dr. Masahiro Motosuke, a Professor in the Department of Mechanical Engineering at TUS and the project's Principal Investigator. He further adds, ""However, gathering accurate data using ROT requires the precise placement and removal of a single cell, and I wanted to make the process of analyzing many cells easier.""
The researchers fabricated the new device with redesigned interdigitating electrodes that induce cell rotation and a microchannel for cell passage. The electrode geometry increases the number of cells that can be analyzed and reduces the time required to replace a cell as measurements are collected. The electrical field applied within the microchannel enables analyzing rotational behavior from a continuous flow of cells. Together, these improvements increase the automated system's throughput. The research team validated the system's accuracy by obtaining cell membrane permittivity and cytoplasm conductivity measurements from HeLa cells, a human cell line commonly used in research.
""We significantly increased measurement throughput to 2,700 cells per hour with our cROT technique,"" says Prof. Motosuke about the report's most significant findings. ""Furthermore, the device does not require precise cell manipulation and takes advantage of rapid image processing when processing the cells' electrical data,"" he adds further. Other advantages of the new system are its high degree of automation and ease of installation or removal.
The cROT device indeed demonstrates a remarkable enhancement in throughput when contrasted with traditional ROT platforms. While conventional ROT techniques typically process 10 to 20 cells per hour, the cROT system achieves an impressive throughput of 2700 cells per hour, which is more than 100 times higher. Furthermore, the cROT system significantly minimizes the time necessary for cell replacement.
Prof. Motosuke envisions a promising future for the cROT system that the team has developed. ""With our cROT technique, we've unlocked the ability to delve into the subtle intricacies of single-cell dynamics, including aspects like cell physiology, the state of the cell membrane, and the concentration of intracellular ions,"" he emphasizes. He anticipates that the swift and accurate analyses offered by this cutting-edge approach will be a catalyst for substantial advancements in the realms of cancer drug development, diagnosis, and novel cell-based therapies. This breakthrough technology opens doors for collaboration and adoption by prominent players in the oncology industry, potentially revolutionizing the way we combat cancer.

","score: 15.469740082079344, grade_level: '15'","score: 16.336456908344736, grade_levels: ['college_graduate'], ages: [24, 100]",10.1039/D3LC00301A,A continuous-flow electrorotation (cROT) device for improved throughput characterization of dielectric properties of cells has been developed.
"
In mice and human cell cultures, MIT researchers showed that novel nanoparticles can deliver a potential therapy for inflammation in the brain, a prominent symptom in Alzheimer's disease.

Some Covid-19 vaccines safely and effectively used lipid nanoparticles (LNPs) to deliver messenger RNA to cells. A new MIT study shows that different nanoparticles could be used for a potential Alzheimer's disease (AD) therapy. In tests in multiple mouse models and with cultured human cells, a newly tailored LNP formulation effectively delivered small interfering RNA (siRNA) to the brain's microglia immune cells to suppress expression of a protein linked to excessive inflammation in Alzheimer's disease.
In a prior study the researchers showed that blocking the consequences of PU.1 protein activity helps to reduce Alzheimer's disease-related neuroinflammation and pathology. The new results, reported in the journal Advanced Materials (impact factor 29.4 ) achieves a reduction in inflammation by directly tamping down expression of the Spi1 gene that encodes PU.1. More generally, the new study also demonstrates a new way to deliver RNA to microglia, which have been difficult to target so far.
Study co-senior author Li-Huei Tsai, Picower Professor of Neuroscience and Director of The Picower Institute for Learning and Memory and Aging Brain Initiative, said she hypothesized that LNPs might work as a way to bring siRNA into microglia because the cells, which clear waste in the brain, have a strong proclivity to uptake lipid molecules. She discussed this with Robert Langer, David Koch Institute Professor, who widely known for his seminal work on nanoparticle drug delivery, They decided to test the idea of reducing PU.1 expression with an LNP-delivered siRNA.
""I still remember the day when I asked to meet with Bob to discuss the idea of testing LNPs as a payload to target inflammatory microglia,"" said Tsai, a faculty member in the Department of Brain and Cognitive Sciences. ""I am very grateful to The JPB Foundation who supported this idea without any preliminary evidence.""
Langer Lab graduate student Jason Andresen and former Tsai Lab postdoc William Ralvenius led the work and are the study's co-lead authors. Owen Fenton, a former Langer Lab postdoc who is now an assistant professor at the University of North Carolina's Eshelman School of Pharmacy, is a co-corresponding author along with Tsai and Langer. Langer is a Professor in Chemical Engineering, Biological Engineering and the Koch Institute for Integrative Cancer Research.
Perfecting a particle
The simplest way to test whether siRNA could therapeutically suppress PU.1 expression would have been to make use of an already available delivery device, but one of the first discoveries in the study is that none of eight commercially available reagents could safely and effectively transfect cultured human microglia-like cells in the lab.

Instead the team had to optimize an LNP to do the job. LNPs have four main components and by changing the structures of two of them, and by varying the ratio of lipids to RNA, the researchers were able to come up with seven formulations to try. Importantly, their testing included trying their formulations on cultured microglia that they had induced into an inflammatory state. That state, after all, is the one in which the proposed treatment is needed.
Among the seven candidates, one the team named ""MG-LNP"" stood out for its especially high delivery efficiency and safety of a test RNA cargo.
What works in a dish sometimes doesn't work in a living organism, so the team next tested their LNP formulations' effectiveness and safety in mice. Testing two different methods of injection, into the body or into the cerebrospinal fluid (CSF), they found that injection into the CSF ensured much greater efficacy in targeting microglia without affecting cells in other organs. Among the seven formulations, MG-LNP again proved the most effective at transfecting microglia. Langer said he believes this could potentially open new ways of treating certain brain diseases with nanoparticles someday.
A targeted therapy
Once they knew MG-LNP could deliver a test cargo to microglia both in human cell cultures and mice, the scientists then tested whether using it to deliver a PU.1-suppressing siRNA could reduce inflammation in microglia. In the cell cultures, a relatively low dose achieved a 42 percent reduction of PU.1 expression (which is good because microglia need at least some PU.1 to live). Indeed MG-LNP transfection did not cause the cells any harm. It also significantly reduced the transcription of the genes that PU.1 expression increases in microglia, indicating that it can reduce multiple inflammatory markers.
In all these measures, and others, MG-LNP outperformed a commercially available reagent called RNAiMAX that the scientists tested in parallel.

""These findings support the use of MG-LNP-mediated anti-PU.1 siRNA delivery as a potential therapy for neuroinflammatory diseases,"" the researchers wrote.
The final set of tests evaluated MG-LNP's performance delivering the siRNA in two mouse models of inflammation in the brain. In one, mice were exposed to LPS, a molecule that simulates infection and stimulates a systemic inflammation response. In the other model, mice exhibit severe neurodegeneration and inflammation when an enzyme called CDK5 becomes hyperactivated by a protein called p25.
In both models, injection of MG-LNPs carrying the anti-PU.1 siRNA reduced expression of PU.1 and inflammatory markers, much like in the cultured human cells.
""MG-LNP delivery of anti-PU.1 siRNA can potentially be used as an anti-inflammatory therapeutic in mice with systemic inflammation an in the CK-p25 mouse model of AD-like neuroinflammation,"" the scientists concluded, calling the results a ""proof-of-principle."" More testing will be required before the idea could be tried in human patients.
In addition to Andresen, Ralvenius, Langer, Tsai and Owen, the paper's other authors are Margaret Huston, Jay Penney and Julia Maeve Bonner.
In addition to the The JPB Foundation and The Picower Institute for Learning and Memory, the Robert and Renee Belfer Family, Eduardo Eurnekian, Lester A. Gimpelson, Jay L. and Carroll Miller, the Koch Institute, the Swiss National Science Foundation and the Alzheimer's Association provided funding for the study.

","score: 15.462857142857143, grade_level: '15'","score: 16.41262276380607, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adma.202309225,"Neuroinflammation is a hallmark of neurodegenerative disorders including Alzheimer's disease (AD). Microglia, the brain's immune cells, express many of the AD‐risk loci identified in genome wide association studies and present a promising target for anti‐inflammatory RNA therapeutics but are difficult to transfect with current methods. Here, several lipid nanoparticle (LNP) formulations are examined, and a lead candidate that supports efficient RNA delivery in cultures of human stem cell‐derived microglia‐like cells (iMGLs) and animal models of neuroinflammation is identified. The lead microglia LNP (MG‐LNP) formulation shows minimal toxicity and improves delivery efficiency to inflammatory iMGLs, suggesting a preference for delivery into activated microglia. Intraperitoneal injection of the MG‐LNP formulation generates widespread expression of the delivered reporter construct in all organs, whereas local intracisternal injection directly into the cerebrospinal fluid leads to preferential expression in the brain. It is shown that LNP‐mediated delivery of siRNA targeting the PU.1 transcription factor, a known AD‐risk locus, successfully reduces PU.1 levels in iMGLs and reduces neuroinflammation in mice injected with LPS and in CK‐p25 mice that mimic the chronic neuroinflammation seen in AD patients. The LNP formulation represents an effective RNA delivery vehicle when applied intrathecally and can be broadly utilized to test potential neuroinflammation‐directed gene therapies."
"
Chiral materials interact with light in very precise ways that are useful for building better displays, sensors and more powerful devices. However, engineering properties such as chirality reliably at scale is still a significant challenge in nanotechnology.

Rice University scientists in the lab of Junichiro Kono have developed two ways of making wafer-scale synthetic chiral carbon nanotube (CNT) assemblies starting from achiral mixtures. According to a study in Nature Communications, the resulting ""tornado"" and ""twisted-and-stacked"" thin films can control ellipticity ⎯ a property of polarized light ⎯ to a level and in a range of the spectrum that was previously largely beyond reach.
""These approaches have granted us the ability to deliberately and consistently introduce chirality to materials that, until now, did not exhibit this property on a macroscopic scale,"" said Jacques Doumani, a graduate student in applied physics at Rice and the lead author of the study. ""Our methods yield thin, flexible films with tunable chiral properties.""
CNTs ⎯ hollow cylindrical structures made from carbon atoms ⎯ possess remarkable electrical, mechanical, thermal and optical properties. A single-wall CNT has a diameter approximately 100,000 times smaller than that of a single human hair.
The problem is that most ways to make CNTs in greater quantities ⎯ which is necessary for use in numerous applications ⎯ typically yield heterogeneous, disorderly nanotube assemblies. Such random architectures decrease a material's overall performance.
The ability to create large enough quantities of films in which the nanotubes have the same diameter and orientation could fuel innovation across a broad range of domains, from information systems to medical or energy applications.
""In prior research, we showed that our vacuum filtration technique can achieve nearly perfect alignment of carbon nanotubes at significant scales,"" said Kono, the Karl F. Hasselmann Professor in Engineering, professor of electrical and computer engineering and materials science and nanoengineering and one of the principal investigators of the paper. ""This research allows us to take that work in an exciting new direction by introducing chirality.""
The discovery that motion could impart a chiral twist on an orderly CNT arrangement happened entirely by chance.

""It was, quite literally, an unexpected twist,"" Doumani said, recounting how a shaky pump placed on the same table as the vacuum filtration system caused unintended vibrations which wound the layer of aligned CNTs into a tornadolike spiral.
""These vibrations had a profound impact on the architecture of the assembled carbon nanotubes, prompting us to explore and refine this newfound phenomenon further,"" he said. ""This chance discovery allowed us to recognize that we can design carbon nanotube architectures with desired characteristics by adjusting rotation angles and shaking conditions.""
Kono likened the resulting chiral symmetry of the CNT assemblies to a ""work of art.""
""I am particularly proud of Jacques for pursuing the discovery that we can combine carbon nanotube filtration and shaking to tune the characteristics of these wafer-scale films,"" Kono said.
The second method of achieving chirality involved stacking highly aligned CNT films at an angle by controlling the number of layers and twisting angles.
""We achieved a remarkable milestone in the deep ultraviolet range, where we set a new record for ellipticity,"" Doumani said. ""What's more, compared to competitors in this space, our technique is very simple to set up. We don't need a complex system to make these films.""
The techniques can be used to engineer materials for new optoelectronic devices, such as LEDs, lasers, solar cells and photodetectors. It's also a setup that can potentially be used to make wafer-scale chiral film using other nanomaterials such as boron nitride nanotubes and tungsten diselenide nanotubes.

""This discovery holds promise for various applications,"" Doumani said. ""In pharmaceuticals and biomedicine, it offers potential in biosensing, deep-sea imaging and identifying useful compounds. In communication, it could enhance missile detection, secure communication channels and bolster anti-interference capabilities. In quantum computing engineering, it paves the way for more deterministic photon-emitter coupling.
""We're excited to extend this technique to other types of nanomaterials as well.""

","score: 15.342963391136802, grade_level: '15'","score: 15.382148362235071, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43199-x,"Creating artificial matter with controllable chirality in a simple and scalable manner brings new opportunities to diverse areas. Here we show two such methods based on controlled vacuum filtration - twist stacking and mechanical rotation - for fabricating wafer-scale chiral architectures of ordered carbon nanotubes (CNTs) with tunable and large circular dichroism (CD). By controlling the stacking angle and handedness in the twist-stacking approach, we maximize the CD response and achieve a high deep-ultraviolet ellipticity of 40 ± 1 mdeg nm−1. Our theoretical simulations using the transfer matrix method reproduce the experimentally observed CD spectra and further predict that an optimized film of twist-stacked CNTs can exhibit an ellipticity as high as 150 mdeg nm−1, corresponding to agfactor of 0.22. Furthermore, the mechanical rotation method not only accelerates the fabrication of twisted structures but also produces both chiralities simultaneously in a single sample, in a single run, and in a controllable manner. The created wafer-scale objects represent an alternative type of synthetic chiral matter consisting of ordered quantum wires whose macroscopic properties are governed by nanoscopic electronic signatures and can be used to explore chiral phenomena and develop chiral photonic and optoelectronic devices."
"
When we last checked in with Caltech's Kerry Vahala three years ago, his lab had recently reported the development of a new optical device called a turnkey frequency microcomb that has applications in digital communications, precision time keeping, spectroscopy, and even astronomy.

This device, fabricated on a silicon wafer, takes input laser light of one frequency and converts it into an evenly spaced set of many distinct frequencies that form a train of pulses whose length can be as short as 100 femtoseconds (quadrillionths of a second). (The comb in the name comes from the frequencies being spaced like the teeth of a hair comb.)
Now Vahala (BS '80, MS '81, PhD '85), Caltech's Ted and Ginger Jenkins Professor of Information Science and Technology and Applied Physics and executive officer for applied physics and materials science, along with members of his research group and the group of John Bowers at UC Santa Barbara, have made a breakthrough in the way the short pulses form in an important new material called ultra-low-loss silicon nitride (ULL nitride), a compound formed of silicon and nitrogen. The silicon nitride is prepared to be extremely pure and deposited in a thin film.
In principle, short-pulse microcomb devices made from this material would require very low power to operate. Unfortunately, short light pulses (called solitons) cannot be properly generated in this material because of a property called dispersion, which causes light or other electromagnetic waves to travel at different speeds, depending on their frequency. ULL has what is known as normal dispersion, and this prevents waveguides made of ULL nitride from supporting the short pulses necessary for microcomb operation.
In a paper appearing in Nature Photonics, the researchers discuss their development of the new microcomb, which overcomes the inherent optical limitations of ULL nitride by generating pulses in pairs. This is a significant development because ULL nitride is created with the same technology used for manufacturing computer chips. This kind of manufacturing technique means that these microcombs could one day be integrated into a wide variety of handheld devices similar in form to smartphones.
The most distinctive feature of an ordinary microcomb is a small optical loop that looks a bit like a tiny racetrack. During operation, the solitons automatically form and circulate around it.
""However, when this loop is made of ULL nitride, the dispersion destabilizes the soliton pulses,"" says co-author Zhiquan Yuan (MS '21), a graduate student in applied physics.

Imagine the loop as a racetrack with cars. If some cars travel faster and some travel slower, then they will spread out as they circle the track instead of staying as a tight pack. Similarly, the normal dispersion of ULL means light pulses spread out in the microcomb waveguides, and the microcomb ceases to work.
The solution devised by the team was to create multiple racetracks, pairing them up so they look a bit like a figure eight. In the middle of that '8,' the two tracks run parallel to each other with only a tiny gap between.
If we continue with the racetrack analogy, this would be like two tracks sharing one straightaway. As the cars from each track converge on that shared section, they encounter something like a traffic jam. Just like two lanes of traffic merging into one on a freeway forces cars to slow down, the conjoined section of the two microcombs forces the paired laser pulses to bunch up. This bunching up counteracts the pulses' tendency to spread out and allows the microcombs to work properly.
""In effect, this counteracts the normal dispersion and gives the overall composite system the equivalent of anomalous dispersion,"" says graduate student and co-author Maodong Gao (MS '22).
The idea extends when one adds even more racetracks, and the team has shown how three racetracks will also operate by creating two sets of pulse pairs. Vahala believes the phenomenon will continue to work even with many coupled racetracks (microcombs), thereby offering a way to create large photonic circuit arrays for the soliton pulses.
As noted above, these ULL microcombs are fabricated with the same equipment used to make computer chips based on complementary metal-oxide-semiconductor (CMOS) technology. Bowers, a professor of electrical and computer engineering, collaborated on the research and notes that ""The manufacturing scalability of the CMOS process means that it will now be easier and more economical to manufacture the short-pulse microcombs and integrate them into existing technologies and applications.""
Concerning these applications, Vahala says ""a comb is like a Swiss army knife for optics. It has many different functions, and that's why it's such a powerful tool.""
Funding for the research was provided by the Defense Advanced Research Projects Agency, the Defense Threat Reduction Agency Joint Science and Technology Office for Chemical and Biological Defense, and the Air Force Office of Scientific Research.

","score: 14.353226603931578, grade_level: '14'","score: 15.698189321743293, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41566-023-01257-2,"Soliton microcombs are helping to advance the miniaturization of a range of comb systems. These combs mode lock through the formation of short temporal pulses in anomalous dispersion resonators. Here, a new microcomb is demonstrated that mode locks through the formation of pulse pairs in coupled normal dispersion resonators. Unlike conventional microcombs, pulses in this system cannot exist alone, and instead phase lock in pairs wherein pulses in each pair feature different optical spectra. The pairwise mode-locking modality extends to multiple pulse pairs and beyond two rings, and it greatly constrains mode-locking states. Two- (bipartite) and three-ring (tripartite) states containing many pulse pairs are demonstrated, including crystal states. Pulse pairs can also form at recurring spectral windows. We obtained the results using an ultra-low-loss Si3N4 platform that has not previously produced bright solitons on account of its inherent normal dispersion. The ability to generate multicolour pulse pairs over multiple rings is an important new feature for microcombs. It can extend the concept of all-optical soliton buffers and memories to multiple storage rings that multiplex pulses with respect to soliton colour and that are spatially addressable. The results also suggest a new platform for the study of topological photonics and quantum combs."
"
An international team of experts undertaking fundamental research has developed a way of using polyethylene waste (PE) as a feedstock and converted it into valuable chemicals, via light-driven photocatalysis.

The University of Adelaide's Professor Shizhang Qiao, Chair of Nanotechnology, and Director, Centre for Materials in Energy and Catalysis, at the School of Chemical Engineering, led the team which published their findings in the journal Science Advances.
""We have upcycled polyethylene plastic waste into ethylene and propionic acid with high selectivity using atomically dispersed metal catalysts,"" said Professor Qiao.
""An oxidation-coupled room-temperature photocatalysis method was used to convert the waste into valuable products with high selectivity.
""Nearly 99 per cent of the liquid product is propionic acid, alleviating the problems associated with complex products that then require separation.
""Renewable solar energy was used rather than industrial processes that consume fossil fuel and emit greenhouse gases.
""This waste-to-value strategy is primarily implemented with four components, including plastic waste, water, sunlight and non-toxic photocatalysts that harness solar energy and boost the reaction. A typical photocatalyst is titanium dioxide with isolated palladium atoms on its surface.""
Most of the plastics used today end up being discarded and accumulated in landfills. PE is the most widely used plastic in the world. Daily food packaging, shopping bags and reagent bottles are all made from PE. It is also the largest proportion of all plastic waste and primarily ends up in landfills, posing a threat to global environment and ecology.

""Plastic waste is an untapped resource that can be recycled and processed into new plastics and other commercial products,"" said Professor Qiao.
""Catalytic recycling of PE waste is still in early development and is practically challenging because of chemical inertness of polymers and side reactions arising from structural complexities of reactant molecules.""
Current chemical recycling for PE waste is operated at high temperatures greater than 400 degrees centigrade that yield complex product compositions.
Ethylene is an important chemical feedstock that can be further processed into a variety of industrial and daily products, while propionic acid is also in high demand owing to its antiseptic and antibacterial properties.
The team's work aims to address contemporary environmental and energy challenges, contributing to a circular economy. It will be of use in further scientific research, waste management and chemical manufacturing.
""Our fundamental research provides a green and sustainable solution to simultaneously reduce plastic pollution and produce valuable chemicals from waste for a circular economy,"" said Professor Qiao.
""It will inspire the rational design of high-performance photocatalysts for solar energy utilisation and benefit the development of solar-driven waste upcycling technology.""

","score: 16.31311711711712, grade_level: '16'","score: 16.455472972972977, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adk2407,"Current chemical recycling of bulk synthetic plastic, polyethylene (PE), operates at high temperature/pressure and yields a complex mixture of products. PE conversion under mild conditions and with good selectivity toward value-added chemicals remains a practical challenge. Here, we demonstrate an atomic engineering strategy to modify a TiO 2 photocatalyst with reversible Pd species for the selective conversion of PE to ethylene (C 2 H 4 ) and propionic acid via dicarboxylic acid intermediates under moderate conditions. TiO 2 -supported atomically dispersed Pd species exhibits C 2 H 4 evolution of 531.2 μmol g cat −1 hour −1 , 408 times that of pristine TiO 2 . The liquid product is a valuable chemical propanoic acid with 98.8% selectivity. Plastic conversion with a C 2 hydrocarbon yield of 0.9% and a propionic acid yield of 6.3% was achieved in oxidation coupled with 3 hours of photoreaction. In situ spectroscopic studies confirm a dual role of atomic Pd species: an electron acceptor to boost charge separation/transfer for efficient photoredox, and a mediator to stabilize reaction intermediates for selective decarboxylation."
"
EPFL researchers have developed a hybrid device that significantly improves existing, ubiquitous laser technology.

The team at EPFL's Photonic Systems Laboratory (PHOSL) has developed a chip-scale laser source that enhances the performance of semiconductor lasers while enabling the generation of shorter wavelengths. This pioneering work, led by Professor Camille Brès and postdoctoral researcher Marco Clementi from EPFL's School of Engineering represents a significant advance in the field of photonics, with implications for telecommunications, metrology, and other high-precision applications.
The study, published in the journal Light: Science & Applications, reveals how the PHOSL researchers, in collaboration with the Laboratory of Photonics and Quantum Measurements, have successfully integrated semiconductor lasers with silicon nitride photonic circuits containing microresonators. This integration results in a hybrid device capable of emitting highly uniform and precise light in both near-infrared and visible ranges, filling a technological gap that has long challenged the industry.
""Semiconductor lasers are ubiquitous in modern technology, found in everything from smartphones to fiber optic communications. However, their potential has been limited by a lack of coherence and the inability to generate visible light efficiently,"" explains Professor Brès . ""Our work not only improves the coherence of these lasers but also shifts their output towards the visible spectrum, opening up new avenues for their use.""
Coherence, in this context, refers to the uniformity of the phases of the light waves emitted by the laser. High coherence means the light waves are synchronized, leading to a beam with a very precise color or frequency. This property is crucial for applications where precision and stability of the laser beam are paramount, such as time keeping and precision sensing.
Increased accuracy and improved functionality 
The team's approach involves coupling commercially available semiconductor lasers with a silicon nitride chip. This tiny chip is created with industry-standard, cost-efficient CMOS technology. Thanks to the material's exceptional low-loss properties, there is little to no light that is absorbed or escapes. The light from the semiconductor laser flows through microscopic waveguides into extremely small cavities, where the beam is trapped. These cavities, called micro-ring resonators, are intricately designed to resonate at specific frequencies, selectively amplifying the desired wavelengths while attenuating others, thereby achieving enhanced coherence in the emitted light.

The other significant achievement is the hybrid system's ability to double the frequency of the light coming from the commercial semiconductor laser -- enabling a shift from the near-infrared spectrum to the visible light spectrum. The relationship between frequency and wavelength is inversely proportional, meaning that if the frequency is doubled, the wavelength is reduced by half. While the near infrared spectrum is exploited for telecommunications, higher frequencies are essential for building smaller, more efficient devices where shorter wavelengths are needed, such as in atomic clocks and medical devices.
These shorter wavelengths are achieved when the trapped light in the cavity undergoes a process called all-optical poling, which induces what is known as second-order nonlinearity in the silicon nitride. Nonlinearity in this context means that there is a significant shift, a jump in magnitude, in the light's behavior that is not directly proportional to its frequency, arising from its interaction with the material. Silicon nitride does not normally incur this specific second order nonlinear effect, and the team performed an elegant engineering feat to induce it: The system takes advantage of the light's capacity, when resonating within the cavity, to produce an electromagnetic wave that provokes the nonlinear properties in the material.
An enabling technology for future applications
""We are not just improving existing technology but also pushing the boundaries of what's possible with semiconductor lasers,"" says Marco Clementi, who played a key role in the project. ""By bridging the gap between telecom and visible wavelengths, we're opening the door to new applications in fields like biomedical imaging and precision timekeeping.
One of the most promising applications of this technology is in metrology, particularly in the development of compact atomic clocks. The history of navigational advancements hinges on the portability of accurate timepieces -- from determining longitude at sea in the 16th Century to ensuring the accurate navigation of space missions and achieving better geo-localization today. ""This significant advancement lays the groundwork for future technologies, some of which are yet to be conceived,"" notes Clementi.
The team's deep understanding of photonics and material science will potentially lead to smaller and lighter devices and lower the energy consumption and production costs of lasers. Their ability to take a fundamental scientific concept and translate it into a practical application using industry standard fabrication underscores the potential of solving complex technological challenges that can lead to unforeseen advances.

","score: 17.906498673740057, grade_level: '18'","score: 19.347944971451696, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41377-023-01329-6,"Second-harmonic generation allows for coherently bridging distant regions of the optical spectrum, with applications ranging from laser technology to self-referencing of frequency combs. However, accessing the nonlinear response of a medium typically requires high-power bulk sources, specific nonlinear crystals, and complex optical setups, hindering the path toward large-scale integration. Here we address all of these issues by engineering a chip-scale second-harmonic (SH) source based on the frequency doubling of a semiconductor laser self-injection-locked to a silicon nitride microresonator. The injection-locking mechanism, combined with a high-Q microresonator, results in an ultra-narrow intrinsic linewidth at the fundamental harmonic frequency as small as 41 Hz. Owing to the extreme resonant field enhancement, quasi-phase-matched second-order nonlinearity is photoinduced through the coherent photogalvanic effect and the high coherence is mapped on the generated SH field. We show how such optical poling technique can be engineered to provide efficient SH generation across the whole C and L telecom bands, in a reconfigurable fashion, overcoming the need for poling electrodes. Our device operates with milliwatt-level pumping and outputs SH power exceeding 2 mW, for an efficiency as high as 280%/W under electrical driving. Our findings suggest that standalone, highly-coherent, and efficient SH sources can be integrated in current silicon nitride photonics, unlocking the potential of χ(2) processes in the next generation of integrated photonic devices."
"
Antibodies (immunoglobulins) are Y-shaped proteins that recognize and neutralize specific pathogens. Their ability to target specific molecules or cells has made them promising candidates for future drug development. However, their light chains -- parts of the antibody that contribute to recognizing and binding to specific antigens -- misfold and aggregate, leading to amyloidosis, a condition that brings about complications and tissue dysfunction in the body. In the context of drug development, antibody aggregation can compromise their capacity to bind to antigens and diminish their therapeutic potential. However, lack of detailed structural information on its aggregation is one of the factors hindering progress in the field. As a result, ongoing efforts aim to provide detailed reports on aggregate structures and their formation mechanisms to advance antibody drug development.

In a study published in Nature Communications, a team of researchers from Japan, led by Shun Hirota from Nara Institute of Science and Technology (NAIST), has recently provided new insights into the structures formed during antibody aggregation through 3D domain swapping (3D-DS), a process where a specific region of a protein is exchanged between two or more molecules of the same protein. The 3D-DS process has been observed in various proteins but not in antibody light chains until the present study.
In their investigation, the researchers used a modified version of the antibody light chain. In this modified form, a cysteine (Cys) residue, which typically forms a disulfide bond with a heavy chain cysteine, was replaced with alanine (Ala). This alteration allowed the team to isolate and study the structures resulting from 3D-DS in the segment of the antibody contributing to antigen binding. The 3D-DS of the antibody light chain involves the formation of dimers (structures consisting of two identical subunits) and tetramers (structures composed of two dimers with four identical subunits). ""Our study provides the first report on the atomic-level structure of the 3D-DS phenomenon in an antibody light chain's variable region,"" points out Hirota.
The size exclusion chromatography of the antibody light chain #4C214A revealed that the antibody exists as individual monomers and four-subunit tetramers. To determine the region where tetramers are formed, the researchers partitioned the antibody light chain into the variable region (the tip of the Y-shaped antibody) and the constant region (the middle part of the Y-shaped antibody). They found that the variable region #4VL can switch between monomeric and tetrameric states.
Further analysis using X-ray crystallography and thermodynamic simulations revealed that tetramer formation is driven by hydrophobic interactions occurring between two 3D-DS dimers.
Compared to monomers, the tetramers were found to have more rigid β-sheet structures, making them less flexible. The formation of the 3D-DS tetramer can help prevent protein aggregation by decreasing flexibility, potentially avoiding the formation of insoluble aggregates. On the other hand, 3D-DS may promote aggregation of antibodies.
Hirota concludes: ""These findings not only clarify the domain-swapped structure of the antibody light chain but also contribute to controlling antibody quality and advancing the development of future molecular recognition agents and drugs.""

","score: 16.160222597914906, grade_level: '16'","score: 16.86693153000845, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43443-4,"Overexpression of antibody light chains in small plasma cell clones can lead to misfolding and aggregation. On the other hand, the formation of amyloid fibrils from antibody light chains is related to amyloidosis. Although aggregation of antibody light chain is an important issue, atomic-level structural examinations of antibody light chain aggregates are sparse. In this study, we present an antibody light chain that maintains an equilibrium between its monomeric and tetrameric states. According to data from X-ray crystallography, thermodynamic and kinetic measurements, as well as theoretical studies, this antibody light chain engages in 3D domain swapping within its variable region. Here, a pair of domain-swapped dimers creates a tetramer through hydrophobic interactions, facilitating the revelation of the domain-swapped structure. The negative cotton effect linked to the β-sheet structure, observed around 215 nm in the circular dichroism (CD) spectrum of the tetrameric variable region, is more pronounced than that of the monomer. This suggests that the monomer contains less β-sheet structures and exhibits greater flexibility than the tetramer in solution. These findings not only clarify the domain-swapped structure of the antibody light chain but also contribute to controlling antibody quality and advancing the development of future molecular recognition agents and drugs."
"
MIT engineers have developed a robotic replica of the heart's right ventricle, which mimics the beating and blood-pumping action of live hearts.

The robo-ventricle combines real heart tissue with synthetic, balloon-like artificial muscles that enable scientists to control the ventricle's contractions while observing how its natural valves and other intricate structures function.
The artificial ventricle can be tuned to mimic healthy and diseased states. The team manipulated the model to simulate conditions of right ventricular dysfunction, including pulmonary hypertension and myocardial infarction. They also used the model to test cardiac devices. For instance, the team implanted a mechanical valve to repair a natural malfunctioning valve, then observed how the ventricle's pumping changed in response.
They say the new robotic right ventricle, or RRV, can be used as a realistic platform to study right ventricle disorders and test devices and therapies aimed at treating those disorders.
""The right ventricle is particularly susceptible to dysfunction in intensive care unit settings, especially in patients on mechanical ventilation,"" says Manisha Singh, a postdoc at MIT's Institute for Medical Engineering and Science (IMES). ""The RRV simulator can be used in the future to study the effects of mechanical ventilation on the right ventricle and to develop strategies to prevent right heart failure in these vulnerable patients.""
Singh and her colleagues report details of the new design in a paper appearing today in Nature Cardiovascular Research. Her co-authors include Associate Professor Ellen Roche, who is a core member of IMES and the associate head for research in the Department of Mechanical Engineering at MIT, along with Jean Bonnemain, Caglar Ozturk, Clara Park, Diego Quevedo-Moreno, Meagan Rowlett, and Yiling Fan of MIT, Brian Ayers of Massachusetts General Hospital, Christopher Nguyen of Cleveland Clinic, and Mossab Saeed of Boston Children's Hospital.
A ballet of beats
The right ventricle is one of the heart's four chambers, along with the left ventricle and the left and right atria. Of the four chambers, the left ventricle is the heavy lifter, as its thick, cone-shaped musculature is built for pumping blood through the entire body. The right ventricle, Roche says, is a ""ballerina"" in comparison, as it handles a lighter though no-less-crucial load.

""The right ventricle pumps deoxygenated blood to the lungs, so it doesn't have to pump as hard,"" Roche notes. ""It's a thinner muscle, with more complex architecture and motion.""
This anatomical complexity has made it difficult for clinicians to accurately observe and assess right ventricle function in patients with heart disease.
""Conventional tools often fail to capture the intricate mechanics and dynamics of the right ventricle, leading to potential misdiagnoses and inadequate treatment strategies,"" Singh says.
To improve understanding of the lesser-known chamber and speed the development of cardiac devices to treat its dysfunction, the team designed a realistic, functional model of the right ventricle that both captures its anatomical intricacies and reproduces its pumping function.
The model includes real heart tissue, which the team chose to incorporate because it retains natural structures that are too complex to reproduce synthetically.
""There are thin, tiny chordae and valve leaflets with different material properties that are all moving in concert with the ventricle's muscle.Trying to cast or print these very delicate structures is quite challenging,"" Roche explains.

A heart's shelf-life
In the new study, the team reports explanting a pig's right ventricle, which they treated to carefully preserve its internal structures. They then fit a silicone wrapping around it, which acted as a soft, synthetic myocardium, or muscular lining. Within this lining, the team embedded several long, balloon-like tubes, which encircled the real heart tissue, in positions that the team determined through computational modeling to be optimal for reproducing the ventricle's contractions. The researchers connected each tube to a control system, which they then set to inflate and deflate each tube at rates that mimicked the heart's real rhythm and motion.
To test its pumping ability, the team infused the model with a liquid similar in viscosity to blood. This particular liquid was also transparent, allowing the engineers to observe with an internal camera how internal valves and structures responded as the ventricle pumped liquid through.
They found that the artificial ventricle's pumping power and the function of its internal structures were similar to what they previously observed in live, healthy animals, demonstrating that the model can realistically simulate the right ventricle's action and anatomy. The researchers could also tune the frequency and power of the pumping tubes to mimic various cardiac conditions, such as irregular heartbeats, muscle weakening, and hypertension.
""We're reanimating the heart, in some sense, and in a way that we can study and potentially treat its dysfunction,"" Roche says.
To show that the artificial ventricle can be used to test cardiac devices, the team surgically implanted ring-like medical devices of various sizes to repair the chamber's tricuspid valve -- a leafy, one-way valve that lets blood into the right ventricle. When this valve is leaky, or physically compromised, it can cause right heart failure or atrial fibrillation, and leads to symptoms such as reduced exercise capacity, swelling of the legs and abdomen, and liver enlargement
The researchers surgically manipulated the robo-ventricle's valve to simulate this condition, then either replaced it by implanting a mechanical valve or repaired it using ring-like devices of different sizes. They observed which device improved the ventricle's fluid flow as it continued to pump.
""With its ability to accurately replicate tricuspid valve dysfunction, the RRV serves as an ideal training ground for surgeons and interventional cardiologists,"" Singh says. ""They can practice new surgical techniques for repairing or replacing the tricuspid valve on our model before performing them on actual patients.""
Currently, the RRV can simulate realistic function over a few months. The team is working to extend that performance and enable the model to run continuously for longer stretches. They are also working with designers of implantable devices to test their prototypes on the artificial ventricle and possibly speed their path to patients. And looking far in the future, Roche plans to pair the RRV with a similar artificial, functional model of the left ventricle, which the group is currently fine-tuning.
""We envision pairing this with the left ventricle to make a fully tunable, artificial heart, that could potentially function in people,"" Roche says. ""We're quite a while off, but that's the overarching vision.""
This research was supported in part by the National Science Foundation.

","score: 14.977265745007681, grade_level: '15'","score: 16.81214132104455, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s44161-023-00387-8,"The increasing recognition of the right ventricle (RV) necessitates the development of RV-focused interventions, devices and testbeds. In this study, we developed a soft robotic model of the right heart that accurately mimics RV biomechanics and hemodynamics, including free wall, septal and valve motion. This model uses a biohybrid approach, combining a chemically treated endocardial scaffold with a soft robotic synthetic myocardium. When connected to a circulatory flow loop, the robotic right ventricle (RRV) replicates real-time hemodynamic changes in healthy and pathological conditions, including volume overload, RV systolic failure and pressure overload. The RRV also mimics clinical markers of RV dysfunction and is validated using an in vivo porcine model. Additionally, the RRV recreates chordae tension, simulating papillary muscle motion, and shows the potential for tricuspid valve repair and replacement in vitro. This work aims to provide a platform for developing tools for research and treatment for RV pathophysiology."
"
Mathieu Vinken, a professor in the In Vitro Toxicology and Dermato-cosmetology (IVTD) lab at the Vrije Universiteit Brussel, and doctoral student Raf Van Campenhout have developed a technique based on nanobody technology to prevent liver inflammation. Nanobodies, or single-domain antibodies, are fragments of antibodies that can selectively bind to a specific antigen. Because they are simple to produce and react in very specific ways, they are often used in various biotechnological, therapeutic and diagnostic applications.

""During a previous research project financed by an ERC Starting Grant, my team discovered that a specific type of molecule, pannexins, played an important role in certain inflammatory diseases,"" says Vinken. ""Pannexins are tube-like molecules found in the cell membrane. In a healthy state, these tubes are closed, but when diseased, they open, allowing substances through, leading to inflammation and eventually cell death. By using nanobodies, the opening of these pannexin tubes is suppressed, interrupting the inflammatory reaction.""
Vinken received additional funding, an ERC Proof of Concept and an FWO research grant, to develop this nanobody technology. For this, he is working with Professor Nick Devoogdt and postdoc Timo De Groof from the Molecular Imaging and Therapy research group at VUB. Devoogdt and De Groof specialise in creating and visualising nanobodies.
""VUB has a long tradition of research into nanobodies,"" says Devoogdt. ""This tradition began with Professor Raymond Hamers. In 1989, with his wife, Cécile Casterman, and Serge Muyldermans, he discovered that camel blood contained a smaller sort of antibody. The discovery led to several spin-offs and various innovative therapeutic techniques. Through the work of Mathieu Vinken, we have discovered another promising research direction. Specifically, we have been able to show that nanobody technology works much better in the event of paracetamol overdose than the current remedy using acetylcysteine.""
""Nanobodies close pannexins with unprecedented efficiency,"" says Vinken. Until now, research has been conducted in vitro and on a mouse model. In the next step, a clinical study will investigate possible side effects. The potential of pannexin-specific nanobodies to treat more complex disease states in combination with other agents will eventually be investigated. The findings were published on 11 October in the Journal of Nanobiotechnology. The team has also filed a patent application with a view to further (commercial) development of the technology and attracting investors or business partners for collaboration.

","score: 14.205385500575371, grade_level: '14'","score: 13.649019562715765, grade_levels: ['college_graduate'], ages: [24, 100]",10.1186/s12951-023-02137-1,"The opening of pannexin1 channels is considered as a key event in inflammation. Pannexin1 channel-mediated release of adenosine triphosphate triggers inflammasome signaling and activation of immune cells. By doing so, pannexin1 channels play an important role in several inflammatory diseases. Although pannexin1 channel inhibition could represent a novel clinical strategy for treatment of inflammatory disorders, therapeutic pannexin1 channel targeting is impeded by the lack of specific, potent and/or in vivo-applicable inhibitors. The goal of this study is to generate nanobody-based inhibitors of pannexin1 channels. Pannexin1-targeting nanobodies were developed as potential new pannexin1 channel inhibitors. We identified 3 cross-reactive nanobodies that showed affinity for both murine and human pannexin1 proteins. Flow cytometry experiments revealed binding capacities in the nanomolar range. Moreover, the pannexin1-targeting nanobodies were found to block pannexin1 channel-mediated release of adenosine triphosphate. The pannexin1-targeting nanobodies were also demonstrated to display anti-inflammatory effects in vitro through reduction of interleukin 1 beta amounts. This anti-inflammatory outcome was reproduced in vivo using a human-relevant mouse model of acute liver disease relying on acetaminophen overdosing. More specifically, the pannexin1-targeting nanobodies lowered serum levels of inflammatory cytokines and diminished liver damage. These effects were linked with alteration of the expression of several NLRP3 inflammasome components. This study introduced for the first time specific, potent and in vivo-applicable nanobody-based inhibitors of pannexin1 channels. As demonstrated for the case of liver disease, the pannexin1-targeting nanobodies hold great promise as anti-inflammatory agents, yet this should be further tested for extrahepatic inflammatory disorders. Moreover, the pannexin1-targeting nanobodies represent novel tools for fundamental research regarding the role of pannexin1 channels in pathological and physiological processes."
"
There has been a surge in academic and business interest in software as a medical device (SaMD). It enables medical professionals to streamline existing medical practices and make innovative medical processes such as digital therapeutics a reality. Furthermore, SaMD is a billion-dollar market. However, it is not clearly understood as a technological change and emerging industry. This enlightened researchers from Tokyo Institute of Technology to a new study. They reviewed FDA-approved SaMDs to shed light on the market landscape, the role of SaMDs, and the innovation within the industry. Their findings highlight the industry's diversity and potential for growth and advocate improving healthcare-related data access.

Software as a Medical Device (SaMD) is an emerging field aimed at assisting medical professionals in diagnosing, monitoring, treating, or preventing diseases. The International Medical Device Regulators Forum defines SaMD as software intended for medical purposes, but not part of a hardware medical device. This refers to a wide range of software such as health apps on smartphones or wearable devices that monitor and track health, as well as complex medical imaging software for X-rays, MRIs, and CT scans. However, the SaMD industry is still in its nascent stages of development and requires clarity on innovation, the market landscape, and the regulatory environment.
To address the limitations associated with current SaMD research, researchers from Tokyo Institute of Technology (Tokyo Tech) and the University of Tokyo recently conducted a comprehensive review of various aspects of SaMDs over the past decade, utilizing data from the U.S. Food and Drug Administration (FDA), the authoritative body for approving commercially marketed medical devices in the United States. Professor Shintaro Sengoku, Jiajie Zhang, and Jiakan Yu, the authors of the study published in the Journal of Medical Internet Research, state: ""The objectives of our work are to clarify the innovation process of SaMD, identify the prevailing typology of such innovation, and elucidate the underlying mechanisms driving the SaMD innovation process.""
The researchers collected information on FDA-approved SaMDs from the OpenFDA website. They also gathered profiles of 268 companies associated with these devices from various sources, including Crunchbase, Bloomberg, PichBook.com , and SaMD company websites. To be considered a SaMD, a device had to function as standalone software fulfilling medical functions. Devices operating solely as part of hardware or requiring additional hardware were excluded from the review.
The findings reveal significant growth in the SaMD industry. Between 2012 and 2021, the number of FDA-approved SaMDs increased from one to 581. Most SaMDs were developed for medical image processing and radiological analysis (78%), followed by cardiology, neurology, ophthalmology, and dentistry. The researchers also identified notable progress in artificial intelligence/machine learning based SaMDs, accounting for 22% of all FDA-approved SaMDs, marking what researchers are calling the 'third AI boom' in healthcare.
The United States leads in SaMD approvals (262 devices, 45%), followed by Germany, South Korea, and the Netherlands. Established companies in the medical device industry such as Siemens, General Electric, and Philips launched the most SaMDs (237 devices, 40.8%). These companies focus on incremental innovations to improve existing medical processes, such as image resolution or reducing manpower requirements for medical image processing.
New entrants or start-ups that were formed after 2012 accounted for about 37% (215 devices) of the launches. These small and micro companies focus on disruptive innovation which enables new medical practices, such as digital therapeutics and remote monitoring. Another notable player is the pharmaceutical industry, which is actively engaged in the digitalization process of healthcare, with significant investments in SaMD initiatives.
The study highlights the diversity and emerging nature of SaMD, its potential for growth, and its transformative impact on healthcare services. The findings emphasize that accelerated growth in this sector is closely linked to data accessibility in driving disruptive innovation within the industry. New entrants focusing on disruptive innovations will need to build their datasets or access existing data within the healthcare system.
""Governments and academic institutions should facilitate data accessibility as a public good to accelerate innovation in SaMD,"" conclude the three authors, outlining recommendations for future developments in the industry.
This study was funded by the Japan Science and Technology Agency, Program on open innovation platform for industry-academia co-creation (COI-NEXT), ""Center of health longevity and nursing innovation with global ecosystem"" (Grant No. JPMJPF2202).

","score: 15.636860198624905, grade_level: '16'","score: 16.46738349885409, grade_levels: ['college_graduate'], ages: [24, 100]",10.2196/47505,"There has been a surge in academic and business interest in software as a medical device (SaMD). SaMD enables medical professionals to streamline existing medical practices and make innovative medical processes such as digital therapeutics a reality. Furthermore, SaMD is a billion-dollar market. However, SaMD is not clearly understood as a technological change and emerging industry. This study aims to review the landscape of SaMD in response to increasing interest in SaMD within health systems and regulation. The objectives of the study are to (1) clarify the innovation process of SaMD, (2) identify the prevailing typology of such innovation, and (3) elucidate the underlying mechanisms driving the SaMD innovation process. We collected product information on 581 US Food and Drug Administration–approved SaMDs from the OpenFDA website and 268 company profiles of the corresponding manufacturers from Crunchbase, Bloomberg, PichBook.com, and other company websites. In addition to assessing the metadata of SaMD, we used correspondence and business process analysis to assess the distribution of intended use and how SaMDs interact with other devices in the medical process. The current SaMD industry is highly concentrated in medical image processing and radiological analysis. Incumbents in the medical device industry currently lead the market and focus on incremental innovation, whereas new entrants, particularly startups, produce more disruptive innovation. We found that hardware medical device functions as a complementary asset for SaMD, whereas how SaMD interacts with the complementary asset differs according to its intended use. Based on these findings, we propose a regime map that illustrates the SaMD innovation process. SaMD, as an industry, is nascent and dominated by incremental innovation. The innovation process of the present SaMD industry is shaped by data accessibility, which is key to building disruptive innovation."
"
The United Nations reports that more than 700 million people are in extreme poverty, earning less than two dollars a day. However, an accurate assessment of poverty remains a global challenge. For example, 53 countries have not conducted agricultural surveys in the past 15 years, and 17 countries have not published a population census. To fill this data gap, new technologies are being explored to estimate poverty using alternative sources such as street views, aerial photos, and satellite images.

The paper published in Nature Communications demonstrates how artificial intelligence (AI) can help analyze economic conditions from daytime satellite imagery. This new technology can even apply to the least developed countries -- such as North Korea -- that do not have reliable statistical data for typical machine learning training.
The researchers used Sentinel-2 satellite images from the European Space Agency (ESA) that are publicly available. They split these images into small six-square-kilometer grids. At this zoom level, visual information such as buildings, roads, and greenery can be used to quantify economic indicators. As a result, the team obtained the first ever fine-grained economic map of regions like North Korea. The same algorithm was applied to other underdeveloped countries in Asia: North Korea, Nepal, Laos, Myanmar, Bangladesh, and Cambodia.
The key feature of their research model is the ""human-machine collaborative approach,"" which lets researchers combine human input with AI predictions for areas with scarce data. In this research, ten human experts compared satellite images and judged the economic conditions in the area, with the AI learning from this human data and giving economic scores to each image. The results showed that the Human-AI collaborative approach outperformed machine-only learning algorithms.
The research was led by an interdisciplinary team of computer scientists, economists, and a geographer from KAIST & IBS (Donghyun Ahn, Meeyoung Cha, Jihee Kim), Sogang University (Hyunjoo Yang), HKUST (Sangyoon Park), and NUS (Jeasurk Yang). Dr Charles Axelsson, Associate Editor at Nature Communications, handled this paper during the peer review process at the journal.
The research team found that the scores showed a strong correlation with traditional socio-economic metrics such as population density, employment, and number of businesses. This demonstrates the wide applicability and scalability of the approach, particularly in data-scarce countries. Furthermore, the model's strength lies in its ability to detect annual changes in economic conditions at a more detailed geospatial level without using any survey data.
This model would be especially valuable for rapidly monitoring the progress of Sustainable Development Goals such as reducing poverty and promoting more equitable and sustainable growth on an international scale. The model can also be adapted to measure various social and environmental indicators. For example, it can be trained to identify regions with high vulnerability to climate change and disasters to provide timely guidance on disaster relief efforts.

As an example, the researchers explored how North Korea changed before and after the United Nations sanctions against the country. By applying the model to satellite images of North Korea both in 2016 and in 2019, the researchers discovered three key trends in the country's economic development between 2016 and 2019. First, economic growth in North Korea became more concentrated in Pyongyang and major cities, exacerbating the urban-rural divide. Second, satellite imagery revealed significant changes in areas designated for tourism and economic development, such as new building construction and other meaningful alterations. Third, traditional industrial and export development zones showed relatively minor changes.
Meeyoung Cha, a data scientist in the team explained, ""This is an important interdisciplinary effort to address global challenges like poverty. We plan to apply our AI algorithm to other international issues, such as monitoring carbon emissions, disaster damage detection, and the impact of climate change.""
An economist on the research team, Jihee Kim, commented that this approach would enable detailed examinations of economic conditions in the developing world at a low cost, reducing data disparities between developed and developing nations. She further emphasized that this is most essential because many public policies require economic measurements to achieve their goals, whether they are for growth, equality, or sustainability.
The research team has made the source code publicly available via GitHub and plans to continue improving the technology, applying it to new satellite images updated annually. The results of this study, with Ph.D. candidate Donghyun Ahn at KAIST and Ph.D. candidate Jeasurk Yang at NUS as joint first authors, were published in Nature Communications under the title ""A human-machine collaborative approach measures economic development using satellite imagery.""

","score: 15.721096815956631, grade_level: '16'","score: 16.41773718493345, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-42122-8,"Machine learning approaches using satellite imagery are providing accessible ways to infer socioeconomic measures without visiting a region. However, many algorithms require integration of ground-truth data, while regional data are scarce or even absent in many countries. Here we present our human-machine collaborative model which predicts grid-level economic development using publicly available satellite imagery and lightweight subjective ranking annotation without any ground data. We applied the model to North Korea and produced fine-grained predictions of economic development for the nation where data is not readily available. Our model suggests substantial development in the country’s capital and areas with state-led development projects in recent years. We showed the broad applicability of our model by examining five of the least developed countries in Asia, covering 400,000 grids. Our method can both yield highly granular economic information on hard-to-visit and low-resource regions and can potentially guide sustainable development programs."
"
EPFL researchers have developed an algorithm to train an analog neural network just as accurately as a digital one, enabling the development of more efficient alternatives to power-hungry deep learning hardware.

With their ability to process vast amounts of data through algorithmic 'learning' rather than traditional programming, it often seems like the potential of deep neural networks like Chat-GPT is limitless. But as the scope and impact of these systems have grown, so have their size, complexity, and energy consumption -- the latter of which is significant enough to raise concerns about contributions to global carbon emissions.
And while we often think of technological advancement in terms of shifting from analog to digital, researchers are now looking for answers to this problem in physical alternatives to digital deep neural networks. One such researcher is Romain Fleury of EPFL's Laboratory of Wave Engineering in the School of Engineering. In a paper published in Science, he and his colleagues describe an algorithm for training physical systems that shows improved speed, enhanced robustness, and reduced power consumption compared to other methods.
""We successfully tested our training algorithm on three wave-based physical systems that use sound waves, light waves, and microwaves to carry information, rather than electrons. But our versatile approach can be used to train any physical system,"" says first author and LWE researcher Ali Momeni.
A ""more biologically plausible"" approach
Neural network training refers to helping systems learn to generate optimal values of parameters for a task like image or speech recognition. It traditionally involves two steps: a forward pass, where data is sent through the network and an error function is calculated based on the output; and a backward pass (also known as backpropagation, or BP), where a gradient of the error function with respect to all network parameters is calculated.
Over repeated iterations, the system updates itself based on these two calculations to return increasingly accurate values. The problem? In addition to being very energy-intensive, BP is poorly suited to physical systems. In fact, training physical systems usually requires a digital twin for the BP step, which is inefficient and carries the risk of a reality-simulation mismatch.

The scientists' idea was to replace the BP step with a second forward pass through the physical system to update each network layer locally. In addition to decreasing power use and eliminating the need for a digital twin, this method better reflects human learning.
""The structure of neural networks is inspired by the brain, but it is unlikely that the brain learns via BP,"" explains Momeni. ""The idea here is that if we train each physical layer locally, we can use our actual physical system instead of first building a digital model of it. We have therefore developed an approach that is more biologically plausible.""
The EPFL researchers, with Philipp del Hougne of CNRS IETR and Babak Rahmani of Microsoft Research, used their physical local learning algorithm (PhyLL) to train experimental acoustic and microwave systems and a modeled optical system to classify data like vowel sounds and images. As well as showing comparable accuracy to BP-based training, the method was robust and adaptable -- even in systems exposed to unpredictable external perturbations -- compared to the state of the art.
An analog future?
While the LWE's approach is the first BP-free training of deep physical neural networks, some digital updates of the parameters are still required. ""It's a hybrid training approach, but our aim is to decrease digital computation as much as possible,"" Momeni says.
The researchers now hope to implement their algorithm on a small-scale optical system, with the ultimate goal of increasing network scalability.
""In our experiments, we used neural networks with up to 10 layers, but would it still work with 100 layers with billions of parameters? This is the next step, and will require overcoming technical limitations of physical systems.""

","score: 14.399451534229485, grade_level: '14'","score: 15.092561964721227, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adi8474,"Recent successes in deep learning for vision and natural language processing are attributed to larger models but come with energy consumption and scalability issues. Current training of digital deep-learning models primarily relies on backpropagation that is unsuitable for physical implementation. In this work, we propose a simple deep neural network architecture augmented by a physical local learning (PhyLL) algorithm, which enables supervised and unsupervised training of deep physical neural networks without detailed knowledge of the nonlinear physical layer’s properties. We trained diverse wave-based physical neural networks in vowel and image classification experiments, showcasing the universality of our approach. Our method shows advantages over other hardware-aware training schemes by improving training speed, enhancing robustness, and reducing power consumption by eliminating the need for system modeling and thus decreasing digital computation."
"
Fewer women pursue careers in physics than biology, and scientists from around the world believe these differences come down to personal preferences, according to a new Rice University study of international scientists. The study's researchers warn that merely chalking this imbalance up to individual choice may diminish the push for gender equality in the sciences.

""Scientists explain the underrepresentation of women in physics compared to biology in four national contexts"" appears in a recent edition of Gender, Work and Organization. Using survey data collected from academic biologists and physicists in the U.S. (1,777 total), Italy (1,257), France (648) and Taiwan (780), the researchers examine how scientists' social identities and the countries in which they reside shape their explanations of gender inequality in science.
Elaine Howard Ecklund, one of the study's authors and the Herbert S. Autrey Chair, professor of sociology and director of Rice's Boniuk Institute, said regardless of the scientists they surveyed, the decisions of women to not pursue careers in physics were interpreted by the respondents through a lens of individualism. The danger in this, Ecklund said, is ignoring the way preferences themselves are shaped by gendered processes. For example, previous studies have demonstrated that women are more likely to be excluded from professional networks because of their gender, penalized for being or potentially becoming mothers and not having sufficient access to professional mentoring -- all of which are factors that can affect the choices they make for pursuing or avoiding a particular field of science.
""These barriers ultimately prevent women from entering, persisting and advancing in academic science along different points in the pipeline,"" noted Di Di, one of the study's lead authors from Santa Clara University.
Ecklund further noted how gendered processes are at work long before women make decisions about their field of study, families or other aspects of life. Prior research suggests women are influenced early on by their parents' gender roles in the family and their occupations, which shape young women's decisions to go into fields like science, technology, engineering, math and other gendered occupations. These occupational selections are viewed as individual choices by scientists surveyed for this study.
""When scientists draw on individualist arguments to explain gender inequality -- thus ignoring these gendered processes -- they may blunt initiatives that can promote women's equity in STEM,"" said Esther Chan, one of the lead authors of the study from the University of Wisconsin-Milwaukee.
The study was funded by the Templeton Religion Trust.

","score: 17.73945054945055, grade_level: '18'","score: 20.080208604954365, grade_levels: ['college_graduate'], ages: [24, 100]",10.1111/gwao.13076,"Women are consistently underrepresented in physics when compared to biology. Yet how scientists themselves explain the causes of this underrepresentation is understudied outside the US context. In this research, we ask the following question: How do scientists in different national/regional contexts explain why there are fewer women in physics than biology? Using original survey data collected among academic biologists and physicists in the US (N = 1777), Italy (N = 1257), France (N = 648), and Taiwan (N = 780), we examine how scientists' social identities, social locations, and country context shape essentialist, individualist, and structural explanations of gender inequality. Findings indicate that scientists across national contexts attribute the unequal gender distribution in physics and biology to women's individual choices. Explanations for the gender distribution also vary by social identities and social locations (gender, discipline, and seniority) in country‐specific ways. Scientists and advocates ought to engage conversations that explicitly confront scientists' assumptions about individual choices in global science."
"

To magnetize an iron nail, one simply has to stroke its surface several times with a bar magnet. Yet, there is a much more unusual method: A team led by the Helmholtz-Zentrum Dresden-Rossendorf (HZDR) discovered some time ago that a certain iron alloy can be magnetized with ultrashort laser pulses. The researchers have now teamed up with the Laserinstitut Hochschule Mittweida (LHM) to investigate this process further. They discovered that the phenomenon also occurs with a different class of materials – which significantly broadens potential application prospects. The working group presents its findings in the scientific journal Advanced Functional Materials (DOI: 10.1002/adfm.202311951).The unexpected discovery was made back in 2018. When the HZDR team irradiated a thin layer of an iron-aluminum alloy with ultrashort laser pulses, the non-magnetic material suddenly became magnetic. The explanation: The laser pulses rearrange the atoms in the crystal in such a way that the iron atoms move closer together, and thus forming a magnet. The researchers were then able to demagnetize the layer again with a series of weaker laser pulses. This enabled them to discover a way of creating and erasing tiny ""magnetic spots"" on a surface.However, the pilot experiment still left some questions unanswered. ""It was unclear whether the effect only occurs in the iron-aluminum alloy or also in other materials,"" explains HZDR physicist Dr. Rantej Bali. ""We also wanted to try tracking the time progression of the process."" For further investigation, he teamed up with Dr. Theo Pflug from the LHM and colleagues from the University of Zaragoza in Spain.Flip book with laser pulsesThe experts focused specifically on an iron-vanadium alloy. Unlike the iron-aluminum alloy with its regular crystal lattice, the atoms in the iron-vanadium alloy are arranged more chaotically, forming an amorphous, glass-like structure. In order to observe what happens upon laser irradiation, the physicists used a special method: The pump-probe method.""First, we irradiate the alloy with a strong laser pulse, which magnetizes the material,"" explains Theo Pflug. ""Simultaneously, we use a second, weaker pulse that is reflected on the material surface.""The analysis of the reflected laser pulse provides an indication of the material's physical properties. This process is repeated several times, whereby the time interval between the first ""pump"" pulse and the subsequent ""probe"" pulse is continually extended.As a result, a time series of reflection data is obtained, which allows to characterize the processes being triggered by the laser excitation. ""The whole procedure is similar to generating a flip book,"" says Pflug. ""Likewise, a series of individual images that animate when viewed in quick succession.""Rapid meltingThe result: Although it has a different atomic structure than the iron-aluminum compound, the iron-vanadium alloy can also be magnetized via laser. ""In both cases, the material melts briefly at the irradiation point"", explains Rantej Bali. ""This causes the laser to erase the previous structure so that a small magnetic area is generated in both alloys.""An encouraging result: Apparently, the phenomenon is not limited to a specific material structure but can be observed in diverse atomic arrangements.The team is also keeping track of the temporal dynamics of the process: ""At least we now know in which time scales something happens,"" explains Theo Pflug. ""Within femtoseconds, the laser pulse excites the electrons in the material. Several picoseconds later, the excited electrons transfer their energy to the atomic nuclei.""Consequently, this energy transfer causes the rearrangement into a magnetic structure, which is stabilized by the subsequent rapid cooling. In follow-up experiments, the researchers aim to observe exactly how the atoms rearrange themselves by examining the magnetization process with intense X-rays.Sights set on applicationsAlthough still in the early stages, this work already provides initial ideas for possible applications: For example, placing tiny magnets on a chip surface via laser is conceivable. ""This could be useful for the production of sensitive magnetic sensors, such as those used in vehicles,"" speculates Rantej Bali. ""It could also find possible applications in magnetic data storage.""Additionally, the phenomenon appears relevant for a new type of electronics, namely spintronics. Here, magnetic signals should be used for digital computing processes instead of electrons passing through transistors as usual – offering a possible approach to computer technology of the future.

","score: 14.445669398907103, grade_level: '14'","score: 14.80577868852459, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adfm.202311951,"Atomic scale reordering of lattices can induce local modulations of functional material properties, such as reflectance and ferromagnetism. Pulsed femtosecond laser irradiation enables lattice reordering in the picosecond range. However, the dependence of the phase transitions on the initial lattice order as well as the temporal dynamics of these transitions remain to be understood. This study investigates the laser‐induced atomic reordering and the concomitant onset of ferromagnetism in thin Fe‐based alloy films with vastly differing initial atomic orders. The optical response to single femtosecond laser pulses on selected prototype systems, one that initially possesses positional disorder, Fe60V40, and a second system initially in a chemically ordered state, Fe60Al40, has been tracked with time. Despite the vastly different initial atomic orders the structure in both systems converges to a positionally ordered but chemically disordered state, accompanied by the onset of ferromagnetism. Time‐resolved measurements of the transient reflectance combined with simulations of the electron and phonon temperatures reveal that the reordering processes occur via the formation of a transient molten state with an approximate lifetime of 200 ps. These findings provide insights into the fundamental processes involved in laser‐induced atomic reordering, paving the way for controlling material properties in the picosecond range."
"
On the highway of heat transfer, thermal energy is moved by way of quantum particles called phonons. But at the nanoscale of today's most cutting-edge semiconductors, those phonons don't remove enough heat. That's why Purdue University researchers are focused on opening a new nanoscale lane on the heat transfer highway by using hybrid quasiparticles called ""polaritons.""

Thomas Beechem loves heat transfer. He talks about it loud and proud, like a preacher at a big tent revival.
""We have several ways of describing energy,"" said Beechem, associate professor of mechanical engineering. ""When we talk about light, we describe it in terms of particles called 'photons.' Heat also carries energy in predictable ways, and we describe those waves of energy as 'phonons.' But sometimes depending on the material, photons and phonons will come together and make something new called a 'polariton.' It carries energy in its own way, distinct from both photons or phonons.""
Like photons and phonons, polaritons aren't physical particles you can see or capture. They are more like ways of describing energy exchange as if they were particles.
Still fuzzy? How about another analogy. ""Phonons are like internal combustion vehicles, and photons are like electric vehicles,"" Beechem said. ""Polaritons are a Toyota Prius. They are a hybrid of light and heat, and retain some of the properties of both. But they are their own special thing.""
Polaritons have been used in optical applications -- everything from stained glass to home health tests. But their ability to move heat has largely been ignored, because their impact becomes significant only when the size of materials becomes very small. ""We know that phonons do a majority of the work of transferring heat,"" said Jacob Minyard, a Ph.D. student in Beechem's lab. ""The effect of polaritons is only observable at the nanoscale. But we've never needed to address heat transfer at that level until now, because of semiconductors.""
""Semiconductors have become so incredibly small and complex,"" he continued. ""People who design and build these chips are discovering that phonons don't efficiently disperse heat at these very small scales. Our paper demonstrates that at those length scales, polaritons can contribute a larger share of thermal conductivity.""
Their research on polaritons has been selected as a Featured Article in the Journal of Applied Physics.

""We in the heat transfer community have been very material-specific in describing the effect of polaritons,"" said Beechem. ""Someone will observe it in this material or at that interface. It's all very disparate. Jacob's paper has established that this isn't some random thing. Polaritons begin to dominate the heat transfer on any surface thinner than 10 nanometers. That's twice as big as the transistors on an iPhone 15.""
Now Beechem gets really fired up. ""We've basically opened up a whole extra lane on the highway. And the smaller the scales get, the more important this extra lane becomes. As semiconductors continue to shrink, we need to think about designing the traffic flow to take advantage of both lanes: phonons and polaritons.""
Minyard's paper just scratches the surface of how this can happen practically. The complexity of semiconductors means that there are many opportunities to capitalize upon polariton-friendly designs. ""There are many materials involved in chipmaking, from the silicon itself to the dielectrics and metals,"" Minyard said. ""The way forward for our research is to understand how these materials can be used to conduct heat more efficiently, recognizing that polaritons provide a whole new lane to move energy.""
Recognizing this, Beechem and Minyard want to show chip manufacturers how to incorporate these polariton-based nanoscale heat transfer principles right into the physical design of the chip -- from the physical materials involved, to the shape and thickness of the layers.
While this work is theoretical now, physical experimentation is very much on the horizon -- which is why Beechem and Minyard are happy to be at Purdue.
""The heat transfer community here at Purdue is so robust,"" Beechem said. ""We can literally go upstairs and talk to Xianfan Xu, who had one of the first experimental realizations of this effect. Then we can walk over to Flex Lab and ask Xiulin Ruan about his pioneering work in phonon scattering. And we have the facilities here at Birck Nanotechnology Center to build nanoscale experiments, and use one-of-a-kind measurement tools to confirm our findings. It's really a researcher's dream.""

","score: 10.423639624724064, grade_level: '10'","score: 9.816146247240617, grade_levels: ['10'], ages: [15, 16]",10.1063/5.0173917,"The material dependence of phonon-polariton-based in-plane thermal conductance is investigated by examining systems composed of air and several wurtzite and zinc-blende crystals. Phonon-polariton-based thermal conductance varies by over an order of magnitude (∼0.5–60 nW/K), which is similar to the variation observed in the materials corresponding to bulk thermal conductivity. Regardless of the material, phonon-polaritons exhibit similar thermal conductance to that of phonons when layers become ultrathin (∼10 nm), suggesting the generality of the effect at these length-scales. A figure of merit is proposed to explain the large variation of in-plane polariton thermal conductance that is composed entirely of easily predicted and measured optical phonon energies and lifetimes. Using this figure of merit, in-plane phonon-polariton thermal conductance enlarges with increases in (1) optical phonon energies, (2) splitting between transverse and longitudinal mode pairs, and (3) phonon lifetimes."
"
How heavy can an element be? An international team of researchers has found that ancient stars were capable of producing elements with atomic masses greater than 260, heavier than any element on the periodic table found naturally on Earth. The finding deepens our understanding of element formation in stars.

We are, literally, made of star stuff. Stars are element factories, where elements constantly fuse or break apart to create other lighter or heavier elements. When we refer to light or heavy elements, we're talking about their atomic mass. Broadly speaking, atomic mass is based on the number of protons and neutrons in the nucleus of one atom of that element.
The heaviest elements are only known to be created in neutron stars via the rapid neutron capture process, or r-process. Picture a single atomic nucleus floating in a soup of neutrons. Suddenly, a bunch of those neutrons get stuck to the nucleus in a very short time period -- usually in less than one second -- then undergo some internal neutron-to-proton changes, and voila! A heavy element, such as gold, platinum or uranium, forms.
The heaviest elements are unstable or radioactive, meaning they decay over time. One way that they do this is by splitting, a process called fission.
""The r-process is necessary if you want to make elements that are heavier than, say, lead and bismuth,"" says Ian Roederer, associate professor of physics at North Carolina State University and lead author of the research. Roederer was previously at the University of Michigan.
""You have to add many neutrons very quickly, but the catch is that you need a lot of energy and a lot of neutrons to do so,"" Roederer says. ""And the best place to find both are at the birth or death of a neutron star, or when neutron stars collide and produce the raw ingredients for the process.
""We have a general idea of how the r-process works, but the conditions of the process are quite extreme,"" Roederer says. ""We don't have a good sense of how many different kinds of sites in the universe can generate the r-process, we don't know how the r-process ends, and we can't answer questions like, how many neutrons can you add? Or, how heavy can an element be? So we decided to look at elements that could be made by fission in some well-studied old stars to see if we could start to answer some of these questions.""
The team took a fresh look at the amounts of heavy elements in 42 well-studied stars in the Milky Way. The stars were known to have heavy elements formed by the r-process in earlier generations of stars. By taking a broader view of the amounts of each heavy element found in these stars collectively, rather than individually as is more common, they identified previously unrecognized patterns.

Those patterns signaled that some elements listed near the middle of the periodic table -- such as silver and rhodium -- were likely the remnants of heavy element fission. The team was able to determine that the r-process can produce atoms with an atomic mass of at least 260 before they fission.
""That 260 is interesting because we haven't previously detected anything that heavy in space or naturally on Earth, even in nuclear weapon tests,"" Roederer says. ""But seeing them in space gives us guidance for how to think about models and fission -- and could give us insight into how the rich diversity of elements came to be.""
The work appears in Science and was supported in part by the National Science Foundation and the National Aeronautics and Space Administration.

","score: 10.778133907114519, grade_level: '11'","score: 10.941107695746936, grade_levels: ['11'], ages: [16, 17]",10.1126/science.adf1341,"The heaviest chemical elements are naturally produced by the rapid neutron-capture process ( r -process) during neutron star mergers or supernovae. The r -process production of elements heavier than uranium (transuranic nuclei) is poorly understood and inaccessible to experiments so must be extrapolated by using nucleosynthesis models. We examined element abundances in a sample of stars that are enhanced in r -process elements. The abundances of elements ruthenium, rhodium, palladium, and silver (atomic numbers Z = 44 to 47; mass numbers A = 99 to 110) correlate with those of heavier elements (63 ≤ Z ≤ 78, A > 150). There is no correlation for neighboring elements (34 ≤ Z ≤ 42 and 48 ≤ Z ≤ 62). We interpret this as evidence that fission fragments of transuranic nuclei contribute to the abundances. Our results indicate that neutron-rich nuclei with mass numbers >260 are produced in r -process events."
"
Engineers at Duke University and Harvard Medical School have developed a bio-compatible ink that solidifies into different 3D shapes and structures by absorbing ultrasound waves. Because it responds to sound waves rather than light, the ink can be used in deep tissues for biomedical purposes ranging from bone healing to heart valve repair.

This work appears on December 7 in the journal Science.
The uses for 3D-printing tools are ever increasing. Printers create prototypes of medical devices, design flexible, lightweight electronics, and even engineer tissues used in wound healing. But many of these printing techniques involve building the object point-by-point in a slow and arduous process that often requires a robust printing platform.
To circumvent these issues over the past several years, researchers developed a photo-sensitive ink that responds directly to targeted beams of light and quickly hardens into a desired structure. While this printing technique can substantially improve the speed and quality of a print, researchers can only use transparent inks for the prints, and biomedical purposes are limited, as light can't reach beyond a few millimeters deep into tissue.
Now, Y. Shrike Zhang, associate bioengineer at Brigham and Women's Hospital and associate professor at Harvard Medical School, and Junjie Yao, associate professor of biomedical engineering at Duke, have developed a new printing method called deep-penetrating acoustic volumetric printing, or DVAP, that resolves these problems. This new technique involves a specialized ink that reacts to soundwaves rather than light, enabling them to create biomedically useful structures at unprecedented tissue depths.
""DVAP relies on the sonothermal effect, which occurs when soundwaves are absorbed and increase the temperature to harden our ink,"" explained Yao, who designed the ultrasound printing technology for DVAP. ""Ultrasound waves can penetrate more than 100 times deeper than light while still spatially confined, so we can reach tissues, bones and organs with high spatial precision that haven't been reachable with light-based printing methods.""
The first component of DVAP involves a sonicated ink, called sono-ink, that is a combination of hydrogels, microparticles and molecules designed to specifically react to ultrasound waves. Once the sono-ink is delivered into the target area, a specialized ultrasound printing probe sends focused ultrasound waves into the ink, hardening portions of it into intricate structures. These structures can range from a hexagonal scaffold that mimics the hardness of bone to a bubble of hydrogel that can be placed on an organ.

""The ink itself is a viscous liquid, so it can be injected into a targeted area fairly easily, and as you move the ultrasound printing probe around, the materials in the ink will link together and harden,"" said Zhang, who designed the sono-ink in his lab at the Brigham. ""Once it's done, you can remove any remaining ink that isn't solidified via a syringe.""
The different components of the sono-ink enable the researchers to adjust the formula for a wide variety uses. For example, if they want to create a scaffold to help heal a broken bone or make up for bone loss, they can add bone mineral particles to the ink. This flexibility also allows them to engineer the hardened formula to be more durable or more degradable, depending on its use. They can even adjust the colors of their final print.
The team conducted three tests as a proof-of-concept of their new technique. The first involved using the ink to seal off a section in a goat's heart. When a human has nonvalvular atrial fibrillation, the heart won't beat correctly, causing blood to pool in the organ. Traditional treatment often requires open-chest surgery to seal off the left atrial appendage to reduce the risk of blood clots and heart attack.
Instead, the team used a catheter to deliver their sono-ink to the left atrial appendage in a goat heart that was placed in a printing chamber. The ultrasound probe then delivered focused ultrasound waves through 12 mm of tissue, hardening the ink without damaging any of the surrounding organ. Once the process was complete, the ink was safely bonded to the heart tissue and was flexible enough to withstand movements that mimicked the heart beating.
Next, the team tested the potential for DVAP's use for tissue reconstruction and regeneration. After creating a bone defect model using a chicken leg, the team injected the sono-ink and hardened it through 10 mm of sample skin and muscle tissue layers. The resulting material bonded seamlessly to the bone and didn't negatively impact any of the surrounding tissues.
Finally, Yao and Zhang showed that DVAP could also be used for therapeutic drug delivery. In their example, they added a common chemotherapy drug to their ink, which they delivered to sample liver tissue. Using their probe, they hardened the sono-ink into hydrogels that slowly release the chemotherapy and diffuse into the liver tissue.
""We're still far from bringing this tool into the clinic, but these tests reaffirmed the potential of this technology,"" said Zhang. ""We're very excited to see where it can go from here.""
""Because we can print through tissue, it allows for a lot of potential applications in surgery and therapy that traditionally involve very invasive and disruptive methods,"" said Yao. ""This work opens up an exciting new avenue in the 3D printing world, and we're excited to explore the potential of this tool together.""

","score: 13.258151447661472, grade_level: '13'","score: 14.323918649630762, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adi1563,"Volumetric printing, an emerging additive manufacturing technique, builds objects with enhanced printing speed and surface quality by forgoing the stepwise ink-renewal step. Existing volumetric printing techniques almost exclusively rely on light energy to trigger photopolymerization in transparent inks, limiting material choices and build sizes. We report a self-enhancing sonicated ink (or sono-ink) design and corresponding focused-ultrasound writing technique for deep-penetration acoustic volumetric printing (DAVP). We used experiments and acoustic modeling to study the frequency and scanning rate–dependent acoustic printing behaviors. DAVP achieves the key features of low acoustic streaming, rapid sonothermal polymerization, and large printing depth, enabling the printing of volumetric hydrogels and nanocomposites with various shapes regardless of their optical properties. DAVP also allows printing at centimeter depths through biological tissues, paving the way toward minimally invasive medicine."
"
The Chirik Group at the Princeton Department of Chemistry is chipping away at one of the great challenges of metal-catalyzed C-H functionalization with a new method that uses a cobalt catalyst to differentiate between bonds in fluoroarenes, functionalizing them based on their intrinsic electronic properties.

In a paper published this week in Science, researchers show they are able to bypass the need for steric control and directing groups to induce cobalt-catalyzed borylation that is meta-selective.
The lab's research showcases an innovative approach driven by deep insights into organometallic chemistry that have been at the heart of its mission for over a decade. In this case, the Chirik Lab drilled down into how transition metals break C-H bonds, uncovering a method that could have vast implications for the synthesis of medicines, natural products, and materials.
And their method is fast -- comparable in speed to those that rely on iridium.
The research is outlined in ""Kinetic and Thermodynamic Control of C(sp2)-H Activation Enable Site-Selective Borylation,"" by lead author Jose Roque, a former postdoc in the Chirik Group; postdoc Alex Shimozono; and P.I. Paul Chirik, the Edwards S. Sanford Professor of Chemistry and former lab members Tyler Pabst, Gabriele Hierlmeier, and Paul Peterson.
'Really fast, really selective'
""Chemists have been saying for decades, let's turn synthetic chemistry on its head and make the C-H bond a reactive part of the molecule. That would be incredibly important for drug discovery for the pharmaceutical industry, or for making materials,"" said Chirik.

""One of the ways we do this is called C-H borylation, in which you turn the C-H bond into something else, into a carbon-boron bond. Turning C-H to C-B is a gateway to great chemistry.""
Benzene rings are highly represented motifs in medicinal chemistry. However, chemists rely on traditional approaches to functionalize them. The Chirik Group develops new methods that access less-explored routes.
""Imagine you have a benzene ring and it has one substituent on it,"" Chikik added. ""The site next to it is called ortho, the one next to that is called meta, and the one opposite is called para. The meta C-H bond is the hardest one to do selectively. That's what Jose has done here with a cobalt catalyst, and no one's done it before.
""He's made a cobalt catalyst that is really fast and really selective.""
Roque, now an assistant professor in Princeton's Department of Chemistry, said rational design was at the heart of their solution.
""We started to get a glimpse of the high activity for C-H activation early during our stoichiometric studies,"" said Roque. ""The catalyst was rapidly activating the C-H bonds of aromatic solvents at room temperature. In order to isolate the catalyst, we had to avoid handling the catalyst in aromatic solvents,"" he added. ""We designed an electronically rich but sterically accessible pincer ligand that we posited -- based on some previous insights from our lab as well as some fundamental organometallic principles -- would lead to a more active catalyst.

""And it has.""
Chirik Lab Target Since 2014 
State-of-the-art borylation uses iridium as a catalyst for sterically driven C-H functionalization. It is highly reactive, and it is fast. But if you have a molecule with many C-H bonds, iridium catalysts fail to selectively functionalize the desired bond.
As a result, pharmaceutical companies have appealed for an alternative with more selectivity. And they've sought it among first-row transition metals like cobalt and iron, which are less expensive and more sustainable than iridium.
Since their first paper on C-H borylation in 2014, the Chirik Lab has articulated the concept of electronically controlled C-H activation as one answer to this challenge. Their idea is to differentiate between C-H bonds based on electronic properties in order to functionalize them. These properties are reflected in the metal-carbon bond strength. With the catalyst designed in this research, chemists can hit the selected bond and only the selected bond by tapping into these disparate strengths.
But they uncovered another result that makes their method advantageous: the site selectivity can be switched by exploiting the kinetic or thermodynamic preferences of C-H activation. This selectivity switch can be accomplished by choosing one reagent over another, a process that is as streamlined as it is cost-effective.
""Site-selective meta-to-fluorine functionalization was a huge challenge. We made some great progress toward that with this research and expanded the chemistry to include other substrate classes beyond fluoroarenes,"" said Roque. ""But as a function of studying first-row metals, we also found out, hey, we can switch the selectivity.""
Added Chirik: ""To me, this is a huge concept in C-H functionalization. Now we can look at metal-carbon bond strengths and predict where things are going to go. This opens a whole new opportunity. We're going to be able to do things that iridium doesn't do.""
Shimozono came to the project late in the game, after Roque had already discovered the pivotal catalyst. His role will deepen in the coming months as he seeks new advances in borylation.
""Jose's catalyst is groundbreaking. Usually, a completely different catalyst is required in order to change site-selectivity,"" said Shimozono. ""Counter to this dogma, Jose demonstrated that using B2Pin2 as the boron source affords meta selective chemistry, while using HBPin as the boron source gives ortho selective borylation using the same iPrACNCCo catalyst.
""In general, the more methods we have to install groups in specific sites in molecules, the better. This gives pharmaceutical chemists more tools to make and discover medications more efficiently.""

","score: 12.107030277185505, grade_level: '12'","score: 11.891663113006402, grade_levels: ['12'], ages: [17, 18]",10.1126/science.adj6527,"Catalysts that distinguish between electronically distinct carbon-hydrogen (C–H) bonds without relying on steric effects or directing groups are challenging to design. In this work, cobalt precatalysts supported by N -alkyl-imidazole–substituted pyridine dicarbene (ACNC) pincer ligands are described that enable undirected, remote borylation of fluoroaromatics and expansion of scope to include electron-rich arenes, pyridines, and tri- and difluoromethoxylated arenes, thereby addressing one of the major limitations of first-row transition metal C–H functionalization catalysts. Mechanistic studies established a kinetic preference for C–H bond activation at the meta -position despite cobalt-aryl complexes resulting from ortho C–H activation being thermodynamically preferred. Switchable site selectivity in C–H borylation as a function of the boron reagent was thereby preliminarily demonstrated using a single precatalyst."
"
A central goal in quantum optics and photonics is to increase the strength of the interaction between light and matter to produce, e.g., better photodetectors or quantum light sources. The best way to do that is to use optical resonators that store light for a long time, making it interact more strongly with matter. If the resonator is also very small, such that light is squeezed into a tiny region of space, the interaction is enhanced even further. The ideal resonator would store light for a long time in a region at the size of a single atom.

Physicists and engineers have struggled for decades with how small optical resonators can be made without making them very lossy, which is equivalent to asking how small you can make a semiconductor device. The semiconductor industry's roadmap for the next 15 years predicts that the smallest possible width of a semiconductor structure will be no less than 8 nm, which is several tens of atoms wide.
The team behind a new paper in Nature, Associate Professor Søren Stobbe and his colleagues at DTU Electro demonstrated 8 nm cavities last year, but now they propose and demonstrate a novel approach to fabricate a self-assembling cavity with an air void at the scale of a few atoms. Their paper 'Self-assembled photonic cavities with atomic-scale confinement' detailing the results is published today in Nature.
To briefly explain the experiment, two halves of silicon structures are suspended on springs, although in the first step, the silicon device is firmly attached to a layer of glass. The devices are made by conventional semiconductor technology, so the two halves are a few tens of nanometers apart. Upon selective etching of the glass, the structure is released and now only suspended by the springs, and because the two halves are fabricated so close to each other, they attract due to surface forces. By carefully engineering the design of the silicon structures, the result is a self-assembled resonator with bowtie-shaped gaps at the atomic scale surrounded by silicon mirrors.
""We are far from a circuit that builds itself completely. But we have succeeded in converging two approaches that have been travelling along parallel tracks so far. And it allowed us to build a silicon resonator with unprecedented miniaturization,"" says Søren Stobbe.
Two separate approaches
One approach -- the top-down approach -- is behind the spectacular development we have seen with silicon-based semiconductor technologies. Here, crudely put, you go from a silicon block and work on making nanostructures from them. The other approach -- the bottom-up approach -- is where you try to have a nanotechnological system assemble itself. It aims to mimic biological systems, such as plants or animals, built through biological or chemical processes. These two approaches are at the very core of what defines nanotechnology. But the problem is that these two approaches were so far disconnected: Semiconductors are scalable but cannot reach the atomic scale, and while self-assembled structures have long been operating at atomic scales, they offer no architecture for the interconnects to the external world.

""The interesting thing would be if we could produce an electronic circuit that built itself -- just like what happens with humans as they grow but with inorganic semiconductor materials. That would be true hierarchical self-assembly. We use the new self-assembly concept for photonic resonators, which may be used in electronics, nanorobotics, sensors, quantum technologies, and much more. Then, we would really be able to harvest the full potential of nanotechnology. The research community is many breakthroughs away from realizing that vision, but I hope we have taken the first steps,"" says Guillermo Arregui, who co-supervised the project.
Approaches converging
Supposing a combination of the two approaches is possible, the team at DTU Electro set out to create nanostructures that surpass the limits of conventional lithography and etching despite using nothing more than conventional lithography and etching. Their idea was to use two surface forces, namely the Casimir force for attracting the two halves and the van der Waals force for making them stick together. These two forces are rooted in the same underlying effect: quantum fluctuations (see Fact box).
The researchers made photonic cavities that confine photons to air gaps so small that determining their exact size was impossible, even with a transmission electron microscope. But the smallest they built are of a size of 1-3 silicon atoms.
""Even if the self-assembly takes care of reaching these extreme dimensions, the requirements for the nanofabrication are no less extreme. For example, structural imperfections are typically on the scale of several nanometers. Still, if there are defects at this scale, the two halves will only meet and touch at the three largest defects. We are really pushing the limits here, even though we make our devices in one of the very best university cleanrooms in the world,"" says Ali Nawaz Babar, a PhD student at the NanoPhoton Center of Excellence at DTU Electro and first author of the new paper.
""The advantage of self-assembly is that you can make tiny things. You can build unique materials with amazing properties. But today, you can't use it for anything you plug into a power outlet. You can't connect it to the rest of the world. So, you need all the usual semiconductor technology for making the wires or waveguides to connect whatever you have self-assembled to the external world.""
Robust and accurate self-assembly

The paper shows a possible way to link the two nanotechnology approaches by employing a new generation of fabrication technology that combines the atomic dimensions enabled by self-assembly with the scalability of semiconductors fabricated with conventional methods.
""We don't have to go in and find these cavities afterwards and insert them into another chip architecture. That would also be impossible because of the tiny size. In other words, we are building something on the scale of an atom already inserted in a macroscopic circuit. We are very excited about this new line of research, and plenty of work is ahead,"" says Søren Stobbe.
Surface forces
There are four known fundamental forces: Gravitational, electromagnetic, and strong and weak nuclear forces. Besides the forces due to static configurations, e.g., the attractive electromagnetic force between positively and negatively charged particles, there can also be forces due to fluctuations. Such fluctuations may be either thermal or quantum in origin, and they give rise to surface forces such as the van der Waals force and the Casimir force which act at different length scales but are rooted in the same underlying physics. Other mechanisms, such as electrostatic surface charges, can add to the net surface force. For example, geckos exploit surface forces to cling to walls and ceilings.
How it was done
The paper details three experiments that the researchers carried out in the labs at DTU:  No fewer than 2688 devices across two microchips were fabricated, each containing a platform that would either collapse onto a nearby silicon wall -- or not collapse, depending upon the surface area details, spring constant, and distance between platform and wall. This allowed the researchers to make a map of which parameters would -- and would not -- lead to deterministic self-assembly. Only 11 devices failed due to fabrication errors or other defects, a remarkably low number for a novel self-assembly process.  The researchers made self-assembled optical resonators whose optical properties were verified experimentally, and the atomic scale was confirmed by transmission electron microscopy.  The self-assembled cavities were embedded in a larger architecture consisting of self-assembled waveguides, springs, and photonic couplers to make the surrounding microchip circuitry in the same process.

","score: 13.429642964770036, grade_level: '13'","score: 14.422562244385446, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06736-8,"Despite tremendous progress in research on self-assembled nanotechnological building blocks, such as macromolecules1, nanowires2 and two-dimensional materials3, synthetic self-assembly methods that bridge the nanoscopic to macroscopic dimensions remain unscalable and inferior to biological self-assembly. By contrast, planar semiconductor technology has had an immense technological impact, owing to its inherent scalability, yet it seems unable to reach the atomic dimensions enabled by self-assembly. Here, we use surface forces, including Casimir–van der Waals interactions4, to deterministically self-assemble and self-align suspended silicon nanostructures with void features well below the length scales possible with conventional lithography and etching5, despite using only conventional lithography and etching. The method is remarkably robust and the threshold for self-assembly depends monotonically on all the governing parameters across thousands of measured devices. We illustrate the potential of these concepts by fabricating nanostructures that are impossible to make with any other known method: waveguide-coupled high-Q silicon photonic cavities6,7 that confine telecom photons to 2 nm air gaps with an aspect ratio of 100, corresponding to mode volumes more than 100 times below the diffraction limit. Scanning transmission electron microscopy measurements confirm the ability to build devices with sub-nanometre dimensions. Our work constitutes the first steps towards a new generation of fabrication technology that combines the atomic dimensions enabled by self-assembly with the scalability of planar semiconductors."
"
Researchers have uncovered the intricate molecular mechanism used by parasitic phytoplasma bacteria, known for inducing 'zombie-like' effects in plants. This detailed revelation opens new horizons for groundbreaking applications in biotechnology and even in biomedicine.

The team led by Professor Saskia Hogenhout at the John Innes Centre, in partnership with The Sainsbury Laboratory, has employed X-ray crystallography to unveil the structure and functional mechanism of SAP05. This molecule plays a crucial role in bridging two distinct components inside plant cells.
The discovery sheds new light on a peculiar phenomenon in nature -- mostly seen in ""witches' brooms"" in which plant stems and leaves proliferate due to Phytoplasma bacteria.
This insect-transmitted bacteria triggers diseases like Aster Yellows, significantly diminishing yields in leaf crops including oilseed rape, lettuce, carrots, grapevines, onions, and a variety of ornamental and vegetable crops worldwide.
Previous research by the Hogenhout group revealed how the bacterial protein SAP05 is able to manipulate plants by hijacking molecular machinery called the proteasome.
The proteasome breaks down and recycles proteins that are no longer required inside plant cells.
SAP05 hijacks this process, causing proteins which regulate growth and development to be dispensed into a molecular recycling centre known as the 26S proteasome.

This latest research focusses on how this happens at the structural level. SAP05 effectively disrupts the molecular recycling pathway, serving as a scaffold that connects its two cellular targets: a transcription factor and the proteasome.
Fascinatingly, SAP05 binds in a manner that enables it to 'lift the dustbin lid', selectively disposing of developmental proteins, while strategically preserving functions vital for the survival of its plant host.
Professor Hogenhout, group leader at the John Innes Centre, and lead of the research team behind these findings explains: ""We now know the structure of this complex and how the protein binds to two cellular components to create a short circuit. Whilst SAP05 allows itself to get involved in the plant, it does not disrupt other important processes. It is so amazing to see evolution crystalized in this way.""
Usually in plants, in fact across all multicellular organisms, this recycling of proteins in the proteasome is dependent on a molecule called ubiquitin.
By short-circuiting this process SAP05 provides a new way of carrying out the essential task of protein degradation which serves its own parasitic purpose and is completely independent of ubiquitin.
The discovery presents some intriguing possibilities. The researchers were struck by the sophisticated ingenuity of SAP05, a master manipulator, and its promising applications in biotechnology.
First author of the paper Dr Qun Liu said: ""It was so exciting to see that this molecule SAP05 had two sides, one side binding to the transcription factor and the other binding to the 26S proteasome, . Iit's very smart.""
By understanding how this bacterial mechanism interacts with cells at a structural level, the researchers can now use this knowledge to engineer SAP05-like molecules which could be repurposed to remove unwanted proteins such as pathogen effectors or viruses, with an impact on therapeutics, research and in agriculture.
The work on the SAP05 effector protein continues with funding from the European Research Council, and a project led by Professor Hogenhout to investigate novel Targeted Protein Degradation (TPD) technology.

","score: 14.84702567363485, grade_level: '15'","score: 16.060627931007076, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2310664120,"In eukaryotes, targeted protein degradation (TPD) typically depends on a series of interactions among ubiquitin ligases that transfer ubiquitin molecules to substrates leading to degradation by the 26S proteasome. We previously identified that the bacterial effector protein SAP05 mediates ubiquitin-independent TPD. SAP05 forms a ternary complex via interactions with the von Willebrand Factor Type A (vWA) domain of the proteasomal ubiquitin receptor Rpn10 and the zinc-finger (ZnF) domains of the SQUAMOSA-PROMOTER BINDING PROTEIN-LIKE (SPL) and GATA BINDING FACTOR (GATA) transcription factors (TFs). This leads to direct TPD of the TFs by the 26S proteasome. Here, we report the crystal structures of the SAP05–Rpn10 vWA complex at 2.17 Å resolution and of the SAP05–SPL5 ZnF complex at 2.20 Å resolution. Structural analyses revealed that SAP05 displays a remarkable bimodular architecture with two distinct nonoverlapping surfaces, a “loop surface” with three protruding loops that form electrostatic interactions with ZnF, and a “sheet surface” featuring two β-sheets, loops, and α-helices that establish polar interactions with vWA. SAP05 binding to ZnF TFs involves single amino acids responsible for multiple contacts, while SAP05 binding to vWA is more stable due to the necessity of multiple mutations to break the interaction. In addition, positioning of the SAP05 complex on the 26S proteasome points to a mechanism of protein degradation. Collectively, our findings demonstrate how a small bacterial bimodular protein can bypass the canonical ubiquitin–proteasome proteolysis pathway, enabling ubiquitin-independent TPD in eukaryotic cells. This knowledge holds significant potential for the creation of TPD technologies."
"
More than 2.2 billion people currently live in water-stressed countries, and the United Nations estimates that 3.5 million die every year from water-related diseases. Because the areas most in need of improved drinking water are also located in some of the sunniest places in the world, there is strong interest in harnessing sunlight to help obtain clean water.

Researchers from Shanghai Jiao Tong University in China developed a promising new solar-powered atmospheric water harvesting technology that could help provide enough drinking water for people to survive in those difficult, dryland areas. They published their work in Applied Physics Reviews, an AIP Publishing journal.
""This atmospheric water harvesting technology can be used to increase the daily water supply needs, such as household drinking water, industrial water, and water for personal hygiene,"" said author Ruzhu Wang.
Historically, researchers have faced challenges when injecting salt into hydrogels as the higher salt content reduced the swelling capacity of the hydrogel due to the salting-out effect. This led to salt leakage and the water absorption capacity decreased.
""We were impressed that even when up to 5 grams of salt was injected into 1 gram of polymer, the resulting gel maintained good swelling and salt-trapping properties,"" said Wang.
The researchers synthesized a super hygroscopic gel using plant derivatives and hygroscopic salts that was capable of absorbing and retaining an unparalleled amount of water. One kilogram of dry gel could adsorb 1.18 kilograms of water in arid atmospheric environments and up to 6.4 kilograms in humid atmospheric environments. This hygroscopic gel was simple and inexpensive to prepare and would consequently be suitable for large-scale preparation.
In addition, the team adopted a prototype with desorption and condensation chambers, configured in parallel. They employed a turbofan in the condensation chamber to increase the recovery of desorbed water to more than 90%.
In an outdoor prototype demonstration, the team found it released adsorbed water even in the morning or afternoon when the sun is weak. The system could also achieve simultaneous adsorption and desorption during the daytime.
The team will work to achieve simultaneous adsorption and desorption using renewable energy to maximize daily water yield per unit mass of adsorbent to further optimize the system's performance for practical applications in water generation.
In addition to daily water production, sorbent materials that harvest atmosphere water could also play an important role in future applications such as dehumidification, agriculture irrigation, and thermal management for electronic devices.

","score: 15.973137254901964, grade_level: '16'","score: 16.775147058823528, grade_levels: ['college_graduate'], ages: [24, 100]",10.1063/5.0160682,"In recent years, solar-powered, passive adsorption-based air–water harvesting has shown tremendous potential in addressing freshwater shortages in arid regions. Although remarkable progress has been witnessed in unlocking the potential of new adsorbents in the laboratory, the productivity of freshwater is still limited by the slow adsorption kinetic, the large latent heat of water evaporation, and the efficiency of condensation. In this work, superhygroscopic porous gels consisting of titanium nitride, hydroxypropyl methylcellulose, and LiCl (THL) were developed and demonstrated to have a unique high water uptake of 1.18–6.43 gwatergsorbent−1 at 25 °C and 15%–90% relative humidity. To validate the feasibility of THL for moisture extraction, reasonable energy management of the water harvester was carried out, and the potential daytime outdoor water collection in summer and winter reached 3.82 and 2.98 lwater kgsorbent−1 day−1, respectively, at relative humidity of ∼60% and ∼30%. The implementation strategy proposed in this paper provides a reliable path for solar-driven AWH, confirming the adaptability and possibility of achieving high yield freshwater production in real scenarios of practical significance."
"
Researchers at the LKS Faculty of Medicine of the University of Hong Kong (HKUMed), and collaborators from the Zhongshan Ophthalmic Centre of Sun Yat-sen University, Guangzhou, have developed a light-activatable prodrug nanomedicine for age-related macular degeneration (AMD) therapy. Through the intravenous injection of the nanomedicine and application of light irradiation to diseased eyes, anti-angiogenic and photodynamic combination therapy can be activated, offering a minimally invasive alternative for the treatment of AMD and other ocular disorders characterised by abnormal blood vessel growth. The research has been published in Advanced Science and a Patent Cooperation Treaty application was filed based on the research.

According to the Hong Kong Eye Survey data published in 2019, the prevalence of early AMD among individuals aged 70 and older has reached 7.5% in Hong Kong1, making AMD the second most common cause of visual impairment and blindness in the adult population of Hong Kong. Currently, intravitreal injections of antibodies against vascular endothelial growth factor are the first-line treatment for wet AMD. However, this invasive procedure is uncomfortable for patients, and carries the risk of serious ocular complications, such as endophthalmitis and retinal detachment. Therefore, there is an urgent need for novel formulations that enable the delivery of anti-angiogenic agents into the eye without an intravitreal injection, such as intravenous injection.
Additionally, anti-angiogenic agents have limited efficacy in regressing existing neovascularisation. Photodynamic therapy (PDT) offers a clinical solution by utilising non-toxic photosensitisers activated by specific wavelengths of light to generate reactive oxygen species (ROS), which can damage and obliterate neovascularisation. PDT is widely used for the treatment of polypoidal choroidal vasculopathy, a common subtype of wet AMD in Asia. Therefore, combining anti-angiogenesis therapy with PDT may offer a more effective approach to treating wet AMD, thus helping slow down the progression of the disease and improve the vision outcome for patients.
Research methods and findings
The research team designed a novel photoactivatable prodrug nanosystem. After a single intravenous injection of the nanoparticles into a choroidal neovascularisation mouse model, red-light irradiation of the mouse's eye activated the nanoparticles to generate ROS, which not only causes the regression of abnormal neovascularisation, but also triggers the release of anti-angiogenic drugs from the nanoparticles to inhibit the growth of new blood vessels. This combinational therapy demonstrated excellent therapeutic efficacy without any noticeable systemic or ocular side effects.
Research significance
The study represents the first attempt at integrating a photoactivatable anti-angiogenic agent with a photosensitiser into a single nanoformulation for AMD treatment. The treatment procedure is simple and safe, as the therapeutic effect of the anti-angiogenic agent and photosensitiser in ocular lesions can be achieved through the intravenous administration of nanoparticles and light irradiation to the eye. This pioneering research may open up new avenues for the development of minimally-invasive therapeutics for AMD and other neovascular ocular disorders. The formulation uses US FDA-approved therapeutic agents and excipients, making it promising for future clinical translation.
The study was led by Dr Wang Weiping, Associate Professor of Dr Li Dak-Sum Research Centre and Department of Pharmacology and Pharmacy, HKUMed, and Principal Investigator of the State Key Laboratory of Pharmaceutical Biotechnology, HKU. The other corresponding author was Professor Liang Xiaoling, Department of Ophthalmology, Guangdong Provincial Key Laboratory of Ophthalmology and Visual Science, State Key Laboratory of Ophthalmology, Sun Yat-Sen University, and Zhongshan Ophthalmic Centre, Sun Yat-sen University; the co-first authors were Xu Shuting, PhD candidate, Department of Pharmacology and Pharmacy, HKUMed, and Dr Cui Kaixuan, Postdoctoral fellow, Department of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-Sen University. Other researchers included Long Kaiqi, PhD candidate, Department of Pharmacology and Pharmacy, HKUMed; Dr Li Jia and Dr Fan Ni, Postdoctoral fellows, Department of Pharmacology and Pharmacy; and Professor Lam Wai-ching, Head and Clinical Professor of the Department of Ophthalmology, Vancouver General Hospital and University of British Columbia, Canada, and Honorary Clinical Professor, Department of Ophthalmology, School of Clinical Medicine, HKUMed.
This work was supported by the National Natural Science Foundation of China Excellent Young Scientists Fund (No. 82222903) and the National Natural Science Foundation of China (No. 82271099).

","score: 20.29644254581476, grade_level: '20'","score: 21.298738236750864, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202301985,"Choroidal neovascularization (CNV) is the key pathological event of wet age‐related macular degeneration (wAMD) leading to irreversible vision loss. Currently, anti‐angiogenic therapy with anti‐vascular endothelial growth factor (VEGF) agents has become the standard treatment for wAMD, while it is still subject to several limitations, including the safety concerns of monthly intravitreal administration and insufficient efficacy for neovascular occlusion. Combined therapy with photodynamic therapy (PDT) and anti‐angiogenic agents has emerged as a novel treatment paradigm. Herein, a novel and less‐invasive approach is reported to achieve anti‐angiogenic and photodynamic combination therapy of wAMD by intravenous administration of a photoactivatable nanosystem (Di‐DAS‐VER NPs). The nanosystem is self‐assembled by reactive oxygen species (ROS)‐sensitive dasatinib (DAS) prodrug and photosensitizer verteporfin (VER). After red‐light irradiation to the diseased eyes, intraocular release of anti‐angiogenic DAS is observed, together with selective neo‐vessels occlusion by VER‐generated ROS. Notably, Di‐DAS‐VER NPs demonstrates promising therapeutic efficacy against CNV with minimized systemic toxicity. The study enables an efficient intravenous wAMD therapy by integrating a photoactivation process with combinational therapeutics into one simple nanosystem."
"
Researchers have discovered magnetic monopoles -- isolated magnetic charges -- in a material closely related to rust, a result that could be used to power greener and faster computing technologies.

Researchers led by the University of Cambridge used a technique known as diamond quantum sensing to observe swirling textures and faint magnetic signals on the surface of hematite, a type of iron oxide.
The researchers observed that magnetic monopoles in hematite emerge through the collective behaviour of many spins (the angular momentum of a particle). These monopoles glide across the swirling textures on the surface of the hematite, like tiny hockey pucks of magnetic charge. This is the first time that naturally occurring emergent monopoles have been observed experimentally.
The research has also shown the direct connection between the previously hidden swirling textures and the magnetic charges of materials like hematite, as if there is a secret code linking them together. The results, which could be useful in enabling next-generation logic and memory applications, are reported in the journal Nature Materials.
According to the equations of James Clerk Maxwell, a giant of Cambridge physics, magnetic objects, whether a fridge magnet or the Earth itself, must always exist as a pair of magnetic poles that cannot be isolated.
""The magnets we use every day have two poles: north and south,"" said Professor Mete Atatüre, who led the research. ""In the 19th century, it was hypothesised that monopoles could exist. But in one of his foundational equations for the study of electromagnetism, James Clerk Maxwell disagreed.""
Atatüre is Head of Cambridge's Cavendish Laboratory, a position once held by Maxwell himself. ""If monopoles did exist, and we were able to isolate them, it would be like finding a missing puzzle piece that was assumed to be lost,"" he said.

About 15 years ago, scientists suggested how monopoles could exist in a magnetic material. This theoretical result relied on the extreme separation of north and south poles so that locally each pole appeared isolated in an exotic material called spin ice.
However, there is an alternative strategy to find monopoles, involving the concept of emergence. The idea of emergence is the combination of many physical entities can give rise to properties that are either more than or different to the sum of their parts.
Working with colleagues from the University of Oxford and the National University of Singapore, the Cambridge researchers used emergence to uncover monopoles spread over two-dimensional space, gliding across the swirling textures on the surface of a magnetic material.
The swirling topological textures are found in two main types of materials: ferromagnets and antiferromagnets. Of the two, antiferromagnets are more stable than ferromagnets, but they are more difficult to study, as they don't have a strong magnetic signature.
To study the behaviour of antiferromagnets, Atatüre and his colleagues use an imaging technique known as diamond quantum magnetometry. This technique uses a single spin -- the inherent angular momentum of an electron -- in a diamond needle to precisely measure the magnetic field on the surface of a material, without affecting its behaviour.
For the current study, the researchers used the technique to look at hematite, an antiferromagnetic iron oxide material. To their surprise, they found hidden patterns of magnetic charges within hematite, including monopoles, dipoles and quadrupoles.

""Monopoles had been predicted theoretically, but this is the first time we've actually seen a two-dimensional monopole in a naturally occurring magnet,"" said co-author Professor Paolo Radaelli, from the University of Oxford.
""These monopoles are a collective state of many spins that twirl around a singularity rather than a single fixed particle, so they emerge through many-body interactions. The result is a tiny, localised stable particle with diverging magnetic field coming out of it,"" said co-first author Dr Hariom Jani, from the University of Oxford.
""We've shown how diamond quantum magnetometry could be used to unravel the mysterious behaviour of magnetism in two-dimensional quantum materials, which could open up new fields of study in this area,"" said co-first author Dr Anthony Tan, from the Cavendish Laboratory. ""The challenge has always been direct imaging of these textures in antiferromagnets due to their weaker magnetic pull, but now we're able to do so, with a nice combination of diamonds and rust.""
The study not only highlights the potential of diamond quantum magnetometry but also underscores its capacity to uncover and investigate hidden magnetic phenomena in quantum materials. If controlled, these swirling textures dressed in magnetic charges could power super-fast and energy-efficient computer memory logic.
The research was supported in part by the Royal Society, the Sir Henry Royce Institute, the European Union, and the Engineering and Physical Sciences Research Council (EPSRC), part of UK Research and Innovation (UKRI).

","score: 15.567525252525254, grade_level: '16'","score: 15.880643939393941, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41563-023-01737-4,"Whirling topological textures play a key role in exotic phases of magnetic materials and are promising for logic and memory applications. In antiferromagnets, these textures exhibit enhanced stability and faster dynamics with respect to their ferromagnetic counterparts, but they are also difficult to study due to their vanishing net magnetic moment. One technique that meets the demand of highly sensitive vectorial magnetic field sensing with negligible backaction is diamond quantum magnetometry. Here we show that an archetypal antiferromagnet—haematite—hosts a rich tapestry of monopolar, dipolar and quadrupolar emergent magnetic charge distributions. The direct read-out of the previously inaccessible vorticity of an antiferromagnetic spin texture provides the crucial connection to its magnetic charge through a duality relation. Our work defines a paradigmatic class of magnetic systems to explore two-dimensional monopolar physics, and highlights the transformative role that diamond quantum magnetometry could play in exploring emergent phenomena in quantum materials."
"
Researchers from EPFL have resolved a long-standing debate surrounding laser additive manufacturing processes with a pioneering approach to defect detection.

The progression of laser additive manufacturing -- which involves 3D printing of metallic objects using powders and lasers -- has often been hindered by unexpected defects. Traditional monitoring methods, such as thermal imaging and machine learning algorithms, have shown significant limitations. They often either overlook defects or misinterpret them, making precision manufacturing elusive and barring the technique from essential industries like aeronautics and automotive manufacturing. But what if it were possible to detect defects in real time based on the differences in the sound the printer makes during a flawless print and one with irregularities? Up until now, the prospect of detecting these defects this way was deemed unreliable. However, researchers at the Laboratory of Thermomechanical Metallurgy (LMTM) at EPFL's School of Engineering have successfully challenged this assumption.
Professor Roland Logé, the head of the laboratory, stated, ""There's been an ongoing debate regarding the viability and effectiveness of acoustic monitoring for laser-based additive manufacturing. Our research not only confirms its relevance but also underscores its advantage over traditional methods.""
This research is of paramount importance to the industrial sector as it introduces a groundbreaking, yet cost-effective solution to monitor and improve the quality of products made through Laser Powder Bed Fusion (LPBF). Lead researcher, Dr. Milad Hamidi Nasab, remarked, ""The synergy of synchrotron X-ray imaging with acoustic recording provides real-time insight into the LPBF process, facilitating the detection of defects that could jeopardize product integrity."" In an era where industries continuously strive for efficiency, precision, and waste reduction, these innovations not only result in significant cost savings but also boost the dependability and security of manufactured products.
How Does LPBF Manufacturing Work?
LPBF is a cutting-edge method that's reshaping metal manufacturing. Essentially, it uses a high-intensity laser to meticulously melt minuscule metal powders, creating layer upon layer to produce detailed 3D metallic constructs. Think of LPBF as the metallic version of a conventional 3D printer, but with an added degree of sophistication. Rather than melted plastic, it employs a fine layer of microscopic metal powder, which can vary in size from the thickness of a human hair to a fine grain of salt (15-100 μm). The laser moves across this layer, melting specific patterns based on a digital blueprint. This technique enables the crafting of bespoke, complex parts like lattice structures or distinct geometries, with minimal excess. Nevertheless, this promising method isn't devoid of challenges.
When the laser interacts with the metal powder, creating what is known as a melt pool, it fluctuates between liquid, vapor, and solid phases. Occasionally, due to variables such as the laser's angle or the presence of specific geometrical attributes of the powder or of the part, the process might falter. These instances, termed ""inter-regime instabilities,"" can sometimes prompt shifts between two melting methods, known as ""conduction"" and ""keyhole"" regimes. During unstable keyhole regimes, when the molten powder pool delves deeper than intended, it can create pockets of porosity, culminating in structural flaws in the end product. To facilitate the measurement of the width and depth of the melt pool in X-ray images, the Image Analysis Hub of the EPFL Center for Imaging developed an approach that makes it easier to visualize small changes associated with the liquid metal and a tool for annotating the melt pool geometry.

Detecting These Defects Using Sound
In a joint venture with the Paul Scherrer Institute (PSI) and the Swiss Federal Laboratories for Materials Science and Technology (Empa), the EPFL team formulated an experimental design that melded operando X-ray imaging experiments with acoustic emission measurements. The experiments were conducted at the TOMCAT beamline of the Swiss Light Source at PSI, with the miniaturized LPBF printer developed in the group of Dr. Steven Van Petegem. The amalgamation with an ultra-sensitive microphone, positioned inside the printing chamber, pinpointed distinct shifts in the acoustic signal during regime transitions, thereby directly identifying defects during manufacturing.
A pivotal moment in the research was the introduction of an adaptive filtering technique by signal processing expert Giulio Masinelli from Empa. ""This filtering approach,"" Masinelli emphasized, "" allows us to discern, with unparalleled clarity, the relationship between defects and the accompanying acoustic signature."" Unlike typical machine learning algorithms, which excel at extracting patterns from statistical data, but are often tailored to specific scenarios, this approach provides broader insights on the physics of melting regimes, while offering superior temporal and spatial precision.
With this research, EPFL contributes valuable insights to the field of laser additive manufacturing. The findings have significant implications for potential industrial applications, particularly in sectors like aerospace and precision engineering. Reinforcing Switzerland's reputation for meticulous craftsmanship and manufacturing accuracy, the study underscores the need for consistent manufacturing techniques. Furthermore, it suggests the potential for early detection and correction of defects, enhancing product quality. Professor Logé concludes, ""This research paves the way for a better understanding and refinement of the manufacturing process, and will ultimately lead to higher product reliability in the long term.""

","score: 16.19771069428162, grade_level: '16'","score: 17.58392796665364, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43371-3,"Laser powder bed fusion (LPBF) is a metal additive manufacturing technique involving complex interplays between vapor, liquid, and solid phases. Despite LPBF’s advantageous capabilities compared to conventional manufacturing methods, the underlying physical phenomena can result in inter-regime instabilities followed by transitions between conduction and keyhole melting regimes — leading to defects. We investigate these issues through operando synchrotron X-ray imaging synchronized with acoustic emission recording, during the remelting processes of LPBF-produced thin walls, monitoring regime changes occurring under constant laser processing parameters. The collected data show an increment in acoustic signal amplitude when switching from conduction to keyhole regime, which we correlate to changes in laser absorptivity. Moreover, a full correlation between X-ray imaging and the acoustic signals permits the design of a simple filtering algorithm to predict the melting regimes. As a result, conduction, stable keyhole, and unstable keyhole regimes are identified with a time resolution of 100 µs, even under rapid transitions, providing a straightforward method to accurately detect undesired processing regimes without the use of artificial intelligence."
