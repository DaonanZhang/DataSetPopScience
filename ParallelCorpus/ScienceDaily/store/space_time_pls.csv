pls,fk_score,ari_score,reference,abstract
"
A pancake stack of radioactivity-sensitive films carried through the sky by a balloon was able to take the world's most accurate picture of a neutron star's gamma ray beam. To achieve this, Kobe University researchers combined the oldest method of capturing radioactive radiation with the newest data capturing techniques and a clever time-recording device.

The stars shine their light on us in the full range of the spectrum of light, from infra-red to gamma rays. For each of these bands, different sensing equipment is needed. The most challenging one is gamma rays, famous for being a high-energy product of nuclear fission, because their very short wavelength means that they don't interact with matter in the same way as other forms of light and thus can't be deflected with lenses or detected by standard sensors. Thus, there is a gap in our ability to detect the light coming from fascinating stellar objects such as supernovae and their remnants.
To resolve this issue, Kobe University astrophysicist AOKI Shigeki and his team turned to the very first material that was used to detect radioactivity, photographic films. ""Our group has been focusing on the excellent capability of emulsion film to trace gamma rays with high precision and proposed that it could become an excellent gamma-ray telescope by introducing several modern data capture and analysis features,"" explains Aoki. Based on the high sensitivity of these films and a novel, automated, high-speed process of extracting data from them, the physicists' idea was to stack up a few of them to accurately capture the trajectory of the particles that the gamma ray produces on impact, just like a single pancake may capture where you poke a straw into it, but it takes a whole stack to record the straw's direction.
To reduce atmospheric interference, they then mounted the stack of films onto a scientific observation balloon to lift it to a height between 35 and 40 kilometers. However, since a balloon is swaying and twisting in the wind, the direction of the ""telescope"" is not stable, so they added a set of cameras to record the gondola's orientation relative to the stars at any time. But this created another issue, because as anybody who has ever taken a photograph with long exposure knows, photographic film does not record the passage of time and so it is not directly possible to know at what time any given gamma ray impact occurred. To overcome this problem, they made the bottom three layers of film move back and forth at regular but different speeds, just like the hands of a clock. From the relative dislocation of the traces in those lower plates they could then calculate the precise time of the impact and thus correlate it with the cameras' footage.
They have now published the first image resulting from this setup in the journal The Astrophysical Journal. It is the most accurate image ever produced of the Vela pulsar, a fast-spinning neutron star that projects a beam of gamma rays into the sky like a lighthouse at night. ""We captured a total of several trillion tracks with an accuracy of 1/10,000 millimeters. By adding time information and combining it with attitude monitoring information, we were able to determine 'when' and 'where' the events originated with such precision that the resulting resolution was more than 40 times higher than that of conventional gamma-ray telescopes,"" Aoki summarizes his group's achievements.
While these results are impressive already, the new technique opens the possibility of capturing more details in this frequency band of light than ever before. The Kobe University researcher explains, ""By means of scientific balloon-borne experiments, we can attempt to contribute to many areas of astrophysics, and in particular to open up gamma-ray telescopy to 'multi-messenger astronomy' where simultaneous measurements of the same event captured through different techniques are required. Based on the success of the 2018 balloon experiment these data were generated with, we will expand the observation area and time in upcoming balloon flights and are looking forward to scientific breakthroughs in the field of gamma-ray astronomy.""
This work was supported by JSPS KAKENHI grants 17H06132, 18H01228 and 18K13562. It was conducted in collaboration with researchers from Okayama University of Science, Aichi University of Education, Nagoya University and Gifu University.

","score: 16.360618612807645, grade_level: '16'","score: 17.992813085807583, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/ad0973,"We are developing the Gamma-Ray Astro-Imager with Nuclear Emulsion project, designed for 10 MeV–100 GeV cosmic γ-ray observations with a high angular resolution (5′/0.°08 at 1–2 GeV) and a polarization-sensitive large-aperture (∼10 m2) emulsion telescope for repeated long-duration balloon flights. In 2018, a balloon-borne experiment was carried out in Australia with a 0.38 m2 sensitive area and a flight duration of 17.4 hr, including 6.7 hr of Vela observations. Significant improvements compared with the 2015 balloon-borne experiment were achieved by a factor of 5, including both an increase in effective area × time and a reduction in the background contribution. We aimed to demonstrate the telescope’s overall performance based on detection and imaging of a known γ-ray source, the Vela pulsar. A robust detection of the Vela pulsar was achieved with a 68% containment radius of 0.°42, at a significance of 6σ, at energies above 80 MeV. The resulting angular profile is consistent with that of a pointlike source. We achieved the current best imaging performance of the Vela pulsar using an emulsion γ-ray telescope with the highest angular resolution of any γ-ray telescope to date."
"
Researchers at the University of Sussex have discovered the transformative potential of Martian nanomaterials, potentially opening the door to sustainable habitation on the red planet.

Using resources and techniques currently applied on the International Space Station and by NASA, Dr Conor Boland, a Lecturer in Materials Physics at the University of Sussex, led a research group that investigated the potential of nanomaterials -- incredibly tiny components thousands of times smaller than a human hair -- for clean energy production and building materials on Mars.
Taking what was considered a waste product by NASA and applying only sustainable production methods, including water-based chemistry and low-energy processes, the researchers have successfully identified electrical properties within gypsum nanomaterials -- opening the door to potential clean energy and sustainable technology production on Mars.
Dr Conor Boland, said:
""This study shows that the potential is quite literally out of this world for nanomaterials. Our study builds off recent research performed by NASA and takes what was considered waste, essentially lumps of rock, and turns it into transformative nanomaterials for a range of applications from creating clean hydrogen fuel to developing an electronic device similar to a transistor, to creating an additive to textiles to increase their robustness.
""This opens avenues for sustainable technology -- and building -- on Mars but also highlights the broader potential for eco-friendly breakthroughs here on Earth.""
To make the breakthrough the researchers used NASA's innovative method for extracting water from Martian gypsum, which is dehydrated by the agency to get water for human consumption. This produces a byproduct called anhydrite -- considered waste material by NASA, but now shown to be hugely valuable.

The Sussex researchers processed anhydrite into nanobelts -- essentially tagliatelle-shaped materials -- demonstrating their potential to provide clean energy and sustainable electronics. Furthermore, at every step of their process, water could be continuously collected and recycled.
Dr Boland added:
""We are optimistic of the feasibility of this process on Mars, as it requires only naturally occurring materials -- everything we used could, in theory, be replicated on the red planet. Arguably this is the most important goal in making the Martian colony sustainable from the outset.""
While full-scale electronics production may be impractical on Mars due to the lack of clean rooms and sterile conditions, the anhydrite nanobelts hold promise for clean energy production on Earth, and could, later down the line, still have a profound effect on sustainable energy production on Mars.

","score: 19.08564485265978, grade_level: '19'","score: 20.709822043628016, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adfm.202310600,"The sky is the limit with regards to the societal impact nanomaterials can have on the lives. However, in this study, it is shown that their potential is out of this world. The planet Mars has an abundant source of calcium sulfate minerals and in this work, it is shown that these deposits can be the basis of transformative nanomaterials to potentially support future space endeavors. Vitally, the methods applied are low cost and require no specialized instruments of great expertise, strengthening the potential involvement of nanotechnology in sustaining Martian inhabitation. Through a scalable eco‐friendly liquid processing technique performed on two common terrestrial gypsum, this simple method presented a cost‐efficient procedure to yield suspensions of large aspect ratio anhydrite nanobelts with long‐term stability that are characterized through scanning electron microscopy and Raman spectroscopy. Transmission electron microscopy shows nanobelts to have a mesocrystal structure, with distinct nanoparticle constituents making up the lattice. Unexpectedly, anhydrite nanobelts have remarkable electronic properties, namely a bandgap that is easily tuned between semiconducting (≈2.2 eV) and insulating (≈4 eV) behaviors through dimensional control measured via atomic force microscopy. To demonstrate the application potential of the nanobelts; optoelectronic, electrochemical, and nanocomposite measurements are made."
"
The North Sea seafloor is dotted with thousands of crater-like depressions in the sediment known as pockmarks. There are probably millions of them around the world ocean. They are formed by fluid discharge such as the greenhouse gas methane or groundwater, according to common scientific understanding. The majority of these pockmarks still puzzle researchers today, as many cannot be explained by fluid seepage. ""Our results show for the first time that these depressions occur in direct connection with the habitat and behavior of porpoises and sand eels and are not formed by rising fluids,"" says Dr Jens Schneider von Deimling, lead author of the current study and geoscientist at Kiel University.

""Our high-resolution data provide a new interpretation for the formation of tens of thousands of pits on the North Sea seafloor, and we predict that the underlying mechanisms occur globally, but have been overseen until now,"" Schneider von Deimling adds. For the study, Schneider von Deimling and researchers from the Alfred Wegener Institute, the Helmholtz Centre for Polar and Marine Research (AWI), the University of Veterinary Medicine Hannover, Foundation (TiHo) as well as the Leibniz Institute for Baltic Sea Research Warnemünde (IOW) examined the seafloor in the North Sea off Heligoland down to centimeters. They also included the behavior of vertebrates such as porpoises in their analyses.
Vertebrates leave pits in the seabed of the North Sea
Most of the depressions in the seafloor in the German Bight, the team suspects, are created by porpoises and other animals in search of food, and then scoured out by bottom currents. The sand eel, a small eel-like fish that spends most of the year buried in shallow sediments, plays a key role in this process. Sand eels are not only popular with the fishing industry, but are also consumed in large quantities by porpoises. ""From analyses of the stomach contents of stranded porpoises, we know that sand eels are an important food source for the North Sea population,"" says Dr Anita Gilles of the TiHo-Institute for Terrestrial and Aquatic Wildlife Research (ITAW), who has long studied the biology of marine mammals. In their study, the researchers showed that the marine mammals leave pits in the seafloor when they hunt for buried sand eels. Although these pits resemble the familiar pockmarks, they are much shallower.
Advanced multibeam echosounder technology provides information on pit condition
The detection of the pits has only become possible in recent years with the help of modern multibeam echosounder technology, which is taught and practiced intensively at Kiel University. ""The formation mechanism of these pits, as we call them, probably also explains the existence of numerous crater-like depressions on the seafloor worldwide, which have been misinterpreted as the result of methane gas leaks,"" says geoscientist Schneider von Deimling. In the North Sea, the researchers identified 42458 of these enigmatically shaped, shallow pits with an average depth of just eleven centimeters, which differ in their morphology from the more conical craters of the pockmarks.
Schneider von Deimling works in the Kiel Marine Geophysics and Hydroacoustics working group at the Institute of Geosciences and the Kiel Marine Science (KMS) priority research area at Kiel University, and is vice chairman of the German Hydrographic Society (DHyG). As an expert in seafloor mapping, methane gas seepage and seafloor pockmarks, he never believed that the depressions in the German Bight were caused by rising fluids. ""We had to come up with an alternative hypothesis for the formation. This allowed us to predict where potential porpoise feeding sites are, and that is exactly where we found the pits -- always close to sandeel habitats. Our extensive and multidisciplinary data analysis now provides a conclusive explanation for our harbor porpoise pits hypothesis.""
An interdisciplinary approach leads to the harbor porpoise pits hypothesis

The key to the new findings was an interdisciplinary approach that brought together geological studies, geophysical sonar measurements, vertebrate behavior and feeding biology, satellite evaluation, and oceanographic analysis. By precisely analyzing millions of echosoundings collected by German research vessels, the researchers were able to locate the unusual pits. ""Using special echosounding methods, we can now measure the seafloor with centimeter precision and thus find the shallow pits. We can also look into the seafloor and see, for example, whether there is free methane gas,"" explains AWI researcher Dr Jasper Hoffmann.
Analyzing the data, collected by research vessels over thousands of nautical miles, was a mammoth task. ""With modern methods, such structures can be automatically detected and characterized in acoustic data sets and automatically analyzed in large data sets,"" says Dr. Jacob Geersen, co-author of the study.
From the North Sea into the world: results with far-reaching effects
The research team currently believes that the initial feeding pits serve as a nucleus for scouring and eventually develop into larger pits. This finding also has global implications. The scouring of sediments by vertebrates in the ocean could modulate the seafloor on a global scale and influence benthic ecosystems. In the study area alone, pits cover nine percent of the seafloor. Initial volume estimates indicate that 773369 tons of sediment have been deposited over an area of 1581 km². This is roughly equivalent to the weight of half a million cars. ""Our results have far-reaching implications from a geological and biological perspective. They can help to assess the ecological risks associated with the expansion of renewable energies in the offshore sector and thus improve marine environmental protection,"" concludes Schneider von Deimling.

","score: 14.451753528773072, grade_level: '14'","score: 16.179940282301843, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s43247-023-01102-y,"Seabed pockmarks are among the most prominent morphologic structures in the oceans. They are usually interpreted as surface manifestation of hydrocarbon fluids venting from sediments. Here we suggest an alternative hypothesis of pockmark formation based on latest multibeam echosounder data with a centimeter resolution. In the North Sea, >40,000 enigmatically shaped shallow depressions or ‘pits’ with a mean depth of 0.11 m were documented, that do not resemble known pockmark morphologies. Combining the new echosounder data with information from behavioral biology, physical oceanography, satellite remote sensing and habitat mapping, we conclude that harbor porpoises excavate sediments during benthic foraging. By grubbing the seabed, they cause sandeels to escape from the sediment and initiate the formation of seafloor pits. Time-lapse data reveals that the initially feeding pits serve as nuclei for scouring and eventually merge into larger scour-pits. With the immense number of vertebrates in the ocean, such megafauna-driven macro-bioturbation reshapes the seafloor, modulates sediment transport, and ultimately impacts associated ecosystems on a global scale."
"
Like a celestial beacon, distant quasars make the brightest light in the universe. They emit more light than our entire Milky Way galaxy. The light comes from matter ripped apart as it is swallowed by a supermassive black hole. Cosmological parameters are important numerical constraints astronomers use to trace the evolution of the entire universe billions of years after the Big Bang.

Quasar light reveals clues about the large-scale structure of the universe as it shines through enormous clouds of neutral hydrogen gas formed shortly after the Big Bang on the scale of 20 million light years across or more.
Using quasar light data, the National Science Foundation (NSF)-funded Frontera supercomputer at the Texas Advanced Computing Center (TACC) helped astronomers develop PRIYA, the largest suite of hydrodynamic simulations yet made for simulating large-scale structure in the universe.
""We've created a new simulation model to compare data that exists at the real universe,"" said Simeon Bird, an assistant professor in astronomy at the University of California, Riverside.
Bird and colleagues developed PRIYA, which takes optical light data from the Extended Baryon Oscillation Spectroscopic Survey (eBOSS) of the Sloan Digital Sky Survey (SDSS). He and colleagues published their work announcing PRIYA October 2023 in the Journal of Cosmology and Astroparticle Physics (JCAP).
""We compare eBOSS data to a variety of simulation models with different cosmological parameters and different initial conditions to the universe, such as different matter densities,"" Bird explained. ""You find the one that works best and how far away from that one you can go without breaking the reasonable agreement between the data and simulations. This knowledge tells us how much matter there is in the universe, or how much structure there is in the universe.""
The PRIYA simulation suite is connected to large-scale cosmological simulations also co-developed by Bird, called ASTRID, which is used to study galaxy formation, the coalescence of supermassive black holes, and the re-ionization period early in the history of the universe. PRIYA goes a step further. It takes the galaxy information and the black hole formation rules found in ASTRID and changes the initial conditions.

""With these rules, we can we take the model that we developed that matches galaxies and black holes, and then we change the initial conditions and compare it to the Lyman-&#120572; forest data from eBOSS of the neutral hydrogen gas,"" Bird said.
The 'Lyman-&#120572; forest' gets its name from the 'forest' of closely packed absorption lines on a graph of the quasar spectrum resulting from electron transitions between energy levels in atoms of neutral hydrogen. The 'forest' indicates the distribution, density, and temperature of enormous intergalactic neutral hydrogen clouds. What's more, the lumpiness of the gas indicates the presence of dark matter, a hypothetical substance that cannot be seen yet is evident by its observed tug on galaxies.
PRIYA simulations have been used to refine cosmological parameters in work submitted to JCAP September 2023 and authored by Simeon Bird and his UC Riverside colleagues, M.A. Fernandez and Ming-Feng Ho.
Previous analysis of the neutrino mass parameters did not agree with data from the Cosmic Microwave Background radiation (CMB), described as the afterglow of the Big Bang. Astronomers use CMB data from the Plank space observatory to place tight constraints on the mass of neutrinos. Neutrinos are the most abundant particle in the universe, so pinpointing their mass value is important for cosmological models of large-scale structure in the universe.
""We made a new analysis with simulations that were a lot larger and better designed than anything before. The earlier discrepancies with the Planck CMB data disappeared, and were replaced with another tension, similar to what is seen in other low redshift large-scale structure measurements,"" Bird said. ""The main result of the study is to confirm the σ8 tension between CMB measurements and weak lensing exists out to redshift 2, ten billion years ago.""
One well-constrained parameter from the PRIYA study is on σ8, which is the amount of neutral hydrogen gas structures on a scale of 8 megaparsecs, or 2.6 million light years. This indicates the number of clumps of dark matter that are floating around there,"" Bird said.

Another parameter constrained was ns, the scalar spectral index. It is connected to how the clumsiness of dark matter varies with the size of the region analyzed. It indicates how fast the universe was expanding just moments after the Big Bang.
""The scalar spectral index sets up how the universe behaves right at the beginning. The whole idea of PRIYA is to work out the initial conditions of the universe, and how the high energy physics of the universe behaves,"" Bird said.
Supercomputers were needed for the PRIYA simulations, Bird explained, simply because they were so big.
""The memory requirements for PRIYA simulations are so big you cannot put them on anything other than a supercomputer,"" Bird said.
TACC awarded Bird a Leadership Resource Allocation on the Frontera supercomputer. Additionally, analysis computations were performed using the resources of the UC Riverside High Performance Computer Cluster.
The PRIYA simulations on Frontera are some of the largest cosmological simulations yet made, needing over 100,000 core-hours to simulate a system of 3072^3 (about 29 billion) particles in a 'box' 120 megaparsecs on edge, or about 3.91 million light years across. PRIYA simulations consumed over 600,000 node hours on Frontera.
""Frontera was very important to the research because the supercomputer needed to be big enough that we could run one of these simulations fairly easily, and we needed to run a lot of them. Without something like Frontera, we wouldn't be able to solve them. It's not that it would take a long time -- they just they wouldn't be able to run at all,"" Bird said.
In addition, TACC's Ranch system provided long-term storage for PRIYA simulation data.
""Ranch is important, because now we can reuse PRIYA for other projects. This could double or triple our science impact,"" Bird said. ""
""Our appetite for more compute power is insatiable,"" Bird concluded. ""It's crazy that we're sitting here on this little planet observing most of the universe.""

","score: 12.896436878408725, grade_level: '13'","score: 13.133311276868781, grade_levels: ['college_graduate'], ages: [24, 100]",10.1088/1475-7516/2023/10/037,"We present the PRIYA suite of cosmological simulations, based on the code and hydrodynamic model of the ASTRID simulation, and designed for cosmological analyses of the Lyman-αforest. Our simulation suite spans a 9-dimensional parameter space, including 4 cosmological parameters and 5 astrophysical/thermal parameters. We have run 48 low fidelity simulations with 15363particles in a 120 Mpc/h box and 3 high fidelity simulations with 30723particles in a 120 Mpc/h box. All our simulations include a full physics model for galaxy formation, including supernova and AGN feedback, and thus also contain a realistic population of DLAs. We advance on earlier simulations suites by larger particle loads, by incorporating new physical models for patchy hydrogen and helium reionization, and by self-consistently incorporating a model for AGN feedback. We show that patchy helium reionization imprints an excess in the 1D flux power spectrum on large scales, which may allow future measurements of helium reionization bubble sizes. Simulation parameters are chosen based on a Latin hypercube design and a Gaussian process is used to interpolate to arbitrary parameter combinations. We build a multi-fidelity emulator for the 1D flux power spectrum and the mean IGM temperature. We show that our final interpolation error is < 1% and that our simulations produce a flux power spectrum converged at the percent level forz= 5.4–2.2. Our simulation suite will be used to interpret Lyman-αforest 1D flux power spectra from SDSS and future DESI data releases."
"
The Earth is a wonderful blue and green dot covered with oceans and life, while Venus is a yellowish sterile sphere that is not only inhospitable but also sterile. However, the difference between the two bears to only a few degrees in temperature. A team of astronomers from the University of Geneva (UNIGE), with the support of the CNRS laboratories of Paris and Bordeaux, has achieved a world's first by managing to simulate the entirety of the runaway greenhouse process which can transform the climate of a planet from idyllic and perfect for life, to a place more than harsh and hostile. The scientists have also demonstrated that from initial stages of the process, the atmospheric structure and cloud coverage undergo significant changes, leading to an almost-unstoppable and very complicated to reverse runaway greenhouse effect. On Earth, a global average temperature rise of just a few tens of degrees, subsequent to a slight rise of the Sun's luminosity, would be sufficient to initiate this phenomenon and to make our planet inhabitable. These results are published in Astronomy & Astrophysics.

The idea of a runaway of the greenhouse effect is not new. In this scenario, a planet can evolve from a temperate state like on Earth to a true hell, with surface temperatures above 1000°C. The cause? Water vapor, a natural greenhouse gas. Water vapor prevents the solar irradiation absorbed by Earth to be reemitted towards the void of space, as thermal radiation. It traps heat a bit like a rescue blanket. A dash of greenhouse effect is useful -- without it, Earth would have an average temperature below the freezing point of water, looking like a ball covered with ice and hostile to life.
On the opposite, too much greenhouse effect increases the evaporation of oceans, and thus the amount of water vapor in the atmosphere. ""There is a critical threshold for this amount of water vapor, beyond which the planet cannot cool down anymore. From there, everything gets carried away until the oceans end up getting fully evaporated and the temperature reaches several hundred degrees,"" explains Guillaume Chaverot, former postdoctoral scholar in the Department of Astronomy at the UNIGE Faculty of Science and main author of the study.
World premiere
""Until now, other key studies in climatology have focused solely on either the temperate state before the runaway, or either the inhabitable state post-runaway,"" reveals Martin Turbet, researcher at CNRS laboratories of Paris and Bordeaux, and co-author of the study. ""It is the first time a team has studied the transition itself with a 3D global climate model, and has checked how the climate and the atmosphere evolve during that process.""
One of the key points of the study describes the appearance of a very peculiar cloud pattern, increasing the runaway effect, and making the process irreversible. ""From the start of the transition, we can observe some very dense clouds developing in the high atmosphere. Actually, the latter does not display anymore the temperature inversion characteristic of the Earth atmosphere and separating its two main layers: the troposphere and the stratosphere. The structure of the atmosphere is deeply altered,"" points out Guillaume Chaverot.
Serious consequences for the search of life elsewhere
This discovery is a key feature for the study of climate on other planets, and in particular on exoplanets -- planets orbiting other stars than the Sun. ""By studying the climate on other planets, one of our strongest motivations is to determine their potential to host life,"" indicates Émeline Bolmont, assistant professor and director of the UNIGE Life in the Universe Center (LUC), and co-author of the study.

The LUC leads state-of-the-art interdisciplinary research projects regarding the origins of life on Earth, and the quest for life elsewhere in our solar system and beyond, in exoplanetary systems. ""After the previous studies, we suspected already the existence of a water vapor threshold, but the appearance of this cloud pattern is a real surprise!"" discloses Émeline Bolmont. ""We have also studied in parallel how this cloud pattern could create a specific signature, or ''fingerprint'', detectable when observing exoplanet atmospheres. The upcoming generation of instruments should be able to detect it,"" unveils Martin Turbet. The team is also not aiming to stop there, Guillaume Chaverot having received a research grant to continue this study at the ""Institut de Planétologie et d'Astrophysique de Grenoble"" (IPAG). This new step of the research project will focus on the specific case of the Earth.
A planet Earth in a fragile equilibrium
With their new climate models, the scientists have calculated that a very small increase of the solar irradiation -- leading to an increase of the global Earth temperature, of only a few tens of degrees -- would be enough to trigger this irreversible runaway process on Earth and make our planet as inhospitable as Venus. One of the current climate goals is to limit global warming on Earth, induced by greenhouse gases, to only 1.5 degrees by 2050. One of the questions of Guillaume Chaverot's research grant is to determine if greenhouse gases can trigger the runaway process as a slight increase of the Sun luminosity might do. If so, the next question will be to determine if the treshold temperatures are the same for both processes.
The Earth is thus not so far from this apocalyptical scenario. ""Assuming this runaway process would be started on Earth, an evaporation of only 10 meters of the oceans' surface would lead to a 1 bar increase of the atmospheric pressure at ground level. In just a few hundred years, we would reach a ground temperature of over 500°C. Later, we would even reach 273 bars of surface pressure and over 1 500°C, when all of the oceans would end up totally evaporated,"" concludes Guillaume Chaverot.

","score: 13.655818077054032, grade_level: '14'","score: 14.267155391425057, grade_levels: ['college_graduate'], ages: [24, 100]",10.1051/0004-6361/202346936,"While their detections remain challenging at present, observations of small terrestrial planets will become easier in a near future thanks to continuous improvements of detection and characterisation instruments. In this quest, climate modeling is a key step to understanding their characteristics, atmospheric composition, and possible histories. If a surface water reservoir is present on such a terrestrial planet, an increase in insolation may lead to a dramatic positive feedback induced by water evaporation: the runaway greenhouse. The resulting rise in the global surface temperature leads to the evaporation of the entire water reservoir, separating two very different population of planets: 1) temperate planets with a surface water ocean and 2) hot planets with a puffed atmosphere dominated by water vapor. Therefore, the understanding of the runaway greenhouse is pivotal to assess the different evolution of Venus and the Earth, as well as every similar terrestrial exoplanet. In this work, we use a 3D General Circulation Model (GCM), the Generic-PCM, to study the runaway greenhouse transition, linking temperate and post-runaway states. Our simulations were comprised of two phases. First, assuming initially a liquid surface ocean, there is an evaporation phase, which enriches the atmosphere with water vapor. Second, when the ocean is considered to be entirely evaporated, there is a dry transition phase for which the surface temperature increases dramatically. Finally, the evolution ends with a hot and stable post-runaway state. By describing in detail the evolution of the climate over these two steps, we show a rapid transition of the cloud coverage and of the wind circulation from the troposphere to the stratosphere. By comparing our result to previous studies using 1D models, we discuss the effect of intrinsically 3D processes such as the global dynamics and the clouds, which are key to understanding the runaway greenhouse. We also explore the potential reversibility of the runaway greenhouse that is limited by its radiative unbalance."
"
For most of us, the countless bright spots in the nighttime sky all seem to be stars. But in fact, some of those spots are actually planets, or distant suns, or even entire galaxies located billions of light years away. Just what you're looking at depends on how far it is from Earth. That's why measuring the exact distance to celestial objects is such an important goal for astronomers -- and one of the biggest challenges they're currently tackling.

It was with this in mind that the European Space Agency (ESA) launched the Gaia mission ten years ago. Data collected by the Gaia satellite are opening up a window into the near Universe, providing astronomic measurements -- such as position, distance from the Earth and movement -- on nearly two billion stars.
At EPFL, the Standard Candles and Distances research group headed by Prof. Richard Anderson is aiming to measure the current expansion of the Universe and sees Gaia as a valuable tool. ""Gaia increased by a factor of 10,000 the number of stars whose parallaxes are measured thanks to a massive gain in accuracy over its predecessor, the ESA Hipparcos mission,"" he says. Today, scientists use parallaxes to calculate the distance to stars. This method involves measuring parallax angles, with the help of the satellite, through a form of triangulation between Gaia's location in space, the Sun and the star in question. The farther away a star, the more difficult the measurement because parallax gets smaller the larger the distance.
Despite the resounding success of Gaia, the measurement of parallax is complex, and there remain small systematic effects that must be checked and corrected in order for Gaia parallaxes to reach their full potential. This is what scientists from EPFL and the University of Bologna, in Italy, have been working on, through calculations performed on over 12,000 oscillating red giant stars* -- the biggest sample size and most accurate measurements to date.
""We measured the Gaia biases by comparing the parallaxes reported by the satellite with parallaxes of the same stars that we determined using asteroseismology,"" says Saniya Khan, a scientist in Anderson's research group and the lead author of a study published today in Astronomy & Astrophysics.
Stellar earthquakes 
In the same way that geologists study the Earth's structure using earthquakes, astronomers use asteroseismology, and specifically stars' vibrations and oscillations, to glean information about their physical properties. Stellar oscillations are measured as tiny variations in light intensity and translated into sound waves, giving rise to a frequency spectrum of these oscillations.

""The frequency spectrum lets us determine how far away a star is, enabling us to obtain asteroseismic parallaxes,"" says Khan. ""In our study, we listened to the 'music' of a vast number of stars -- some of them 15,000 light-years away!""
To turn sounds into distance measurements, the research team started with a simple fact. The speed with which sound waves propagate across space depends on the temperature and density of the star's interior. ""By analyzing the frequency spectrum of stellar oscillations, we can estimate the size of a star, much like you can identify the size of a musical instrument by the kind of sound it makes -- think of the difference in pitch between a violon and a cello,"" says Andrea Miglio, a full professor at the University of Bologna's Department of Physics and Astronomy and the study's third author.
Sophisticated analyses
Having thus calculated a star's size, the astronomers then determined its luminosity and compared this figure to the luminosity perceived here on Earth. They coupled this information with temperature and chemical-composition readings obtained from spectroscopy and ran these data through sophisticated analyses to calculate the distance to the star. Finally, the astronomers compared the parallaxes obtained in this process with those reported by Gaia in order to check the accuracy of the satellite's measurements.
""Asteroseismology is the only way we can check Gaia's parallax accuracy across the full sky -- that is, for both low- and high-intensity stars,"" says Anderson. And the future of this field is bright, as Khan outlines:
""Upcoming space missions like TESS and PLATO intended to detect and survey exoplanets will employ asteroseismology and deliver the required datasets across increasingly large regions of the sky. Methods similar to ours will therefore play a crucial role in improving Gaia's parallax measurements, which will help us pinpoint our place in the Universe and benefit a plethora of subfields of astronomy and astrophysics.""

","score: 15.142878179384208, grade_level: '15'","score: 16.564939759036143, grade_levels: ['college_graduate'], ages: [24, 100]",10.1051/0004-6361/202347919,"We analyse Gaia EDR3 parallax systematics as a function of magnitude and sky location using a recently published catalogue of 12 500 asteroseismic red-giant star distances. We selected ∼3500 red clump (RC) stars of similar chemical composition as the optimal subsample for this purpose because (1) their similar luminosity allows for straightforward interpretation of trends with apparent magnitude; (2) RC stars are the most distant stars in our sample at a given apparent magnitude, so uncertainties related to asteroseismic radii and distances are the smallest; (3) and they provide the largest sample of intrinsically similar stars. We performed a detailed assessment of systematic uncertainties relevant for parallax offset estimation based on the asteroseismic distances. Specifically, we investigated (1) the impact of measuring the basic asteroseismic quantities νmax and ⟨Δν⟩ using different pipelines, (2) uncertainties related to extinction, (3) the impact of adopting spectroscopic information from different surveys, and (4) blending issues related to photometry. Following this assessment, we adopted for our baseline analysis the asteroseismic parameters measured in Elsworth et al. (2020, Res. Notes Am. Astron. Soc., 4, 177) and spectroscopy from the Apache Point Observatory Galactic Evolution Experiment (DR17), and we further restricted the sample to low-extinction (AV ≤ 0.5 mag) RC stars with quality astrometric solutions from Gaia EDR3, as indicated by RUWE < 1.4. We then investigated both the parallax offset relative to the published Gaia EDR3 parallaxes and the residual parallax offset after correcting Gaia EDR3 parallaxes following Lindegren et al. (2021, A&A, 649, A4). We found residual parallax offsets very close to zero (−1.6 ± 0.5 (stat.)±10 (syst.) μas) for stars fainter than G > 11 mag in the initial Kepler field, suggesting that the Lindegren parallax offset corrections are adequate in this magnitude range. For 17 K2 campaigns in the same magnitude range, the residual parallax offset is +16.5 ± 1.7 (stat.)±10 (syst.) μas. At brighter magnitudes (G ≤ 11 mag), we found inconsistent residual parallax offsets between the Kepler field, 17 K2 campaigns, and the TESS southern continuous viewing zone, with differences of up to 60 μas. This contradicts the studies that suggest a monotonic trend between magnitude and residual parallax offsets and instead suggests a significant dependence on sky location at bright magnitudes due to a lack of bright physical pairs being available to determine the parallax offset corrections. Inspection of the 17 K2 campaigns allowed for investigation of parallax offsets as a function of ecliptic longitude and revealed a possible signal. Finally, we estimated the absolute magnitude of the red clump and obtained MKsRC = −1.650 ± 0.025 mag in the 2MASS Ks band and MGRC = (0.432 ± 0.004) − (0.821 ± 0.033) · (Teff [K]−4800 K)/1000 K [mag] in the Gaia G-band."
"
Not all discoveries turn out to be actual new discoveries. This was the case for the extremely red objects (EROs) found in James Webb Space Telescope (JWST) data. Analysis shows that they are very similar to blue-excess dust obscured galaxies (BluDOGs) already reported in Subaru Telescope data.

Quasars, some of the brightest objects in the Universe, are driven by a supermassive black hole with a mass that can reach more than a billion times that of the Sun. These objects are the focus of much research, but how they form remains poorly understood. The prevailing theory is that they form in galaxies with clouds of gas and dust that obscure the growing quasar until it is powerful enough to blast away the clouds. If this is true, it should be able to catch the short timeframe where a quasar breaks out of its cloud.
Because the transition period is short, it is necessary to observe a large number of pre-quasar candidates and hope to get lucky enough to catch a galaxy just as the quasar starts to break out. Looking at data from JWST, a group of extremely red objects (EROs) were identified as possible transitionary quasars. But then researchers at the Subaru Telescope, a Japanese telescope in Hawai`i, noticed that even though they are called ""red,"" EROs also have a significant blue component, similar to blue-excess dust obscured galaxies (BluDOGs) found in Big Data from the Subaru Telescope and described in a report last year.
Analysis showed that EROs and BluDOGs are likely the same class of objects, but important differences also exist. One possibility is that EROs are in an earlier stage in their evolution than BluDOGs. To determine the true relationship between EROs, BluDOGs, and quasars a larger sample of candidates needs to be collected. The larger sample will be studied by the next generation of astronomy instruments including an infrared space telescope project called GREX-PLUS being planned in Japan.

","score: 12.51501314636284, grade_level: '13'","score: 12.968225241016647, grade_levels: ['college'], ages: [18, 24]",10.3847/2041-8213/ad0e00,"Spatially compact objects with extremely red color in the rest-frame optical to near-infrared (0.4–1 μm) and blue color in the rest-frame ultraviolet (UV; 0.2–0.4 μm) have been discovered at 5 < z < 9 using the James Webb Space Telescope (JWST). These extremely red objects (JWST-EROs) exhibit spectral energy distributions (SEDs) that are difficult to explain using a single component of either star-forming galaxies or quasars, leading to two-component models in which the blue UV and extremely red optical are explained using less-dusty and dusty spectra of galaxies or quasars, respectively. Here, we report the remarkable similarity in SEDs between JWST-EROs and blue-excess dust-obscured galaxies (BluDOGs) identified at 2 < z < 3. BluDOGs are a population of active galactic nuclei (AGNs) with black hole masses of ∼108–9 M ⊙, which are 1 order of magnitude larger than those in some JWST-EROs. The Eddington ratios of BluDOGs are 1 or higher, whereas those of JWST-EROs are in the range of 0.1–1. Therefore, JWST-EROs are less massive, less active, and more common counterparts in higher-z of BluDOGs in cosmic noon. Conversely, JWST-EROs have a significantly higher fraction of those with blue excess than DOGs. We present the average UV spectra of BluDOGs as a comparison to JWST-EROs and discuss a coherent evolutionary scenario for dusty AGN populations."
"
Astronomers at the University of Toronto have discovered a population of massive stars that have been stripped of their hydrogen envelopes by their companions in binary systems. The findings, published today in Science, shed light on the hot helium stars that are believed to be the origins of hydrogen-poor core-collapse supernovae and neutron star mergers.

For over a decade, scientists have theorized that approximately one in three massive stars are stripped of their hydrogen envelope in binary systems. Yet, until now, only one possible candidate had been identified.
""This was such a big, glaring hole,"" says co-lead author Maria Drout, an Assistant Professor in the David A. Dunlap Department of Astronomy & Astrophysics and a Dunlap Institute for Astronomy & Astrophysics Associate at the University of Toronto.
""If it turned out that these stars are rare, then our whole theoretical framework for all these different phenomena is wrong, with implications for supernovae, gravitational waves, and the light from distant galaxies,"" Drout says. ""This finding shows these stars really do exist.""
""Going forward, we are going to be able to do much more detailed physics with these stars,"" Drout says. ""For example, predictions for how many neutron star mergers we should see are dependent on the properties of these stars, such as how much material comes off of them in stellar winds. Now, for the first time, we'll be able to measure that, whereas people have been extrapolating it before.""
Binary stripped stars have been previously evoked to explain why a third of core-collapse supernovae contain much less hydrogen than a typical explosion of a Red Supergiant star. Drout and her colleagues propose that these newly discovered stars will eventually explode as hydrogen-poor supernovae. These star systems are also thought to be necessary to form neutron star mergers, like those that emit gravitational waves detected from Earth by the LIGO experiment.
In fact, the researchers believe that a few objects in their current sample are stripped stars with neutron star or blackhole companions. These objects are at the stage immediately before they become double neutron star or neutron star plus blackhole systems that could eventually merge.

""Many stars are part of a cosmic dance with a partner, orbiting each other in a binary system. They're not solitary giants but part of dynamic duos, interacting and influencing each other throughout their lifetimes,"" says Bethany Ludwig, a PhD student in in the David A. Dunlap Department of Astronomy & Astrophysics at the University Toronto and the third author on this paper. ""Our work sheds light on these fascinating relationships, revealing a universe that is far more interconnected and active than we previously imagined.""
""Just as humans are social beings, stars too, especially the massive ones, are rarely alone,"" Ludwig says.
As stars evolve and expand to become red giants, the hydrogen at the outer edges of one can be stripped by the gravitational pull of its companion -- leaving a very hot helium core exposed. The process can take tens of thousands, or even hundreds of thousands, of years.
Stripped stars are difficult to find because much of the light they emit is outside of the visible light spectrum and can be obstructed by dust in the universe or outshone by their companion stars.
Drout and her collaborators began their search in 2016. Having studied hydrogen-poor supernovae during her PhD, Drout set out to find the stripped stars thought to be at the heart of them during a NASA Hubble Postdoctoral Fellowship at the Observatories of the Carnegie Institution for Science. She met fellow co-author Ylva Götberg, now Assistant Professor at the Institute of Science and Technology Austria (ISTA), at a conference, who had recently built new theoretical models of what these stars should look like.
Drout, Götberg, and their collaborators designed a new survey to look in the ultraviolet part of the spectrum where extremely hot stars emit most of their light. While invisible to the naked eye, ultraviolet light can be detected by specialized instruments and telescopes.

Using data from the Swift Ultra-Violet/Optical Telescope, the researchers collected brightnesses for millions of stars in the Large and Small Magellanic Clouds, two of the closest galaxies to Earth. Ludwig developed the first wide-field UV catalog of the Magellanic Clouds and used UV photometry to detect systems with unusual UV emissions, signaling the possible presence of a stripped star.
They carried out a pilot study of 25 objects, obtaining optical spectroscopy with the Magellan Telescopes at Las Campanas Observatory between 2018 and 2022. They used these observations to demonstrate that the stars were hot, small, hydrogen-poor, and in binary systems -- all consistent with their model predictions.
Currently, the researchers are continuing to study the stars identified in this paper and expanding their search to find more. They will be looking both within nearby galaxies and within our own Milky Way with approved programs on the Hubble Space Telescope, the Chandra X-Ray Telescope, the Magellan Telescopes, and the Anglo-Australian Telescope. As part of this publication, all theoretical models and data used to identify these stars have been made public and available to other scientists.
Collaborating institutions include the University of Toronto, the Observatories of the Carnegie Institution for Science, Max-Planck-Institut für Astrophysik, Anton Pannekoek Institute for Astronomy, Dunlap Institute for Astronomy & Astrophysics, and Steward Observatory.
.

","score: 14.186487695749438, grade_level: '14'","score: 15.442841163310966, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.ade4970,"The hydrogen-rich outer layers of massive stars can be removed by interactions with a binary companion. Theoretical models predict that this stripping produces a population of hot helium stars of ~2 to 8 solar masses ( M ☉ ), however, only one such system has been identified thus far. We used ultraviolet photometry to identify potential stripped helium stars then investigated 25 of them using optical spectroscopy. We identified stars with high temperatures (~60,000 to 100,000 kelvin), high surface gravities, and hydrogen-depleted surfaces; 16 stars also showed binary motion. These properties match expectations for stars with initial masses of 8 to 25 M ☉ that were stripped by binary interaction. Their masses fall in the gap between subdwarf helium stars and Wolf-Rayet stars. We propose that these stars could be progenitors of stripped-envelope supernovae."
"
Supernovae-stellar explosions as bright as an entire galaxy-have fascinated us since time immemorial. Yet, there are more hydrogen-poor supernovae than astrophysicists can explain. Now, a new Assistant Professor at the Institute of Science and Technology Austria (ISTA) has played a pivotal role in identifying the missing precursor star population. The results, now published in Science, go back to a conversation the involved professors had many years ago as junior scientists.

Some stars do not simply die down, but explode in a stellar blast that could outshine entire galaxies. These cosmic phenomena, called supernovae, spread light, elements, energy, and radiation in space and send galactic shock waves that could compress gas clouds and generate new stars. In other words, supernovae shape our universe. Among these, hydrogen-poor supernovae from exploding massive stars have long puzzled astrophysicists. The reason: scientists have not been able to put their finger on their precursor stars. It is almost as if these supernovae appeared out of nowhere.
""There are many more hydrogen-poor supernovae than our current models can explain. Either we can't detect the stars that mature on this path, or we must revise all our models,"" says ISTA Assistant Professor Ylva Götberg. She pioneered this work together with Maria Drout, an Associated Faculty Member of the Dunlap Institute for Astronomy & Astrophysics, University of Toronto, Canada. ""Single stars would typically explode as hydrogen-rich supernovae. Being hydrogen-poor indicates that the precursor star must have lost its thick hydrogen-rich envelope. This happens naturally in a third of all massive stars through envelope stripping by a binary companion star,"" says Götberg. Now, Götberg and Drout combined their areas of expertise in theoretical modeling and observation to hunt down the missing stars. Their quest is successful: they document a first-of-its-kind star population that finally bridges a large knowledge gap and sheds light on the origin of hydrogen-poor supernovae.
Binary stars and envelope stripping
The stars that Götberg and Drout search for go in pairs: interlocked in a binary star system. Some binary systems are well-known to us Earthlings: these include the brightest star in our night sky, Sirius A, and its faint companion star Sirius B. The Sirius binary system is located only 8.6 light-years away from Earth-a stone's throw in cosmic terms. This explains Sirius A's observed brightness in our night sky.
Astrophysicists expect the missing stars to be initially formed from massive binary systems. In a binary system, the stars would orbit around one another until the more massive star's thick, hydrogen-rich envelope expands. Eventually, the expanding envelope experiences a stronger gravitational pull to the companion star than to its own core. This causes a transfer of mass to begin, which eventually leads the entire hydrogen-rich envelope to be stripped off, leaving the hot and compact helium core exposed-more than 10 times hotter than the Sun's surface. This is precisely the type of stars that Götberg and Drout are looking for. ""Intermediate mass helium stars stripped through binary interaction are predicted to play important roles in astrophysics. Yet, they were not observed until now,"" says Götberg. In fact, there is an important mass gap between the known classes of helium stars: the more massive Wolf-Rayet (WR) stars have more than 10 times the Sun's mass, and the low-mass subdwarf stars could have around half the Sun's mass. However, models have predicted the precursors of hydrogen-poor supernovae to lie between 2 and 8 solar masses following stripping.
Not just a needle in the haystack
Before Götberg and Drout's study, only one star was found to fulfill the expected mass and composition criteria and was called ""Quasi-WR"" (or ""Almost Wolf-Rayet""). ""Yet, the stars that follow this path have such a long lifetime that many must be scattered all over the observable universe,"" says Götberg. Did the scientists simply not ""see"" them? Thus, Götberg and Drout drew on their complementary expertise. With the help of UV photometry and optical spectroscopy, they identified a population of 25 stars that are consistent with the expectations for intermediate-mass helium stars. The stars are located in two well-studied neighboring galaxies, the Large and the Small Magellanic Clouds. ""We showed that these stars were bluer than the stellar birthline, the bluest phase in a single star's lifetime. Single stars mature by evolving towards the redder region of the spectrum. A star only shifts in the opposite direction if its outer layers are removed-something that is expected to be common in interacting binary stars and rare among single massive stars,"" explains Götberg.

The scientists then verified their candidate star population using optical spectroscopy: they showed that the stars had strong spectral signatures of ionized helium. ""Strong ionized helium lines tell us two important things: first, they confirm that the stars' outermost layers are dominated by helium and, second, that their surface is very hot. This is what happens to stars left as an exposed, compact, helium-rich core following stripping,"" says Götberg. Yet, both stars in a binary system contribute to the observed spectra. Thus, this technique allowed the researchers to classify their candidate population depending on which star contributed the most to the spectrum. ""This work allowed us to find the missing population of intermediate-mass, stripped helium stars, the predicted progenitors of hydrogen-poor supernovae. These stars have always been there and there are probably many more out there. We must simply come up with ways to find them,"" says Götberg. ""Our work may be one of the first attempts, but there should be other ways possible.""
From graduate students at a conference to group leaders
The idea behind this project sparked in a discussion following a talk by Götberg at a conference that she and Drout attended during their graduate studies. Both scientists, then Early Career Researchers reaching for the stars, are now group leaders in their field. Götberg joined ISTA in September following her research at the Carnegie Observatories in Pasadena, California, as a NASA Hubble postdoctoral fellow. At ISTA, Götberg joins the Institute's growing ranks of young group leaders in astrophysics and leads her own group focused on studying the binary interactions of stars.
This work, led by Maria R. Drout (Dunlap Institute for Astronomy & Astrophysics, University of Toronto, Canada) and Ylva Götberg (Institute of Science and Technology Austria, ISTA), was done in collaboration with The Observatories of the Carnegie Institution for Science (Pasadena, USA), and the Max Planck Institute for Astrophysics (Garching, Germany), among others.

","score: 11.88300400123115, grade_level: '12'","score: 13.204592182209915, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.ade4970,"The hydrogen-rich outer layers of massive stars can be removed by interactions with a binary companion. Theoretical models predict that this stripping produces a population of hot helium stars of ~2 to 8 solar masses ( M ☉ ), however, only one such system has been identified thus far. We used ultraviolet photometry to identify potential stripped helium stars then investigated 25 of them using optical spectroscopy. We identified stars with high temperatures (~60,000 to 100,000 kelvin), high surface gravities, and hydrogen-depleted surfaces; 16 stars also showed binary motion. These properties match expectations for stars with initial masses of 8 to 25 M ☉ that were stripped by binary interaction. Their masses fall in the gap between subdwarf helium stars and Wolf-Rayet stars. We propose that these stars could be progenitors of stripped-envelope supernovae."
"
Two galaxies in the early universe, which contain extremely productive star factories, have been studied by a team of scientists led by Chalmers University of Technology in Sweden. Using powerful telescopes to split the galaxies' light into individual colours, the scientists were amazed to discover light from many different molecules -- more than ever before at such distances. Studies like this could revolutionise our understanding of the lives of the most active galaxies when the universe was young, the researchers believe.

When the universe was young, galaxies were very different from today's stately spirals, which are full of gently-shining suns and colourful gas clouds. New stars were being born, at rates hundreds of times faster than in today's universe. Most of this however, was hidden behind thick layers of dust, making it a challenge for scientists to discover these star factories' secrets -- until now. By studying the most distant galaxies visible with powerful telescopes, astronomers can get glimpses of how these factories managed to create so many stars.
In a new study, published in the journal Astronomy & Astrophysics, a team of scientists led by Chalmers astronomer Chentao Yang, used the telescopes of NOEMA (NOrthern Extended Millimetre Array) in France to find out more about how these early star factories managed to create so many stars. Yang and his colleagues measured light from two luminous galaxies in the early universe -- one of them classified as a quasar, and both with high rates of star formation.
""We knew these galaxies were prodigious star factories, perhaps amongst the biggest the universe has ever seen. To be able to find out how they work, we measured their light at wavelengths around one millimetre, hoping to collect new clues,"" says Chentao Yang.
Dramatic chemistry in the distant galaxies excites the astronomers
The measurements proved to be successful beyond the scientists' expectations. In the light they recorded from both galaxies, they identified traces of many different kinds of molecules. From deep within these galaxies, light is emitted in many different wavelengths from the clouds of gas and dust where new stars are born.
""It's an amazing explosion of colour, in shades that the human eye can't see. But by combining our observations with our knowledge of physics and chemistry, we can understand what the colours mean, and see what differences there are between different galaxies,"" explains Sergio Martín, astronomer at ESO and Joint ALMA Observatory, Chile, and member of the research team.

By analysing each galaxy's spectrum -- the individual colours of their light -- the scientists were able to identify 13 molecules, several of which have never been seen before in such distant galaxies. Each molecule gives different clues about the temperature, pressure, and density in the space between the stars, and about how starlight, radiation and matter interact -- providing key new information on the physical and chemical conditions in these galaxies.
""Interpreting the signals is a challenge. We are seeing part of the electromagnetic spectrum that is hard to observe in nearby galaxies. But thanks to the expansion of the universe, the light from distant galaxies like these is shifted to longer wavelengths that we can see with radio telescopes observing in the sub-millimetre,"" says Chentao Yang.
More like a neon-lit city than a night under the stars
The two galaxies studied by the team are so far away that their light takes almost 13 billion years to reach us.
""Looking at these galaxies is less like a night under the stars and more like seeing a city lit with neon lights,"" says Susanne Aalto, Chalmers astronomer and team member.
Astronomers are used to taking pictures of our galaxy's star factories, like the Orion Nebula and the Carina Nebula, she explains.

""In these two distant galaxies, we are instead seeing star factories that are bigger, brighter, full of dust, and different in many ways. The Orion and Carina nebulae are lit up thanks to ultraviolet light from hot, newborn stars. In these two distant galaxies, ultraviolet light can't get past the layers of dust. Much of the illumination is instead thanks to cosmic rays -- high energy particles that can be created by exploding stars, or close to a supermassive black hole,"" says Susanne Aalto.
The galaxies in the early universe can now tell their stories
While galaxies like these two are rare, the scientists have plans to study more of them, using both NOEMA and its even bigger sister telescope, ALMA (the Atacama Large Millimetre/Submillimetre Array) in Chile. Both telescopes are sensitive to light with wavelengths of around one millimetre.
""Our results show how NOEMA, with its broadband receivers and powerful correlator computer, has opened up new opportunities for studying extreme galaxies like these in the northern sky. From the southern hemisphere, ALMA's planned wideband sensitivity upgrades will offer even more exciting prospects. The most remarkable galaxies in the early universe are finally able to tell their stories through their molecules,"" says Pierre Cox, astronomer at CNRS and Sorbonne Université, France.
More about the research results:
Over a hundred different molecules have been detected in interstellar space. In this study, the astronomers identified molecules of carbon monoxide (CO), the cyano radical (CN), the ethynyl radical (CCH), hydrogen cyanide (HCN), the formyl cation (HCO+), hydrogen isocyanide (HNC), carbon monosulphide (CS), water (H2O), the hydronium ion (H3O+), nitric oxide (NO), diazenylium (N2H+), the methylidyne radical (CH), and cyclopropenylidene (c-C3H2). Several of these (CH, CCH, c-C3H2, N2H+, and H3O+) have never been seen before at such large distances.
The two galaxies in the study have catalogue numbers APM 08279+5255 and NCv1.143. Previous studies have shown that they are so far away that their light has been traveling towards us for nearly 13 billion years, corresponding to redshifts of 3.911 and 3.565, respectively. Redshift means that the expansion of the universe stretches the light from distant galaxies to longer wavelengths, which can be observed with radio telescopes.
Despite their distance, the galaxies shine brightly at radio wavelengths. Their signals are amplified thanks to clusters of other galaxies that lie along the light's path -- an effect known as gravitational lensing. One of the galaxies, APM 08279+5255, is also a quasar, a galaxy whose centre glows brightly all the way from radio waves to X-rays, due to material swirling around a supermassive black hole. NCv1.143 may also contain a central black hole.

","score: 13.415674418604652, grade_level: '13'","score: 14.85659534883721, grade_levels: ['college_graduate'], ages: [24, 100]",10.1051/0004-6361/202347610,"Understanding the nature of high-redshift dusty galaxies requires a comprehensive view of their interstellar medium (ISM) and molecular complexity. However, the molecular ISM at high redshifts is commonly studied using only a few species beyond 12C16O, limiting our understanding. In this paper, we present the results of deep 3 mm spectral line surveys using the NOrthern Extended Millimeter Array (NOEMA) targeting two strongly lensed dusty galaxies observed when the Universe was less than 1.8 Gyr old: APM 08279+5255, a quasar at redshift z = 3.911, and NCv1.143 (H-ATLAS J125632.7+233625), a z = 3.565 starburst galaxy. The spectral line surveys cover rest-frame frequencies from about 330 to 550 GHz for both galaxies. We report the detection of 38 and 25 emission lines in APM 08279+5255 and NCv1.143, respectively. These lines originate from 17 species, namely CO, 13CO, C18O, CN, CCH, HCN, HCO+, HNC, CS, C34S, H2O, H3O+, NO, N2H+, CH, c-C3H2, and the vibrationally excited HCN and neutral carbon. The spectra reveal the chemical richness and the complexity of the physical properties of the ISM. By comparing the spectra of the two sources and combining the analysis of the molecular gas excitation, we find that the physical properties and the chemical imprints of the ISM are different: the molecular gas is more excited in APM 08279+5255, which exhibits higher molecular gas temperatures and densities compared to NCv1.143; the molecular abundances in APM 08279+5255 are akin to the values of local active galactic nuclei (AGN), showing boosted relative abundances of the dense gas tracers that might be related to high-temperature chemistry and/or the X-ray-dominated regions, while NCv1.143 more closely resembles local starburst galaxies. The most significant differences between the two sources are found in H2O: the 448 GHz ortho-H2O(423 − 330) line is significantly brighter in APM 08279+5255, which is likely linked to the intense far-infrared radiation from the dust powered by AGN. Our astrochemical model suggests that, at such high column densities, far-ultraviolet radiation is less important in regulating the ISM, while cosmic rays (and/or X-rays and shocks) are the key players in shaping the molecular abundances and the initial conditions of star formation. Both our observed CO isotopologs line ratios and the derived extreme ISM conditions (high gas temperatures, densities, and cosmic-ray ionization rates) suggest the presence of a top-heavy stellar initial mass function. From the ∼330–550 GHz continuum, we also find evidence of nonthermal millimeter flux excess in APM 08279+5255 that might be related to the central supermassive black hole. Such deep spectral line surveys open a new window into the physics and chemistry of the ISM and the radiation field of galaxies in the early Universe."
"
Brown dwarfs are objects that straddle the dividing line between stars and planets. They form like stars, growing dense enough to collapse under their own gravity, but they never become dense and hot enough to begin fusing hydrogen and turn into a star. At the low end of the scale, some brown dwarfs are comparable with giant planets, weighing just a few times the mass of Jupiter.

What are the smallest stars?
Astronomers are trying to determine the smallest object that can form in a star-like manner. A team using NASA's James Webb Space Telescope has identified the new record-holder: a tiny, free-floating brown dwarf with only three to four times the mass of Jupiter.
""One basic question you'll find in every astronomy textbook is, what are the smallest stars? That's what we're trying to answer,"" explained lead author Kevin Luhman of Pennsylvania State University.
Search Strategy
To locate this newfound brown dwarf, Luhman and his colleague, Catarina Alves de Oliveira, chose to study the star cluster IC 348, located about 1,000 light-years away in the Perseus star-forming region. This cluster is young, only about 5 million years old. As a result, any brown dwarfs would still be relatively bright in infrared light, glowing from the heat of their formation.
The team first imaged the center of the cluster using Webb's NIRCam (Near-Infrared Camera) to identify brown dwarf candidates from their brightness and colors. They followed up on the most promising targets using Webb's NIRSpec (Near-Infrared Spectrograph) microshutter array.

Webb's infrared sensitivity was crucial, allowing the team to detect fainter objects than ground-based telescopes. In addition, Webb's sharp vision enabled them to determine which red objects were pinpoint brown dwarfs and which were blobby background galaxies.
This winnowing process led to three intriguing targets weighing three to eight Jupiter masses, with surface temperatures ranging from 1,500 to 2,800 degrees Fahrenheit (830 to 1,500 degrees Celsius). The smallest of these weighs just three to four times Jupiter, according to computer models.
Explaining how such a small brown dwarf could form is theoretically challenging. A heavy and dense cloud of gas has plenty of gravity to collapse and form a star. However, because of its weaker gravity, it should be more difficult for a small cloud to collapse to form a brown dwarf, and that is especially true for brown dwarfs with the masses of giant planets.
""It's pretty easy for current models to make giant planets in a disk around a star,"" said Catarina Alves de Oliveira of ESA (European Space Agency), principal investigator on the observing program. ""But in this cluster, it would be unlikely this object formed in a disk, instead forming like a star, and three Jupiter masses is 300 times smaller than our Sun. So we have to ask, how does the star formation process operate at such very, very small masses?""
A Mystery Molecule
In addition to giving clues about the star-formation process, tiny brown dwarfs also can help astronomers better understand exoplanets. The least massive brown dwarfs overlap with the largest exoplanets; therefore, they would be expected to have some similar properties. However, a free-floating brown dwarf is easier to study than a giant exoplanet since the latter is hidden within the glare of its host star.

Two of the brown dwarfs identified in this survey show the spectral signature of an unidentified hydrocarbon, or molecule containing both hydrogen and carbon atoms. The same infrared signature was detected by NASA's Cassini mission in the atmospheres of Saturn and its moon Titan. It has also been seen in the interstellar medium, or gas between stars.
""This is the first time we've detected this molecule in the atmosphere of an object outside our solar system,"" explained Alves de Oliveira. ""Models for brown dwarf atmospheres don't predict its existence. We're looking at objects with younger ages and lower masses than we ever have before, and we're seeing something new and unexpected.""
Brown Dwarf or Rogue Planet?
Since the objects are well within the mass range of giant planets, it raises the question of whether they are actually brown dwarfs, or if they're really rogue planets that were ejected from planetary systems. While the team can't rule out the latter, they argue that they are far more likely to be a brown dwarf than an ejected planet.
An ejected giant planet is unlikely for two reasons. First, such planets are uncommon in general compared to planets with smaller masses. Second, most stars are low-mass stars, and giant planets are especially rare among those stars. As a result, it's unlikely that most of the stars in IC 348 (which are low-mass stars) are capable of producing such massive planets. In addition, since the cluster is only 5 million years old, there probably hasn't been enough time for giant planets to form and then be ejected from their systems.
The discovery of more such objects will help clarify their status. Theories suggest that rogue planets are more likely to be found in the outskirts of a star cluster, so expanding the search area may identify them if they exist within IC 348.
Future work may also include longer surveys that can detect fainter, smaller objects. The short survey conducted by the team was expected to detect objects as small as twice the mass of Jupiter. Longer surveys could easily reach one Jupiter mass.
These observations were taken as part of Guaranteed Time Observation program 1229. The results were published in the Astronomical Journal.

","score: 10.515033854345983, grade_level: '11'","score: 11.62095779109, grade_levels: ['12'], ages: [17, 18]",10.3847/1538-3881/ad00b7,"We have obtained images of the center of the star-forming cluster IC 348 with the James Webb Space Telescope and have identified brown dwarf candidates based on their photometry and point-like flux profiles. Low-resolution spectroscopy has been performed on four promising candidates, three of which have molecular absorption bands that indicate late spectral types. Among those late-type objects, the brightest is similar to known young L dwarfs while the other two show the so-called 3.4 μm feature that has been previously observed in the diffuse interstellar medium and in the atmospheres of Saturn and Titan, which has been attributed to an unidentified aliphatic hydrocarbon. Those two objects also exhibit features between 1.1 and 2.6 μm that we identify as the overtone and combination bands for that hydrocarbon. After accounting for the hydrocarbon bands, the remaining spectral features are consistent with youth and inconsistent with field dwarfs. Based on the low extinctions of those objects and the strengths of the overtone and combination bands, we conclude that the hydrocarbon resides in their atmospheres rather than in foreground material. Thus, our detections of the 3.4 μm feature are the first in atmospheres outside of the solar system. The presence of this hydrocarbon is not predicted by any atmospheric models of young brown dwarfs. Based on its luminosity and evolutionary models, the faintest new member of IC 348 has an estimated mass of 3–4 M Jup, making it a strong contender for the least massive free-floating brown dwarf that has been directly imaged to date."
"
A NASA study expands the search for life beyond our solar system by indicating that 17 exoplanets (worlds outside our solar system) could have oceans of liquid water, an essential ingredient for life, beneath icy shells. Water from these oceans could occasionally erupt through the ice crust as geysers. The science team calculated the amount of geyser activity on these exoplanets, the first time these estimates have been made. They identified two exoplanets sufficiently close where signs of these eruptions could be observed with telescopes.

The search for life elsewhere in the Universe typically focuses on exoplanets that are in a star's ""habitable zone,"" a distance where temperatures allow liquid water to persist on their surfaces. However, it's possible for an exoplanet that's too distant and cold to still have an ocean underneath an ice crust if it has enough internal heating. Such is the case in our solar system where Europa, a moon of Jupiter, and Enceladus, a moon of Saturn, have subsurface oceans because they are heated by tides from the gravitational pull of the host planet and neighboring moons.
These subsurface oceans could harbor life if they have other necessities, such as an energy supply as well as elements and compounds used in biological molecules. On Earth, entire ecosystems thrive in complete darkness at the bottom of oceans near hydrothermal vents, which provide energy and nutrients.
""Our analyses predict that these 17 worlds may have ice-covered surfaces but receive enough internal heating from the decay of radioactive elements and tidal forces from their host stars to maintain internal oceans,"" said Dr. Lynnae Quick of NASA's Goddard Space Flight Center in Greenbelt, Maryland. ""Thanks to the amount of internal heating they experience, all planets in our study could also exhibit cryovolcanic eruptions in the form of geyser-like plumes."" Quick is lead author of a paper on the research published on October 4 in the Astrophysical Journal.
The team considered conditions on 17 confirmed exoplanets that are roughly Earth-sized but less dense, suggesting that they could have substantial amounts of ice and water instead of denser rock. Although the planets' exact compositions remain unknown, initial estimates of their surface temperatures from previous studies all indicate that they are much colder than Earth, suggesting that their surfaces could be covered in ice.
The study improved estimates of each exoplanet's surface temperature by recalculating using the known surface brightness and other properties of Europa and Enceladus as models. The team also estimated the total internal heating in these exoplanets by using the shape of each exoplanet's orbit to get the heat generated from tides and adding it to the heat expected from radioactive activity. Surface temperature and total heating estimates gave the ice layer thickness for each exoplanet since the oceans cool and freeze at the surface while being heated from the interior. Finally, they compared these figures to Europa's and used estimated levels of geyser activity on Europa as a conservative baseline to estimate geyser activity on the exoplanets.
They predict that surface temperatures are colder than previous estimates by up to 60 degrees Fahrenheit (16 degrees Celsius). Estimated ice shell thickness ranged from about 190 feet (58 meters) for Proxima Centauri b and one mile (1.6 kilometers) for LHS 1140 b to 24 miles (38.6 kilometers) for MOA 2007 BLG 192Lb, compared to Europa's estimated average of 18 miles (almost 29 kilometers). Estimated geyser activity went from just 17.6 pounds per second (about 8 kilograms/second) for Kepler 441b to 639,640 pounds/second (290,000 kilograms/second) for LHS 1140b and 13.2 million pounds/second (six million kilograms/second) for Proxima Centauri b, compared to Europa at 4,400 pounds/second (2,000 kilograms/second).

""Since our models predict that oceans could be found relatively close to the surfaces of Proxima Centauri b and LHS 1140 b, and their rate of geyser activity could exceed Europa's by hundreds to thousands of times, telescopes are most likely to detect geological activity on these planets,"" said Quick, who is presenting this research December 12at the American Geophysical Union meeting in San Francisco, California.
This activity could be seen when the exoplanet passes in front of its star. Certain colors of starlight could be dimmed or blocked by water vapor from the geysers. ""Sporadic detections of water vapor in which the amount of water vapor detected varies with time, would suggest the presence of cryovolcanic eruptions,"" said Quick. The water might contain other elements and compounds that could reveal if it can support life. Since elements and compounds absorb light at specific ""signature"" colors, analysis of the starlight would let scientists determine the geyser's composition and evaluate the exoplanet's habitability potential.
For planets like Proxima Centauri b that don't cross their stars from our vantage point, geyser activity could be detected by powerful telescopes that are able to measure light that the exoplanet reflects while orbiting its star. Geysers would expel icy particles at the exoplanet's surface which would cause the exoplanet to appear very bright and reflective.
The research was funded by NASA's Habitable Worlds Program, the University of Washington's Astrobiology Program, and the Virtual Planetary Laboratory, a member of the NASA Nexus for Exoplanet System Science coordination group.

","score: 15.943296085138734, grade_level: '16'","score: 17.783930064614218, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/ace9b6,"We have estimated total internal heating rates and depths to possible subsurface oceans for 17 planets that may be cold ocean planets, low-mass exoplanets with equilibrium surface temperatures and/or densities that are consistent with icy surfaces and a substantial H2O content. We have also investigated the potential for tidally driven cryovolcanism and exosphere formation on these worlds. Estimated internal heating rates from tidal and radiogenic sources are large enough that all planets in our study may harbor subsurface oceans, and their geological activity rates are likely to exceed the geological activity rates on Jupiter’s moon Europa. Several planets are likely to experience enhanced volcanic activity rates that exceed that of Io. Owing to their relatively thin ice shells and high rates of internal heating, Proxima Cen b and LHS 1140 b are the most favorable candidates for telescopic detection of explosive, tidally driven cryovolcanism. Estimates for thin ice shells on Proxima Cen b, LHS 1140 b, Trappist-1f, and several Kepler planets suggest that any H2O vented into space during explosive cryovolcanic eruptions on these worlds could be sourced directly from their subsurface oceans. Like the icy moons in our outer solar system, cold ocean planets may be astrobiologically significant worlds that harbor habitable environments beneath their icy surfaces. These possibilities should be considered during analyses of observational data for small exoplanets from current and upcoming telescopes and during planning for a future space telescope mission aimed at characterization of potentially habitable exoplanets (e.g., Habitable Worlds Observatory)."
"
A groundbreaking study conducted by a team of international scientists has unveiled unprecedented insights into the nature of the asteroid Ryugu and shed light on the composition of water- and carbon-rich small bodies in the solar system.

Asteroids like Ryugu are remnants of planetary embryos that never reached larger sizes, making them invaluable windows into materials that formed in the early solar system. The study centered on laboratory measurements of the samples brought back to the Earth by the Hayabusa2 spacecraft in 2020. Led by the Japan Aerospace Exploration Agency (JAXA), Hayabusa2 aimed to uncover the true nature of Ryugu and explore how astrologists can use knowledge from meteorites to interpret telescopic observations of other hydrous asteroids.
Unlike meteorites derived from similar hydrous asteroids, the Ryugu samples avoided terrestrial alteration -- the interaction with oxygen and water in the Earth's atmosphere.
Reflectance spectroscopy, a primary technique linking laboratory analyses of meteorites to asteroid observations, was employed to compare fresh Ryugu samples with meteorites altered in terrestrial environments. The team successfully developed analytical procedures that avoided exposing the samples to Earth's atmosphere, ensuring the preservation of their original conditions.
Previous studies suggested that Ryugu's sample mineralogy resembled CI chondrites, the most primitive meteorites chemically. However, other studies have contradicted this by revealing a significant difference in reflectance spectra between Ryugu samples and CI chondrites. Further investigations in the new study indicated that heating CI samples under reducing conditions at 300 °C reproduced Ryugu's sample mineralogy well, resulting in spectra closely matching those of Ryugu samples.
The findings challenge previous assumptions about the parent bodies of CI chondrites and underscore the susceptibility of primitive meteorite spectra to terrestrial weathering. The study suggests that actual CI chondrite parent bodies likely exhibit darker and flatter reflectance spectra than previously thought.
""This study opens new avenues for understanding the composition and evolution of small bodies in our solar system. By considering the impact of terrestrial weathering on meteorites, we can refine our interpretations of asteroid compositions and advance our knowledge of the solar system's early history,"" said Kana Amano, a former PhD student at the early Solar System evolution Research Group at Tohoku University and co-author of the paper.
Details of Amano and her colleagues' findings were published in the journal Science Advances on December 6, 2023.

","score: 17.972086355785844, grade_level: '18'","score: 19.086563039723664, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adi3789,"The carbonaceous asteroid Ryugu has been explored by the Hayabusa2 spacecraft to elucidate the actual nature of hydrous asteroids. Laboratory analyses revealed that the samples from Ryugu are comparable to unheated CI carbonaceous chondrites; however, reflectance spectra of Ryugu samples and CIs do not coincide. Here, we demonstrate that Ryugu sample spectra are reproduced by heating Orgueil CI chondrite at 300°C under reducing conditions, which caused dehydration of terrestrial weathering products and reduction of iron in phyllosilicates. Terrestrial weathering of CIs accounts for the spectral differences between Ryugu sample and CIs, which is more severe than space weathering that likely explains those between asteroid Ryugu and the collected samples. Previous assignments of CI chondrite parent bodies, i.e., chemically most primitive objects in the solar system, are based on the spectra of CI chondrites. This study indicates that actual spectra of CI parent bodies are much darker and flatter at ultraviolet to visible wavelengths than the spectra of CI chondrites."
"
The shimmering green, red and purple curtains of the northern and southern lights -- the auroras -- may be the best-known phenomena lighting up the nighttime sky, but the most mysterious are the mauve and white streaks called Steve and their frequent companion, a glowing green ""picket fence.""

First recognized in 2018 as distinct from the common auroras, Steve -- a tongue-in-cheek reference to the benign name given a scary hedge in a 2006 children's movie -- and its associated picket fence were nevertheless thought to be caused by the same physical processes. But scientists were left scratching their heads about how these glowing emissions were produced.
Claire Gasque, a University of California, Berkeley, graduate student in physics, has now proposed a physical explanation for these phenomena that is totally different from the processes responsible for the well-known auroras. She has teamed up with researchers at the campus's Space Sciences Laboratory (SSL) to propose that NASA launch a rocket into the heart of the aurora to find out if she's correct.
Vibrant auroras and glowing phenomena such as Steve and the picket fence are becoming more common as the sun enters the active period of its 11-year cycle, and November was a good month for Steve observations in the northern latitudes. Because all these transient luminous phenomena are triggered by solar storms and coronal mass ejections from the sun, the approaching solar maximum is an ideal time to study rare events like Steve and the picket fence.
Gasque described the physics behind the picket fence in a paper published last month in the journal Geophysical Research Letters and will discuss the results on Dec. 14 in an invited talk at the American Geophysical Union meeting in San Francisco.
She calculated that in a region of the upper atmosphere farther south than that in which auroras form, electric fields parallel to Earth's magnetic field could produce the color spectrum of the picket fence. If correct, this unusual process has implications for how physicists understand energy flow between Earth's magnetosphere, which surrounds and protects Earth from the solar wind, and the ionosphere at the edge of space.
""This would upend our modeling of what creates light and the energy in the aurora in some cases,"" Gasque said.

""The really interesting thing about Claire's paper is that we've known for a couple of years now that the Steve spectrum is telling us there's some very exotic physics going on. We just didn't know what it was,"" said Brian Harding, a co-author of the paper and an SSL assistant research physicist. ""Claire's paper showed that parallel electric fields are capable of explaining this exotic spectrum.""
The paper was a side project from Gasque's Ph.D. thesis, which is focused on the connection between events like volcanoes on Earth's surface and phenomena in the ionosphere 100 kilometers or more above our heads.
But after hearing about Steve -- which has now become an acronym for Strong Thermal Emission Velocity Enhancement -- at a conference in 2022, she couldn't resist looking into the physics behind Steve and the picket fence.
""It's really cool,"" she said. ""It's one of the biggest mysteries in space physics right now.""
The physics of Steve and picket fence
The common auroras are produced when the solar wind energizes particles in Earth's magnetosphere, often at altitudes higher than 1,000 kilometers above the surface. These energized particles spiral around Earth's magnetic field lines toward the poles, where they crash into and excite oxygen and nitrogen molecules in the upper atmosphere. When those molecules relax, oxygen emits specific frequencies of green and red light, while nitrogen generates a bit of red, but primarily a blue, emission line.

The colorful, shimmering curtains that result can extend for thousands of kilometers across the northern or southern latitudes.
Steve, however, displays not individual emission lines, but a broad range of frequencies centered around purple or mauve. And unlike auroras, neither Steve nor the picket fence emit blue light, which is generated when the most energetic particles hit and ionize nitrogen. Steve and the picket fence also occur at lower latitudes than the aurora, potentially even as far south as the equator.
Some researchers proposed that Steve is caused by ion flows in the upper atmosphere, referred to as subauroral ion drift, or SAID, though there's no well accepted physical explanation for how SAID could generate the colorful emissions.
Gasque's interest was sparked by suggestions that the picket fence's emissions could be generated by low-altitude electric fields parallel to Earth's magnetic field, a situation thought to be impossible because any electric field aligned with the magnetic field should quickly short out and disappear.
Using a common physical model of the ionosphere, Gasque subsequently showed that a moderate parallel electric field -- around 100 millivolts per meter -- at a height of about 110 km could accelerate electrons to an energy that would excite oxygen and nitrogen and generate the spectrum of light observed from the picket fence. Unusual conditions in that area, such as a lower density of charged plasma and more neutral atoms of oxygen and nitrogen, could potentially act as insulation to keep the electric field from shorting out.
""If you look at the spectrum of the picket fence, it's much more green than you would expect. And there's none of the blue that's coming from the ionization of nitrogen,"" Gasque said. ""What that's telling us is that there's only a specific energy range of electrons that can create those colors, and they can't be coming from way out in space down into the atmosphere, because those particles have too much energy.""
Instead, she said, ""the light from the picket fence is being created by particles that have to be energized right there in space by a parallel electric field, which is a completely different mechanism than any of the aurora that we've studied or known before.""
She and Harding suspect that Steve itself may be produced by related processes. Their calculations also predict the type of ultraviolet emissions that this process would produce, which can be checked to verify the new hypothesis about the picket fence.
Though Gasque's calculations don't directly address the on-off glow that makes the phenomenon look like a picket fence, it's likely due to wavelike variations in the electric field, she said. And while the particles that are accelerated by the electric field are probably not from the sun, the scrambling of the atmosphere by solar storms probably triggers Steve and the picket fence, as it does the common aurora.
Enhanced auroras exhibit a picket fence-like glow
The next step, Harding said, is to launch a rocket from Alaska through these phenomena and measure the strength and direction of the electric and magnetic fields. SSL scientists specialize in designing and building instruments that do just that. Many of these instruments are on spacecraft now orbiting Earth and the sun.
Initially, the target would be what's known as an enhanced aurora, which is a normal aurora with picket fence-like emissions embedded in it.
""The enhanced aurora is basically this bright layer that's embedded in the normal aurora. The colors are similar to the picket fence in that there's not as much blue in them, and there's more green from oxygen and red from nitrogen. The hypothesis is that these are also created by parallel electric fields, but they are a lot more common than the picket fence,"" Gasque said.
The plan is not only ""to fly a rocket through that enhanced layer to actually measure those parallel electric fields for the first time,"" she said, but also send a second rocket up to measure the particles at higher altitudes, ""to distinguish the conditions from those that cause the auroras."" Eventually, she hopes for a rocket that will fly directly through Steve and the picket fence.
Harding, Gasque and colleagues proposed just such a sounding rocket campaign to NASA this fall and expect to hear back regarding its selection in the first half of 2024. Gasque and Harding consider the experiment an important step in understanding the chemistry and physics of the upper atmosphere, the ionosphere and Earth's magnetosphere, and a proposal in line with the Low Cost Access to Space (LCAS) program sponsored by NASA for projects like this.
""It's fair to say that there's going to be a lot of study in the future about how those electric fields got there, what waves they are or aren't associated with, and what that means for the larger energy transfer between Earth's atmosphere and space,"" Harding said. ""We really don't know. Claire's paper is the first step in the chain of that understanding.""
Gasque expressed appreciation for the input from people who study the middle ionosphere, or mesosphere, and the stratosphere, whose ideas helped her puzzle out the solution.
""With this collaboration, we were able to make some really cool progress in this field,"" she said. ""Honestly, it was just following our nose and being excited about it.""
In addition to Harding, her other co-authors are Reza Janalizadeh of Pennsylvania State University in University Park, Justin Yonker of the Applied Physics Laboratory at Johns Hopkins University in Laurel, Maryland, and D. Megan Gillies of the University of Calgary in Alberta, Canada.
Partial support for this work was provided by the National Science Foundation (AGS-2010088), National Aeronautics and Space Administration (80NSSC21K1386) and Robert P. Lin Fellowship at UC Berkeley.

","score: 14.410093323761664, grade_level: '14'","score: 16.165648779612347, grade_levels: ['college_graduate'], ages: [24, 100]",10.1029/2023GL106073,"Recent studies suggest that, despite its aurora‐like appearance, the picket fence may not be driven by magnetospheric particle precipitation but instead by local electric fields parallel to Earth's magnetic field. Here, we evaluate the parallel electric fields hypothesis by quantitatively comparing picket fence spectra with the emissions generated in a kinetic model driven by local parallel electric fields energizing ambient electrons in a realistic neutral atmosphere. We find that, at a typical picket fence altitude of 110 km, parallel electric fields between 40 and 70 Td (∼80–150 mV/m at 110 km) energize ambient electrons sufficiently so that, when they collide with neutrals, they reproduce the observed ratio of N2 first positive to atomic oxygen green line emissions, without producing first negative emissions. These findings establish a quantitative connection between ionospheric electrodynamics and observable picket fence emissions, offering verifiable targets for future models and experiments."
"
Only two of the more than 5300 known exoplanets have so far provided evidence of moons in orbit around them. In observations of the planets Kepler-1625b and Kepler-1708b from the Kepler and Hubble space telescopes, researchers had discovered traces of such moons for the first time. A new study now raises doubts about these previous claims. As scientists from the Max Planck Institute for Solar System Research (MPS) and the Sonnenberg Observatory, both in Germany, report today in the journal Nature Astronomy, ""planet-only"" interpretations of the observations are more conclusive. For their analysis, the researchers used their newly developed computer algorithm Pandora, which facilitates and accelerates the search for exomoons. They also investigated what kind of exomoons can be found in principle in modern space-based astronomical observations. Their answer is quite shocking.

In our Solar System, the fact that a planet is orbited by one or more moons is rather the rule than the exception: apart from Mercury and Venus, all other planets have such companions; in the case of the gas giant Saturn researchers have found 140 natural satellites until today. Scientists therefore consider it likely that planets in distant star systems also harbor moons. So far, however, there has only been evidence of such exomoons in two cases: Kepler-1625b and Kepler-1708b. This low yield is not surprising. After all, distant satellites are naturally much smaller than their home worlds -- and therefore much harder to find. And it is extremely time-consuming to comb through the observational data of thousands of exoplanets for evidence of moons.
To make the search easier and faster, the authors of the new study rely on a search algorithm they developed and optimized themselves for the search for exomoons. They published their method last year and the algorithm is available to all researchers as open source code. When applied to the observational data from Kepler-1625b and Kepler-1708b, the results were astonishing. ""We would have liked to confirm the discovery of exomoons around Kepler-1625b and Kepler-1708b,"" says first author of the new study, MPS scientist Dr. René Heller. ""But unfortunately, our analyses show otherwise,"" he adds.
Hide and seek of an exomoon
The Jupiter-like planet Kepler-1625b made headlines five years ago. Researchers at Columbia University in New York reported strong evidence of a giant moon in its orbit that would dwarf all the moons in the Solar System. The scientists had analyzed data from NASA's Kepler space telescope, which observed more than 100,000 stars during its first mission from 2009 to 2013 and discovered over 2000 exoplanets. However, in the years that followed the 2018 discovery claim, the exomoon candidate forced astronomers to play a cosmic version of hide-and-seek. First it disappeared after the Kepler data had been cleaned from systematic noise. Yet clues were found again in further observations with the Hubble Space Telescope. And then last year, this extraordinary exomoon candidate got company: according to the New York researchers, another giant moon much larger than Earth orbits the Jupiter-sized planet Kepler-1708b.
The right match
""Exomoons are so far away that we cannot see them directly, even with the most powerful modern telescopes,"" explains Dr. René Heller. Instead, telescopes record the fluctuations in brightness of distant stars, the time series of which is called a light curve. Researchers then look for signs of moons in these light curves. If an exoplanet passes in front of its star as seen from Earth, it dims the star by a tiny fraction. This event is called a transit, and it re-occurs regularly with the orbital period of the planet around the star. An exomoon accompanying the planet would have a similar dimming effect. Its trace in the light curve, however, would not only be significantly weaker. Due to the movement of the moon and planet around their mutual center of gravity, this additional dimming in the light curve would follow a rather complicated pattern. And there are other effects to be considered, such as planet-moon eclipses, natural brightness variations of the star and other sources of noise generated during telescopic measurements.

In order to detect the moons nevertheless, both the New York researchers and their German colleagues first calculate many millions of ""artificial"" light curves for all conceivable sizes, mutual distances and orbital orientations of possible planets and moons. An algorithm then compares these simulated light curves with the observed light curve and looks for the best match. The researchers from Göttingen and Sonneberg used their open-source algorithm Pandora, which is optimized for the search for exomoons and can solve this task several orders of magnitude faster than previous algorithms.
No trace of moons 
In the case of the planet Kepler-1708b, the German duo now found that scenarios without a moon can explain the observational data just as accurately as those with a moon. ""The probability of a moon orbiting Kepler-1708b is clearly lower than previously reported,"" says Michael Hippke from the Sonneberg Observatory and co-author of the new study. ""The data do not suggest the existence of an exomoon around Kepler-1708b,"" Hippke continues.
There is much to suggest that Kepler-1625b is also devoid of a giant companion. Transits of this planet in front of its star have previously been observed with the Kepler and the Hubble telescopes. The German researchers now argue that the instantaneous brightness variation of the star across its disk, an effect known as stellar limb darkening, has a crucial impact on the proposed exomoon signal. The limb of the solar disk, for example, appears darker than the center. However, depending on whether you look at the home star of Kepler-1625b through the Kepler or the Hubble telescope, this limb darkening effect looks different. This is because Kepler and Hubble are sensitive to different wavelengths of the light that they receive. The researchers from Göttingen and Sonneberg now argue that their modeling of this effect explains the data more conclusively than a giant exomoon.
Their new, extensive analyses also show that exomoon search algorithms often produce false-positive results. Time and again, they ""discover"" a moon when there really is just a planet transiting its host star. In the case of a light curve like that of Kepler-1625b, the rate of ""false hits"" is likely to be around 11 percent. ""The earlier exomoon claim by our colleagues from New York was the result of a search for moons around dozens of exoplanets,"" says Heller. ""According to our estimates, a false-positive finding is not at all surprising, but almost to be expected,"" he adds.
Strange satellites 
The researchers also used their algorithm to predict the types of actual exomoons that could be clearly detectable in light curves space missions like Kepler. According to their analysis, only particularly large moons orbiting their planet in a wide orbit are detectable using current technology. Compared to the familiar moons of our Solar System, they would all be oddballs: at least twice the size of Ganymede, the largest moon in the Solar System and therefore almost as big as Earth. ""The first exomoons that will be discovered in future observations, such as from the PLATO mission, will certainly be very unusual and therefore exciting to explore,"" says Heller.

","score: 11.932270823638898, grade_level: '12'","score: 13.053601675197768, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41550-023-02148-w,"There are more than 200 moons in our Solar System, but their relatively small radii make similarly sized extrasolar moons very hard to detect with current instruments. The best exomoon candidates so far are two nearly Neptune-sized bodies orbiting the Jupiter-sized transiting exoplanets Kepler-1625 b and Kepler-1708 b, but their existence has been contested. Here we reanalyse the Hubble and Kepler data used to identify the two exomoon candidates employing nested sampling and Bayesian inference techniques coupled with a fully automated photodynamical transit model. We find that the evidence for the Kepler-1625 b exomoon candidate comes almost entirely from the shallowness of one transit observed with Hubble. We interpret this as a fitting artefact in which a moon transit is used to compensate for the unconstrained stellar limb darkening. We also find much lower statistical evidence for the exomoon candidate around Kepler-1708 b than previously reported. We suggest that visual evidence of the claimed exomoon transits is corrupted by stellar activity in the Kepler light curve. Our injection-retrieval experiments of simulated transits in the original Kepler data reveal false positive rates of 10.9% and 1.6% for Kepler-1625 b and Kepler-1708 b, respectively. Moreover, genuine transit signals of large exomoons would tend to exhibit much higher Bayesian evidence than these two claims. We conclude that neither Kepler-1625 b nor Kepler-1708 b are likely to be orbited by a large exomoon."
"
How heavy can an element be? An international team of researchers has found that ancient stars were capable of producing elements with atomic masses greater than 260, heavier than any element on the periodic table found naturally on Earth. The finding deepens our understanding of element formation in stars.

We are, literally, made of star stuff. Stars are element factories, where elements constantly fuse or break apart to create other lighter or heavier elements. When we refer to light or heavy elements, we're talking about their atomic mass. Broadly speaking, atomic mass is based on the number of protons and neutrons in the nucleus of one atom of that element.
The heaviest elements are only known to be created in neutron stars via the rapid neutron capture process, or r-process. Picture a single atomic nucleus floating in a soup of neutrons. Suddenly, a bunch of those neutrons get stuck to the nucleus in a very short time period -- usually in less than one second -- then undergo some internal neutron-to-proton changes, and voila! A heavy element, such as gold, platinum or uranium, forms.
The heaviest elements are unstable or radioactive, meaning they decay over time. One way that they do this is by splitting, a process called fission.
""The r-process is necessary if you want to make elements that are heavier than, say, lead and bismuth,"" says Ian Roederer, associate professor of physics at North Carolina State University and lead author of the research. Roederer was previously at the University of Michigan.
""You have to add many neutrons very quickly, but the catch is that you need a lot of energy and a lot of neutrons to do so,"" Roederer says. ""And the best place to find both are at the birth or death of a neutron star, or when neutron stars collide and produce the raw ingredients for the process.
""We have a general idea of how the r-process works, but the conditions of the process are quite extreme,"" Roederer says. ""We don't have a good sense of how many different kinds of sites in the universe can generate the r-process, we don't know how the r-process ends, and we can't answer questions like, how many neutrons can you add? Or, how heavy can an element be? So we decided to look at elements that could be made by fission in some well-studied old stars to see if we could start to answer some of these questions.""
The team took a fresh look at the amounts of heavy elements in 42 well-studied stars in the Milky Way. The stars were known to have heavy elements formed by the r-process in earlier generations of stars. By taking a broader view of the amounts of each heavy element found in these stars collectively, rather than individually as is more common, they identified previously unrecognized patterns.

Those patterns signaled that some elements listed near the middle of the periodic table -- such as silver and rhodium -- were likely the remnants of heavy element fission. The team was able to determine that the r-process can produce atoms with an atomic mass of at least 260 before they fission.
""That 260 is interesting because we haven't previously detected anything that heavy in space or naturally on Earth, even in nuclear weapon tests,"" Roederer says. ""But seeing them in space gives us guidance for how to think about models and fission -- and could give us insight into how the rich diversity of elements came to be.""
The work appears in Science and was supported in part by the National Science Foundation and the National Aeronautics and Space Administration.

","score: 10.778133907114519, grade_level: '11'","score: 10.941107695746936, grade_levels: ['11'], ages: [16, 17]",10.1126/science.adf1341,"The heaviest chemical elements are naturally produced by the rapid neutron-capture process ( r -process) during neutron star mergers or supernovae. The r -process production of elements heavier than uranium (transuranic nuclei) is poorly understood and inaccessible to experiments so must be extrapolated by using nucleosynthesis models. We examined element abundances in a sample of stars that are enhanced in r -process elements. The abundances of elements ruthenium, rhodium, palladium, and silver (atomic numbers Z = 44 to 47; mass numbers A = 99 to 110) correlate with those of heavier elements (63 ≤ Z ≤ 78, A > 150). There is no correlation for neighboring elements (34 ≤ Z ≤ 42 and 48 ≤ Z ≤ 62). We interpret this as evidence that fission fragments of transuranic nuclei contribute to the abundances. Our results indicate that neutron-rich nuclei with mass numbers >260 are produced in r -process events."
"
Through analysis of high-resolution data from a ten-metre telescope in Hawaii, researchers at Lund University in Sweden have succeeded in generating new knowledge about three stars at the very heart of the Milky Way. The stars proved to be unusually young with a puzzling chemical composition that surprised the researchers.

The study, which has been published in The Astrophysical Journal Letters, examined a group of stars located in the nuclear star cluster that makes up the heart of the galaxy. It concerns three stars that are difficult to study because they are extremely far away from our solar system, and hidden behind enormous clouds of dust and gas that block out light. The fact that the area is also full of stars makes it very complicated to discern individual stars.
In a previous study, the researchers put forward a hypothesis that these specific stars in the middle of the Milky Way could be unusually young.
""We can now confirm this. In our study we have been able to date three of these stars as relatively young, at least as far as astronomers are concerned, with ages of 100 million to about 1 billion years. This can be compared with the sun, which is 4.6 billion years old,"" says Rebecca Forsberg, researcher in astronomy at Lund University.
The nuclear star cluster has mainly been seen, quite rightly, as a very ancient part of the galaxy. But the researchers' new discovery of such young stars indicates that there is also active star formation going on in this ancient component of the Milky Way. However, dating stars 25,000 light years from Earth is not something that can be done in a hurry.
The researchers used high-resolution data from the Keck II telescope in Hawaii, one of the world's largest telescopes with a mirror ten metres in diameter. For further verification, they then measured how much of the heavy element, iron, the stars contained. The element is important for tracing the galaxy's development, as the theories the astronomers have about how stars are formed and galaxies develop indicate that young stars have more of the heavy elements, as heavy elements are formed to an increasing extent over time in the universe.
To determine the level of iron, the astronomers observed the stars' spectra in infrared light which, compared with optical light, are parts of the light spectrum that can more easily shine through the densely dust-laden parts of the Milky Way. It was shown that the iron levels varied considerably, which surprised the researchers.

""The very wide spread of iron levels could indicate that the innermost parts of the galaxy are incredibly inhomogeneous, i.e. unmixed. This is something we had not expected and not only says something about how the centre of the galaxy appears, but also how the early universe may have looked,"" says Brian Thorsbro, researcher in astronomy at Lund University.
The study sheds significant light on our understanding of the early universe and the functioning of the very centre of the Milky Way. The results may also be of benefit to inspire continued and future explorations of the heart of the galaxy, as well as the further development of models and simulations of the formation of galaxies and stars.
""Personally, I think it is very exciting that we can now study the very centre of our galaxy with such a high level of detail. These types of measurements have been standard for observations of the galactic disc where we are located, but have beenunreachable goal for more faraway and exotic parts of the galaxy. We can learn a lot about how our home galaxy was formed and developed from such studies,"" concludes Rebecca Forsberg.
In addition to Lund University, the following organisations and higher education institutions participated in the study: Observatoire de la Côte d'Azur, the University of Tokyo, Observatoire de Paris, the University of California Los Angeles, and Miyagi University of Education.

","score: 13.791766079140888, grade_level: '14'","score: 14.092652036885724, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/ad08b1,"We report metallicities for three ∼Gyr-old stars in the Milky Way nuclear star cluster (NSC) using high-resolution near-infrared spectroscopy. We derive effective temperatures from a calibration with Sc line strength, which yields results in good agreement with other methods, and metallicities from spectral fits to Fe i lines. Our derived metallicities range from −1.2 < [Fe/H] < + 0.5, a span of 1.7 dex. In addition we use isochrone projection to obtain masses of 1.6–4.3 M ⊙, and ages assuming single-star evolution. The oldest of these stars is 1.5 Gyr while the youngest and most metal-rich is only 100 Myr. The wide range in metallicity poses interesting questions concerning the chemical evolution and enrichment of the NSC and adds to the evidence for the presence of a young, metal-rich population in the NSC. We suggest that the candidate intermediate-age, metal-poor ([Fe/H] = −1.2) star may be best explained as a blue straggler from an underlying old population."
"
As astrophysics technology and research continue to advance, one question persists: is there life elsewhere in the universe? The Milky Way galaxy alone has hundreds of billions of celestial bodies, but scientists often look for three crucial elements in their ongoing search: water, energy and organic material. Evidence indicates that Saturn's icy moon Enceladus is an 'ocean world' that contains all three, making it a prime target in the search for life.

During its 20-year mission, NASA's Cassini spacecraft discovered that ice plumes spew from Enceladus' surface at approximately 800 miles per hour (400 m/s). These plumes provide an excellent opportunity to collect samples and study the composition of Enceladus' oceans and potential habitability. However, until now it was not known if the speed of the plumes would fragment any organic compounds contained within the ice grains, thus degrading the samples.
Now researchers from the University of California San Diego have shown unambiguous laboratory evidence that amino acids transported in these ice plumes can survive impact speeds of up to 4.2 km/s, supporting their detection during sampling by spacecraft. Their findings appear in The Proceedings of the National Academy of Sciences (PNAS).
Beginning in 2012, UC San Diego Distinguished Professor of Chemistry and Biochemistry Robert Continetti and his co-workers custom-built a unique aerosol impact spectrometer, designed to study collision dynamics of single aerosols and particles at high velocities. Although not built specifically to study ice grain impacts, it turned out to be exactly the right machine to do so.
""This apparatus is the only one of its kind in the world that can select single particles and accelerate or decelerate them to chosen final velocities,"" stated Continetti. ""From several micron diameters down to hundreds of nanometers, in a variety of materials, we're able to examine particle behavior, such as how they scatter or how their structures change upon impact.""
In 2024 NASA will launch the Europa Clipper, which will travel to Jupiter. Europa, one of Jupiter's largest moons, is another ocean world, and has a similar icy composition to Enceladus. There is hope that the Clipper or any future probes to Saturn will be able to identify a specific series of molecules in the ice grains that could point to whether life exists in the subsurface oceans of these moons, but the molecules need to survive their speedy ejection from the moon and collection by the probe.
Although there has been research into the structure of certain molecules in ice particles, Continetti's team is the first to measure what happens when a single ice grain impacts a surface.

To run the experiment, ice grains were created using electrospray ionization, where water is pushed through a needle held at a high voltage, inducing a charge that breaks the water into increasingly smaller droplets. The droplets were then injected into a vacuum where they freeze. The team measured their mass and charge, then used image charge detectors to observe the grains as they flew through the spectrometer. A key element to the experiment was installing a microchannel plate ion detector to accurately time the moment of impact down to the nanosecond.
The results showed that amino acids -- often called the building blocks of life -- can be detected with limited fragmentation up to impact velocities of 4.2 km/s.
""To get an idea of what kind of life may be possible in the solar system, you want to know there hasn't been a lot of molecular fragmentation in the sampled ice grains, so you can get that fingerprint of whatever it is that makes it a self-contained life form,"" said Continetti. ""Our work shows that this is possible with the ice plumes of Enceladus.""
Continetti's research also raises interesting questions for chemistry itself, including how salt affects the detectability of certain amino acids. It is believed that Enceladus contains vast salty oceans -- more than is present on Earth. Because salt changes the properties of water as a solvent as well as the solubility of different molecules, this could mean that some molecules cluster on the surface of the ice grains, making them more likely to be detected.
""The implications this has for detecting life elsewhere in the solar system without missions to the surface of these ocean-world moons is very exciting, but our work goes beyond biosignatures in ice grains,"" stated Continetti. ""It has implications for fundamental chemistry as well. We are excited by the prospect of following in the footsteps of Harold Urey and Stanley Miller, founding faculty at UC San Diego in looking at the formation of the building blocks of life from chemical reactions activated by ice grain impact.""
This work was supported by the Air Force Office of Science Research (MURI-22, grant FA9550-22-0199) and the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration (grant 80NM0018D0004).

","score: 14.778530579181854, grade_level: '15'","score: 15.962571891454033, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2313447120,"Astrobiology studies are a top priority in answering one of the most fundamental questions in planetary science: Is there life beyond Earth? Saturn’s icy moon Enceladus is a prime target in the search for life in our solar system, identified by NASA as the second-highest priority site for a flagship mission in the next decade. The orbital sampling technique of impact ionization mass spectrometry indicated the presence of complex organics in the small icy plume particles ejected by Enceladus encountered previously by Cassini. However, high interaction velocities caused ambiguity as to the origin and identity of the organics. Laboratory validation of this technique is needed to show that biosignature molecules can survive an impact at hypervelocity speeds for detection. Here, we present results on the hypervelocity impact of organic-laden submicron ice grains for in situ mass spectrometric characterization with the first technique to accurately replicate this plume sampling scenario: the Hypervelocity Ice Grain Impact Mass Spectrometer. Our results show good agreement with Cassini data at comparable compositions. We show that amino acids entrained in ice grains can be detected intact after impact at speeds up to 4.2 km/s and that salt reduces their detectability, validating the predictions from other model systems. Our results provide a benchmark for this orbital sampling method to successfully detect signs of life and for the interpretation of past and future data. This work has implications not only for a potential Enceladus mission but also for the forthcoming Europa Clipper mission."
"
An entirely new way to probe how active black holes behave when they eat has been discovered by an international team of astronomers.

A sample of active black holes at the centre of 136 galaxies were found to shine in microwave and X-ray light in the same way, no matter their appetite for the surrounding galactic matter like gaseous clouds of dust and plasma.
Led by scientists at Cardiff University, the team says the process is not something predicted by our current understanding of how black holes eat.
Currently understood to be intrinsically different depending on their appetites, active black holes are characterised by the layout of their cores and the way they draw in galactic matter.
However, the team found these black holes may have more similarities than previously thought.
Their findings, published in Monthly Notices of the Royal Astronomical Society: Letters, could offer new information about how galaxies evolve.
Lead author, Dr Ilaria Ruffa, a postdoctoral research associate at Cardiff University's School of Physics and Astronomy, said: ""The microwave and X-ray glow we detect from the regions around these black holes seems to directly relate to their mass and to originate from streams of plasma disorderly falling into them.

""This is the case in both systems that have huge appetites that are eating nearly an entire star like our Sun per year, and those with lesser appetites which are eating the same amount of material over 10 million years.
""This was very surprising because we had previously thought that such streams should occur only in systems eating at low rates, whereas in those with huge appetites the black hole should be fed through a more ordered and constant flow of matter (usually called `the accretion disc').""
The team made the discovery while investigating the link between the cold gas around active black holes and how these are fuelled in the WISDOM sample of 35 nearby galaxies captured by the Atacama Large Millimeter/submillimeter Array (ALMA) of telescopes in Chile.
Dr Ruffa added: ""Our study suggests that the microwave light we detect may actually come from these streams of plasma in all types of active black holes, changing our view on how these systems consume matter, and grow to be the cosmic monsters we see today.""
The correlations observed by the team also provide a new method for estimating the masses of black holes -- something astronomers believe is central to understanding their impact on the evolution of galaxies across the Universe.
Co-author Dr Timothy Davis, a Reader in Cardiff University's School of Physics and Astronomy, added: ""Galaxies care very much about the black holes that exist within their cores. And they probably shouldn't because, while we always think of black holes as these super massive beasts consuming everything around them, they are really very small and lightweight in the context of an entire galaxy. ""And yet they have a mysterious non-gravitational influence over material tens of thousands of light years away from them. This is something we have puzzled over as astronomers for many years.
""Measuring black hole masses, and how these compare to the properties of their host galaxies is the best way to begin to understand why this mystery endures. Our new method opens a new window onto this problem, and with the next generation of instruments will allow us to explore this in depth over cosmic time.""
Made up of researchers from theCardiff Hub for Astrophysics Research and Technology (CHART) and international partners from across Europe, Canada, and Japan, the team plans to further test their findings as part of anew ""multi-Wavelength Observations of Nuclear Dark-object Emission Regions"" (WONDER) project led by Dr Ruffa.

","score: 16.22290322580645, grade_level: '16'","score: 18.23827334465195, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnrasl/slad167,"We report the discovery of the ‘mm fundamental plane of black hole accretion’, which is a tight correlation between the nuclear 1 mm luminosity (Lν, mm), the intrinsic 2–10 keV X-ray luminosity (LX, 2–10) and the supermassive black hole (SMBH) mass (MBH) with an intrinsic scatter (σint) of 0.40 dex. The plane is found for a sample of 48 nearby galaxies, most of which are low-luminosity active galactic nuclei. Combining these sources with a sample of high-luminosity (quasar-like) nearby AGN, we show that the plane still holds. We also find that MBH correlates with Lν, mm at a highly significant level, although such correlation is less tight than the mm fundamental plane (σint = 0.51 dex). Crucially, we show that spectral energy distribution (SED) models for both advection-dominated accretion flows (ADAFs) and compact jets can explain the existence of these relations, which are not reproduced by the standard torus-thin accretion disc models usually associated to quasar-like AGN. The ADAF models reproduces the observed relations somewhat better than those for compact jets, although neither provides a perfect fit. Our findings thus suggest that radiatively inefficient accretion processes such as those in ADAFs or compact (and thus possibly young) jets may play a key role in both low- and high-luminosity AGN. This mm fundamental plane also offers a new, rapid method to (indirectly) estimate SMBH masses."
"
A radical theory that consistently unifies gravity and quantum mechanics while preserving Einstein's classical concept of spacetime is announced today in two papers published simultaneously by UCL (University College London) physicists.

Modern physics is founded upon two pillars: quantum theory on the one hand, which governs the smallest particles in the universe, and Einstein's theory of general relativity on the other, which explains gravity through the bending of spacetime. But these two theories are in contradiction with each other and a reconciliation has remained elusive for over a century.
The prevailing assumptionhas been that Einstein's theory of gravity must be modified, or ""quantised,"" in order to fit within quantum theory. This is the approach of two leading candidates for a quantum theory of gravity, string theory and loop quantum gravity.
But a new theory, developed by Professor Jonathan Oppenheim (UCL Physics & Astronomy) and laid out in a new paper in Physical Review X (PRX), challenges that consensus and takes an alternative approach by suggesting that spacetime may be classical -- that is, not governed by quantum theory at all.
Instead of modifying spacetime, the theory -- dubbed a ""postquantum theory of classical gravity"" -- modifies quantum theory and predicts an intrinsic breakdown in predictability that is mediated by spacetime itself. This results in random and violent fluctuations in spacetime that are larger than envisaged under quantum theory, rendering the apparent weight of objects unpredictable if measured precisely enough.
A second paper, published simultaneously in Nature Communications and led by Professor Oppenheim's former PhD students,looks atsome of the consequences of the theory, and proposes an experiment to test it: to measure a mass very precisely to see if its weight appears to fluctuate over time.
For example, the International Bureau of Weights and Measures in France routinely weigh a 1kg mass which used to be the 1kg standard. If the fluctuations in measurements of this 1kg mass are smaller than required for mathematical consistency, the theory can be ruled out.

The outcome of the experiment, or other evidence emerging which would confirm the quantum vs classical nature of spacetime, is the subject of a 5000:1 odds bet between Professor Oppenheim and Professor Carlo Rovelli and Dr Geoff Penington -- leading proponents of quantum loop gravity and string theory respectively.
For the past five years, the UCL research group has been stress-testing the theory, and exploring its consequences.
Professor Oppenheim said: ""Quantum theory and Einstein's theory of general relativity are mathematically incompatible with each other, so it's important to understand how this contradiction is resolved. Should spacetime be quantised, or should we modify quantum theory, or is it something else entirely? Now that we have a consistent fundamental theory in which spacetime does not get quantised, it's anybody's guess.""
Co-author Zach Weller-Davies, who as a PhD student at UCL helped develop the experimental proposal and made key contributions to the theory itself, said: ""This discovery challenges our understanding of the fundamental nature of gravity but also offers avenues to probe its potential quantum nature.
""We have shown that if spacetime doesn't have a quantum nature, then there must be random fluctuations in the curvature of spacetime which have a particular signature that can be verified experimentally.
""In both quantum gravity and classical gravity, spacetime must be undergoing violent and random fluctuations all around us, but on a scale which we haven't yet been able to detect. But if spacetime is classical, the fluctuations have to be larger than a certain scale, and this scale can be determined by another experiment where we test how long we can put a heavy atom in superposition* of being in two different locations.""
Co-authors Dr Carlo Sparaciari and Dr Barbara Šoda, whose analytical and numerical calculations helped guide the project, expressed hope that these experiments could determine whether the pursuit of a quantum theory of gravity is the right approach.

Dr Šoda (formerly UCL Physics & Astronomy, now at the Perimeter Institute of Theoretical Physics, Canada) said: ""Because gravity is made manifest through the bending of space and time, we can think of the question in terms of whether the rate at which time flows has a quantum nature, or classical nature.
""And testing this is almost as simple as testing whether the weight of a mass is constant, or appears to fluctuate in a particular way.""
Dr Sparaciari (UCL Physics & Astronomy) said: ""While the experimental concept is simple, the weighing of the object needs to be carried out with extreme precision.
""But what I find exciting is that starting from very general assumptions, we can prove a clear relationship between two measurable quantities -- the scale of the spacetime fluctuations, and how long objects like atoms or apples can be put in quantum superposition of two different locations. We can then determine these two quantities experimentally.""
Weller-Davies added: ""A delicate interplay must exist if quantum particles such as atoms are able to bend classical spacetime. There must be a fundamental trade-off between the wave nature of atoms, and how large the random fluctuations in spacetime need to be.""
The proposal to test whether spacetime is classical by looking for random fluctuations in mass is complementary to another experimental proposal which aims to verify the quantum nature of spacetime by looking for something called ""gravitationally mediated entanglement.""
Professor Sougato Bose (UCL Physics & Astronomy), who was not involved with the announcement today, but was among those to first propose the entanglement experiment, said: ""Experiments to test the nature of spacetime will take a large-scale effort, but they're of huge importance from the perspective of understanding the fundamental laws of nature. I believe these experiments are within reach -- these things are difficult to predict, but perhaps we'll know the answer within the next 20 years.""
The postquantum theory has implications beyond gravity. The infamous and problematic ""measurement postulate"" of quantum theory is not needed, since quantum superpositions necessarily localise through their interaction with classical spacetime.
The theory was motivated by Professor Oppenheim's attempt to resolve the black hole information problem. According to standard quantum theory, an object going into a black hole should be radiated back out in some way as information cannot be destroyed, but this violates general relativity, which says you can never know about objects that cross the black hole's event horizon. The new theory allows for information to be destroyed, due to a fundamental breakdown in predictability.
* Background information
Quantum mechanics background: All the matter in the universe obeys the laws of quantum theory, but we only really observe quantum behaviour at the scale of atoms and molecules. Quantum theory tells us that particles obey Heisenberg's uncertainty principle, and we can never know their position or velocity at the same time. In fact, they don't even have a definite position or velocity until we measure them. Particles like electrons can behave more like waves and act almost as if they can be in many places at once (more precisely, physicists describe particles as being in a ""superposition"" of different locations).
Quantum theory governs everything from semiconductors which are ubiquitous in computer chips, to lasers, to superconductivity to radioactive decay. In contrast, we say that a system behaves classically if it has definite underlying properties. A cat appears to behave classically -- it is either dead or alive, not both, nor in a superposition of being dead and alive. Why do cats behave classically, and small particles quantumly? We don't know, but the postquantum theory doesn't require the measurement postulate, because the classicality of spacetime infects quantum systems and causes them to localise.
Gravity background: Newton's theory of gravity, gave way to Einstein's theory of general relativity (GR), which holds that gravity is not a force in the usual sense. Instead, heavy objects such as the sun, bend the fabric of spacetime in such a way that causes the earth to revolve around it. Spacetime is just a mathematical object consisting of the three dimensions of space, and time considered as a fourth dimension. General relativity predicted the formation of black holes and the big bang. It holds that time flows at different rates at different points in space, and the GPS in your smartphone needs to account for this in order to properly determine your location.
Historical context: The framework presented by Oppenheim in PRX, and in a companion paper with Sparaciari, Šoda and Weller-Davies, derives the most general consistent form of dynamics in which a quantum system interacts with a classical system. It then applies this framework to the case of general relativity coupled to quantum fields theory. It builds on earlier work and a community of physicists. An experiment to test the quantum nature of gravity via gravitationally mediated entanglement was proposed by Bose et. al. and by C. Marletto and V. Vadral. Two examples of consistent classical-quantum dynamics were discovered in the 90's by Ph. Blanchard and A. Jadzyk, and by Lajos Diosi, and again by David Poulin around 2017. From a different perspective, in 2014 a model of Newtonian gravity coupled to quantum systems via a ""measurement-and-feedback"" approach, was presented by Diosi and Antoinne Tilloy in 2016, and by D Kafri, J. Taylor, and G. Milburn, in 2014. The idea that gravity might be somehow related to the collapse of the wavefunction, dates back to F. Karolyhazy (1966), L. Diosi (1987) and R. Penrose (1996). That classical-quantum couplings might explain localistation of the wavefunction has been suggested by others including M. Hall and M. Reginatto, Diosi and Tilloy, and David Poulin. The idea that spacetime might be classical dates back to I. Sato (1950), and C. Moller (1962), but no consistent theory was found until now.

","score: 15.264452839144795, grade_level: '15'","score: 16.11068748640256, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-43348-2,"We consider two interacting systems when one is treated classically while the other system remains quantum. Consistent dynamics of this coupling has been shown to exist, and explored in the context of treating space-time classically. Here, we prove that any such hybrid dynamics necessarily results in decoherence of the quantum system, and a breakdown in predictability in the classical phase space. We further prove that a trade-off between the rate of this decoherence and the degree of diffusion induced in the classical system is a general feature of all classical quantum dynamics; long coherence times require strong diffusion in phase-space relative to the strength of the coupling. Applying the trade-off relation to gravity, we find a relationship between the strength of gravitationally-induced decoherence versus diffusion of the metric and its conjugate momenta. This provides an experimental signature of theories in which gravity is fundamentally classical. Bounds on decoherence rates arising from current interferometry experiments, combined with precision measurements of mass, place significant restrictions on theories where Einstein’s classical theory of gravity interacts with quantum matter. We find that part of the parameter space of such theories are already squeezed out, and provide figures of merit which can be used in future mass measurements and interference experiments."
"
In a recent study led by University of Florida astronomer Adam Ginsburg, groundbreaking findings shed light on a mysterious dark region at the center of the Milky Way. The turbulent gas cloud, playfully nicknamed ""The Brick"" due to its opacity, has sparked lively debates within the scientific community for years.

To decipher its secrets, Ginsburg and his research team, including UF graduate students Desmond Jeff, Savannah Gramze, and Alyssa Bulatek, turned to the James Webb Space Telescope (JWST). The implications of their observations, published in The Astrophysical Journal, are monumental. The findings not only unearth a paradox within the center of our galaxy but indicate a critical need to re-evaluate established theories regarding star formation.
The Brick has been one of the most intriguing and highly studied regions of our galaxies, thanks to its unexpectedly low star formation rate. It has challenged scientists' expectations for decades: as a cloud full of dense gas, it should be ripe for the birth of new stars. However, it demonstrates an unexpectedly low star formation rate.
Using the JWST's advanced infrared capabilities, the team of researchers peered into the Brick, discovering a substantial presence of frozen carbon monoxide (CO) there. It harbors a significantly larger amount of CO ice than previously anticipated, carrying profound implications for our understanding of star formation processes.
No one knew how much ice there was in the Galactic Center, according to Ginsburg. ""Our observations compellingly demonstrate that ice is very prevalent there, to the point that every observation in the future must take it into account,"" he said.
Stars typically emerge when gases are cool, and the significant presence of CO ice should suggest a thriving area for star formation in the Brick. Yet, despite this wealth of CO, Ginsburg and the research team found that the structure defies expectations. The gas inside the Brick is warmer than comparable clouds.
These observations challenge our understanding of CO abundance in the center of our galaxy and the critical gas-to-dust ratio there. According to the findings, both measures appear to be lower than previously thought.

""With JWST, we're opening new paths to measure molecules in the solid phase (ice), while previously we were limited to looking at gas,"" said Ginsburg. ""This new view gives us a more complete look at where molecules exist and how they are transported. ""
Traditionally, the observation of CO has been limited to emission from gas. To unveil the distribution of CO ice within this vast cloud, the researchers required intense backlighting from stars and hot gas. Their findings move beyond the limitations of previous measurements, which were confined to around a hundred stars. The new results encompass over ten thousand stars, providing valuable insights into the nature of interstellar ice.
Since the molecules present in our Solar System today were, at some point, likely ice on small dust grains that combined to form planets and comets, the discovery also marks a leap forward toward understanding the origins of the molecules that shape our cosmic surroundings.
These are just the team's initial findings from a small fraction of their JWST observations of the Brick. Looking ahead, Ginsburg sets his sights on a more extensive survey of celestial ices.
""We don't know, for example, the relative amounts of CO, water, CO2, and complex molecules,"" said Ginsburg. ""With spectroscopy, we can measure those and get some sense of how chemistry progresses over time in these clouds.""
With the advent of the JWST and its advanced filters, Ginsburg and his colleagues are presented with their most promising opportunity yet to expand our cosmic exploration.

In a recent study led by University of Florida astronomer Adam Ginsburg, groundbreaking findings shed light on a mysterious dark region at the center of the Milky Way. The turbulent gas cloud, playfully nicknamed ""The Brick"" due to its opacity, has sparked lively debates within the scientific community for years.
To decipher its secrets, Ginsburg and his research team, including UF graduate students Desmond Jeff, Savannah Gramze, and Alyssa Bulatek, turned to the James Webb Space Telescope (JWST). The implications of their observations, published in The Astrophysical Journal, are monumental. The findings not only unearth a paradox within the center of our galaxy but indicate a critical need to re-evaluate established theories regarding star formation.
The Brick has been one of the most intriguing and highly studied regions of our galaxies, thanks to its unexpectedly low star formation rate. It has challenged scientists' expectations for decades: as a cloud full of dense gas, it should be ripe for the birth of new stars. However, it demonstrates an unexpectedly low star formation rate.
Using the JWST's advanced infrared capabilities, the team of researchers peered into the Brick, discovering a substantial presence of frozen carbon monoxide (CO) there. It harbors a significantly larger amount of CO ice than previously anticipated, carrying profound implications for our understanding of star formation processes.
No one knew how much ice there was in the Galactic Center, according to Ginsburg. ""Our observations compellingly demonstrate that ice is very prevalent there, to the point that every observation in the future must take it into account,"" he said.
Stars typically emerge when gases are cool, and the significant presence of CO ice should suggest a thriving area for star formation in the Brick. Yet, despite this wealth of CO, Ginsburg and the research team found that the structure defies expectations. The gas inside the Brick is warmer than comparable clouds.
These observations challenge our understanding of CO abundance in the center of our galaxy and the critical gas-to-dust ratio there. According to the findings, both measures appear to be lower than previously thought.
""With JWST, we're opening new paths to measure molecules in the solid phase (ice), while previously we were limited to looking at gas,"" said Ginsburg. ""This new view gives us a more complete look at where molecules exist and how they are transported. ""
Traditionally, the observation of CO has been limited to emission from gas. To unveil the distribution of CO ice within this vast cloud, the researchers required intense backlighting from stars and hot gas. Their findings move beyond the limitations of previous measurements, which were confined to around a hundred stars. The new results encompass over ten thousand stars, providing valuable insights into the nature of interstellar ice.
Since the molecules present in our Solar System today were, at some point, likely ice on small dust grains that combined to form planets and comets, the discovery also marks a leap forward toward understanding the origins of the molecules that shape our cosmic surroundings.
These are just the team's initial findings from a small fraction of their JWST observations of the Brick. Looking ahead, Ginsburg sets his sights on a more extensive survey of celestial ices.
""We don't know, for example, the relative amounts of CO, water, CO2, and complex molecules,"" said Ginsburg. ""With spectroscopy, we can measure those and get some sense of how chemistry progresses over time in these clouds.""
With the advent of the JWST and its advanced filters, Ginsburg and his colleagues are presented with their most promising opportunity yet to expand our cosmic exploration.

","score: 12.095244110617958, grade_level: '12'","score: 13.0579293274155, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acfc34,"We report JWST NIRCam observations of G0.253+0.016, the molecular cloud in the Central Molecular Zone known as “The Brick,” with the F182M, F187N, F212N, F410M, F405N, and F466N filters. We catalog 56,146 stars detected in all six filters using the crowdsource package. Stars within and behind The Brick exhibit prodigious absorption in the F466N filter that is produced by a combination of CO ice and gas. In support of this conclusion, and as a general resource, we present models of CO gas and ice and CO2 ice in the F466N, F470N, and F410M filters. Both CO gas and ice contribute to the observed stellar colors. We show, however, that CO gas does not absorb the Pfβ and Huϵ lines in F466N, but that these lines show excess absorption, indicating that CO ice is present and contributes to observed F466N absorption. The most strongly absorbed stars in F466N are extincted by ∼2 mag, corresponding to >80% flux loss. This high observed absorption requires very high column densities of CO, and thus a total CO column that is in tension with standard CO abundance and/or gas-to-dust ratios. This result suggests the CO/H2 ratio and dust-to-gas ratio are greater in the Galactic Center than in the Galactic disk. Ice and/or gas absorption is observed even in the cloud outskirts, implying that additional caution is needed when interpreting stellar photometry in filters that overlap with ice bands throughout galactic centers."
"
It first appeared as a glowing blob from ground-based telescopes and then vanished completely in images from the Hubble Space Telescope. Now, the ghostly object has reappeared as a faint, yet distinct galaxy in an image from the James Webb Space Telescope (JWST).

Astronomers with the COSMOS-Web collaboration have identified the object AzTECC71 as a dusty star-forming galaxy. Or, in other words, a galaxy that's busy forming many new stars but is shrouded in a dusty veil that's hard to see through -- from nearly 1 billion years after the Big Bang. These galaxies were once thought to be extremely rare in the early universe, but this discovery, plus more than a dozen additional candidates in the first half of COSMOS-Web data that have yet to be described in the scientific literature, suggests they might be three to 10 times as common as expected.
""This thing is a real monster,"" said Jed McKinney, a postdoctoral researcher at The University of Texas at Austin. ""Even though it looks like a little blob, it's actually forming hundreds of new stars every year. And the fact that even something that extreme is barely visible in the most sensitive imaging from our newest telescope is so exciting to me. It's potentially telling us there's a whole population of galaxies that have been hiding from us.""
If that conclusion is confirmed, it suggests the early universe was much dustier than previously thought.
The team published its findings in The Astrophysical Journal.
The COSMOS-Web project -- the largest initial JWST research initiative, co-led by Caitlin Casey, an associate professor at UT Austin -- aims to map up to 1 million galaxies from a part of the sky the size of three full moons. The goal in part is to study the earliest structures of the universe. The team of more than 50 researchers was awarded 250 hours of observing time in JWST's first year and received a first batch of data in December 2022, with more coming in through January 2024.
A dusty star-forming galaxy is hard to see in optical light because much of the light from its stars is absorbed by a veil of dust and then re-emitted at redder (or longer) wavelengths. Before JWST, astronomers sometimes referred to them as ""Hubble-dark galaxies,"" in reference to the previously most-sensitive space telescope.

""Until now, the only way we've been able to see galaxies in the early universe is from an optical perspective with Hubble,"" McKinney said. ""That means our understanding of the history of galaxy evolution is biased because we're only seeing the unobscured, less dusty galaxies.""
This galaxy, AzTECC71, was first detected as an indistinct blob of dust emission by a camera on the James Clerk Maxwell Telescope in Hawaii that sees in wavelengths between far infrared and microwave. The COSMOS-Web team next spotted the object in data collected by another team using the ALMA telescope in Chile, which has higher spatial resolution and can see in infrared. That allowed them to narrow down the location of the source. When they looked in the JWST data in the infrared at a wavelength of 4.44 microns, they found a faint galaxy in exactly the same place. In shorter wavelengths of light, below 2.7 microns, it was invisible.
Now, the team is working to uncover more of these JWST-faint galaxies.
""With JWST, we can study for the first time the optical and infrared properties of this heavily dust-obscured, hidden population of galaxies,"" McKinney said, ""because it's so sensitive that not only can it stare back into the farthest reaches of the universe, but it can also pierce the thickest of dusty veils.""
The team estimates that the galaxy is being viewed at a redshift of about 6, which translates to about 900 million years after the Big Bang.
Study authors from UT Austin are McKinney, Casey, Olivia Cooper (a National Science Foundation graduate research fellow), Arianna Long (a NASA Hubble fellow), Hollis Akins and Maximilien Franco.
Support was provided by NASA through a grant from the Space Telescope Science Institute.

","score: 12.55860781867332, grade_level: '13'","score: 13.26349033063007, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acf614,"A growing number of far-infrared (FIR) bright sources completely invisible in deep extragalactic optical surveys hint at an elusive population of z > 4 dusty, star-forming galaxies. Cycle 1 JWST surveys are now detecting their rest-frame optical light, which provides key insight into their stellar properties and statistical constraints on the population as a whole. This work presents the JWST Near Infrared Camera (NIRCam) counterpart from the COSMOS-Web survey to an FIR SCUBA-2 and Atacama Large Millimeter/submillimeter Array (ALMA) source, AzTECC71, which was previously undetected at wavelengths shorter than 850 μm. AzTECC71, among the reddest galaxies in COSMOS-Web with F277W − F444W ∼ 0.9, is undetected in NIRCam/F150W and F115W and fainter in F444W than other submillimeter galaxies identified in COSMOS-Web by 2–4 magnitudes. This is consistent with the system having both a lower stellar mass and higher redshift than the median dusty, star-forming galaxy. With deep ground- and space-based upper limits combined with detections in F277W, F444W, and the FIR including ALMA Band 6, we find a high probability (99%) that AzTECC71 is at z > 4 with z phot = 5.7 − 0.7 + 0.8 . This galaxy is massive ( log M * / M ⊙ ∼ 10.7 ) and infrared-luminous ( log L IR / L ⊙ ∼ 12.7 ), comparable to other optically undetected but FIR-bright dusty, star-forming galaxies at z > 4. This population of luminous, infrared galaxies at z > 4 is largely unconstrained but comprises an important bridge between the most extreme dust-obscured galaxies and more typical high-redshift star-forming galaxies. If further FIR-selected galaxies that drop out of the F150W filter in COSMOS-Web have redshifts z > 4 like AzTECC71, then the volume density of such sources may be ∼3–10 × greater than previously estimated."
"
The universe is expanding. How fast it does so is described by the so-called Hubble-Lemaitre constant. But there is a dispute about how big this constant actually is: Different measurement methods provide contradictory values. This so-called ""Hubble tension"" poses a puzzle for cosmologists. Researchers from the Universities of Bonn and St. Andrews are now proposing a new solution: Using an alternative theory of gravity, the discrepancy in the measured values can be easily explained -- the Hubble tension disappears. The study has now been published in the Monthly Notices of the Royal Astronomical Society (MNRAS).

The expansion of the universe causes the galaxies to move away from each other. The speed at which they do this is proportional to the distance between them. For instance, if galaxy A is twice as far away from Earth as galaxy B, its distance from us also grows twice as fast. The US astronomer Edwin Hubble was one of the first to recognize this connection.
In order to calculate how fast two galaxies are moving away from each other, it is therefore necessary to know how far apart they are. However, this also requires a constant by which this distance must be multiplied. This is the so-called Hubble-Lemaitre constant, a fundamental parameter in cosmology. Its value can be determined, for example, by looking at the very distant regions of the universe. This gives a speed of almost 244,000 kilometers per hour per megaparsec distance (one megaparsec is just over three million light years).
244.000 kilometers per hour per megaparsec -- or 264,000?
""But you can also look at celestial bodies that are much closer to us -- so-called category 1a supernovae, which are a certain type of exploding star,"" explains Prof. Dr. Pavel Kroupa from the Helmholtz Institute of Radiation and Nuclear Physics at the University of Bonn. It is possible to determine the distance of a 1a supernova to Earth very precisely. We also know that shining objects change color when they move away from us -- and the faster they move, the stronger the change. This is similar to an ambulance, whose siren sounds deeper as it moves away from us.
If we now calculate the speed of the 1a supernovae from their color shift and correlate this with their distance, we arrive at a different value for the Hubble-Lemaitre constant -- namely just under 264,000 kilometers per hour per megaparsec distance. ""The universe therefore appears to be expanding faster in our vicinity -- that is, up to a distance of around three billion light years -- than in its entirety,"" says Kroupa. ""And that shouldn't really be the case.""
However, there has recently been an observation that could explain this. According to this, the Earth is located in a region of space where there is relatively little matter -- comparable to an air bubble in a cake. The density of matter is higher around the bubble. Gravitational forces emanate from this surrounding matter, which pull the galaxies in the bubble towards the edges of the cavity. ""That's why they are moving away from us faster than would actually be expected,"" explains Dr. Indranil Banik from St. Andrews University. The deviations could therefore simply be explained by a local ""under-density.""
In fact, another research group recently measured the average speed of a large number of galaxies that are 600 million light years away from us. ""It was found that these galaxies are moving away from us four times faster than the standard model of cosmology allows,"" explains Sergij Mazurenko from Kroupa's research group, who was involved in the current study.

Bubble in the dough of the universe
This is because the standard model does not provide for such under-densities or ""bubbles"" -- they should not actually exist. Instead, matter should be evenly distributed in space. If this were the case, however, it would be difficult to explain which forces propel the galaxies to their high speed.
""The standard model is based on a theory of the nature of gravity put forward by Albert Einstein,"" says Kroupa. ""However, the gravitational forces may behave differently than Einstein expected."" The working groups from the Universities of Bonn and St. Andrews have used a modified theory of gravity in a computer simulation. This ""modified Newtonian dynamics"" (abbreviation: MOND) was proposed four decades ago by the Israeli physicist Prof. Dr. Mordehai Milgrom. It is still considered an outsider theory today. ""In our calculations, however, MOND does accurately predict the existence of such bubbles,"" says Kroupa.
If one were to assume that gravity actually behaves according to Milgrom's assumptions, the Hubble tension would disappear: There would actually only be one constant for the expansion of the universe, and the observed deviations would be due to irregularities in the distribution of matter.
In addition to the University of Bonn, the University of Saint Andrews (Scotland) and Charles University in Prague (Czech Republic) were also involved in the study. The work was funded by the British Science and Technology Facilities Council.

","score: 11.566426786743914, grade_level: '12'","score: 11.396074517448724, grade_levels: ['12'], ages: [17, 18]",10.1093/mnras/stad3357,"The Λ cold dark matter (ΛCDM) standard cosmological model is in severe tension with several cosmological observations. Foremost is the Hubble tension, which exceeds 5σ confidence. Galaxy number counts show the Keenan–Barger–Cowie (KBC) supervoid, a significant underdensity out to 300 Mpc that cannot be reconciled with ΛCDM cosmology. Haslbauer et al. previously showed that a high local Hubble constant arises naturally due to gravitationally driven outflows from the observed KBC supervoid. The main prediction of this model is that peculiar velocities are typically much larger than expected in the ΛCDM framework. This agrees with the recent discovery by Watkins et al. that galaxies in the CosmicFlows-4 catalogue have significantly faster bulk flows than expected in the ΛCDM model on scales of $100-250 \, h^{-1}$ Mpc. The rising bulk flow curve is unexpected in standard cosmology, causing 4.8σ tension at $200 \, h^{-1}$ Mpc. In this work, we determine what the semi-analytic void model of Haslbauer et al. predicts for the bulk flows on these scales. We find qualitative agreement with the observations, especially if our vantage point is chosen to match the observed bulk flow on a scale of $50 \, h^{-1}$ Mpc. This represents a highly non-trivial success of a previously published model that was not constrained by bulk flow measurements, but which was shown to solve the Hubble tension and explain the KBC void consistently with the peculiar velocity of the Local Group. Our results suggest that several cosmological tensions can be simultaneously resolved if structure grows more efficiently than in the ΛCDM paradigm on scales of tens to hundreds of Mpc."
"
In early November of this year, aurora borealis were observed at surprisingly low latitudes, as far south as Italy and Texas. Such phenomena indicate the impacts of a solar coronal mass ejection on the Earth's magnetic field and atmosphere. Far more dramatic than this recent light show was, it was nothing compared to a huge solar storm in February 1872. The resulting auroral display from that event ringed the globe and produced auroras observed in sites as close to the equator as Bombay and Khartoum. An international team consisting of scientists from nine counties has now published a detailed study of this historically important event, tracing its solar origin and widespread terrestrial impacts. Telegraph communications were widely disrupted by this storm, but in today's technologically dependent society, such a storm would disrupt power grids and satellite communications. Their findings confirm that such extreme storms are more common than previously thought.

In the modern world, we are increasingly dependent on technological infrastructure such as power grids, communication systems, and satellites. However, this dependency makes us increasingly vulnerable to the effects of large geomagnetic storms. ""The longer the power supply could be cut off, the more society, especially those living in urban areas, will struggle to cope,"" Designated Assistant Professor Hayakawa, the lead author of the study, explains. Such storms could be big enough to knock out the power grid, communication systems, airplanes, and satellites in the worst case. ""Could we maintain our life without such infrastructure?"" Hayakawa comments: ""Well, let us just say that it would be extremely challenging.""
Such extreme storms are rare. In recent studies, two such storms stand out: the Carrington storm in September 1859 and the New York Railroad storm in May 1921. The new study suggests that another storm, the Chapman-Silverman storm in February 1872, should also be considered as one of these extreme events. At the time, the storm was big enough to affect the technological infrastructure even in the tropics. Telegraph communications on the submarine cable in the Indian Ocean between Bombay (Mumbai) and Aden were disrupted for hours. Similar disturbances were reported on the land line between Cairo and Khartoum.
The multidisciplinary team, consisting of 22 scientists, was led by Nagoya University in Japan (Hisashi Hayakawa), the US National Solar Observatory (Edward Cliver), and the Royal Observatory of Belgium (Frédéric Clette). The 22 researchers used historical records and modern techniques to assess the Chapman-Silverman storm from its solar origin to its terrestrial impacts. For the solar origin, the group turned to largely forgotten sunspot records from historical archives, especially Belgian and Italian records. For terrestrial impacts, they used geomagnetic field measurements recorded in places as diverse as Bombay (Mumbai), Tiflis (Tbilisi), and Greenwich to assess temporal evolution and storm intensity. They also examined hundreds of accounts of visual aurora in different languages caused by the storm.
One of the more interesting aspects of the 1872 storm was that it likely originated in a medium-sized, but complex, sunspot group near the solar disk centre as confirmed by analyses of solar records from Belgium and Italy. These findings suggest that even a medium-sized sunspot group triggered one of the most extreme magnetic storms in history.
Hayakawa and his colleagues extended their investigations of the historical aurorae by combing through records in libraries, archives, and observatories around the world. They identified more than 700 auroral records that indicated that the night sky was illuminated by magnificent auroral displays from the polar regions to the tropics (down to ≈ 20° in latitude in both hemispheres).
""Our findings confirm the Chapman-Silverman storm in February 1872 as one of the most extreme geomagnetic storms in recent history. Its size rivalled those of the Carrington storm in September 1859 and the NY Railroad storm in May 1921,"" Hayakawa said. ""This means that we now know that the world has seen at least three geomagnetic superstorms in the last two centuries. Space weather events that could cause such a major impact represent a risk that cannot be discounted.""
Hayakawa said: ""Such extreme events are rare. On the one hand, we are fortunate to have missed such superstorms in the modern time. On the other hand, the occurrence of three such superstorms in 6 decades shows that the threat to modern society is real. Therefore, the preservation and analysis of historical records is important to assess, understand, and mitigate the impact of such events.""
Recent auroral displays have been observed from northern Greece and the northern US. Currently, the Sun is approaching the maximum of Solar Cycle 25, predicted to occur in 2025, and we may expect enhanced auroral activity in the coming years.

","score: 12.76236641221374, grade_level: '13'","score: 13.516761751707513, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acc6cc,"We review observations of solar activity, geomagnetic variation, and auroral visibility for the extreme geomagnetic storm on 1872 February 4. The extreme storm (referred to here as the Chapman–Silverman storm) apparently originated from a complex active region of moderate area (≈ 500 μsh) that was favorably situated near disk center (S19° E05°). There is circumstantial evidence for an eruption from this region at 9–10 UT on 1872 February 3, based on the location, complexity, and evolution of the region, and on reports of prominence activations, which yields a plausible transit time of ≈29 hr to Earth. Magnetograms show that the storm began with a sudden commencement at ≈14:27 UT and allow a minimum Dst estimate of ≤ −834 nT. Overhead aurorae were credibly reported at Jacobabad (British India) and Shanghai (China), both at 19.°9 in magnetic latitude (MLAT) and 24.°2 in invariant latitude (ILAT). Auroral visibility was reported from 13 locations with MLAT below ∣20∣° for the 1872 storm (ranging from ∣10.°0∣–∣19.°9∣ MLAT) versus one each for the 1859 storm (∣17.°3∣ MLAT) and the 1921 storm (∣16.°2∣ MLAT). The auroral extension and conservative storm intensity indicate a magnetic storm of comparable strength to the extreme storms of 1859 September (25.°1 ± 0.°5 ILAT and −949 ± 31 nT) and 1921 May (27.°1 ILAT and −907 ± 132 nT), which places the 1872 storm among the three largest magnetic storms yet observed."
"
Micrometeorites originating from icy celestial bodies in the outer Solar System may be responsible for transporting nitrogen to the near-Earth region in the early days of our solar system. That discovery was published today in Nature Astronomy by an international team of researchers, including University of Hawai'i at Manoa scientists, led by Kyoto University.

Nitrogen compounds, such as ammonium salts, are abundant in material born in regions far from the sun, but evidence of their transport to Earth's orbital region had been poorly understood.
""Our recent findings suggests the possibility that a greater amount of nitrogen compounds than previously recognized was transported near Earth, potentially serving as building blocks for life on our planet,"" says Hope Ishii, study co-author and affiliate faculty at the Hawai'i Institute of Geophysics and Planetology in the UH Manoa School of Ocean and Earth Science and Technology (SOEST).
Like all asteroids, Ryugu is a small, rocky object that orbits the sun. The Japan Aerospace Exploration Agency's Hayabusa2 spacecraft explored Ryugu and brought material from its surface back to Earth in 2020. This intriguing asteroid is rich in carbon and has undergone significant space weathering caused by micrometeorite collisions and exposure to charged ions streaming from the sun.
In this study, the scientists aimed to discover clues about the materials arriving near Earth's orbit, where Ryugu is currently located, by examining the evidence of space weathering in Ryugu samples. Using an electron microscope, they found that the surface of the Ryugu samples are covered with tiny minerals composed of iron and nitrogen (iron nitride: Fe4N).
""We proposed that tiny meteorites, called micrometeorites, containing ammonia compounds were delivered from icy celestial bodies and collided with Ryugu,"" said Toru Matsumoto, lead author of the study and assistant professor at Kyoto University. ""The micrometeorite collisions trigger chemical reactions on magnetite and lead to the formation of the iron nitride.""
The iron nitride was observed on the surface of magnetite, which consists of iron and oxygen atoms. When magnetite is exposed to the space environment, oxygen atoms are lost from the surface by the irradiation of hydrogen ions from the sun (solar wind) and by heating through micrometeorite impact. These processes form metallic iron on the very surface of the magnetite, which readily reacts with ammonia, creating ideal conditions for synthesis of iron nitride.

","score: 16.691399342345637, grade_level: '17'","score: 17.81891487029594, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41550-023-02137-z,"Large amounts of nitrogen compounds, such as ammonium salts, may be stored in icy bodies and comets, but the transport of these nitrogen-bearing solids into the near-Earth region is not well understood. Here, we report the discovery of iron nitride on magnetite grains from the surface of the near-Earth C-type carbonaceous asteroid Ryugu, suggesting inorganic nitrogen fixation. Micrometeoroid impacts and solar wind irradiation may have caused the selective loss of volatile species from major iron-bearing minerals to form the metallic iron. Iron nitride is a product of nitridation of the iron metal by impacts of micrometeoroids that have higher nitrogen contents than the CI chondrites. The impactors are probably primitive materials with origins in the nitrogen-rich reservoirs in the outer Solar System. Our observation implies that the amount of nitrogen available for planetary formation and prebiotic reactions in the inner Solar System is greater than previously recognized."
"
The discovery of a planet that is far too massive for its sun is calling into question what was previously understood about the formation of planets and their solar systems, according to Penn State researchers.

In a paper published online today (Nov. 30) in the journal Science, researchers report the discovery of a planet more than 13 times as massive as Earth orbiting the ""ultracool"" star LHS 3154, which itself is nine times less massive than the sun. The mass ratio of the newly found planet with its host star is more than 100 times higher than that of Earth and the sun.
The finding reveals the most massive known planet in a close orbit around an ultracool dwarf star, the least massive and coldest stars in the universe. The discovery goes against what current theories would predict for planet formation around small stars and marks the first time a planet with such high mass has been spotted orbiting such a low-mass star.
""This discovery really drives home the point of just how little we know about the universe,"" said Suvrath Mahadevan, the Verne M. Willaman Professor of Astronomy and Astrophysics at Penn State and co-author on the paper. ""We wouldn't expect a planet this heavy around such a low-mass star to exist.""
He explained that stars are formed from large clouds of gas and dust. After the star is formed, the gas and dust remain as disks of material orbiting the newborn star, which can eventually develop into planets.
""The planet-forming disk around the low-mass star LHS 3154 is not expected to have enough solid mass to make this planet,"" Mahadevan said. ""But it's out there, so now we need to reexamine our understanding of how planets and stars form.""
The researchers spotted the oversized planet, named LHS 3154b, using an astronomical spectrograph built at Penn State by a team of scientists led by Mahadevan. The instrument, called the Habitable Zone Planet Finder or HPF, was designed to detect planets orbiting the coolest stars outside our solar system with the potential for having liquid water -- a key ingredient for life -- on their surfaces.

While such planets are very difficult to detect around stars like our sun, the low temperature of ultracool stars means that planets capable of having liquid water on their surface are much closer to their star relative to Earth and the sun. This shorter distance between these planets and their stars, combined with the low mass of the ultracool stars, results in a detectable signal announcing the presence of the planet, Mahadevan explained.
""Think about it like the star is a campfire. The more the fire cools down, the closer you'll need to get to that fire to stay warm,"" Mahadevan said. ""The same is true for planets. If the star is colder, then a planet will need to be closer to that star if it is going to be warm enough to contain liquid water. If a planet has a close enough orbit to its ultracool star, we can detect it by seeing a very subtle change in the color of the star's spectra or light as it is tugged on by an orbiting planet.""
Located at the Hobby-Eberly Telescope at the McDonald Observatory in Texas, the HPF provides some of the highest precision measurements to date of such infrared signals from nearby stars.
""Making the discovery with HPF was extra special, as it is a new instrument that we designed, developed and built from the ground-up for the purpose of looking at the uncharted planet population around the lowest mass stars,"" said Guðmundur Stefánsson, NASA Sagan Fellow in Astrophysics at Princeton University and lead author on the paper, who helped develop HPF and worked on the study as a graduate student at Penn State. ""Now we are reaping the rewards, learning new and unexpected aspects of this exciting population of planets orbiting some of the most nearby stars.""
The instrument has already yielded critical information in the discovery and confirmation of new planets, Stefánsson explained, but the discovery of the planet LHS 3154b exceeded all expectations.
""Based on current survey work with the HPF and other instruments, an object like the one we discovered is likely extremely rare, so detecting it has been really exciting,"" said Megan Delamer, astronomy graduate student at Penn State and co-author on the paper. ""Our current theories of planet formation have trouble accounting for what we're seeing.""
In the case of the massive planet discovered orbiting the star LHS 3154, the heavy planetary core inferred by the team's measurements would require a larger amount of solid material in the planet-forming disk than current models would predict, Delamer explained. The finding also raises questions about prior understandings of the formation of stars, as the dust-mass and dust-to-gas ratio of the disk surrounding stars like LHS 3154 -- when they were young and newly formed -- would need to be 10 times higher than what was observed in order to form a planet as massive as the one the team discovered.

""What we have discovered provides an extreme test case for all existing planet formation theories,"" Mahadevan said. ""This is exactly what we built HPF to do, to discover how the most common stars in our galaxy form planets -- and to find those planets.""
Other Penn State authors on the paper are Eric Ford, Brianna Zawadzki, Fred Hearty, Andrea Lin, Lawrence Ramsey and Jason Wright. Other authors on the paper are Joshua Winn of Princeton University, Yamila Miguel of the University of Leiden, Paul Robertson of the University of California, Irvine, and Rae Holcomb of the University of California, Shubham Kanodia of the Carnegie Institution for Science, Caleb Cañas of the NASA Goddard Space Flight Center, Joe Ninan of India's Tata Institute of Fundamental Research, Ryan Terrien of Carleton College, Brendan Bowler, William Cochran, Michael Endl and Gary Hill of The University of Texas at Austin, Chad Bender of The University of Arizona, Scott Diddams, Connor Fredrick and Andrew Metcalf of the University of Colorado, Samuel Halverson of California Institute of Technology's Jet Propulsion Laboratory, Andrew Monson of the University of Arizona, Arpita Roy of Johns Hopkins University, Christian Schwab of Australia 's Macquarie University, and Gregory Zeimann of the Hobby-Eberly Telescope at UT Austin.
The work was funded by the Center for Exoplanets and Habitable Worlds at Penn State, the Pennsylvania Space Grant Consortium, the National Aeronautics and Space Administration, the National Science Foundation and the Heising-Simons Foundation.

","score: 16.213127096738713, grade_level: '16'","score: 17.970708353956994, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.abo0233,"Theories of planet formation predict that low-mass stars should rarely host exoplanets with masses exceeding that of Neptune. We used radial velocity observations to detect a Neptune-mass exoplanet orbiting LHS 3154, a star that is nine times less massive than the Sun. The exoplanet’s orbital period is 3.7 days, and its minimum mass is 13.2 Earth masses. We used simulations to show that the high planet-to-star mass ratio (>3.5 × 10 −4 ) is not an expected outcome of either the core accretion or gravitational instability theories of planet formation. In the core-accretion simulations, we show that close-in Neptune-mass planets are only formed if the dust mass of the protoplanetary disk is an order of magnitude greater than typically observed around very low-mass stars."
"
An international team of astronomers has used NASA's James Webb Space Telescope to provide the first observation of water and other molecules in the highly irradiated inner, rocky-planet-forming regions of a disk in one of the most extreme environments in our galaxy. These results suggest that the conditions for terrestrial planet formation can occur in a possible broader range of environments than previously thought.

These are the first results from the eXtreme Ultraviolet Environments (XUE) James Webb Space Telescope program, which focuses on the characterization of planet-forming disks (vast, spinning clouds of gas, dust, and chunks of rock where planets form and evolve) in massive star-forming regions. These regions are likely representative of the environment in which most planetary systems formed. Understanding the impact of environment on planet formation is important for scientists to gain insights into the diversity of the different types of exoplanets.
The XUE program targets a total of 15 disks in three areas of the Lobster Nebula (also known as NGC 6357), a large emission nebula roughly 5,500 light-years away from Earth in the constellation Scorpius. The Lobster Nebula is one of the youngest and closest massive star-formation complexes, and is host to some of the most massive stars in our galaxy. Massive stars are hotter, and therefore emit more ultraviolet (UV) radiation. This can disperse the gas, making the expected disk lifetime as short as a million years. Thanks to Webb, astronomers can now study the effect of UV radiation on the inner rocky-planet forming regions of protoplanetary disks around stars like our Sun.
""Webb is the only telescope with the spatial resolution and sensitivity to study planet-forming disks in massive star-forming regions,"" said team lead María Claudia Ramírez-Tannus of the Max Planck Institute for Astronomy in Germany.
Astronomers aim to characterize the physical properties and chemical composition of the rocky-planet-forming regions of disks in the Lobster Nebula using the Medium Resolution Spectrometer on Webb's Mid-Infrared Instrument (MIRI). This first result focuses on the protoplanetary disk termed XUE 1, which is located in the star cluster Pismis 24.
""Only the MIRI wavelength range and spectral resolution allow us to probe the molecular inventory and physical conditions of the warm gas and dust where rocky planets form,"" added team member Arjan Bik of Stockholm University in Sweden.
Due to its location near several massive stars in NGC 6357, scientists expect XUE 1 to have been constantly exposed to high amounts of ultraviolet radiation throughout its life. However, in this extreme environment the team still detected a range of molecules that are the building blocks for rocky planets.

""We find that the inner disk around XUE 1 is remarkably similar to those in nearby star-forming regions,"" said team member Rens Waters of Radboud University in the Netherlands. ""We've detected water and other molecules like carbon monoxide, carbon dioxide, hydrogen cyanide, and acetylene. However, the emission found was weaker than some models predicted. This might imply a small outer disk radius.""
""We were surprised and excited because this is the first time that these molecules have been detected under these extreme conditions,"" added Lars Cuijpers of Radboud University. The team also found small, partially crystalline silicate dust at the disk's surface. This is considered to be the building blocks of rocky planets.
These results are good news for rocky planet formation, as the science team finds that the conditions in the inner disk resemble those found in the well-studied disks located in nearby star-forming regions, where only low-mass stars form. This suggests that rocky planets can form in a much broader range of environments than previously believed.
The team notes that the remaining observations from the XUE program are crucial to establish the commonality of these conditions.
""XUE 1 shows us that the conditions to form rocky planets are there, so the next step is to check how common that is,"" said Ramírez-Tannus. ""We will observe other disks in the same region to determine the frequency with which these conditions can be observed.""

","score: 13.766678939617083, grade_level: '14'","score: 15.132893961708398, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/ad03f8,"We present the first results of the eXtreme UV Environments (XUE) James Webb Space Telescope (JWST) program, which focuses on the characterization of planet-forming disks in massive star-forming regions. These regions are likely representative of the environment in which most planetary systems formed. Understanding the impact of environment on planet formation is critical in order to gain insights into the diversity of the observed exoplanet populations. XUE targets 15 disks in three areas of NGC 6357, which hosts numerous massive OB stars, including some of the most massive stars in our Galaxy. Thanks to JWST, we can, for the first time, study the effect of external irradiation on the inner (<10 au), terrestrial-planet-forming regions of protoplanetary disks. In this study, we report on the detection of abundant water, CO, 12CO2, HCN, and C2H2 in the inner few au of XUE 1, a highly irradiated disk in NGC 6357. In addition, small, partially crystalline silicate dust is present at the disk surface. The derived column densities, the oxygen-dominated gas-phase chemistry, and the presence of silicate dust are surprisingly similar to those found in inner disks located in nearby, relatively isolated low-mass star-forming regions. Our findings imply that the inner regions of highly irradiated disks can retain similar physical and chemical conditions to disks in low-mass star-forming regions, thus broadening the range of environments with similar conditions for inner disk rocky planet formation to the most extreme star-forming regions in our Galaxy."
"
Cutting-edge computer simulations combined with theoretical calculations are helping astronomers better understand the origin of some of the universe's most energetic and mysterious light shows -- gamma-ray bursts, or GRBs. The new unified model confirms that some long-lasting GRBs are created in the aftermath of cosmic mergers that spawn an infant black hole surrounded by a giant disk of natal material.

Astronomers previously thought that black holes that generate long GRBs typically form when massive stars collapse. However, the new model shows that they can also arise when two dense objects merge, such as a pair of neutron stars -- the dense, dead remnants of massive stars -- or a black hole and a neutron star. The findings explain recently observed long GRBs that astronomers couldn't link to collapsing stars.
The simulation's creators present their results November 29 in The Astrophysical Journal Letters.
""Our findings, which connect observations with underlying physics, have unified many unresolved mysteries in the field of gamma-ray bursts,"" says Ore Gottlieb, lead author on the new study and a research fellow at the Flatiron Institute's Center for Computational Astrophysics (CCA) in New York City. ""For the first time, we can look at GRB observations and know what happened before the black hole formed.""
GRBs are some of the brightest and most violent events in the cosmos. Since their first detection in 1967, GRBs have dazzled and puzzled astronomers. Even decades later, the exact mechanisms that generate the powerful blasts of gamma rays remain uncertain. Over the years, astronomers have noticed two distinct populations of GRBs -- ones lasting less than a second and others that linger for 10 seconds or more. Researchers eventually determined that short GRBs originate from jets launched after the merger of two compact objects and that long GRBs can occur when jets are launched during the collapse of massive rotating stars. But in the past year, two unusual long GRB observations suggested that collapsing behemoths weren't the only things causing long GRBs.
Gottlieb and his colleagues ran state-of-the-art simulations to test how mergers of massive compact objects can spark GRBs. The new simulations took months to run and were conducted in part on one of the Flatiron Institute's supercomputers. The new simulations start when the two compact objects are in a close orbit and follow the jets until they are far from the merger site. This approach allows the researchers to make fewer assumptions about the physics involved. By combining the simulations with constraints from astronomical data, the scientists constructed a unified model for the GRB origins.
The researchers determined that the unusual GRBs are generated in the aftermath of a merger between two compact objects. After merging, the objects create a black hole surrounded by a large accretion disk -- a rapidly-rotating doughnut of magnetically charged leftover material -- that can pump out long GRBs. This information from the simulation helps astronomers understand not only the objects creating these GRBs but also what came before them.
""If we see a long GRB like the ones observed in 2022, we now know that it's coming from a black hole with a massive disk,"" Gottlieb says. ""And knowing there is a massive disk, we now can figure out the ratio of the masses of the two parental objects because their mass ratio is related to the properties of the disk. For example, the merger of unequal-mass neutron stars will inevitably produce a long-duration GRB.""
The scientists hope to use the unified model to identify what objects create short GRBs. Those bursts, the model suggests, could be caused by black holes with smaller accretion disks, or they might come from an object called a hypermassive neutron star, which is an unstable form of the star that quickly collapses to form a black hole, but not before it pulses out short GRBs. The scientists hope that with more observations of GRBs, they can further refine their simulation to determine all GRB origins. Though GRB sightings remain relatively rare, astronomers aim to capture many more when the Vera C. Rubin Observatory starts observing in early 2025.
""As we get more observations of GRBs at different pulse durations, we'll be better able to probe the central engines powering these extreme events,"" Gottlieb says.

","score: 12.449530516431931, grade_level: '12'","score: 14.324826291079809, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/ad096e,"The recent detections of the ∼10 s long γ-ray bursts (GRBs) 211211A and 230307A followed by softer temporally extended emission (EE) and kilonovae point to a new GRB class. Using state-of-the-art first-principles simulations, we introduce a unifying theoretical framework that connects binary neutron star (BNS) and black hole–NS (BH–NS) merger populations with the fundamental physics governing compact binary GRBs (cbGRBs). For binaries with large total masses, M tot ≳ 2.8 M ⊙, the compact remnant created by the merger promptly collapses into a BH surrounded by an accretion disk. The duration of the pre-magnetically arrested disk (MAD) phase sets the duration of the roughly constant power cbGRB and could be influenced by the disk mass, M d . We show that massive disks (M d ≳ 0.1 M ⊙), which form for large binary mass ratios q ≳ 1.2 in BNS or q ≲ 3 in BH–NS mergers, inevitably produce 211211A-like long cbGRBs. Once the disk becomes MAD, the jet power drops with the mass accretion rate as M ̇ ∼ t − 2 , establishing the EE decay. Two scenarios are plausible for short cbGRBs. They can be powered by BHs with less massive disks, which form for other q values. Alternatively, for binaries with M tot ≲ 2.8 M ⊙, mergers should go through a hypermassive NS (HMNS) phase, as inferred for GW170817. Magnetized outflows from such HMNSs, which typically live for ≲1 s, offer an alternative progenitor for short cbGRBs. The first scenario is challenged by the bimodal GRB duration distribution and the fact that the Galactic BNS population peaks at sufficiently low masses that most mergers should go through an HMNS phase."
"
In a remarkable discovery, astronomers have found a disc around a young star in the Large Magellanic Cloud, a galaxy neighbouring ours. It's the first time such a disc, identical to those forming planets in our own Milky Way, has ever been found outside our galaxy. The new observations reveal a massive young star, growing and accreting matter from its surroundings and forming a rotating disc. The detection was made using the Atacama Large Millimeter/submillimeter Array (ALMA) in Chile, in which the European Southern Observatory (ESO) is a partner.

""When I first saw evidence for a rotating structure in the ALMA data I could not believe that we had detected the first extragalactic accretion disc, it was a special moment,""  says Anna McLeod, an associate professor at Durham University in the UK and lead author of the study published today in Nature.  ""We know discs are vital to forming stars and planets in our galaxy, and here, for the first time, we're seeing direct evidence for this in another galaxy.""
This study follows up observations with the Multi Unit Spectroscopic Explorer (MUSE) instrument on ESO's Very Large Telescope (VLT), which spotted a jet from a forming star -- the system was named HH 1177 -- deep inside a gas cloud in the Large Magellanic Cloud.  ""We discovered a jet being launched from this young massive star, and its presence is a signpost for ongoing disc accretion,""  McLeod says. But to confirm that such a disc was indeed present, the team needed to measure the movement of the dense gas around the star.
As matter is pulled towards a growing star, it cannot fall directly onto it; instead, it flattens into a spinning disc around the star. Closer to the centre, the disc rotates faster, and this difference in speed is the smoking gun that shows astronomers an accretion disc is present.
""The frequency of light changes depending on how fast the gas emitting the light is moving towards or away from us,""  explains Jonathan Henshaw, a research fellow at Liverpool John Moores University in the UK, and co-author of the study.  ""This is precisely the same phenomenon that occurs when the pitch of an ambulance siren changes as it passes you and the frequency of the sound goes from higher to lower.""
The detailed frequency measurements from ALMA allowed the authors to distinguish the characteristic spin of a disc, confirming the detection of the first disc around an extragalactic young star.
Massive stars, like the one observed here, form much more quickly and live far shorter lives than low-mass stars like our Sun. In our galaxy, these massive stars are notoriously challenging to observe and are often obscured from view by the dusty material from which they form at the time a disc is shaping around them. However, in the Large Magellanic Cloud, a galaxy 160 000 light-years away, the material from which new stars are being born is fundamentally different from that in the Milky Way. Thanks to the lower dust content, HH 1177 is no longer cloaked in its natal cocoon, offering astronomers an unobstructed, if far away, view of star and planet formation.

","score: 14.209491173416406, grade_level: '14'","score: 15.51088681204569, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06790-2,"The canonical picture of star formation involves disk-mediated accretion, with Keplerian accretion disks and associated bipolar jets primarily observed in nearby, low-mass young stellar objects (YSOs). Recently, rotating gaseous structures and Keplerian disks have been detected around several massive (M > 8 M⊙) YSOs (MYSOs)1–4, including several disk-jet systems5–7. All the known MYSO systems are in the Milky Way, and all are embedded in their natal material. Here we report the detection of a rotating gaseous structure around an extragalactic MYSO in the Large Magellanic Cloud. The gas motion indicates that there is a radial flow of material falling from larger scales onto a central disk-like structure. The latter exhibits signs of Keplerian rotation, so that there is a rotating toroid feeding an accretion disk and thus the growth of the central star. The system is in almost all aspects comparable to Milky Way high-mass YSOs accreting gas from a Keplerian disk. The key difference between this source and its Galactic counterparts is that it is optically revealed rather than being deeply embedded in its natal material as is expected of such a massive young star. We suggest that this is the consequence of the star having formed in a low-metallicity and low-dust content environment. Thus, these results provide important constraints for models of the formation and evolution of massive stars and their circumstellar disks."
"
The U.S. Naval Research Laboratory (NRL), in conjunction with the international Fermi Large Area Telescope Collaboration, announce the discovery of nearly 300 gamma ray pulsars in the publication of their Third Catalog of Gamma Ray Pulsars. This milestone comes 15 years since the launch of Fermi in 2008, when there were fewer than ten known gamma-ray pulsars.

""Work on this important catalog has been going on in our group for years,"" said Paul Ray, Ph.D., head of the High Energy Astrophysics and Applications Section at NRL. ""Our scientists and postdocs have been able to both discover and analyze the timing behavior and spectra of many of these newfound pulsars as part of our quest to further our understanding of these exotic stars that we are able to use as cosmic clocks.""
Pulsars are formed when massive stars have burned though their fuel supply and become unable to resist the inward pull of their own gravity. This results in the star collapsing into a dense, spinning magnetized neutron star. Their spinning magnetic fields send out beams of gamma rays, the most energetic form of light. As these beams sweep across the Earth, the highly sensitive Fermi gamma-ray telescope can observe their periodic pulses of energy. With more than 15 years of data, Fermi has transformed the field of pulsar research.
""We have been very excited about how many millisecond pulsars (MSPs) we have been able to detect using these gamma rays,"" said Matthew Kerr, Ph.D., an NRL astrophysicist. ""We are able to study these objects that began as young pulsars in a binary system. Like a spinning top, they eventually slowed down and became inert. Over the past hundreds of millions of years, their binary companions dumped matter on to them, causing their speed to increase again, very dramatically and far faster than before, ""recycling"" these pulsars into MSPs. These high speed MSPs are now some of Nature's most precise timekeepers.""
Scientists have been using these cosmic clocks in experiments called Pulsar Timing Arrays. By searching for tiny deviations in the times at which the pulses arrive, scientist have been able to search for ripples in spacetime. These ripples, known as gravitational waves, are produced when very massive objects, like pulsars, accelerate very quickly. Very strong gravitational wave sources indicate a cataclysmic crash of dense, compact objects such as neutron stars and black holes.
Recently, several pulsar timing array collaborations, including several NRL researchers, published the first compelling evidence for very low-frequency gravitational waves, likely from the merger of supermassive black holes. ""These are such exciting results,"" said Thankful Cromartie, Ph.D., a National Research Council Research Associate at NRL. ""These low frequency gravitational waves allow us to peer into the centers of massive galaxies and better understand how they were formed.""
The pulsar timing array results have important practical applications as well. The spacetime distortions set a limit on how precisely we can use pulsars for critical navigation and timing. In pulsar-based navigation, these spinning pulsars play much the same role as GPS satellites do, but we are able to use them far beyond the Earth's orbit. ""Now we know where that ultimate stability limit is,"" said Dr. Ray.

Using Fermi's gamma ray detection abilities are also having an impact on pulsar timing array work. ""Previously, once we found an MSP we had to hand it off to radio astronomers to monitor with huge telescopes,"" said Dr. Kerr. ""What we have found is that Fermi is sensitive enough by itself to constrain these gravitational waves and, unlike radio waves, which are bent like the light in a prism as they travel to earth, the gamma rays shoot straight to us. This reduces potential systemic errors in measurements.""
For Megan DeCesar, Ph.D., a George Mason University scientist working at NRL, the most intriguing aspect of the new work in the dramatic increase of ""spider"" pulsars. ""Spider pulsars are named after arachnids that eat their smaller mates,"" DeCesar said. ""Something similar can happen when a neutron star and its binary companion are very close to each other and the MSP ""recycling"" process gets a little carried away. The intense radiation and particle wind from the pulsar eats away at the surface of the other star, resulting in a puffball of evaporated material.""
When compared to radio observations, Fermi is particularly adept at finding these ""spiders"" as, in many cases, radio waves are eclipsed as the pulsar beam passes the remnants of the companion star. Gamma rays, however, are capable of passing right through. ""While it may be that spider systems are also intrinsically brighter in gamma rays, studying them will help us to understand their origins and the bonanza of discoveries we have made with Fermi,"" said DeCesar.
The Third Catalog of Gamma-Ray Pulsars is published in the Astrophysical Journal, Supplement. This compilation of the latest information on gamma ray pulsars, with its consistent form should prove invaluable to the scientific community.

","score: 11.994438054157683, grade_level: '12'","score: 12.500106637910378, grade_levels: ['college'], ages: [18, 24]",10.3847/1538-4357/acee67,"We present 294 pulsars found in GeV data from the Large Area Telescope (LAT) on the Fermi Gamma-ray Space Telescope. Another 33 millisecond pulsars (MSPs) discovered in deep radio searches of LAT sources will likely reveal pulsations once phase-connected rotation ephemerides are achieved. A further dozen optical and/or X-ray binary systems colocated with LAT sources also likely harbor gamma-ray MSPs. This catalog thus reports roughly 340 gamma-ray pulsars and candidates, 10% of all known pulsars, compared to ≤11 known before Fermi. Half of the gamma-ray pulsars are young. Of these, the half that are undetected in radio have a broader Galactic latitude distribution than the young radio-loud pulsars. The others are MSPs, with six undetected in radio. Overall, ≥236 are bright enough above 50 MeV to fit the pulse profile, the energy spectrum, or both. For the common two-peaked profiles, the gamma-ray peak closest to the magnetic pole crossing generally has a softer spectrum. The spectral energy distributions tend to narrow as the spindown power E ̇ decreases to its observed minimum near 1033 erg s−1, approaching the shape for synchrotron radiation from monoenergetic electrons. We calculate gamma-ray luminosities when distances are available. Our all-sky gamma-ray sensitivity map is useful for population syntheses. The electronic catalog version provides gamma-ray pulsar ephemerides, properties, and fit results to guide and be compared with modeling results."
"
Researchers at the Center of Excellence in Space Sciences India at IISER Kolkata have discovered a new relationship between the Sun's magnetic field and its sunspot cycle, that can help predict when the peak in solar activity will occur. Their work indicates that the maximum intensity of solar cycle 25, the ongoing sunspot cycle, is imminent and likely to occur within a year. The new research appears in Monthly Notices of the Royal Astronomical Society: Letters.

Our star, the Sun, is made up of hot ionized gas known as plasma. Huge plasma flows and convection conspire together to form magnetic fields inside the Sun which manifest on the surface as dark spots. These sunspots are comparable to the size of the Earth and are seats of intense magnetism, about 10,000 times stronger than the Earth's magnetic field.
Sometimes the sunspot magnetic fields are disrupted in violent events which result in the birth of solar magnetic storms such as flares or coronal mass ejections. These storms release high energy radiation and hurl vast amounts of magnetized plasma in to outer space. The most intense of these storms can cause serious damage to orbiting satellites, electric power grids and telecommunications when Earth directed.
Centuries of observations starting from the early 1600s show that the number of sunspots observed on the Sun varies periodically. Approximately every 11 years the number of spots and the intensity of solar activity reach a peak when the most violent perturbations in planetary space environments -- or space weather -- are expected. However, predicting when this peak is going to occur has remained challenging.
The solar cycle is produced by a dynamo mechanism driven by energy from plasma flows inside the Sun. This dynamo mechanism is understood to involve two primary components of the Sun's magnetic field, one which manifests in the cycle of sunspots and another which manifests in a recycling of the large-scale dipole field of the Sun; the latter is much like the Earth's magnetic field -- stretching from one pole of the Sun to another. With the cycle of sunspots, the Sun's dipole field is also observed to wax and wane in strength, the north and south magnetic poles swap places, also every 11 years.
In 1935, Swiss astronomer Max Waldmeier discovered that the faster the rate of rise of a sunspot cycle the stronger its strength, so stronger cycles take less time to rise to their peak intensity. This relationship has often been utilised to forecast the strength of a sunspot cycle based on observations of its early rising phase.
In a research manuscript appearing in the Monthly Notices of the Royal Astronomical Society Letters, Priyansh Jaswal, Chitradeep Saha and Dibyendu Nandy of IISER Kolkata report the discovery of a new relationship, namely, the rate of decrease in the Sun's dipole magnetic field is also related to the rate of rise of the ongoing sunspot cycle.
This discovery, utilising decades-old data archives from multiple ground-based solar observatories around the world, complements the Waldmeier effect, connecting the two primary magnetic field components of the Sun and supporting the theory that the evolution of sunspots are integral to the functioning of the solar dynamo process rather than being a mere symptom of it.
The scientists demonstrate how observations of the rate of decrease of the Sun's dipole magnetic field can be usefully combined with sunspot observations to predict when the ongoing cycle would peak. Their analysis suggests that the maximum of solar cycle 25 is most likely to occur in early 2024 with an uncertainty in the estimate that ranges to September 2024.
With this discovery, a new window opens up for forecasting the timing of the peak of solar cycles -- when the most intense activity and most frequent space weather disturbances are expected.

","score: 15.16585826314261, grade_level: '15'","score: 16.61813534708103, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnrasl/slad122,"Sunspots have been observed for over four centuries and the magnetic nature of sunspot cycles has been known for about a century; however, some of its underlying physics still remain elusive. It is known that the solar magnetic cycle involves a recycling of magnetic flux between the poloidal and toroidal components of the magnetic field, that manifests as the solar dipole and sunspots, respectively. Here, we report the discovery of a new relationship between the rise rate of the sunspot cycle and the decay rate of the solar (axial) dipole moment. This provides an extension to the Waldmeier effect in sunspot cycles and points to the existence of a causal connection between the aforementioned physical quantities, which can be succinctly stated as the decay rate of the Sun’s dipole moment is related to the rate of rise of the following sunspot cycle. We demonstrate how one may take advantage of this new relationship to predict the timing of the sunspot cycle. Our analysis indicates solar cycle 25 is expected to be a weak-moderate cycle, peaking in $2024.00_{-0.49}^{+0.68}$."
"
In 1991, the University of Utah Fly's Eye experiment detected the highest-energy cosmic ray ever observed. Later dubbed the Oh-My-God particle, the cosmic ray's energy shocked astrophysicists. Nothing in our galaxy had the power to produce it, and the particle had more energy than was theoretically possible for cosmic rays traveling to Earth from other galaxies. Simply put, the particle should not exist.

The Telescope Array has since observed more than 30 ultra-high-energy cosmic rays, though none approaching the Oh-My-God-level energy. No observations have yet revealed their origin or how they are able to travel to the Earth.
On May 27, 2021, the Telescope Array experiment detected the second-highest extreme-energy cosmic ray. At 2.4 x 1020eV, the energy of this single subatomic particle is equivalent to dropping a brick on your toe from waist height. Led by the University of Utah (the U) and the University of Tokyo, the Telescope Array consists of 507 surface detector stations arranged in a square grid that covers 700 km2 (~270 miles2) outside of Delta, Utah in the state's West Desert. The event triggered 23 detectors at the north-west region of the Telescope Array, splashing across 48 km2 (18.5 mi2). Its arrival direction appeared to be from the Local Void, an empty area of space bordering the Milky Way galaxy.
""The particles are so high energy, they shouldn't be affected by galactic and extra-galactic magnetic fields. You should be able to point to where they come from in the sky,"" said John Matthews, Telescope Array co-spokesperson at the U and co-author of the study. ""But in the case of the Oh-My-God particle and this new particle, you trace its trajectory to its source and there's nothing high energy enough to have produced it. That's the mystery of this -- what the heck is going on?""
In their observation that published on Nov. 24, 2023, in the journal Science, an international collaboration of researchers describe the ultra-high-energy cosmic ray, evaluate its characteristics, and conclude that the rare phenomena might follow particle physics unknown to science. The researchers named it the Amaterasu particle after the sun goddess in Japanese mythology. The Oh-My-God and the Amaterasu particles were detected using different observation techniques, confirming that while rare, these ultra-high energy events are real.
""These events seem like they're coming from completely different places in the sky. It's not like there's one mysterious source,"" said John Belz, professor at the U and co-author of the study. ""It could be defects in the structure of spacetime, colliding cosmic strings. I mean, I'm just spit-balling crazy ideas that people are coming up with because there's not a conventional explanation.""
Natural particle accelerators
Cosmic rays are echoes of violent celestial events that have stripped matter to its subatomic structures and hurled it through universe at nearly the speed of light. Essentially cosmic rays are charged particles with a wide range of energies consisting of positive protons, negative electrons, or entire atomic nuclei that travel through space and rain down onto Earth nearly constantly.

Cosmic rays hit Earth's upper atmosphere and blasts apart the nucleus of oxygen and nitrogen gas, generating many secondary particles. These travel a short distance in the atmosphere and repeat the process, building a shower of billions of secondary particles that scatter to the surface. The footprint of this secondary shower is massive and requires that detectors cover an area as large as the Telescope Array. The surface detectors utilize a suite of instrumentation that gives researchers information about each cosmic ray; the timing of the signal shows its trajectory and the amount of charged particles hitting each detector reveals the primary particle's energy.
Because particles have a charge, their flight path resembles a ball in a pinball machine as they zigzag against the electromagnetic fields through the cosmic microwave background. It's nearly impossible to trace the trajectory of most cosmic rays, which lie on the low- to middle-end of the energy spectrum. Even high-energy cosmic rays are distorted by the microwave background. Particles with Oh-My-God and Amaterasuenergy blast through intergalactic space relatively unbent. Only the most powerful of celestial events can produce them.
""Things that people think of as energetic, like supernova, are nowhere near energetic enough for this. You need huge amounts of energy, really high magnetic fields to confine the particle while it gets accelerated,"" said Matthews.
Ultra-high-energy cosmic rays must exceed 5 x 1019 eV. This means that a single subatomic particle carries the same kinetic energy as a major league pitcher's fast ball and has tens of millions of times more energy than any human-made particle accelerator can achieve. Astrophysicists calculated this theoretical limit, known as the Greisen-Zatsepin-Kuzmin (GZK) cutoff, as the maximum energy a proton can hold traveling over long distances before the effect of interactions of the microwave background radiation take their energy. Known source candidates, such as active galactic nuclei or black holes with accretion disks emitting particle jets, tend to be more than 160 million light years away from Earth. The new particle's 2.4 x 1020 eV and the Oh-My-God particle's 3.2 x 1020 eV easily surpass the cutoff.
Researchers also analyze cosmic ray composition for clues of its origins. A heavier particle, like iron nuclei, are heavier, have more charge and are more susceptible to bending in a magnetic field than a lighter particle made of protons from a hydrogen atom. The new particle is likely a proton. Particle physics dictates that a cosmic ray with energy beyond the GZK cutoff is too powerful for the microwave background to distort its path, but back tracing its trajectory points towards empty space.
""Maybe magnetic fields are stronger than we thought, but that disagrees with other observations that show they're not strong enough to produce significant curvature at these ten-to-the-twentieth electron volt energies,"" said Belz. ""It's a real mystery.""
Expanding the footprint

The Telescope Array is uniquely positioned to detect ultra-high-energy cosmic rays. It sits at about 1,200 m (4,000 ft), the elevation sweet-spot that allows secondary particles maximum development, but before they start to decay. Its location in Utah's West Desert provides ideal atmospheric conditions in two ways: the dry air is crucial because humidity will absorb the ultraviolet light necessary for detection; and the region's dark skies are essential, as light pollution will create too much noise and obscure the cosmic rays.
Astrophysicists are still baffled by the mysterious phenomena. The Telescope Array is in the middle of an expansion that that they hope will help crack the case. Once completed, 500 new scintillator detectors will expand the Telescope Array will sample cosmic ray-induced particle showers across 2,900 km2  (1,100 mi2 ), an area nearly the size of Rhode Island. The larger footprint will hopefully capture more events that will shed light on what's going on.

","score: 13.087766910088224, grade_level: '13'","score: 13.883427287446715, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.abo5095,"Cosmic rays are energetic charged particles from extraterrestrial sources, with the highest-energy events thought to come from extragalactic sources. Their arrival is infrequent, so detection requires instruments with large collecting areas. In this work, we report the detection of an extremely energetic particle recorded by the surface detector array of the Telescope Array experiment. We calculate the particle’s energy as 244 ± 29 stat . − 76 + 51 syst . exa–electron volts (~40 joules). Its arrival direction points back to a void in the large-scale structure of the Universe. Possible explanations include a large deflection by the foreground magnetic field, an unidentified source in the local extragalactic neighborhood, or an incomplete knowledge of particle physics."
"
U.S. Naval Research Laboratory (NRL) researchers have discovered solar-wind hydrogen in lunar samples, which indicates that water on the surface of the Moon may provide a vital resource for future lunar bases and longer-range space exploration. Space-based resource identification is a key factor in planning for civilian- and government-led space exploration.

""Hydrogen has the potential to be a resource that can be used directly on the lunar surface when there are more regular or permanent installations there,"" said Dr. Katherine D. Burgess, geologist in NRL's Materials Science and Technology Division. ""Locating resources and understanding how to collect them prior to getting to the Moon is going to be incredibly valuable for space exploration.""
The Apollo lunar soil samples were provided by a NASA-funded research mission to NRL scientists for investigation and testing. The research team, led by scientists in NRL's Materials Science and Technology Division, continues to study lunar surface and asteroidal samples to gain understanding of how surfaces interact with the space environment, which is known as space weathering. Previous testing from additional Apollo samples confirmed location of solar wind helium in lunar soil grains.
""This is the first time scientists have demonstrated detection of hydrogen-bearing species within vesicles in lunar samples,"" said Dr. Burgess. ""Previously, the same team at NRL used state-of-the-art techniques such as scanning transmission electron microscopy and electron energy loss spectroscopy to detect helium in lunar samples, and other researchers have found water in other planetary samples, but this is the first publication to show hydrogen in-situ in lunar samples.""
The research article was published to the Communications Earth & Environment journal on Wednesday, Nov. 15, 2023.

","score: 15.702012987012989, grade_level: '16'","score: 17.151808441558437, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s43247-023-01060-5,"Water on the surface of the Moon is a potentially vital resource for future lunar bases and longer-range space exploration. Effective use of the resource depends on developing an understanding of where and how within the regolith the water is formed and retained. Solar wind hydrogen, which can form molecular hydrogen, water and/or hydroxyl on the lunar surface, reacts and is retained differently depending on regolith mineral content, thermal history, and other variables. Here we present transmission electron microscopy analyses of Apollo lunar soil 79221 that reveal solar-wind hydrogen concentrated in vesicles as molecular hydrogen in the calcium-phosphates apatite and merrillite. The location of the vesicles in the space weathered grain rims offers a clear link between the vesicle contents and solar wind irradiation, as well as individual grain thermal histories. Hydrogen stored in grain rims is a source for volatiles released in the exosphere during impacts."
"
A ground-breaking new discovery by University of Leeds scientists could transform the way astronomers understand some of the biggest and most common stars in the Universe.

Research by PhD student Jonathan Dodd and Professor René Oudmaijer, from the University's School of Physics and Astronomy, points to intriguing new evidence that massive Be stars -- until now mainly thought to exist in double stars -- could in fact be ""triples.""
The remarkable discovery could revolutionise our understanding of the objects -- a subset of B stars -- which are considered an important ""test bed"" for developing theories on how stars evolve more generally.
These Be stars are surrounded by a characteristic disc made of gas -- similar to the rings of Saturn in our own Solar System. And although Be stars have been known for about 150 years -- having first been identified by renowned Italian astronomer Angelo Secchi in 1866 -- until now, no one has known how they were formed.
Consensus among astronomers so far has said the discs are formed by the rapid rotation of the Be stars, and that itself can be caused by the stars interacting with another star in a binary system.
Triple systems
Mr Dodd, corresponding author of the research, said: ""The best point of reference for that is if you've watched Star Wars, there are planets where they have two Suns.""
But now, by analysing data from the European Space Agency's Gaia satellite, the scientists say they have found evidence these stars actually exist in triple systems -- with three bodies interacting instead of just two.

Mr Dodd added: ""We observed the way the stars move across the night sky, over longer periods like 10 years, and shorter periods of around six months. If a star moves in a straight line, we know there's just one star, but if there is more than one, we will see a slight wobble or, in the best case, a spiral.
""We applied this across the two groups of stars that we are looking at -- the B stars and the Be stars -- and what we found, confusingly, is that at first it looks like the Be stars have a lower rate of companions than the B stars. This is interesting because we'd expect them to have a higher rate.""
However, Principal Investigator Prof Oudmaijer said: ""The fact that we do not see them might be because they are now too faint to be detected.""
Mass transfer
The researchers then looked at a different set of data, looking for companion stars that are further away, and found that at these larger separations the rate of companion stars is very similar between the B and Be stars.
From this, they were able to infer that in many cases a third star is coming into play, forcing the companion closer to the Be star -- close enough that mass can be transferred from one to the other and form the characteristic Be star disc. This could also explain why we do not see these companions anymore; they have become too small and faint to be detected after the ""vampire"" Be star has sucked in so much of their mass.

The discovery could have huge impacts on other areas of astronomy -- including our understanding of black holes, neutron stars and gravitational wave sources.
Prof Oudmaijer said: ""There's a revolution going on in physics at the moment around gravitational waves. We have only been observing these gravitational waves for a few years now, and these have been found to be due to merging black holes.
""We know that these enigmatic objects -- black holes and neutron stars -- exist, but we don't know much about the stars that would become them. Our findings provide a clue to understanding these gravitational wave sources.""
He added: ""Over the last decade or so, astronomers have found that binarity is an incredibly important element in stellar evolution. We are now moving more towards the idea it is even more complex than that and that triple stars need to be considered.""
""Indeed,"" Oudmaijer said, ""triples have become the new binaries.""
The team behind the discovery includes PhD student Mr Dodd and Prof Oudmaijer from Leeds, along with University of Leeds PhD student Isaac Radley and two former Leeds academics Dr Miguel Vioque of the ALMA Observatory in Chile and Dr Abigail Frost at the European Southern Observatory in Chile. The team received funding from the Science and Technology Facilities Council (STFC).

","score: 13.371237901171678, grade_level: '13'","score: 14.692846663270508, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnras/stad3105,"Be stars make up almost 20 per cent of the B star population, and are rapidly rotating stars surrounded by a disc; however the origin of this rotation remains unclear. Mass transfer within close binaries provides the leading hypothesis, with previous detections of stripped companions to Be stars supporting this. Here, we exploit the exquisite astrometric precision of Gaia to carry out the largest to date comparative study into the binarity of matched samples of nearby B and Be stars from the Bright Star Catalogue. By utilizing new ‘proper motion anomaly’ values, derived from Gaia DR2 and DR3 astrometric data alongside previous values calculated using Hipparcos and Gaia data, and the Gaia-provided RUWE, we demonstrate that we can identify unresolved binaries down to separations of 0.02 arcsec. Using these measures, we find that the binary fractions of B and Be stars are similar between 0.04 and 10 arcsec, but the Be binary fraction is significantly lower than that of the B stars for separations below 0.04 arcsec. As the separation range of these ‘missing’ binaries is too large for mass transfer, and stripped companions are not retrieved by these measures, we suggest the companions migrate inwards via binary hardening within a triple system. This confirms statistically for the first time the hypothesis that binary interaction causes the Be phenomenon, with migration causing the dearth of Be binaries between 0.02 and 0.04 arcsec. Furthermore, we suggest that triplicity plays a vital role in this migration, and thus in the formation of Be stars as a whole."
"
Our own Milky Way galaxy is part of a much larger formation, the local Supercluster structure, which contains several massive galaxy clusters and thousands of individual galaxies. Due to its pancake-like shape, which measures almost a billion light years across, it is also referred to as the Supergalactic Plane.

Most galaxies in the universe fall into one of two categories: firstly, elliptical galaxies, made mostly of old stars and containing typically extremely massive central black holes, and secondly actively star-forming disk galaxies, with a spiral-like structure similar to the Milky Way's. Both types of galaxies are also found in the Local Supercluster, but while the Supergalactic Plane is teeming with bright ellipticals, bright disk galaxies are conspicuously absent.
A cosmic anomaly challenges the standard model of cosmology
This peculiar segregation of galaxies in the Local Universe, which has been known since the 1960s, features prominently in a recent list of ""cosmic anomalies"" compiled by renowned cosmologist and 2019 Nobel laureate Jim Peebles.
Now an international team led by University of Helsinki astrophysicists Till Sawala and Peter Johansson appear to have found an explanation. In an article published in Nature Astronomy, they show how the different distributions of elliptical and disk galaxies arise naturally due to the different environments found inside and outside of the Supergalactic Plane.
""In the dense galaxy clusters that are found on the Supergalactic Plane, galaxies experience frequent interactions and mergers, which leads to the formation of ellipticals and the growth of supermassive black holes. By contrast, away from the plane, galaxies can evolve in relative isolation, which helps them preserve their spiral structure,"" says Till Sawala.
In their work, the team made use of the SIBELIUS (Simulations Beyond The Local Universe) simulation, that follows the evolution of the universe over 13.8 billion years, from the early universe to the present. It was run on supercomputers in England and on CSC's Mahti supercomputer in Finland.
While most similar simulations consider random patches of the universe which cannot be directly compared to observations, the SIBELIUS simulation aims to precisely reproduce the observed structures, including the Local Supercluster. The final simulation result is remarkably consistent with the observations.
""By chance, I was invited to a symposium in honour of Jim Peebles last December, where he presented the problem in his lecture. And I realised that we had already completed a simulation that might contain the answer,"" comments Till Sawala. ""Our research shows that the known mechanisms of galaxy evolution also work in this unique cosmic environment.""
Next to the physics department, the University of Helsinki's Kumpula campus hosts a large statue showing the distribution of galaxies in the Local Supercluster. It was inaugurated 20 years ago by the British cosmologist Carlos Frenk, who is one of the co-authors of this new study. ""The distribution of galaxies in the Local Supercluster is indeed remarkable,"" says Frenk of the new results. ""But it is not an anomaly: our result shows that our standard model of dark matter can produce the most remarkable structures in the universe.""

","score: 15.687545454545457, grade_level: '16'","score: 16.37509671179884, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41550-023-02130-6,"Galaxies of different types are not equally distributed in the Local Universe. In particular, the supergalactic plane is prominent among the brightest ellipticals, but inconspicuous among the brightest disk galaxies. This striking difference provides a unique test for our understanding of galaxy and structure formation. Here we use the SIBELIUS DARK constrained simulation to confront the predictions of the standard Lambda Cold Dark Matter (ΛCDM) model and standard galaxy formation theory with these observations. We find that SIBELIUS DARK reproduces the spatial distributions of disks and ellipticals and, in particular, the observed excess of massive ellipticals near the supergalactic equator. We show that this follows directly from the local large-scale structure and from the standard galaxy formation paradigm, wherein disk galaxies evolve mostly in isolation, while giant ellipticals congregate in the massive clusters that define the supergalactic plane. Rather than being anomalous as earlier works have suggested, the distributions of giant ellipticals and disks in the Local Universe and in relation to the supergalactic plane are key predictions of the ΛCDM model."
"
Similar to human teenagers, teenage galaxies are awkward, experience growth spurts and enjoy heavy metal -- nickel, that is.

A Northwestern University-led team of astrophysicists has just analyzed the first results from the CECILIA (Chemical Evolution Constrained using Ionized Lines in Interstellar Aurorae) Survey, a program that uses NASA's James Webb Space Telescope (JWST) to study the chemistry of distant galaxies.
According to the early results, so-called ""teenage galaxies"" -- which formed two-to-three billion years after the Big Bang -- are unusually hot and contain unexpected elements, like nickel, which are notoriously difficult to observe.
The research will be published on Monday (Nov. 20) in The Astrophysical Journal Letters. It marks the first in a series of forthcoming studies from the CECILIA Survey.
""We're trying to understand how galaxies grew and changed over the 14 billion years of cosmic history,"" said Northwestern's Allison Strom, who led the study. ""Using the JWST, our program targets teenage galaxies when they were going through a messy time of growth spurts and change. Teenagers often have experiences that determine their trajectories into adulthood. For galaxies, it's the same.""
One of the principal investigators of the CECILIA Survey, Strom is an assistant professor of physics and astronomy at Northwestern's Weinberg College of Arts and Sciences and a member of Northwestern's Center for Interdisciplinary Exploration and Research in Astrophysics (CIERA). Strom co-leads the CECILIA Survey with Gwen Rudie, a staff scientist at Carnegie Observatories.
'Chemical DNA' gives insight into galaxy formation
Named after Cecilia Payne-Gaposchkin, one of the first women to earn a Ph.D. in astronomy, the CECILIA Survey observes spectra (or the amount of light across different wavelengths) from distant galaxies. Strom likens a galaxy's spectra to its ""chemical DNA."" By examining this DNA during a galaxy's ""teenage"" years, researchers can better understand how it grew and how it will evolve into a more mature galaxy.

For example, astrophysicists still don't understand why some galaxies appear ""red and dead"" while others, like our Milky Way, are still forming stars. A galaxy's spectrum can reveal its key elements, such as oxygen and sulfur, which provide a window into what a galaxy was previously doing and what it might do in the future.
""These teenage years are really important because that's when the most growth happens,"" Strom said. ""By studying this, we can begin exploring the physics that caused the Milky Way to look like the Milky Way -- and why it might look different from its neighboring galaxies.""
In the new study, Strom and her collaborators used the JWST to observe 33 distant teenaged galaxies for a continuous 30 hours this past summer. Then, they combined spectra from 23 of those galaxies to construct a composite picture.
""This washes out the details of individual galaxies but gives us a better sense of an average galaxy. It also allows us to see fainter features,"" Strom said. ""It's significantly deeper and more detailed than any spectrum we could collect with ground-based telescopes of galaxies from this time period in the universe's history.""
Spectra surprises
The ultra-deep spectrum revealed eight distinct elements: Hydrogen, helium, nitrogen, oxygen, silicon, sulfur, argon and nickel. All elements that are heavier than hydrogen and helium form inside stars. So, the presence of certain elements provides information about star formation throughout a galaxy's evolution.

While Strom expected to see lighter elements, she was particularly surprised by the presence of nickel. Heavier than iron, nickel is rare and incredibly difficult to observe.
""Never in my wildest dreams did I imagine we would see nickel,"" Strom said. ""Even in nearby galaxies, people don't observe this. There has to be enough of an element present in a galaxy and the right conditions to observe it. No one ever talks about observing nickel. Elements have to be glowing in gas in order for us to see them. So, in order for us to see nickel, there may be something unique about the stars within the galaxies.""
Another surprise: The teenage galaxies were extremely hot. By examining the spectra, physicists can calculate a galaxy's temperature. While the hottest pockets with galaxies can reach over 9,700 degrees Celsius (17,492 degrees Fahrenheit), the teenage galaxies clock in at higher than 13,350 degrees Celsius (24,062 degrees Fahrenheit).
""This is just additional evidence of how different galaxies likely were when they were younger,"" Strom said. ""Ultimately, the fact that we see a higher characteristic temperature is just another manifestation of their different chemical DNA because the temperature and chemistry of gas in galaxies are intrinsically linked.""
The study, ""CECILIA: Faint emission line spectrum of z~2-3 star-forming galaxies,"" was supported by NASA, the Pittsburgh Foundation and the Research Corporation for Scientific Advancement. The data were obtained from the Mikulski Archive for Space Telescopes at the Space Telescope Science Institute and from the W.M. Keck Observatory.

","score: 12.193950255614912, grade_level: '12'","score: 12.540157389855821, grade_levels: ['college'], ages: [18, 24]",10.3847/2041-8213/ad07dc,"We present the first results from Chemical Evolution Constrained Using Ionized Lines in Interstellar Aurorae (CECILIA), a Cycle 1 JWST NIRSpec/MSA program that uses ultra-deep ∼30 hr G235M/F170LP observations to target multiple electron temperature-sensitive auroral lines in the spectra of 33 galaxies at z ∼ 1–3. Using a subset of 23 galaxies, we construct two ∼600 object-hour composite spectra, both with and without the stellar continuum, and use these to investigate the characteristic rest-optical (λ rest ≈ 5700–8500 Å) spectrum of star-forming galaxies at the peak epoch of cosmic star formation. Emission lines of eight different elements (H, He, N, O, Si, S, Ar, and Ni) are detected, with most of these features observed to be ≲3% the strength of Hα. We report the characteristic strength of three auroral features ([N ii]λ5756, [S iii]λ6313, and [O ii]λ λ7322, 7332), as well as other semi-strong and faint emission lines, including forbidden [Ni ii]λ λ7380, 7414 and permitted O i λ8449, some of which have never before been observed outside of the local Universe. Using these measurements, we find T e [N ii] = 13,630 ± 2540 K, representing the first measurement of electron temperature using [N ii] in the high-redshift Universe. We also see evidence for broad line emission with a FWHM of 536 − 167 + 45 km s−1; the broad component of Hα is 6.01%–28.31% the strength of the narrow component and likely arises from star-formation-driven outflows. Finally, we briefly comment on the feasibility of obtaining large samples of faint emission lines using JWST in the future."
"
Gamma-ray flares from blazars can be accompanied by high-energy neutrino emission. To better understand this phenomenon, an international research team has statistically analyzed 145 bright blazars. They constructed weekly binned light curves and utilized a Bayesian algorithm, finding that their sample was dominated by blazars with low flare duty cycles and energy fractions. The study suggests that high-energy neutrinos of blazars might be produced mainly during the flare phase.

Blazars belong to the family of active galactic nuclei called quasars. What differentiates them from quasars is that the flares ejected out of these active galactic nuclei are pointed toward the Earth. These flares contain high-energy cosmic rays which are released from the core of these galaxies as jets spanning many light years. Such cosmic rays can interact with photons to produce subatomic particles called neutrinos.
Gamma-ray flares from blazars are thought to be the primary events behind neutrino detection in the sky. In 2017, the South Pole neutrino detector ""IceCube"" detected a high-energy neutrino event whose timings and positioning in the night sky coincided with the flare of a blazar called TXS 0506+056. Some scientists suggest that there could be a population of blazars whose flares are accompanied by high-energy neutrino emission. However, the relationship between blazar flaring activity and neutrino flux is yet to be properly understood.
In this regard, an international research team, led by Professor Kenji Yoshida from the Department of Electronic Information Systems at Shibaura Institute of Technology, Japan, has recently performed a comprehensive statistical analysis to understand the contribution of gamma-ray flares to neutrino emission. The team included Maria Petropoulou from the National and Kapodistrian University of Athens, Kohta Murase from The Pennsylvania State University, and Foteini Oikonomou from the Norwegian University of Science and Technology. Their paper was published in Volume 954, Number 2 of The Astrophysical Journal on September 6, 2023.
The researchers analyzed 145 blazars, 144 of them taken from the Fermi Large Area Telescope Monitored Source List and including TXS 0506+056, in this study. They first calculated a weekly average of the gamma-ray flux of the blazars and plotted their light curves. The team then derived the flare duty cycle (fraction of time spent in flaring state) and the corresponding energy fraction from these curves using a Bayesian blocks algorithm, a statistical method used to identify changes in a time series.
""We find that blazars with lower flare duty cycles and energy fractions are more numerous among our sample.Their flare duty cycles and energy fractions represent power law-like distributions, correlating strongly with each other. We found a significant difference between blazar subclasses for the flare duty cycles at the 5% significant level,"" says Prof. Yoshida, highlighting the major results of their analysis.
The researchers evaluated the neutrino energy flux of each gamma-ray flare, using a general scaling relation for the neutrino and gamma-ray luminosities with a power law's weighting exponent of 1.0-2.0, normalized to the quiescent gamma-ray or X-ray flux of each blazar. They also found that the gamma-ray flare distribution indicates that blazar neutrino emission may be dominated by flares for the weighting exponent >1.5. Furthermore, by comparing their neutrino predictions for each blazar for one-week and 10-year periods to the time-integrated IceCube sensitivity, the team placed upper limits on the contributions of the flares to the isotropic diffuse neutrino flux.
Prof. Yoshida remarks: ""We hope that this study helps improve our understanding of the contribution of blazars to astrophysical neutrinos. Application of the present method to further observations might have the potential to contribute to the advancement of scientific knowledge of the origin of astrophysical neutrinos.""

","score: 15.502327868852465, grade_level: '16'","score: 16.659557377049175, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acea74,"Gamma-ray flares of blazars may be accompanied by high-energy neutrinos due to interactions of high-energy cosmic rays in the jet with photons, as suggested by the detection of the high-energy neutrino IceCube-170922A during a major gamma-ray flare from blazar TXS 0506+056 at the ∼3σ significance level. In this work, we present a statistical study of gamma-ray emission from blazars to constrain the contribution of gamma-ray flares to their neutrino output. We construct weekly binned light curves for 145 gamma-ray bright blazars in the Fermi Large Area Telescope Monitored Source List adding TXS 0506+056. We derive the fraction of time spent in the flaring state (flare duty cycle) and the fraction of energy released during each flare from the light curves with a Bayesian blocks algorithm. We find that blazars with lower flare duty cycles and energy fractions are more numerous among our sample. We identify a significant difference in flare duty cycles between blazar subclasses at a significance level of 5%. Then using a general scaling relation for the neutrino and gamma-ray luminosities, L ν ∝ ( L γ ) γ with a weighting exponent of γ = 1.0–2.0, normalized to the quiescent gamma-ray or X-ray flux of each blazar, we evaluate the neutrino energy flux of each gamma-ray flare. The gamma-ray flare distribution indicates that blazar neutrino emission may be dominated by flares for γ ≳ 1.5. The neutrino energy fluxes for 1 week and 10 yr bins are compared with the decl.-dependent IceCube sensitivity to constrain the standard neutrino emission models for gamma-ray flares. Finally, we present the upper-limit contribution of blazar gamma-ray flares to the isotropic diffuse neutrino flux."
"
Optical scientists have found a new way to significantly increase the power of fibre lasers while maintaining their beam quality, making them a future key defence technology against low-cost drones and for use in other applications such as remote sensing.

Researchers from the University of South Australia (UniSA), the University of Adelaide (UoA) and Yale University have demonstrated the potential use of multimode optical fibre to scale up power in fibre lasers by three-to-nine times but without deteriorating the beam quality so that it can focus on distant targets.
The breakthrough is published in Nature Communications.
Co-first author Dr Linh Nguyen, a researcher at UniSA's Future Industries Institute, says the new approach will allow the industry to continue squeezing out extremely high power from fibre lasers, make them more useful for the defence industry, and for remote sensing applications and gravitational wave detection.
""High-power fibre lasers are vital in manufacturing and defence, and becoming more so with the proliferation of cheap, unmanned aerial vehicles (drones) in modern battlefields,"" Dr Nguyen says.
""A swarm of cheap drones can quickly drain the missile resource, leaving military assets and vehicles with depleted firing power for more combat-critical missions. High-power fibre lasers, with their extremely low-cost-per-shot and speed of light action, are the only feasible defence solution in the long run.
""This is known as asymmetric advantage: a cheaper approach can defeat a more expensive, high-tech system by playing the large number.""
In delivering an asymmetric advantage this advanced capability has the potential to provide a strong deterrent effect, aligning well with the objectives of the Defence Strategic Review and AUKUS Pillar 2 objectives.

Dr Ori Henderson-Sapir, project investigator at the UoA's Institute for Photonics and Advanced Sensing, says that Australia has a long history of developing innovative fibre optics technologies.
""Our research launches Australia into a world-leading position to develop the next generation of high-power fibre lasers, not only for defence applications, but to aid new scientific discoveries.""
The researchers have demonstrated the technology in fibre lasers and will report their findings at Photonics West, the premium international conference on photonics technology, in early 2024.

","score: 17.800617455896013, grade_level: '18'","score: 19.676049210770657, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-42806-1,"The key challenge for high-power delivery through optical fibers is overcoming nonlinear optical effects. To keep a smooth output beam, most techniques for mitigating optical nonlinearities are restricted to single-mode fibers. Moving out of the single-mode paradigm, we show experimentally that wavefront-shaping of coherent input light to a highly multimode fiber can increase the power threshold for stimulated Brillouin scattering (SBS) by an order of magnitude, whilst simultaneously controlling the output beam profile. The SBS suppression results from an effective broadening of the Brillouin spectrum under multimode excitation, without broadening of transmitted light. Strongest suppression is achieved with selective mode excitation that gives the broadest Brillouin spectrum. Our method is efficient, robust, and applicable to continuous waves and pulses. This work points toward a promising route for mitigating detrimental nonlinear effects in optical fibers, enabling further power scaling of high-power fiber systems for applications to directed energy, remote sensing, and gravitational-wave detection."
"
ALMA (Atacama Large Millimeter/submillimeter Array) has demonstrated the highest resolution yet with observations of an old star. The observations show that the star is surrounded by a ring-like structure of gas and that gas from the star is escaping to the surrounding space. Future observations with the newly demonstrated high resolution are expected to elucidate, not only the end of a star's life, but also the beginning, when planets are still forming.

ALMA is a radio interferometric array telescope, in which individual antennas work together to observe a celestial object. ALMA's resolution, the ability to see small details, is determined by the maximum separation between the antennas and the frequency of the observed radio waves. In this research, an international team comprised mainly of astronomers from the Joint ALMA Observatory, National Astronomical Observatory of Japan (NAOJ), National Radio Astronomy Observatory, and European Southern Observatory used ALMA's maximum antenna separation of 16 km and highest frequency receivers (known as Band 10, up to 950 GHz) to achieve the best resolution possible. Pushing ALMA's resolution to new limits also required a new calibration technique to correct for fluctuations in Earth's atmosphere above the antennas. The calibration technique the team used, known as ""band-to-band (B2B),"" was originally tested in the 1990s at Nobeyama Radio Observatory of NAOJ for future millimeter/submillimeter interferometers.
For their demonstration observations, the team chose R Leporis, a star in the final stage of stellar evolution, located approximately 1,535 light-years away from Earth. The team succeeded in observing R Leporis with the best resolution ever, 5 milli-arcsec, which is the equivalent of being able to see a single human hair two and a half miles away. The observations show the surface of the star and a ring of gas around the star. The team also confirmed that gas from the star is escaping to the surrounding space.
This newly demonstrated high resolution capability can now be applied to young stars with protoplanetary disks where planets are forming. Future high-resolution observations will provide new insights into how planets, particularly Earth-like planets, form.

","score: 16.211387163561078, grade_level: '16'","score: 16.33908074534162, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acf619,"The Atacama Large Millimeter/submillimeter Array (ALMA) was used in 2021 to image the carbon-rich evolved star R Lep in Bands 8–10 (397–908 GHz) with baselines up to 16 km. The goal was to validate the calibration, using band-to-band (B2B) phase referencing with a close phase calibrator J0504-1512, 1.°2 from R Lep in this case, and the imaging procedures required to obtain the maximum angular resolution achievable with ALMA. Images of the continuum emission and the hydrogen cyanide (HCN) maser line at 890.8 GHz, from the J = 10−9 transition between the (1110) and (0400) vibrationally excited states, achieved angular resolutions of 13, 6, and 5 mas in Bands 8–10, respectively. Self-calibration (self-cal) was used to produce ideal images to compare with the B2B phase referencing technique. The continuum emission was resolved in Bands 9 and 10, leaving too little flux for the self-cal of the longest baselines, so these comparisons are made at coarser resolution. Comparisons showed that B2B phase referencing provided phase corrections sufficient to recover 92%, 83%, and 77% of the ideal image continuum flux densities. The HCN maser was sufficiently compact to obtain self-cal solutions in Band 10 for all baselines (up to 16 km). In Band 10, B2B phase referencing as compared to the ideal images recovered 61% and 70% of the flux density for the HCN maser and continuum, respectively."
"
Given the hostile conditions of extraterrestrial environments, unmanned rovers play a critical role in the exploration of planets and moons. NASA's Mars and lunar exploration rovers have significantly contributed to our understanding of these extraterrestrial bodies. Planetary surfaces often present challenging landscapes with slopes, craters, and dunes. More importantly, the presence of regolith, fine particles that cover these surfaces, poses a significant challenge for rover mobility. The slipping of rovers on these loose surfaces can hinder their progress and even jeopardize their missions.

Various methods, primarily relying on visual data from cameras, have been explored to detect the traveling state or slip condition of rovers. However, these methods have limitations as they may struggle to differentiate between various terrain features such as distinguishing rocks from loose sand. A solution to this problem is for the rovers to obtain information about the traction on each wheel. This way, the rover could detect its traveling state faster and correct its posture to avoid slipping.
To realize this, Professor Kojiro Iizuka from the Department of Machinery and Control Systems of the College of Systems Engineering and Science at Shibaura Institute of Technology (SIT), Japan, and Dr. Kohei Inaba, also from SIT, have recently developed a novel system that allows a rover to detect its traveling state by the change in shape of its chassis. ""Our inspiration came from how humans detect their own traveling state based on muscle tension while walking. We aimed to develop a similar system that recognizes the traveling state based on the chassis shape deformation,"" explains Prof. Iizuka. Their study was published in Volume 15, Issue 17 of the journal Remote Sensing on August 30, 2023.
The muscles in the human body have special muscle fibers called nuclear chain fibers and nuclear bag fibers which help in detecting the traveling state of the body. The nuclear chain fibers detect the displacement of the tension in the muscles and help in determining the static posture of the body. On the other hand, nuclear bag fibers detect how fast muscle fibers stretch and help in detecting the dynamic state of the body.
Drawing parallels with human muscles, the researchers classified the change in the shape of the chassis of the rover, which manifests as strain, into two categories: displacement of strain and vibrational change in strain. They studied the strain displacement data using nuclear chain fibers analysis and strain velocity as nuclear bag fibers analysis.
The nuclear chain fiber analysis revealed that the forces acting vertically and in the direction of the rover's motion changed with strain. Therefore, monitoring strain changes can enable the detection of force alterations, ultimately indicating the rover's traveling state. In addition, through nuclear bag analysis, the researchers found that the rate of strain change could effectively gauge the level of slippage and subsequent alterations in the rover's travel state. Using this data, the system can determine the rover's condition in real time, thus enabling the rover to make essential maneuvers to avert potential slipping incidents.
The study also emphasizes the system's capabilities to detect environmental obstacles, such as rocks and stones, highlighting its potential to enhance the safety and efficiency of rover operations.
Highlighting the importance of this study, Prof. Iizuka remarks: ""During rover route planning, the experiences from this study should be considered to ensure that the rovers can travel safely. These findings represent the first step towards incorporating elements of biological functionality in sensing moving objects. We believe that our approach will also be effective for unmanned aerial vehicles and automatic driving in the future.""
In conclusion, this innovative study marks a significant step towards improving the safety and effectiveness of rover missions, promising advancements in our exploration of other planets and celestial bodies.

","score: 14.466260683760684, grade_level: '14'","score: 15.713536324786325, grade_levels: ['college_graduate'], ages: [24, 100]",10.3390/rs15174270,"The surface of the Moon and planets have been covered with loose soil called regolith, and there is a risk that the rovers may stack, so it is necessary for them to recognize the traveling state such as its posture, slip behavior, and sinkage. There are several methods for recognizing the traveling state such as a system using cameras and Lidar, and they are used in real exploration missions like Mars Exploration Rovers of NASA/JPL. When a rover travels and travels across loose soil with steep slopes like a side wall of a crater on the lunar surface, the rover has side slipping. It means that its behavior makes the rover slip down to the valley direction. Even if this detection uses sensors like a camera and Lidar or other controlling systems like SLAM (Simultaneous Localization and Mapping), it would be too difficult for the rover to avoid slipping down to valley direction, because it is not able to detect the traction or resistance given from ground by individual wheel of the rover, as the traction of individual wheel of the rover is not clear. This means that the movement of the rover appeared by integrating the traction of all wheels mounted on the rover. Even if the localization by sensors is carried out, the location would be the location after slipping down. This is because when traveling on unstable ground, the driving force of each individual wheel cannot be accurately predicted, and the sum of the driving force of all wheels is the motion of the rover, which is detected after the position changes. Therefore, if the rover obtains information on the traction of each wheel, its maneuver to change its posture would work sooner and it would be able to travel more efficiently than in a state without that information. Because the onboard computer of rovers can identify their location and state from the information of the traction of each wheel, they can decide the next work carefully and in detail. From these tasks, we focused on the intrinsic sensation of a biological function like a human body and aimed to develop a system that recognizes the traveling state (slip condition) from the shape deformation of the chassis. In this study, we experimentally verified the relationship between the change in strain, which is the amount of deformation acting on the chassis, and the traveling state while the wheel is traveling. From the experimental results, we confirmed that the strain in the chassis was displaced dynamically and that the strain changed oscillatory while the wheel was traveling. In addition, based on the function of muscle spindles as mechanoreceptors, we discussed two methods of analyzing strain change: nuclear chain fiber analysis and nuclear bag fiber analysis. These analyses mean that the raw data of the strain are updated to detect the characteristic strain elements of a chassis while the wheel is traveling through loose soil. Eventually, the slipping state could be estimated by updating the data of a lot of strain raw data, and it was confirmed that the traveling state could be detected."
"
Data from a NASA mission to map dark matter around galaxy clusters has been saved by a new recovery system designed by scientists at the University of Sydney. The system allowed the retrieval of gigabytes of information, even after communication failed and the balloon-based telescope was damaged in the landing process.

In April, the Super Pressure Balloon Imaging Telescope (SuperBIT) was launched from Wānaka Airport, New Zealand, suspended under a helium-filled balloon the size of a sports stadium on top of the Earth's atmosphere, and floated around the world 5.5 times. Unfortunately, it was damaged on landing in southern Argentina the following month.
Separately, two Data Recovery System packages storing more than 200 gigabytes of SuperBIT's information descended by parachute and landed safely, including a map of dark matter around galaxies and stunning photos of space. Dark matter is an invisible substance that has a mass six times greater than regular matter in the universe.
A study led by Dr Ellen Sirks from the University of Sydney's School of Physics, published today in the journal Aerospace, provides instructions to build the Data Recovery System she designed, and recounts the mission that demonstrated, for a relatively small cost, scientists can ensure the information they gather can be salvaged in the worst-case scenario.
The authors of the study, comprised of a team of international scientists from Australia, the United Kingdom, the United States, Canada, Europe and Taiwan, said that the first use of the Data Recovery System capsules during a live science mission proved a huge success.
""Our telescope got to the point where it was completely destroyed, and we lost high bandwidth communications, so not only did the Data Recovery System work; it was really quite essential to the mission's success,"" Dr Sirks said.
""When you're dropping something from the sky, in our case from 33 kilometres, there's always a chance that something goes wrong, so recovery packages are quite essential to keep your data safe.

""This drop package is something we've been developing for about five years, but only now have we been able to test it in its final configuration. It's got to the point where NASA wants to start producing these packages for other science missions as well, so this was really our final test to show that this system works.""
Dr Sirks said Data Recovery Systems are comprised of small computers with SD cards to store the data, a home-made ""find my phone"" satellite link, and parachutes -- housed in foam enclosures using everyday objects such as chicken roasting bags to keep them waterproof.
The story of recovering the packages itself was a mission. Dr Sirks said the local police in the Argentinian countryside helped retrieve the packages, given the rough terrain where they landed.
""We couldn't find one at first and when we did, there were cougar tracks in the snow near it, so we thought maybe the chicken roast bag was not the best idea. It was quite funny. But we did retrieve them quite easily,"" Dr Sirks said.
In a typical balloon-based mission like NASA's, data is downloaded by satellite, but Dr Sirks said scientists often need line-of-sight communication to download the data quickly, which isn't always efficient or possible.
Balloon-based observations also provide the quality of space telescopes at a fraction of the budget -- millions of dollars compared to billions.
""In our case, we were getting so much data per night that it would just be incredibly slow and expensive to retrieve this data mid-flight,"" Dr Sirks said.
""At the moment, the most efficient way for us to download data is to copy it onto an SD drive and just drop it to Earth which is kind of crazy, but it works well.""

","score: 14.389338319907939, grade_level: '14'","score: 15.730930667433832, grade_levels: ['college_graduate'], ages: [24, 100]",10.3390/aerospace10110960,"In April 2023, the superBIT telescope was lifted to the Earth’s stratosphere by a helium-filled super-pressure balloon to acquire astronomical imaging from above (99.5% of) the Earth’s atmosphere. It was launched from New Zealand and then, for 40 days, circumnavigated the globe five times at a latitude 40 to 50 degrees south. Attached to the telescope were four “drs” (Data Recovery System) capsules containing 5 TB solid state data storage, plus a gnss receiver, Iridium transmitter, and parachute. Data from the telescope were copied to these, and two were dropped over Argentina. They drifted 61 km horizontally while they descended 32 km, but we predicted their descent vectors within 2.4 km: in this location, the discrepancy appears irreducible below ∼2 km because of high speed, gusty winds and local topography. The capsules then reported their own locations within a few metres. We recovered the capsules and successfully retrieved all of superBIT’s data despite the telescope itself being later destroyed on landing."
"
How did the molecular building blocks for life end up on Earth? One long-standing theory is that they could have been delivered by comets. Now, researchers from the University of Cambridge have shown how comets could deposit similar building blocks to other planets in the galaxy.

In order to deliver organic material, comets need to be travelling relatively slowly -- at speeds below 15 kilometres per second. At higher speeds, the essential molecules would not survive -- the speed and temperature of impact would cause them to break apart.
The most likely place where comets can travel at the right speed are 'peas in a pod' systems, where a group of planets orbit closely together. In such a system, the comet could essentially be passed or 'bounced' from the orbit of one planet to another, slowing it down.
At slow enough speeds, the comet would crash on a planet's surface, delivering the intact molecules that researchers believe are the precursors for life. The results, reported in the Proceedings of the Royal Society A, suggest that such systems would be promising places to search for life outside our Solar System if cometary delivery is important for the origins of life.
Comets are known to contain a range of the building blocks for life, known as prebiotic molecules. For example, samples from the Ryugu asteroid, analysed in 2022, showed that it carried intact amino acids and vitamin B3. Comets also contain large amounts of hydrogen cyanide (HCN), another important prebiotic molecule. The strong carbon-nitrogen bonds of HCN make it more durable to high temperatures, meaning it could potentially survive atmospheric entry and remain intact.
""We're learning more about the atmospheres of exoplanets all the time, so we wanted to see if there are planets where complex molecules could also be delivered by comets,"" said first author Richard Anslow from Cambridge's Institute of Astronomy. ""It's possible that the molecules that led to life on Earth came from comets, so the same could be true for planets elsewhere in the galaxy.""
The researchers do not claim that comets are necessary to the origin of life on Earth or any other planet, but instead they wanted to place some limits on the types of planets where complex molecules, such as HCN, could be successfully delivered by comets.

Most of the comets in our Solar System sit beyond the orbit of Neptune, in what is known as the Kuiper Belt. When comets or other Kuiper Belt objects (KBOs) collide, they can be pushed by Neptune's gravity toward the Sun, eventually getting pulled in by Jupiter's gravity. Some of these comets make their way past the Asteroid Belt and into the inner Solar System.
""We wanted to test our theories on planets that are similar to our own, as Earth is currently our only example of a planet that supports life,"" said Anslow. ""What kinds of comets, travelling at what kinds of speed, could deliver intact prebiotic molecules?""
Using a variety of mathematical modelling techniques, the researchers determined that it is possible for comets to deliver the precursor molecules for life, but only in certain scenarios. For planets orbiting a star similar to our own Sun, the planet needs to be low mass and it is helpful for the planet to be in close orbit to other planets in the system. The researchers found that nearby planets on close orbits are much more important for planets around lower-mass stars, where the typical speeds are much higher.
In such a system, a comet could be pulled in by the gravitational pull of one planet, then passed to another planet before impact. If this 'comet-passing' happened enough times, the comet would slow down enough so that some prebiotic molecules could survive atmospheric entry.
""In these tightly-packed systems, each planet has a chance to interact with and trap a comet,"" said Anslow. ""It's possible that this mechanism could be how prebiotic molecules end up on planets.""
For planets in orbit around lower-mass stars, such as M-dwarfs, it would be more difficult for complex molecules to be delivered by comets, especially if the planets are loosely packed. Rocky planets in these systems also suffer significantly more high-velocity impacts, potentially posing unique challenges for life on these planets.
The researchers say their results could be useful when determining where to look for life outside the Solar System.
""It's exciting that we can start identifying the type of systems we can use to test different origin scenarios,"" said Anslow. ""It's a different way to look at the great work that's already been done on Earth. What molecular pathways led to the enormous variety of life we see around us? Are there other planets where the same pathways exist? It's an exciting time, being able to combine advances in astronomy and chemistry to study some of the most fundamental questions of all.""
The research was supported in part by the Royal Society and the Science and Technology Facilities Council (STFC), part of UK Research and Innovation (UKRI). Richard Anslow is a Member of Wolfson College, Cambridge.

","score: 12.150697674418605, grade_level: '12'","score: 12.504742962056305, grade_levels: ['college'], ages: [18, 24]",10.1098/rspa.2023.0434,"In this work, we consider the potential of cometary impacts to deliver complex organic molecules and the prebiotic building blocks required for life to rocky exoplanets. Numerical experiments have demonstrated that for these molecules to survive, impacts at very low velocities are required. This work shows that for comets scattered from beyond the snow-line into the habitable zone, the minimum impact velocity is always lower for planets orbiting Solar-type stars than M-dwarfs. Using both an analytical model and numerical N-body simulations, we show that the lowest velocity impacts occur onto planets in tightly packed planetary systems around high-mass (i.e. Solar-mass) stars, enabling the intact delivery of complex organic molecules. Impacts onto planets around low-mass stars are found to be very sensitive to the planetary architecture, with the survival of complex prebiotic molecules potentially impossible in loosely packed systems. Rocky planets around M-dwarfs also suffer significantly more high velocity impacts, potentially posing unique challenges for life on these planets. In the scenario that cometary delivery is important for the origins of life, this study predicts the presence of biosignatures will be correlated with (i) decreasing planetary mass (i.e. escape velocity), (ii) increasing stellar-mass and (iii) decreasing planetary separation (i.e. exoplanets in tightly-packed systems)."
"
A Lancaster University PhD student has measured the optical depth of Saturn's rings using a new method based on how much sunlight reached the Cassini spacecraft while it was in the shadow of the rings.

The optical depth is connected to the transparency of an object, and it shows how far light can travel through that object before it gets absorbed or scattered.
The research, led by Lancaster University in collaboration with the Swedish Institute of Space Physics, is published in the Monthly Notices of the Royal Astronomical Society.
The NASA-ESA Cassini spacecraft was launched in 1997 and reached Saturn in 2004, carrying out the most extensive survey of the planet and its moons to date. The mission ended in 2017 when Cassini plunged into the Saturnian atmosphere, after diving 22 times between the planet and its rings.
Lancaster University PhD student George Xystouris, under the supervision of Dr Chris Arridge, analysed historic data from the Langmuir Probe on board Cassini, an instrument that was measuring the cold plasma, i.e., low energy ions and electrons, in the magnetosphere of Saturn.
For their study they focused on solar eclipses of the spacecraft: periods where Cassini was in the shadow of Saturn or the main rings. During each eclipse, the Langmuir Probe recorded dramatic changes in the data.
George said: ""As the probe is metallic, whenever it is sunlit, the sunlight can give enough energy to the probe to release electrons. This is the photoelectric effect, and the electrons that are released are so-called 'photoelectrons. They can create problems though, as they have the same properties as the electrons in the cold plasma around Saturn and there is not an easy way to separate the two.""
""Focusing on the data variations we realised that they were connected with how much sunlight each ring would allow to pass. Eventually, using the properties of the material that the Langmuir Probe was made of, and how bright the Sun was in Saturn's neighbourhood, we managed to calculate the change in the photoelectrons number for each ring, and calculate Saturn's rings optical depth.

""This was a novel and exciting result! We used an instrument that is mainly used for plasma measurements to measure a planetary feature, which is a unique use of the Langmuir Probe, and our results agreed with studies that used high-resolution imagers to measure the transparency of the rings.""
The main rings, which extend up to 140,000 km from the planet, but have a maximum thickness of only 1km, are to disappear from view from Earth by 2025. In that year the rings will be tilted edge-on to Earth, making it almost impossible to view them. They will tilt back towards Earth during the next phase of Saturn's 29-year orbit and will continue to become more visible and brighter until 2032.
Professor Mike Edmunds, the President of the Royal Astronomical Society, added: ""It is always good to see a postgraduate student involved in using space probe instrumentation in an unusual and inventive way. Innovation of this kind is just what is needed in astronomical research -- and an approach which many former students who are in a variety of careers are applying to help address the world's problems.""

","score: 13.567883977900554, grade_level: '14'","score: 14.879640883977899, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnras/stad2793,"A Langmuir Probe (LP) measures currents from incident charged particles as a function of the applied bias voltage. While onboard a spacecraft the particles are either originated from the surrounding plasma, or emitted (e.g. through photoemission) from the spacecraft itself. The obtained current–voltage curve reflects the properties of the plasma in which the probe is immersed into, but also any photoemission due to illumination of the probe surface: As photoemission releases photoelectrons into space surrounding the probe, these can be recollected and measured as an additional plasma population. This complicates the estimation of the properties of the ambient plasma around the spacecraft. The photoemission current is sensitive to the extreme ultraviolet (UV) part of the spectrum, and it varies with the illumination from the Sun and the properties of the LP surface material, and any variation in the photoelectrons irradiance can be measured as a change in the current voltage curve. Cassini was eclipsed multiple times by Saturn and the main rings over its 14 yr mission. During each eclipse the LP recorded dramatic changes in the current–voltage curve, which were especially variable when Cassini was in shadow behind the main rings. We interpret these variations as the effect of spatial variations in the optical depth of the rings and hence use the observations to estimate the optical depth of Saturn’s main rings. Our estimates are comparable with UV optical depth measurements from Cassini’s remote sensing instruments."
"
The one thing everyone knows about black holes is that absolutely everything nearby gets sucked into them.

Almost everything, it turns out.
""Even though black holes are defined as objects from which nothing can escape, one of the astonishing predictions of Einstein's theory of relativity is that black holes can actually lose energy,"" says astrophysicist Eliot Quataert, Princeton's Charles A. Young Professor of Astronomy on the Class of 1897 Foundation. ""They can rotate, and just like a spinning top slows down over time and loses that energy in its rotation, a rotating black hole can also lose energy to its surroundings.""
Scientists have widely accepted this model since the 1970s. They knew that magnetic fields probably extracted energy from spinning black holes -- they just didn't know how.
A team of Princeton astrophysicists has now determined conclusively that energy close to the event horizon of black hole M87* is pushing outward, not inward. (M87 is the name of the galaxy, Messier 87, so the black hole at its center is designated M87*.) The researchers have also created a way to test the prediction that black holes lose rotational energy, Quataert said, and to establish it's that energy that produces ""the incredibly powerful outflows we see that we call jets.""
These energy outflow jets ""are basically like million-light-year-long Jedi lightsabers,"" said former Princeton postdoc Alexandru Lupsasca, and they can extend 10 times longer than the Milky Way galaxy.
The results of their work appear in the current issue of The Astrophysical Journal. Andrew Chael, an associate research scholar in astrophysics, is the first author on the paper. He and co-author George Wong are both members of the Event Horizon Telescope team and have played a critical role in developing the models that are used to interpret black holes. Chael, Wong, Lupsasca and Quataert are all theorists affiliated with the Princeton Gravity Initiative.

The team gave Chael credit for the vital insight at the core of the new paper: that the direction in which the magnetic field lines are spiraling reveals the direction of the energy flow. From that, ""the rest sort of fell into place,"" Quataert said.
""If you took the Earth, turned it all into TNT and blew it up 1,000 times a second for millions and millions of years, that's the amount of energy that we're getting out of M87,"" said Wong, an associate research scholar with the Princeton Gravity Initiative and a member of the Institute for Advanced Study.
Scientists have known for decades that as a black hole starts to spin, it drags the fabric of spacetime around with it. Magnetic field lines that thread through the black hole get dragged along, and that slows down the rotation, leading to the energy release.
""Our new, sharp prediction is that whenever you look at an astrophysical black hole, if it has magnetic field lines attached to it, there will be energy transfer -- truly insane amounts of energy transfer,"" said Lupsasca, a former associate research scholar at Princeton who is now an assistant professor of physics and mathematics at Vanderbilt University, and who won the 2024 New Horizons in Physics Prize from the Breakthrough Prize Foundation for his black hole research.
While the energy flow close to M87*'s event horizon is streaming outwards, the team said that the energy flow could theoretically go inward in a different black hole. They are confident in their link between energy flow and the direction of the magnetic field lines, and their prediction that the energy flow comes from the black hole will be tested with the launch of the still-theoretical ""next generation"" Event Horizon Telescope.
For the past year and a half, black hole researchers around the world have been proposing specs for the future instrument, Wong said. ""Papers like ours can play a crucial role in determining what we need. I think it's an incredibly exciting time.""
The four researchers stressed in their paper that they haven't conclusively shown that the black hole's spin ""truly powers the extragalactic jet,"" though the evidence certainly leans in that direction. Even though the levels of energy that their model shows are commensurate with what the jets need, they couldn't rule out the possibility that the jet could be powered by rotating plasma outside the black hole. ""I think it's extremely likely the black hole powers the jet, but we can't prove it,"" said Lupsasca. ""Yet.""

","score: 12.790816777041943, grade_level: '13'","score: 13.81124061810155, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acf92d,"In 1977, Blandford and Znajek showed that the electromagnetic field surrounding a rotating black hole can harvest its spin energy and use it to power a collimated astrophysical jet, such as the one launched from the center of the elliptical galaxy M87. Today, interferometric observations with the Event Horizon Telescope (EHT) are delivering high-resolution, event-horizon-scale, polarimetric images of the supermassive black hole M87* at the jet launching point. These polarimetric images offer an unprecedented window into the electromagnetic field structure around a black hole. In this paper, we show that a simple polarimetric observable—the phase ∠β 2 of the second azimuthal Fourier mode of the linear polarization in a near-horizon image—depends on the sign of the electromagnetic energy flux and therefore provides a direct probe of black hole energy extraction. In Boyer–Lindquist coordinates, the Poynting flux for axisymmetric electromagnetic fields is proportional to the product B ϕ B r . The phase ∠β 2 likewise depends on the ratio B ϕ /B r , thereby enabling an observer to determine the direction of electromagnetic energy flow in the near-horizon environment experimentally. Data from the 2017 EHT observations of M87* are consistent with electromagnetic energy outflow. Currently envisioned multifrequency observations of M87* will achieve higher dynamic range and angular resolution, and hence deliver measurements of ∠β 2 closer to the event horizon as well as better constraints on Faraday rotation. Such observations will enable a definitive test for energy extraction from the black hole M87*."
"
The second- and fourth-most distant galaxies ever observed have been discovered in a region of space known as Pandora's Cluster, or Abell 2744, using data from NASA's James Webb Space Telescope (JWST). Following up on a deep field image of the area, an international team led by Penn State researchers confirmed the distance of these ancient galaxies and inferred their properties using new spectroscopic data -- information about light emitted across the electromagnetic spectrum -- from JWST. At nearly 33 billion light years away, these incredibly distant galaxies offer insights into how the earliest galaxies might have formed.

Unlike other galaxies confirmed at this distance that appear in images as red dots, the new galaxies are larger and appear like a peanut and a fluffy ball, according to the researchers. A paper describing the galaxies appears today (Nov 13) in the journal Astrophysical Journal Letters.
""Very little is known about the early universe, and the only way to learn about that time and to test our theories of early galaxy formation and growth is with these very distant galaxies,"" said first-author Bingjie Wang, postdoctoral scholar in the Penn State Eberly College of Science and a member of the JWST UNCOVER (Ultradeep NIRSpec and NIRCam ObserVations before the Epoch of Reionization) team that conducted the research. ""Prior to our analysis, we knew of only three galaxies confirmed at around this extreme distance. Studying these new galaxies and their properties has revealed the diversity of galaxies in the early universe and how much there is to be learned from them.""
Because the light from these galaxies had to travel for so long to reach Earth, it provides a window into the past. The research team estimates that the light detected by JWST was emitted by the two galaxies when the universe was about 330 million years old and traveled for about 13.4 billion light years to reach the JWST. But, the researchers said, the galaxies are currently closer to 33 billion light years away from Earth due to the expansion of the universe over this time.
""The light from these galaxies is ancient, about three times older than the Earth,"" said Joel Leja, assistant professor of astronomy and astrophysics at Penn State and a member of UNCOVER. ""These early galaxies are like beacons, with light bursting through the very thin hydrogen gas that made up the early universe. It is only by their light that we can begin to understand the exotic physics that governed the galaxy near the cosmic dawn.""
Notably, the two galaxies are considerably larger than the three galaxies previously located at these extreme distances. One is at least six times larger at about 2,000 light years across. For comparison, the Milky Way is approximately 100,000 light years across, but, Wang said, the early universe is thought to have been very compressed, so it's surprising that the galaxy is as large as it is.
""Previously discovered galaxies at these distances are point sources -- they appear as a dot in our images,"" Wang said. ""But one of ours appears elongated, almost like a peanut, and the other looks like a fluffy ball. It is unclear if the difference in size is due to how the stars formed or what happened to them after they formed, but the diversity in the galaxy properties is really interesting. These early galaxies are expected to have formed out of similar materials, but already they are showing signs of being very different than one another.""
The two galaxies were among 60,000 sources of light in Pandora's Cluster detected in one of JWST's first deep field images taken during 2022, its first year of science operations. This region of space was selected in part because it is located behind several galaxy clusters that create a natural magnification effect called gravitational lensing. The gravitational pull of the clusters' combined mass warps the space around it, focusing and magnifying any light that passes nearby and providing a magnified view behind the clusters.

In a matter of months, the UNCOVER team narrowed down the 60,000 light sources to 700 candidates for follow up study, eight of which they thought could potentially be among the first galaxies. Then, JWST again pointed at Pandora's Cluster, recording the candidates' spectra -- a sort of fingerprint detailing the amount of light given off at each wavelength.
""Several different teams are using different approaches to look for these ancient galaxies, and each have their strengths and weaknesses,"" Leja said. ""The fact that we're pointing at this giant magnifying lens in space gives us an incredibly deep window, but it's a very small window so we were rolling the dice. Several of the candidates were inconclusive, and at least one was a case of mistaken identity -- it was something much closer that mimics a distant galaxy. But we were lucky, and two turned out to be these ancient galaxies. It's incredible.""
The researchers also used detailed models to infer the properties of these early galaxies when they emitted the light detected by JWST. As the researchers expected, the two galaxies were young, had few metals in their composition, and were growing rapidly and actively forming stars.
""The first elements were forged in the cores of early stars through the process of fusion,"" Leja said. ""It makes sense that these early galaxies don't have heavy elements like metals because they were some of the first factories to build those heavy elements. And, of course, they would have to be young and star-forming to be the first galaxies, but confirming these properties is an important basic test of our models and helps confirm the whole paradigm of the Big Bang theory.""
The researchers noted that, alongside the gravitational lens, JWST's powerful infrared instruments should be able to detect galaxies at an even further distance, if they exist.
""We had a very tiny window into this region, and we didn't observe anything beyond these two galaxies, even though JWST has the capability,"" Leja said. ""That could mean that galaxies just didn't form before that time and that we're not going to find anything further away. Or it could mean we didn't get lucky enough with our small window.""
This work was the result of a successful proposal submitted to NASA suggesting how to use JWST during its first year of science operations. In the first three cycles of submissions, NASA received four to ten times more proposals than available observing time on the telescope would allow and had to select only a fraction of those proposals.

""Our team was very excited and a little surprised when our proposal was accepted,"" Leja said. ""It involved coordination, quick human action and the telescope pointing at the same thing twice, which is a lot to ask of a telescope in its first year. There was a lot of pressure because we only had a few months to determine the objects for follow up. But JWST was built for finding these first galaxies, and it's so exciting to be doing that now.""
In addition to Penn State, the team includes researchers from the University of Texas Austin, the Swinburne University of Technology in Australia, Ben-Gurion University of the Negev in Israel, Yale University, the University of Pittsburgh, Sorbonne Université in France, the University of Copenhagen in Denmark, the University of Geneva in Switzerland, the University of Massachusetts, the University of Groningen in the Netherlands, Princeton University, Waseda University in Japan, Tufts University and the National Optical-Infrared Astronomy Research (NOIR) Lab.
This work was supported by NASA, the United States-Israel Binational Science Foundation, the U.S. National Science Foundation, the Israel Ministry of Science & Technology, the French National Centre for Space Studies, the French National Institute for Earth Sciences and Astronomy, the Research Corporation for Scientific Advancement, the Dutch Research Council, the European Commission's and University of Groningen's CO-FUND Rosalind Franklin program, the National Astronomical Observatory of Japan and the NOIR Lab.

","score: 14.26011904761905, grade_level: '14'","score: 15.74151785714286, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/acfe07,"Observations of high-redshift galaxies provide a critical direct test to the theories of early galaxy formation, yet to date, only three have been spectroscopically confirmed at z > 12. Due to strong gravitational lensing over a wide area, the galaxy cluster field A2744 is ideal for searching for the earliest galaxies. Here we present JWST/NIRSpec observations of two galaxies: a robust detection at z spec = 12.393 − 0.001 + 0.004 , and a plausible candidate at z spec = 13.079 − 0.001 + 0.013 . The galaxies are discovered in JWST/NIRCam imaging and their distances are inferred with JWST/NIRSpec spectroscopy, all from the JWST Cycle 1 UNCOVER Treasury survey. Detailed stellar population modeling using JWST NIRCam and NIRSpec data corroborates the primeval characteristics of these galaxies: low mass (∼108 M ⊙), young, rapidly assembling, metal-poor, and star-forming. Interestingly, both galaxies are spatially resolved, having lensing-corrected rest-UV effective radii on the order of 300–400 pc, which are notably larger than other spectroscopically confirmed systems at similar redshifts. The observed dynamic range of z ≳ 10 sizes spans over 1 order of magnitude, implying a significant scatter in the size–mass relation at early times. Deep into the epoch of reionization, these discoveries elucidate the emergence of the first galaxies."
"
Using the James Webb Space Telescope, an international team, including astronomer Alexander de la Vega of the University of California, Riverside, has discovered the most distant barred spiral galaxy similar to the Milky Way that has been observed to date.

Until now it was believed that barred spiral galaxies like the Milky Way could not be observed before the universe, estimated to be 13.8 billion years old, reached half of its current age.
The research, published in Nature this week, was led by scientists at the Centro de Astrobiología in Spain.
""This galaxy, named ceers-2112, formed soon after the Big Bang,"" said coauthor de la Vega, a postdoctoral researcher in the Department of Physics and Astronomy. ""Finding ceers-2112 shows that galaxies in the early universe could be as ordered as the Milky Way. This is surprising because galaxies were much more chaotic in the early universe and very few had similar structures to the Milky Way.""
Ceers-2112 has a bar in its center. De la Vega explained that a galactic bar is a structure, made of stars, within galaxies. Galactic bars resemble bars in our everyday lives, such as a candy bar. It is possible to find bars in non-spiral galaxies, he said, but they are very rare.
""Nearly all bars are found in spiral galaxies,"" said de la Vega, who joined UCR last year after receiving his doctoral degree in astronomy at Johns Hopkins University. ""The bar in ceers-2112 suggests that galaxies matured and became ordered much faster than we previously thought, which means some aspects of our theories of galaxy formation and evolution need revision.""
Astronomers' previous understanding of galaxy evolution was that it took several billion years for galaxies to become ordered enough to develop bars.

""The discovery of ceers-2112 shows that it can happen in only a fraction of that time, in about one billion years or less,"" de la Vega said.
According to him, galactic bars are thought to form in spiral galaxies with stars that rotate in an ordered fashion, the way they do in the Milky Way.
""In such galaxies, bars can form spontaneously due to instabilities in the spiral structure or gravitational effects from a neighboring galaxy,"" de la Vega said. ""In the past, when the universe was very young, galaxies were unstable and chaotic. It was thought that bars could not form or last long in galaxies in the early universe.""
The discovery of ceers-2112 is expected to change at least two aspects of astronomy.
""First, theoretical models of galaxy formation and evolution will need to account for some galaxies becoming stable enough to host bars very early in the universe's history,"" de la Vega said. ""These models may need to adjust how much dark matter makes up galaxies in the early universe, as dark matter is believed to affect the rate at which bars form. Second, the discovery of ceers-2112 demonstrates that structures like bars can be detected when the universe was very young. This is important because galaxies in the distant past were smaller than they are now, which makes finding bars harder. The discovery of ceers-2112 paves the way for more bars to be discovered in the young universe.""
De la Vega helped the research team by estimating the redshift and properties of ceers-2112. He also contributed to the interpretation of the measurements.

""Redshift is an observable property of a galaxy that indicates how far away it is and how far back in time the galaxy is seen, which is a consequence of the finite speed of light,"" he said.
What surprised de la Vega most about the discovery of ceers-2112 is how well the properties of its bar could be constrained.
""Initially, I thought detecting and estimating properties of bars in galaxies like ceers-2112 would be fraught with measurement uncertainties,"" he said. ""But the power of the James Webb Space Telescope and the expertise of our research team helped us place strong constraints on the size and shape of the bar.""
At UCR, de la Vega oversees astronomy outreach. He plans telescope nights on and off campus, and visits to local schools to give presentations on astronomy. He also leads the public astronomy talk series ""Cosmic Thursdays"" as well as one-off events for special occasions, such as viewing parties for eclipses.

","score: 11.598491304523264, grade_level: '12'","score: 11.617296533914377, grade_levels: ['12'], ages: [17, 18]",10.1038/s41586-023-06636-x,"The majority of massive disk galaxies in the local Universe show a stellar barred structure in their central regions, including our Milky Way1,2. Bars are supposed to develop in dynamically cold stellar disks at low redshift, as the strong gas turbulence typical of disk galaxies at high redshift suppresses or delays bar formation3,4. Moreover, simulations predict bars to be almost absent beyond z = 1.5 in the progenitors of Milky Way-like galaxies5,6. Here we report observations of ceers-2112, a barred spiral galaxy at redshift zphot ≈ 3, which was already mature when the Universe was only 2 Gyr old. The stellar mass (M★ = 3.9 × 109 M⊙) and barred morphology mean that ceers-2112 can be considered a progenitor of the Milky Way7–9, in terms of both structure and mass-assembly history in the first 2 Gyr of the Universe, and was the closest in mass in the first 4 Gyr. We infer that baryons in galaxies could have already dominated over dark matter at z ≈ 3, that high-redshift bars could form in approximately 400 Myr and that dynamically cold stellar disks could have been in place by redshift z = 4–5 (more than 12 Gyrs ago)10,11."
"
Professor Amri Wandel, from Hebrew University of Jerusalem, has unveiled research that promises to redefine our comprehension of habitable exoplanets. In a recent study published in the Astronomical Journal, Professor Wandel introduces the concept of subglacial liquid water as a pivotal element in broadening the boundaries of the conventional Habitable Zone.

The classical Habitable Zone, often colloquially referred to as the ""Goldilocks Zone,"" typically defines the region around a star where conditions allow the presence of surface liquid water and, by extension, life as we understand it. However, Professor Wandel's research offers a fresh perspective by illustrating that the existence of subglacial liquid water can considerably extend this zone.
One of the primary discoveries of this research is the potential to expand the Habitable Zone inwards for tidally locked planets closely orbiting M-dwarf stars, which are frequently regarded as candidates for detecting spectral evidence for life (so called biosignatures) in exoplanets. The study delineates how an atmosphere and liquid water could coexist on these planets, pushing the limits of the Habitable Zone further than previously assumed.
Moreover, the research postulates that subglacial liquid water can also broaden the Habitable Zone beyond the outer limits of the conservative Habitable Zone. These findings unlock the possibility of liquid water on a more diverse range of exoplanets than previously envisioned, presenting tantalizing opportunities for the search for extraterrestrial life.
A noteworthy implication of this research is its connection to recent observations made by the James Webb Space Telescope (JWST). The potential identification of atmospheric water vapor on GJ 486 b, a rocky Earth-sized exoplanet, and the evidence for an ocean on K2-18b, a Super Earth exoplanet, hint at the existence of liquid water, possibly organic chemistry, and the potential for life on such celestial bodies. This discovery provides empirical substantiation to address the long-standing question of whether exoplanets orbiting M-dwarf stars can sustain habitable conditions.
Professor Wandel remarked, ""This work demonstrates that the Habitable Zone of red dwarfs is likely significantly broader than previously assumed, and planets within it have the capacity to maintain water and an atmosphere. The latter conclusion is empirically supported by recent findings of water on such exoplanets by the Webb Telescope, particularly in K2-18 b, as predicted in the article submitted two months prior. In particular, it may optimize the target allocation and priority for biosignature research by JWST.""
Professor Wandel's research elucidates how water on terrestrial planets closely orbiting M-dwarf stars may endure within a subglacial melting layer, presenting a unique perspective on the sustainability of liquid water. The study further explores how the detection of water on various exoplanets can aid in constraining their atmospheric characteristics.
In conclusion, Professor Amri Wandel's research spotlights the transformative potential of subglacial liquid water in expanding the Habitable Zone of exoplanets. This discovery not only advances our comprehension of habitable environments in the cosmos but also illuminates the prospect of life beyond our planet.

","score: 18.113628117913837, grade_level: '18'","score: 19.14345804988662, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-3881/ad0045,"Considering subglacial liquid water, a significant extension of the classical Habitable Zone is obtained. Elaborating on the model of Wandel it is shown how an atmosphere and liquid water could survive on tidally locked planets closely orbiting an M-dwarf host, extending the Habitable Zone boundary inwards. In addition, subglacial liquid water could extend the Habitable Zone beyond the outer boundary of the conservative Habitable Zone as well. These two results enhance the circumstellar region with a potential for liquid water well beyond the conservative boundaries of the classical Habitable Zone. It is argued that the probable recent JWST detection of atmospheric water vapor on the rocky Earth-sized exoplanet GJ 486 b, along with earlier detections of water on other planets orbiting M-dwarf stars, gives an empirical answer to the much-argued question of whether such planets can support liquid water, organic chemistry, and eventually life. It is shown how water on terrestrial planets closely orbiting M-dwarf stars may sustain in a subglacial melting layer. Finally, the model is applied to a few exoplanets demonstrating how water detection may constrain their atmospheric properties."
"
The observed variations in chromium (Cr) isotope ratios in the Ryugu asteroid samples collected by Hayabusa2 likely resulted from elemental redistribution of slightly soluble Cr by water within the parent body, reveals a multinational study led by researchers from Tokyo Tech. The results provide useful insights for expanding our understanding of the origin and evolution of materials in our solar system.

Hayabusa2 space mission by the Japan Aerospace Exploration Agency (JAXA) returned home with samples of the asteroid Ryugu that orbits the Sun between Earth and Mars. Preliminary chemical analysis of Ryugu samples revealed that the asteroid is rich in volatile and organic-rich materials, which shows similarities to the class of meteorites known as Ivuna-type carbonaceous chondrites (CIs). Such asteroids have gained the attention of scientists due to their close chemical resemblance with elemental environments during the birth of the solar system.
Studies have shown that isotopic anomalies in chromium (54Cr/52Cr) and titanium ratios (50Ti/47Ti), often expressed as ε54Cr and ε50Ti, respectively, can help decipher the nucleosynthetic origins of chemical components in extraterrestrial materials. While the isotopic variability of other elements in bulk Ryugu samples is similar to that in CIs, anomalies in Cr isotopes are slightly different from those recorded in the literature. To unravel the origin of these deviations, an international team of scientists led by Professor Tetsuya Yokoyama from Tokyo Institute of Technology has recently investigated ε54Cr and ε50Ti in five different Ryugu samples. Their results have been published in Scientific Advances.
""Prior studies on the asteroid samples established that Ryugu and Ivuna-type carbonaceous chondrites were born in a common place; more distant part of the solar system than other meteorite parent bodies. However, the slight discrepancy in isotopic anomalies of Cr between Ryugu and CIs gave rise to the question whether the heterogeneity is due to the difference in the birth place, or did it arise from secondary processes that occurred after the accretion of their parent bodies,"" explains Prof. Yokoyama.
For precise analysis of the Cr and Ti anomalies, the team selected two Ryugu samples from the first touchdown and three from the second touchdown site. The samples were first digested in acids and subjected to inductively coupled plasma mass spectrometry (ICP-MS) and thermal ionization mass spectrometry (TIMS). The test results in samples weighing less than 24 milligrams indicated that the variation in ε50Ti is marginal and agrees with the data available on CIs. The same was not true for ε54Cr values, where the dispersions exceeded formerly reported values for CIs. However, when the sample was greater than 90 milligrams, isotopic similarity was found. This observation suggested that Cr isotopes are not uniformly distributed in the Ryugu parent body at the microscopic level, while Ryugu has a Cr isotopic composition similar to CIs at the macroscopic level, thus corroborating the idea that Ryugu and CIs share a common genetic heritage.
Further analysis of the samples indicated that the microscopic heterogeneity in Cr isotope distribution arose from the physicochemical fractionation of 54Cr-rich presolar nanoparticles and Cr-bearing secondary minerals. This phenomenon was attributed to the aqueous alteration within the asteroid. The water in the asteroid dissolved the mildly soluble Cr while 54Cr-rich presolar nanoparticles undissolved, circulated the 54Cr-depleted fluid within the body, resulting in the precipitation of secondary minerals depleted in 54Cr. This scenario was supported by the analysis of radiogenic isotope 53Cr carried out by the team, which revealed that the precipitation of secondary minerals occurred around 5.2 million years after the birth of the solar system.
Nucleosynthetic 54Cr anomalies in extraterrestrial materials are often connected to their nebular origins, but this study reveals that apparent 54Cr variabilities in asteroidal materials could also rise from parent body processes such as elemental redistribution by water.
""Unlike meteorites that plummet to earth from space, Ryugu samples are unaffected by terrestrial contamination, and they are particularly valuable for unravelling the earliest history of the solar system as they retain primitive chemical characteristics. Therefore, this study is a step closer to fully understanding our chemical past,"" concludes Prof. Yokoyama.

","score: 18.047843137254905, grade_level: '18'","score: 18.960284313725488, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adi7048,"Studies of material returned from Cb asteroid Ryugu have revealed considerable mineralogical and chemical heterogeneity, stemming primarily from brecciation and aqueous alteration. Isotopic anomalies could have also been affected by delivery of exogenous clasts and aqueous mobilization of soluble elements. Here, we show that isotopic anomalies for mildly soluble Cr are highly variable in Ryugu and CI chondrites, whereas those of Ti are relatively uniform. This variation in Cr isotope ratios is most likely due to physicochemical fractionation between 54 Cr-rich presolar nanoparticles and Cr-bearing secondary minerals at the millimeter-scale in the bulk samples, likely due to extensive aqueous alteration in their parent bodies that occurred 5.2 − 1.4 + 1.8 Ma after Solar System birth. In contrast, Ti isotopes were marginally affected by this process. Our results show that isotopic heterogeneities in asteroids are not all nebular or accretionary in nature but can also reflect element redistribution by water."
"
Scientists using NASA's James Webb Space Telescope just made a breakthrough discovery in revealing how planets are made. By observing water vapor in protoplanetary disks, Webb confirmed a physical process involving the drifting of ice-coated solids from the outer regions of the disk into the rocky-planet zone.

Theories have long proposed that icy pebbles forming in the cold, outer regions of protoplanetary disks -- the same area where comets originate in our solar system -- should be the fundamental seeds of planet formation. The main requirement of these theories is that pebbles should drift inward toward the star due to friction in the gaseous disk, delivering both solids and water to planets.
A fundamental prediction of this theory is that as icy pebbles enter into the warmer region within the ""snowline"" -- where ice transitions to vapor -- they should release large amounts of cold water vapor. This is exactly what Webb observed.
""Webb finally revealed the connection between water vapor in the inner disk and the drift of icy pebbles from the outer disk,"" said principal investigator Andrea Banzatti of Texas State University, San Marcos, Texas. ""This finding opens up exciting prospects for studying rocky planet formation with Webb!""
""In the past, we had this very static picture of planet formation, almost like there were these isolated zones that planets formed out of,"" explained team member Colette Salyk of Vassar College in Poughkeepsie, New York. ""Now we actually have evidence that these zones can interact with each other. It's also something that is proposed to have happened in our solar system.""
Harnessing the Power of Webb
The researchers used Webb's MIRI (the Mid-Infrared Instrument) to study four disks -- two compact and two extended -- around Sun-like stars. All four of these stars are estimated to be between 2 and 3 million years old, just newborns in cosmic time.

The two compact disks are expected to experience efficient pebble drift, delivering pebbles to well within a distance equivalent to Neptune's orbit. In contrast, the extended disks are expected to have their pebbles retained in multiple rings as far out as six times the orbit of Neptune.
The Webb observations were designed to determine whether compact disks have a higher water abundance in their inner, rocky planet region, as expected if pebble drift is more efficient and is delivering lots of solid mass and water to inner planets. The team chose to use MIRI's MRS (the Medium-Resolution Spectrometer) because it is sensitive to water vapor in disks.
The results confirmed expectations by revealing excess cool water in the compact disks, compared with the large disks.
As the pebbles drift, any time they encounter a pressure bump -- an increase in pressure -- they tend to collect there. These pressure traps don't necessarily shut down pebble drift, but they do impede it. This is what appears to be happening in the large disks with rings and gaps.
Current research proposes that large planets may cause rings of increased pressure, where pebbles tend to collect. This also could have been a role of Jupiter in our solar system -- inhibiting pebbles and water delivery to our small, inner, and relatively water-poor rocky planets.
Solving the Riddle
When the data first came in, the results were puzzling to the research team. ""For two months, we were stuck on these preliminary results that were telling us that the compact disks had colder water, and the large disks had hotter water overall,"" remembered Banzatti. ""This made no sense, because we had selected a sample of stars with very similar temperatures.""
Only when Banzatti overlaid the data from the compact disks onto the data from the large disks did the answer clearly emerge: the compact disks have extra cool water just inside the snowline, at about ten times closer than the orbit of Neptune.
""Now we finally see unambiguously that it is the colder water that has an excess,"" said Banzatti. ""This is unprecedented and entirely due to Webb's higher resolving power!""

","score: 12.379568326947641, grade_level: '12'","score: 13.255531034482757, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/acf5ec,"Previous analyses of mid-infrared water spectra from young protoplanetary disks observed with the Spitzer-IRS found an anticorrelation between water luminosity and the millimeter dust disk radius observed with ALMA. This trend was suggested to be evidence for a fundamental process of inner disk water enrichment proposed decades ago to explain some properties of the solar system, in which icy pebbles drift inward from the outer disk and sublimate after crossing the snow line. Previous analyses of IRS water spectra, however, were uncertain due to the low spectral resolution that blended lines together. We present new JWST-MIRI spectra of four disks, two compact and two large with multiple radial gaps, selected to test the scenario that water vapor inside the snow line is regulated by pebble drift. The higher spectral resolving power of MIRI-MRS now yields water spectra that separate individual lines, tracing upper level energies from 900 to 10,000 K. These spectra clearly reveal excess emission in the low-energy lines in compact disks compared to large disks, demonstrating an enhanced cool component with T ≈ 170–400 K and equivalent emitting radius R eq ≈ 1–10 au. We interpret the cool water emission as ice sublimation and vapor diffusion near the snow line, suggesting that there is indeed a higher inward mass flux of icy pebbles in compact disks. Observation of this process opens up multiple exciting prospects to study planet formation chemistry in inner disks with JWST."
"
An international research team led by Takuma Izumi, an assistant professor at the National Astronomical Observatory of Japan, has observed in high resolution (approximately 1 light year) the active galactic nucleus of the Circinus Galaxy -- one of the closest major galaxies to the Milky Way. The observation was made possible by the Atacama Large Millimeter/Submillimeter Array (ALMA) astronomical observatory in Chile.

This breakthrough marks the world's first quantitative measurement at this scale of gas flows and their structures of a nearby supermassive black hole in all phase gases, including plasma, atomic, and molecular. Such high resolution allowed the team to team to capture the accretion flow heading towards the supermassive black hole, revealing that this accretion flow is generated by a physical mechanism known as 'gravitational instability.' Furthermore, the team also found that a significant portion of this accretion flow does not contribute to the growth of the black hole. Instead, most of the gas is expelled from the vicinity of the black hole as atomic or molecular outflows, and returns to the gas disk to participate again into an accretion flow towards the black hole, much like how water gets recycled in a water fountain. These findings represent a crucial advancement towards a greater understanding of the growth mechanisms of supermassive black holes.
These observation results were published in Science on November 2, 2023.
'Supermassive black holes,' with masses exceeding a million times that of the Sun, exist at the centers of many galaxies. But astronomers have long pondered the mechanisms responsible their formation. One proposed mechanism, as outlined in previous research, suggests that gas accretes onto the black hole as it gravitates towards the center of the host galaxy.
As gas approaches the supermassive black holes, the intense gravitational pull of the black hole causes the gas to accelerate. The resulting increase in friction between gas particles leads to the gas heating up to temperatures as high as several million degrees and results in the emission of brilliant light. Known as an active galactic nucleus (AGN), the brightness can at times surpass the combined light of all the stars in the galaxy. Interestingly, a portion of the gas that falls towards the black hole (accretion flow) is thought to be blown away by the immense energy of this active galactic nucleus, leading to outflows.
Previous theoretical and observational studies have provided detailed insights into gas accretion mechanisms from the 100,000 light-years scale down to a scale of a few hundred light-years at the center. However, gas accretion occurs a few dozen light-years from the galactic center. This limited spacial scale has hindered further understanding of the accretion process. For instance, to comprehend quantitatively the growth of black holes, it is necessary to measure the accretion flow rate (how much gas is flowing in) and to determine the amounts and types of gases (plasma, atomic gas, molecular gas) that are expelled as outflows at that small scale. Unfortunately, observational understanding has not progressed significantly until now.
""Observations of multiphase gases can provide a more comprehensive and thorough understanding of the distribution and dynamics of matter around a black hole and our observation marks the highest resolution ever achieved for multiphase gas observations in an active galactic nucleus,"" points out Izumi.

Izumi and his colleagues initially captured, for the first time, the accretion flow heading towards the supermassive black hole within the high-density gas disk that extends over several light-years from the galactic center. Identifying this accretion flow had long been a challenge due to the small scale of the region and the complex motions of gas near the galactic center. However, the research team pinpointed the location where the foreground molecular gas was absorbing the light from the active galactic nucleus shining brightly in the background. Detailed analysis revealed that this absorbing material is moving away from Earth. As the absorbing material consistently resides between the active galactic nucleus and Earth, this indicates that the team has successfully captured the accretion flow heading toward the active galactic nucleus.
The study also elucidated the physical mechanism responsible for inducing this gas accretion. The observed gas disk exhibited a gravitational force so substantial that it could not be sustained by the pressure calculated from the gas disk's motion. When this situation occurs, the gas disk collapses under its own weight, forming complex structures and losing its ability to maintain stable motion at the galactic center. Consequently, the gas rapidly falls towards the central black hole, A phenomenon known as ""gravitational instability"" at the heart of the galaxy.
Furthermore, the study advanced quantitative understanding of gas flows around the active galactic nucleus. By considering the density of the observed gas and the velocity of the accretion flow, the researchers were able to calculate the rate at which gas is supplied to the black hole. Surprisingly, this rate was found to be 30 times greater than what is needed to sustain the active galactic nucleus. In other words, the majority of the accretion flow at the 1-light-year scale around the galactic center was not contributing to the growth of the black hole.
So, where did this surplus gas go? High-sensitivity observations of all phase gases with ALMA detected outflows from the active galactic nucleus. Quantitative analysis revealed that the majority of the gas flowing towards the black hole was expelled as atomic or molecular outflows. However, due to their slow velocities, they couldn't escape the gravitational pull of the black hole and eventually returned to the gas disk. There, they were recycled into an accretion flow toward the black hole, completing a fascinating gas recycling process at the galactic center.
Reflecting on the achievements Takuma Izumi iterates, ""Detecting accretion flows and outflows in a region just a few light-years around the actively growing supermassive black hole, particularly in a multiphase gas, and even deciphering the accretion mechanism itself, are monumental achievements in the quest to reveal more about supermassive black holes."" Looking ahead to the future, he continues, ""To gain a comprehensive understanding of the growth of supermassive black holes in cosmic history, it is essential to investigate various types of supermassive black holes that are located farther away from us. This requires high-resolution and high-sensitivity observations, and we have high expectations for the continued use of ALMA, as well as for upcoming large radio interferometers in the next generation.""

","score: 15.496265382557517, grade_level: '15'","score: 16.408695826645264, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adf0569,"Active galaxies contain a supermassive black hole at their center that grows by accreting matter from the surrounding galaxy. The accretion process in about the central 10 parsecs has not been directly resolved in previous observations because of the small apparent angular sizes involved. We observed the active nucleus of the Circinus Galaxy using submillimeter interferometry. A dense inflow of molecular gas was evident on subparsec scales. We calculated that less than 3% of this inflow is accreted by the black hole, with the rest being ejected by multiphase outflows, providing feedback to the host galaxy. Our observations also reveal a dense gas disk surrounding the inflow that is gravitationally unstable, which drives the accretion into about the central 1 parsec."
"
New observations down to light-year scale of the gas flows around a supermassive black hole have successfully detected dense gas inflows and shown that only a small portion (about 3 percent) of the gas flowing towards the black hole is eaten by the black hole. The remainder is ejected and recycled back into the host galaxy.

Not all of the matter which falls towards a black hole is absorbed, some of it is ejected as outflows. But the ratio of the matter that the black hole ""eats,"" and the amount ""dropped"" has been difficult to measure.
An international research team led by Takuma Izumi, an assistant professor at the National Astronomical Observatory of Japan, used the Atacama Large Millimeter/submillimeter Array (ALMA) to observe the supermassive black hole in the Circinus Galaxy, located 14 million light-years away in the direction of the constellation Circinus. This black hole is known to be actively feeding.
Thanks to ALMA's high resolution, the team was the first in the world to measure the amount of inflow and outflow down to a scale of a few light-years around the black hole. By measuring the flows of gasses in different states (molecular, atomic, and plasma) the team was able to determine the overall efficiency of black hole feeding, and found that it was only about 3 precent. The team also confirmed that gravitational instability is driving the inflow. Analysis also showed that the bulk of the expelled outflows are not fast enough to escape the galaxy and be lost. They are recycled back into the circumnuclear regions around the black hole, and start to slowly fall towards the black hole again.

","score: 13.841730205278598, grade_level: '14'","score: 13.636979472140766, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adf0569,"Active galaxies contain a supermassive black hole at their center that grows by accreting matter from the surrounding galaxy. The accretion process in about the central 10 parsecs has not been directly resolved in previous observations because of the small apparent angular sizes involved. We observed the active nucleus of the Circinus Galaxy using submillimeter interferometry. A dense inflow of molecular gas was evident on subparsec scales. We calculated that less than 3% of this inflow is accreted by the black hole, with the rest being ejected by multiphase outflows, providing feedback to the host galaxy. Our observations also reveal a dense gas disk surrounding the inflow that is gravitationally unstable, which drives the accretion into about the central 1 parsec."
"
Things may not have ended well for dinosaurs on Earth, but Cornell University astronomers say the ""light fingerprint"" of the conditions that enabled them to emerge here provide a crucial missing piece in our search for signs of life on planets orbiting alien stars.

Their analysis of the most recent 540 million years of Earth's evolution, known as the Phanerozoic Eon, finds that telescopes could better detect potential chemical signatures of life in the atmosphere of an Earth-like exoplanet more closely resembling the age the dinosaurs inhabited than the one we know today.
Two key biosignature pairs -- oxygen and methane, and ozone and methane -- appeared stronger in models of Earth roughly 100 million to 300 million years ago, when oxygen levels were significantly higher. The models simulated the transmission spectra, or light fingerprint, generated by an atmosphere that absorbs some colors of starlight and lets others filter through, information scientists use to determine the atmosphere's composition.
""Modern Earth's light fingerprint has been our template for identifying potentially habitable planets, but there was a time when this fingerprint was even more pronounced -- better at showing signs of life,"" said Lisa Kaltenegger, director of the Carl Sagan Institute (CSI) and associate professor of astronomy. ""This gives us hope that it might be just a little bit easier to find signs of life -- even large, complex life -- elsewhere in the cosmos.""
Kaltenegger is co-author of ""Oxygen Bounty for Earth-like Exoplanets: Spectra of Earth Through the Phanerozoic,"" published in Monthly Notices of the Royal Astronomical Society: Letters. First author, Rebecca Payne, research associate at CSI, led the new models that details a critical epoch including the origins of land plants, animals and dinosaurs.
Using estimates from two established climate models (called GEOCARB and COPSE), the researchers simulated Earth's atmospheric composition and resulting transmission spectra over five 100-million-year increments of the Phanerozoic. Each features significant changes as a complex ocean biosphere diversified, forests proliferated and terrestrial biospheres flourished, influencing the mix of oxygen and other gasses in the atmosphere.
""It's only the most recent 12% or so of Earth's history, but it encompasses pretty much all of the time in which life was more complex than sponges,"" said Payne. ""These light fingerprints are what you'd search for elsewhere, if you were looking for something more advanced than a single-celled organism.""
While similar evolutionary processes may or may not unfold on exoplanets, Payne and Kaltenegger said their models fill in a missing puzzle piece of what a Phanerozoic would look like to a telescope, creating new templates for habitable planets with varying atmospheric oxygen levels.

Kaltenegger pioneered modeling of what Earth would look like to faraway observers based on changes over time in its geology, climate and atmosphere -- our ""ground truth,"" she said, for identifying potential evidence of life on other worlds.
To date, about 35 rocky exoplanets have been discovered in habitable zones where liquid water could exist, Kaltenegger said. Analyzing an exoplanet's atmosphere -- if it has one -- is at the edge of technical capability for NASA's James Webb Space Telescope but is now a possibility. But, the researchers said, scientists need to know what to look for. Their models identify planets like Phanerozoic Earth as the most promising targets for finding life in the cosmos.
They also allow scientists to entertain the possibility -- purely theoretical -- that if a habitable exoplanet is discovered to have an atmosphere with 30% oxygen, life there might not be limited to microbes, but could include creatures as large and varied as the megalosauruses or microraptors that once roamed Earth.
""If they're out there,"" Payne said, ""this sort of analysis lets us figure out where they could be living.""
Dinosaurs or not, the models confirm that from a great distance, such a planet's light fingerprint would stand out more than a modern Earth's.
 

","score: 16.387543090855974, grade_level: '16'","score: 18.604591732398482, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnrasl/slad147,"In the search for life in the Universe, Earth provides a template of evolution for the one habitable planet we know. Earth’s atmospheric composition has changed significantly throughout its history. The last 500 Myr – the Phanerozoic Eon, which includes the origins of animals, dinosaurs, and land plants – saw oxygen rise from ≤10 per cent to 35 per cent. But the resulting transmission spectra are a crucial missing piece in our search for signs of life in exoplanet atmospheres. Here, we simulate the atmosphere and transmission spectra of the Phanerozoic, using estimates from established climate models, and present the first high-resolution transmission spectra for Phanerozoic Earth. We demonstrate that the spectral biosignature pairs O2 + CH4 and O3 + CH4 in the atmosphere of a transiting Earth-like planet would indicate a biosphere, with O2 and O3 features potentially stronger than for modern Earth. The full model and high-resolution transmission spectra, covering 0.4–20 µm, are available online and provides a tool to plan and optimize observations, train retrieval methods, and interpret upcoming observations with ground- and space-based telescopes."
"
Giant gas planets can be agents of chaos, ensuring nothing lives on their Earth-like neighbors around other stars. New studies show, in some planetary systems, the giants tend to kick smaller planets out of orbit and wreak havoc on their climates.

Jupiter, by far the biggest planet in our solar system, plays an important protective role. Its enormous gravitational field deflects comets and asteroids that might otherwise hit Earth, helping create a stable environment for life. However, giant planets elsewhere in the universe do not necessarily protect life on their smaller, rocky planet neighbors.
A new Astronomical Journal paper details how the pull of massive planets in a nearby star system are likely to toss their Earth-like neighbors out of the ""habitable zone."" This zone is defined as the range of distances from a star that are warm enough for liquid water to exist on a planet's surface, making life possible.
Unlike most other known solar systems, the four giant planets in HD 141399 are farther from their star. This makes it a good model for comparison with our solar system where Jupiter and Saturn are also relatively far from the sun.
""It's as if they have four Jupiters acting like wrecking balls, throwing everything out of whack,"" said Stephen Kane, UC Riverside astrophysicist and author of the journal paper.
Taking data about the system's planets into account, Kane ran multiple computer simulations to understand the effect of these four giants. He wanted specifically to look at the habitable zone in this star system and see if an Earth could remain in a stable orbit there.
""The answer is yes, but it's very unlikely. There are only a select few areas where the giants' gravitational pull would not knock a rocky planet out of its orbit and send it flying right out of the zone,"" Kane said.

While this paper shows giant planets outside the habitable zone destroying the chances for life, a second, related paper shows how one big planet in the middle of the zone would have a similar effect.
Also published in the Astronomical Journal, this second paper examines a star system only 30 light years away from Earth called GJ 357. For reference, the galaxy is estimated to be 100,000 light years in diameter, so this system is ""definitely in our neighborhood,"" Kane said.
Earlier studies found that a planet in this system, named GJ 357 d, resides in the system's habitable zone and has been measured at about six times the mass of the Earth. However, in this paper titled ""Agent of Chaos,"" Kane shows the mass is likely much bigger.
""It's possible GJ 357 d is as much as 10 Earth masses, which means it's probably not terrestrial, so you couldn't have life on it,"" Kane said. ""Or at least, it would not be able to host life as we know it.""
In the second part of the paper, Kane and his collaborator, UCR planetary science postdoctoral scholar Tara Fetherolf, demonstrate that if the planet is much larger than previously believed, it is certain to prevent more Earth-like planets from residing in the habitable zone alongside it.
Though there are also a select few locations in the habitable zone of this system where an Earth could potentially reside, their orbits would be highly elliptical around the star. ""In other words, the orbits would produce crazy climates on those planets,"" Kane said. ""This paper is really a warning, when we find planets in the habitable zone, not to assume they are automatically capable of hosting life.""
Ultimately, the pair of papers shows how uncommon it is to find the right set of circumstances to host life elsewhere in the universe. ""Our work gives us more reasons to be very grateful for the particular planetary configuration we have in our solar system,"" Kane said.

","score: 11.85493526961612, grade_level: '12'","score: 12.458407069683666, grade_levels: ['college'], ages: [18, 24]",10.3847/1538-3881/acfb01,"The search for exoplanets has revealed a diversity of planetary system architectures, the vast majority of which diverge significantly from the template of the solar system. In particular, giant planets beyond the snow line are relatively rare, especially for low-mass stars, placing the solar system within a small category of systems with multiple giant planets at large separations. An exoplanetary system of note is that of HD 141399, consisting of a K-dwarf host star that harbors four giant planets with separations extending to ∼4.5 au. The architecture of the system creates a complex pattern of mean motion resonances and gravitationally perturbed regions that may exclude the presence of other planets, including within the habitable zone of the system. Here, we present the results of dynamical simulations that explore the interaction of the known planets of the system, their apsidal trajectories, resonance locations, and dynamical evolution. We further investigate the results of injecting Earth-mass planets and provide the regions of dynamical viability within the habitable zone where terrestrial planets may maintain long-term stability. We discuss these results in the context of the importance of giant planets for volatile delivery and planetary habitability considerations."
"
A study from an international team led by researchers from Nagoya University in Japan and the University of New Hampshire in the United States has revealed the importance of the Earth's upper atmosphere in determining how large geomagnetic storms develop. Their findings reveal the previously underestimated importance of the Earth's atmosphere. Understanding the factors that cause geomagnetic storms is important because they can have a direct impact on the Earth's magnetic field such as causing unwanted currents in the power grid and disrupting radio signals and GPS. This research may help predict the storms that will have the greatest consequences.

Scientists have long known that geomagnetic storms are associated with the activities of the Sun. Hot charged particles make up the Sun's outer layer, the one visible to us. These particles flow out of the Sun creating the 'solar wind', and interact with objects in space, such as the Earth. When the particles reach the magnetic field surrounding our planet, known as the magnetosphere, they interact with it. The interactions between the charged particles and magnetic fields lead to space weather, the conditions in space that can affect the Earth and technological systems such as satellites.
An important part of the magnetosphere is the magnetotail. The magnetotail is the part of the magnetosphere that extends away from the Sun, in the direction of the solar wind flow. Inside the magnetotail is the plasma sheet region, which is full of charged particles (plasma). The plasma sheet is important because it is the source region for the particles that get into the inner magnetosphere, creating the current that causes geomagnetic storms.
Although the importance of the Sun is well known, an international group of researchers aimed to solve the mystery of how much of the plasma in the magnetosphere comes from Earth and how that contribution changes during a geomagnetic storm. The group was led by Lynn Kistler, Nagoya University Designated Professor and University of New Hampshire Professor (cross-appointment), Yoshizumi Miyoshi, Nagoya University Professor, and Tomoaki Hori, Nagoya University Designated Professor. For their study, they used data from a large geomagnetic storm that happened on September 7-8, 2017. During this time, the Sun released a massive coronal mass ejection that collided with the Earth's atmosphere, resulting in a huge geomagnetic storm. The impact disrupted the magnetosphere, leading to interference with radio signals, GPS, and precision timing applications.
The researchers retrospectively analyzed the ion transport during this event using data from several space missions, including the NASA/Magnetospheric Multiscale (MMS) mission, the Japanese Arase mission, the ESA/Cluster mission, and the NASA/Wind mission. They distinguished the ions from those of the solar wind and from those of the ionosphere itself.
Using simultaneous measurements of the solar wind composition to track the source changes, they identified substantial changes in the composition and other properties of the near-earth plasma sheet as it developed. These properties of the plasma sheet, such as density, particle energy distribution, and composition, affect the development of the geomagnetic storm.
At the start of the main phase of the storm, the source changed from solar wind dominated to ionosphere dominated. ""The most important discovery was that at the beginning of the geomagnetic storm, the plasma changed from mostly solar to mostly ionospheric,"" explained Kistler. ""This shows that the geomagnetic storm drives more outflow from the Earth's ionosphere, and that the ionospheric plasma can move quickly throughout the magnetosphere.""
""Overall, our research contributes to understanding the development of geomagnetic storms by showing the importance of Earth's ionospheric plasma,"" she continues. ""We found compelling evidence that plasmas from not only the Sun but also the Earth drive a geomagnetic storm. In short, the properties of the plasma sheet (the density, the particle energy distribution, the composition) will affect geomagnetic storms, and these properties are different for different sources.""

","score: 14.001552795031056, grade_level: '14'","score: 15.572748447204965, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-41735-3,"Both solar wind and ionospheric sources contribute to the magnetotail plasma sheet, but how their contribution changes during a geomagnetic storm is an open question. The source is critical because the plasma sheet properties control the enhancement and decay rate of the ring current, the main cause of the geomagnetic field perturbations that define a geomagnetic storm. Here we use the solar wind composition to track the source and show that the plasma sheet source changes from predominantly solar wind to predominantly ionospheric as a storm develops. Additionally, we find that the ionospheric plasma during the storm main phase is initially dominated by singly ionized hydrogen (H+), likely from the polar wind, a low energy outflow from the polar cap, and then transitions to the accelerated outflow from the dayside and nightside auroral regions, identified by singly ionized oxygen (O+). These results reveal how the access to the magnetotail of the different sources can change quickly, impacting the storm development."
"
The presence of an infrared aurora on the cold, outer planet of Uranus has been confirmed for the first time by University of Leicester astronomers.

The discovery could shed light on the mysteries behind the magnetic fields of the planets of our solar system, and even on whether distant worlds might support life.
The team of scientists, supported by the Science and Technology Facilities Council (STFC), have obtained the first measurements of the infrared (IR) aurora at Uranus since investigations began in 1992. While the ultraviolet (UV) aurorae of Uranus has been observed since 1986, no confirmation of the IR aurora had been observed until now. The scientists' conclusions have been published in the journal Nature Astronomy.
The ice giants Uranus and Neptune are unusual planets in our solar system as their magnetic fields are misaligned with the axes in which they spin. While scientists have yet to find an explanation for this, clues may lie in Uranus's aurora.
Aurorae are caused by highly energetic charged particles, which are funnelled down and collide with a planet's atmosphere via the planet's magnetic field lines. On Earth, the most famous result of this process are the spectacles of the Northern and Southern Lights. At planets such as Uranus, where the atmosphere is predominately a mix of hydrogen and helium, this aurora will emit light outside of the visible spectrum and in wavelengths such as the infrared (IR).
The team used infrared auroral measurements taken by analysing specific wavelengths of light emitted from the planet, using the Keck II telescope. From this, they can analyse the light (known as emission lines) from these planets, similar to a barcode. In the infrared spectrum, the lines emitted by a charged particle known as H3+ will vary in brightness depending on how hot or cold the particle is and how dense this layer of the atmosphere is. Hence, the lines act like a thermometer into the planet.
Their observations revealed distinct increases in H3+ density in Uranus's atmosphere with little change in temperature, consistent with ionisation caused by the presence of an infrared aurora. Not only does this help us better understand the magnetic fields of the outer planets of our own solar system, but it may also help in identifying other planets that are suitable of supporting life.

Lead author Emma Thomas, a PhD student in the University of Leicester School of Physics and Astronomy, said: ""The temperature of all the gas giant planets, including Uranus, are hundreds of degrees Kelvin/Celsius above what models predict if only warmed by the sun, leaving us with the big question of how these planets are so much hotter than expected? One theory suggests the energetic aurora is the cause of this, which generates and pushes heat from the aurora down towards the magnetic equator.
""A majority of exoplanets discovered so far fall in the sub-Neptune category, and hence are physically similar to Neptune and Uranus in size. This may also mean similar magnetic and atmospheric characteristics too. By analysing Uranus's aurora which directly connects to both the planet's magnetic field and atmosphere, we can make predictions about the atmospheres and magnetic fields of these worlds and hence their suitability for life.
""This paper is the culmination of 30 years of auroral study at Uranus, which has finally revealed the infrared aurora and begun a new age of aurora investigations at the planet. Our results will go on to broaden our knowledge of ice giant auroras and strengthen our understanding of planetary magnetic fields in our solar system, at exoplanets and even our own planet.""
The results may also give scientists an insight into a rare phenomenon on Earth, in which the north and south pole switch hemisphere locations known as geomagnetic reversal.
Emma adds: ""We don't have many studies on this phenomena and hence do not know what effects this will have on systems that rely on Earth's magnetic field such as satellites, communications and navigation. However, this process occurs every day at Uranus due to the unique misalignment of the rotational and magnetic axes. Continued study of Uranus's aurora will provide data on what we can expect when Earth exhibits a future pole reversal and what that will mean for its magnetic field.""

","score: 14.37893647837782, grade_level: '14'","score: 15.096396130767637, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41550-023-02096-5,"Near-infrared (NIR)-wavelength observations of Uranus have been unable to locate any infrared aurorae, despite many attempts to do so since the 1990s. While at Jupiter and Saturn, NIR investigations have redefined our understanding of magnetosphere–ionosphere–thermosphere coupling, the lack of NIR auroral detection at Uranus means that we have lacked a window through which to study these processes at Uranus. Here we present NIR Uranian observations with the Keck II telescope taken on the 5 September 2006 and detect enhanced H3+ emissions. Analysing temperatures and column densities, we identify an 88% increase in localized H3+ column density, with no significant temperature increases, consistent with auroral activity generating increased ionization. By comparing these structures against the Q3mp magnetic-field model and the Voyager 2 ultraviolet observations, we suggest that these regions make up sections of the northern aurora."
"
Supernovae, exploding stars, play a critical role in the formation and evolution of galaxies. However, key aspects of them are notoriously difficult to simulate accurately in reasonably short amounts of time. For the first time, a team of researchers, including those from The University of Tokyo, apply deep learning to the problem of supernova simulation. Their approach can speed up the simulation of supernovae, and therefore of galaxy formation and evolution as well. These simulations include the evolution of the chemistry which led to life.

When you hear about deep learning, you might think of the latest app that sprung up this week to do something clever with images or generate humanlike text. Deep learning might be responsible for some behind-the-scenes aspects of such things, but it's also used extensively in different fields of research. Recently, a team at a tech event called a hackathon applied deep learning to weather forecasting. It proved quite effective, and this got doctoral student Keiya Hirashima from the University of Tokyo's Department of Astronomy thinking.
""Weather is a very complex phenomenon but ultimately it boils down to fluid dynamics calculations,"" said Hirashima. ""So, I wondered if we could modify deep learning models used for weather forecasting and apply them to another fluid system, but one that exists on a vastly larger scale and which we lack direct access to: my field of research, supernova explosions.""
Supernovae occur when suitably massive stars burn through most of their fuel and collapse in enormous explosions. They are so huge that they can, and do, influence large areas inside their host galaxies. If a supernova had happened a few hundred years ago within a few hundred light-years from Earth, you might not be reading this article right now. So, the better we understand supernovae, the better we can understand why galaxies are the way they are.
""The problem is the time it takes to calculate the way supernovae explode. Currently, many models of galaxies over long time spans simplify things by pretending supernovae explode in a perfectly spherical fashion, as this is relatively easy to calculate,"" said Hirashima. ""However, in reality, they are quite asymmetric. Some regions of the shell of material that forms the boundary of the explosion are more complex than others. We applied deep learning to help ascertain which parts of the explosion require more, or less, attention during a simulation to ensure the best accuracy, whilst also taking the least amount of time overall. This way of dividing a problem is called Hamiltonian splitting. Our new model, 3D-MIM, can reduce the number of computational steps in the calculation of 100,000 years of supernova evolution by 99%. So, I think we'll really help reduce a bottleneck too.""
Of course, deep learning requires deep training. Hirashima and his team had to run hundreds of simulations taking millions of hours of computer time (supercomputers are highly parallel, so this length of time would be divided amongst the thousands of computing elements required). But their results proved it was worth it. They now hope to apply their methodology to other areas of astrophysics; for example, galactic evolution is also influenced by large star-forming regions. 3D-MIM models the deaths of stars, and perhaps soon it will be used to model their births as well. It could even find use beyond astrophysics altogether in other fields requiring high spatial and temporal resolutions, such as climate and earthquake simulations.

","score: 12.113204868154156, grade_level: '12'","score: 12.215897864216679, grade_levels: ['college'], ages: [18, 24]",10.1093/mnras/stad2864,"Supernova (SN) plays an important role in galaxy formation and evolution. In high-resolution galaxy simulations using massively parallel computing, short integration time-steps for SNe are serious bottlenecks. This is an urgent issue that needs to be resolved for future higher-resolution galaxy simulations. One possible solution would be to use the Hamiltonian splitting method, in which regions requiring short time-steps are integrated separately from the entire system. To apply this method to the particles affected by SNe in a smoothed particle hydrodynamics simulation, we need to detect the shape of the shell on and within which such SN-affected particles reside during the subsequent global step in advance. In this paper, we develop a deep learning model, 3D-Memory In Memory (3D-MIM), to predict a shell expansion after a SN explosion. Trained on turbulent cloud simulations with particle mass mgas = 1 M⊙, the model accurately reproduces the anisotropic shell shape, where densities decrease by over 10 per cent by the explosion. We also demonstrate that the model properly predicts the shell radius in the uniform medium beyond the training data set of inhomogeneous turbulent clouds. We conclude that our model enables the forecast of the shell and its interior where SN-affected particles will be present."
"
Scientists have observed the creation of rare chemical elements in the second-brightest gamma-ray burst ever seen -- casting new light on how heavy elements are made.

Researchers examined the exceptionally bright gamma-ray burst GRB 230307A, which was caused by a neutron star merger. The explosion was observed using an array of ground and space-based telescopes, including NASA's James Webb Space Telescope, Fermi Gamma-ray Space Telescope, and Neil Gehrels Swift Observatory.
Publishing their findings today in Nature (25 Oct), the international research team which included experts from the University of Birmingham, reveal that they found the heavy chemical element tellurium, in the aftermath of the explosion.
Other elements such as iodine and thorium, which are needed to sustain life on earth, are also likely to be amongst the material ejected by the explosion, also known as a kilonova.
Dr Ben Gompertz, Assistant Professor of Astronomy at the University of Birmingham, and co-author of the study explains: ""Gamma-ray bursts come from powerful jets travelling at almost the speed of light -- in this case driven by a collision between two neutron stars. These stars spent several billion years spiralling towards one another before colliding to produce the gamma-ray burst we observed in March this year. The merger site is the approximate length of the Milky Way (about 120,000 light-years) outside of their home galaxy, meaning they must have been launched out together.
""Colliding neutron stars provide the conditions needed to synthesise very heavy elements, and the radioactive glow of these new elements powered the kilonova we detected as the blast faded. Kilonovae are extremely rare and very difficult to observe and study, which is why this discovery is so exciting.""
GRB 230307A was one of the brightest gamma-ray bursts ever observed -- over a million times brighter than the entire Milky Way Galaxy combined. This is the second time individual heavy elements have been detected using spectroscopic observations after a neutron star merger, providing invaluable insight into how these vital building blocks needed for life are formed.

Lead author of the study Andrew Levan, Professor of Astrophysics at Radboud University in the Netherlands, said: ""Just over 150 years since Dmitri Mendeleev wrote down the periodic table of elements, we are now finally in the position to start filling in those last blanks of understanding where everything was made, thanks to the James Webb Telescope.""
GRB 230307A lasted for 200 seconds, meaning it is categorised as a long-duration gamma-ray burst. This is unusual as short gamma-ray bursts, which last less than two seconds, are more commonly caused by neutron star mergers. Long gamma-ray bursts like this one are usually caused by the explosive death of a massive star.
The researchers are now seeking to learn more about how these neutron star mergers work and how they power these huge element-generating explosions.
Dr Samantha Oates, a co-author of the study while a postdoctoral research fellow at the University of Birmingham (now a lecturer at Lancaster University) said: ""Just a few short years ago discoveries like this one would not have been possible, but thanks to the James Webb Space Telescope we can observe these mergers in exquisite detail.""
Dr Gompertz concludes: ""Until recently, we didn't think mergers could power gamma-ray bursts for more than two seconds. Our next job is to find more of these long-lived mergers and develop a better understanding of what drives them -- and whether even heavier elements are being created. This discovery has opened the door to a transformative understanding of our universe and how it works.""

","score: 15.198486308520035, grade_level: '15'","score: 17.009486067614226, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06759-1,"The mergers of binary compact objects such as neutron stars and black holes are of central interest to several areas of astrophysics, including as the progenitors of gamma-ray bursts (GRBs)1, sources of high-frequency gravitational waves (GWs)2 and likely production sites for heavy-element nucleosynthesis by means of rapid neutron capture (the r-process)3. Here we present observations of the exceptionally bright GRB 230307A. We show that GRB 230307A belongs to the class of long-duration GRBs associated with compact object mergers4–6 and contains a kilonova similar to AT2017gfo, associated with the GW merger GW170817 (refs. 7–12). We obtained James Webb Space Telescope (JWST) mid-infrared imaging and spectroscopy 29 and 61 days after the burst. The spectroscopy shows an emission line at 2.15 microns, which we interpret as tellurium (atomic mass A = 130) and a very red source, emitting most of its light in the mid-infrared owing to the production of lanthanides. These observations demonstrate that nucleosynthesis in GRBs can create r-process elements across a broad atomic mass range and play a central role in heavy-element nucleosynthesis across the Universe."
"
NASA's InSight mission to Mars helped scientists map out Mars' internal structure, including the size and composition of its core, and provided general hints about its tumultuous formation.

But findings from a new paper published in the journal Nature could lead to reanalysis of that data. An international team of researchers discovered the presence of a molten silicate layer overlying Mars' metallic core -- providing new insights into how Mars formed, evolved and became the barren planet it is today.
Published on October 25, 2023, the team's paper details the use of seismic data to locate and identify a thin layer of molten silicates (rock-forming minerals that make up the crust and mantle of Mars and Earth) lying between the Martian mantle and core. With the discovery of this molten layer, the researchers determined that Mars' core is both denser and smaller than previous estimates, a conclusion that better aligns with other geophysical data and analysis of Martian meteorites.
Vedran Lekic, a professor of geology at the University of Maryland and co-author of the paper, compared the molten layer to a 'heating blanket' covering the Martian core.
""The blanket not only insulates the heat coming from the core and prevents the core from cooling, but also concentrates radioactive elements whose decay generates heat"" Lekic said. ""And when that happens, the core is likely to be unable to produce the convective motions that would create a magnetic field -- which can explain why Mars currently doesn't have an active magnetic field around it.""
Without a functional protective magnetic field around itself, a terrestrial planet such as Mars would be extremely vulnerable to harsh solar winds and lose all the water on its surface, making it incapable of sustaining life. Lekic added that this difference between Earth and Mars could be attributed to differences in internal structure and the different planetary evolution paths the two planets took.
""The thermal blanketing of Mars' metallic core by the liquid layer at the base of the mantle implies that external sources are necessary to generate the magnetic field recorded in the Martian crust during the first 500 to 800 million years of its evolution,"" said the paper's lead author Henri Samuel, a scientist with the French National Center for Scientific Research. ""These sources could be energetic impacts or core motion generated by gravitational interactions with ancient satellites which have since then disappeared.""
The team's conclusions support theories that Mars was at one time a molten ocean of magma that later crystallized to produce a layer of silicate melt enriched in iron and radioactive elements at the base of the Martian mantle. The heat emanating from the radioactive elements would then have dramatically altered the thermal evolution and cooling history of the red planet.

""These layers, if widespread, can have pretty big consequences for the rest of the planet,"" Lekic said. ""Their existence can help tell us whether magnetic fields can be generated and maintained, how planets cool over time, and also how the dynamics of their interiors change over time.""
NASA's InSight mission officially ended in December 2022 after more than four years of collecting data on Mars, but the analysis of the observations continues. Samuel, Lekic and their co-authors are among the latest researchers to reexamine prior models of Mars using seismology to confirm the planet's structure and turbulent history.
""This new discovery of a molten layer is just one example of how we continue to learn new things from the completed InSight mission,"" Lekic said. ""We hope that the information we've gathered on planetary evolution using seismic data is paving the way for future missions to celestial bodies like the moon and other planets like Venus.""

","score: 16.328422647527912, grade_level: '16'","score: 17.975287081339715, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06601-8,"The detection of deep reflected S waves on Mars inferred a core size of 1,830 ± 40 km (ref. 1), requiring light-element contents that are incompatible with experimental petrological constraints. This estimate assumes a compositionally homogeneous Martian mantle, at odds with recent measurements of anomalously slow propagating P waves diffracted along the core–mantle boundary2. An alternative hypothesis is that Mars’s mantle is heterogeneous as a consequence of an early magma ocean that solidified to form a basal layer enriched in iron and heat-producing elements. Such enrichment results in the formation of a molten silicate layer above the core, overlain by a partially molten layer3. Here we show that this structure is compatible with all geophysical data, notably (1) deep reflected and diffracted mantle seismic phases, (2) weak shear attenuation at seismic frequency and (3) Mars’s dissipative nature at Phobos tides. The core size in this scenario is 1,650 ± 20 km, implying a density of 6.5 g cm−3, 5–8% larger than previous seismic estimates, and can be explained by fewer, and less abundant, alloying light elements than previously required, in amounts compatible with experimental and cosmochemical constraints. Finally, the layered mantle structure requires external sources to generate the magnetic signatures recorded in Mars’s crust."
"
Astrophysicists from Trinity College Dublin are scanning the Universe for ""technosignatures"" emanating from distant planets that would provide support for the existence of intelligent, alien life.

Using the Irish LOFAR telescope and its counterpart in Onsala, Sweden, the team -- led by Professor Evan Keane, Associate Professor of Radio Astronomy in Trinity's School of Physics, and Head of the Irish LOFAR Telescope -- plans to monitor millions of star systems.
Scientists have been searching for extraterrestrial radio signals for well over 60 years. Many of these have been carried out using single observatories which limits the ability to identify signals from the haze of terrestrial interference on Earth. Much of the effort has focused on frequencies above 1 GHz because the single-dish telescopes employed operate at these frequencies.
Now, a new collaboration led by Trinity College Dublin, with the Breakthrough Listen team and Onsala Space Observatory in Sweden, is perfecting a multi-site, multi-telescope technique that allows them to search at much lower frequencies of 110 -- 190 MHz.
The Breakthrough Listen programme is the most comprehensive search for technologically advanced extraterrestrial life, developing dedicated instruments at the Irish and Swedish LOFAR stations. Using multiple sites has the major benefit that it is much less likely to provide a ""false positive"" signal; such signals arise due to interference from many human sources on Earth.
The team has just published details of their method and their ongoing search in the Astronomical Journal They have already scanned 1.6 million star systems flagged as interesting targets by the Gaia and TESS space missions, run by ESA and NASA respectively. So far these searches have drawn a blank.
But the search has only just begun...

Prof. Keane said: ""In the last 50 years evidence has steadily mounted that the constituents and conditions necessary for life are relatively common in the Universe, which begs one of life's greatest unanswered questions: are we really alone?
""To some people the 'Search for Extra-terrestrial Intelligence, or SETI' might seem like something from a movie, but it has been a scientific pursuit for decades, and for a host of very good reasons. With this project we are basing our search on the common assumption that civilisations elsewhere in the Universe may employ similar technologies to those developed on Earth. As a result radio frequencies are a logical domain for conducting SETI surveys due to the widespread use of telecommunications and radar and our access to next-gen radio telescopes offers a great chance for a deep dive into the Universe.""
Owen Johnson, PhD Candidate in Trinity's School of Physics, is the first author of the journal article, and the first Irish person to ever undertake a PhD on the topic of SETI. He added:
""What makes surveys like this one truly captivating is the fact that we're pushing these telescopes to their absolute limits, directing them towards substantial portions of the sky. As a result, we have the exciting possibility of discovering all sorts of wild and wondrous phenomena during this process and if we're very fortunate, even encountering our cosmic neighbours.
""LOFAR is soon to undergo a staged series of upgrades across all stations in the array across Europe, which will allow an even broader SETI at ranges of 15 -- 240 MHz. We have billions of star systems to explore and will be relying on some machine learning techniques to sift through the immense volume of data.
""That in itself is interesting -- it would be fairly ironic if humankind discovered alien life by using artificial intelligence.""

","score: 15.809838926174496, grade_level: '16'","score: 17.391426174496644, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-3881/acf9f5,"The Search for Extraterrestrial Intelligence aims to find evidence of technosignatures, which can point toward the possible existence of technologically advanced extraterrestrial life. Radio signals similar to those engineered on Earth may be transmitted by other civilizations, motivating technosignature searches across the entire radio spectrum. In this endeavor, the low-frequency radio band has remained largely unexplored; with prior radio searches primarily above 1 GHz. In this survey at 110–190 MHz, observations of 1,631,198 targets from TESS and Gaia are reported. Observations took place simultaneously with two international stations (noninterferometric) of the Low Frequency Array in Ireland and Sweden. We can reject the presence of any Doppler drifting narrowband transmissions in the barycentric frame of reference, with equivalent isotropic radiated power of 1017 W, for 0.4 million (or 1.3 million) stellar systems at 110 (or 190) MHz. This work demonstrates the effectiveness of using multisite simultaneous observations for rejecting anthropogenic signals in the search for technosignatures."
"
New analysis of data from the Curiosity rover reveals that much of the craters on Mars today could have once been habitable rivers.

""We're finding evidence that Mars was likely a planet of rivers,"" said Benjamin Cardenas, assistant professor of geosciences at Penn State and lead author on a new paper announcing the discovery. ""We see signs of this all over the planet.""
In a study published in Geophysical Research Letters, the researchers used numerical models to simulate erosion on Mars over millennia and found that common crater formations -- called bench-and-nose landforms -- are most likely remnants of ancient riverbeds.
The study was the first to map the erosion of ancient Martian soil by training a computer model on a combination of satellite data, Curiosity images and 3D scans of the stratigraphy -- or layers of rock, called strata, deposited over millions of years -- beneath the Gulf of Mexico seafloor. The analysis revealed a new interpretation for common Martian crater formations which, until now, have never been associated with eroded river deposits.
""We have everything to learn about Mars by better understanding how these river deposits can be interpreted stratigraphically, thinking about rocks today as layers of sediment deposited over time,"" Cardenas said. ""This analysis is not snapshot, but a record of change. What we see on Mars today is the remnants of an active geologic history, not some landscape frozen in time.""
Prior studies of satellite data from Mars had identified erosional landforms called fluvial ridges as being possible candidates for ancient river deposits. Using data collected by the Curiosity rover at Gale crater, the team found signs of river deposits that are not associated with fluvial ridges, but rather bench-and-nose landforms that have never been linked to ancient river deposits.
""This suggests that there could be undiscovered river deposits elsewhere on the planet, and that an even larger section of the Martian sedimentary record could have been built by rivers during a habitable period of Mars history,"" Cardenas said. ""On Earth, river corridors are so important for life, chemical cycles, nutrient cycles and sediment cycles. Everything is pointing to these rivers behaving similarly on Mars.""
In designing their computer model, Cardenas and his team found a new use for 25-year-old scans of Earth's stratigraphy. Collected by oil companies, the scans of beneath the Gulf of Mexico seafloor provided an ideal comparison to Mars, Cardenas explained.

The team simulated Mars-like erosion using the 3D scans of actual, recorded stratigraphy on Earth. When they ran the simulation, the model revealed erosional Martian landscapes that formed topographic benches and noses, rather than fluvial ridges, appearing almost identical to landforms observed by the Curiosity rover inside the Gale crater.
""Our research indicates that Mars could have had far more rivers than previously believed, which certainly paints a more optimistic view of ancient life on Mars,"" Cardenas said. ""It offers a vision of Mars where most of the planet once had the right conditions for life.""
The other co-author on the paper is Kaitlyn Stacey, a doctoral candidate in planetary geosciences at Penn State. A NASA Solar System Workings Grant funded this work.

","score: 14.185114698385728, grade_level: '14'","score: 14.692866610025483, grade_levels: ['college_graduate'], ages: [24, 100]",10.1029/2023GL103618,"Fluvial channel belts, the deposits accumulated in rivers surrounded by floodplain deposits, are sensitive environmental recorders. Across Mars, wind has exposed ancient channel belts via the preferential erosion of floodplain strata, creating landforms called fluvial ridges. However, river deposits observed by the Mars rover Curiosity are instead exposed along a series of steep slopes and shallow benches, and short, truncated ridges we call noses. Here, we tested the hypothesis that these exposures record channel‐belt exhumation with a preferential direction of scarp retreat (a slope‐aspect control), in contrast with models of fluvial‐ridge formation. Using a landscape evolution model sensitive to lithology and an Earth‐analog 3D‐seismic‐reflectance volume imaging fluvial stratigraphy, we generated synthetic erosional landscapes where channel‐belt exhumation created benches and noses rather than fluvial ridges, depending on the orientation of belts relative to the preferential direction of scarp retreat, which we suggest is set by winds steered along crater topography."
"
In 2021, a team of University of Arizona astronomers suggested that a recently discovered near-Earth asteroid, Kamo`oalewa, could be a chunk of the moon. Two years after the striking discovery, another UArizona research group has found that a rare pathway could have enabled this to happen.

So far, only distant asteroids from beyond the orbit of Mars have been considered a source of near-Earth asteroids, said Renu Malhotra, Regents Professor of Planetary Sciences and a senior author on the paper.
""We are now establishing that the moon is a more likely source of Kamo`oalewa,"" Malhotra said.
The implication is that many more lunar fragments remain to be discovered among the near-Earth asteroid population. The study was published in the journal Communications Earth & Environment.
UArizona researchers decided to study Kamo`oalewa for two reasons. Kamo`oalewa is uncommon in that it is Earth's quasi-satellite, a term used for asteroids whose orbits are so Earth-like that they appear to orbit Earth even though they actually orbit the sun.
The other peculiar aspect of Kamo`oalewa is its longevity, said Jose Daniel Castro-Cisneros, the study's lead author and a graduate student in the Department of Physics. Kamo`oalewa is expected to remain as a companion of the Earth for millions of years, which is its remarkable feature, Castro-Cisneros said, unlike other known objects that stay in these very Earth-like orbits only for a few decades.
Aaron Rosengren, a former assistant professor in the Department of Aerospace and Mechanical Engineering, in the College of Engineering, was part of the study. Rosengren is now at the University of California, San Diego.

The 2021 study found that Kamo`oalewa's spectrum was unlike that of other near-Earth asteroids but matched most closely that of the moon. Based on this, the team hypothesized that the asteroid could have been ejected from the lunar surface as a result of a meteoroidal impact.
In the new study, Malhotra and her team wanted to determine the feasibility for a knocked-off piece of the moon to get into this quasi-satellite orbit -- a phenomenon that is quite unlikely, Malhotra said. Moon fragments that have enough kinetic energy to escape the Earth-moon system also have too much energy to land in the Earth-like orbits of quasi-satellites, she said.
With numerical simulations that accurately account for the gravitational forces of all the solar system's planets, Malhotra's group found that some lucky lunar fragments could actually find their way to such orbits. Kamo`oalewa could be one of those fragments created during an impact on the moon in the past few million years, according to the study.
Throughout its history, the moon has been bombarded by asteroids, which is evident in the numerous impact craters preserved on its surface, explained Malhotra. Impact craters are created when asteroids or meteorites crash into the surface of a planet or the moon. Impacts cause lunar material to be ejected from the moon's surface, but most of that material usually falls back on the moon, she said.
Some of the ejected materials fall on Earth, and that's how we get meteorites from the moon, Malhotra said. But a small fraction could escape the gravity of both the moon and the Earth and end up orbiting around the sun like other near-Earth asteroids. Numerical simulation suggests that Kamo`oalewa could be one of even tinier fractions that gained entry into the hard-to-reach Earth's co-orbital space.
The study's findings could help understand more about near-Earth asteroids, which are considered a hazard to Earth, Malhotra said. More detailed studies of Kamo`oalewa and determining this asteroid's origin in a specific impact crater on the moon will provide useful insights on impact mechanics, she said.
In the future, Castro-Cisneros said the team is planning to identify the specific conditions that allowed the orbital pathway of Kamo`oalewa. The group is also aiming to work on determining Kamo`oalewa's exact age, he said.
""We looked at Kamo`oalewa's spectrum only because it was in an unusual orbit,"" Malhotra said. ""If it had been a typical near-Earth asteroid, no one would have thought to find its spectrum and we wouldn't have known Kamo`oalewa could be a lunar fragment.""

","score: 13.371216357584405, grade_level: '13'","score: 13.749581550166432, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s43247-023-01031-w,"Near-Earth asteroid, Kamo’oalewa (469219), is one of a small number of known quasi-satellites of Earth; it transitions between quasi-satellite and horseshoe orbital states on centennial timescales, maintaining this dynamics over megayears. The similarity of its reflectance spectrum to lunar silicates and its Earth-like orbit both suggest that it originated from the lunar surface. Here we carry out numerical simulations of the dynamical evolution of particles launched from different locations on the lunar surface with a range of ejection velocities in order to assess the hypothesis that Kamo‘oalewa originated as a debris-fragment from a meteoroidal impact with the lunar surface. As these ejecta escape the Earth-Moon environment, they face a dynamical barrier for entry into Earth’s co-orbital space. However, a small fraction of launch conditions yields outcomes that are compatible with Kamo‘oalewa’s orbit. The most favored conditions are launch velocities slightly above the escape velocity from the trailing lunar hemisphere."
"
NASA's James Webb Space Telescope has discovered a new, never-before-seen feature in Jupiter's atmosphere. The high-speed jet stream, which spans more than 3,000 miles (4,800 kilometers) wide, sits over Jupiter's equator above the main cloud decks. The discovery of this jet is giving insights into how the layers of Jupiter's famously turbulent atmosphere interact with each other, and how Webb is uniquely capable of tracking those features.

""This is something that totally surprised us,"" said Ricardo Hueso of the University of the Basque Country in Bilbao, Spain, lead author on the paper describing the findings. ""What we have always seen as blurred hazes in Jupiter's atmosphere now appear as crisp features that we can track along with the planet's fast rotation.""
The research team analyzed data from Webb's NIRCam (Near-Infrared Camera) captured in July 2022. The Early Release Science program -- jointly led by Imke de Pater from the University of California, Berkeley and Thierry Fouchet from the Observatory of Paris -- was designed to take images of Jupiter 10 hours apart, or one Jupiter day, in four different filters, each uniquely able to detect changes in small features at different altitudes of Jupiter's atmosphere.
""Even though various ground-based telescopes, spacecraft like NASA's Juno and Cassini, and NASA's Hubble Space Telescope have observed the Jovian system's changing weather patterns, Webb has already provided new findings on Jupiter's rings, satellites, and its atmosphere,"" de Pater noted.
While Jupiter is different from Earth in many ways -- Jupiter is a gas giant, Earth is a rocky, temperate world -- both planets have layered atmospheres. Infrared, visible, radio, and ultraviolet light wavelengths observed by these other missions detect the lower, deeper layers of the planet's atmosphere -- where gigantic storms and ammonia ice clouds reside.
On the other hand, Webb's look farther into the near-infrared than before is sensitive to the higher-altitude layers of the atmosphere, around 15-30 miles (25-50 kilometers) above Jupiter's cloud tops. In near-infrared imaging, high-altitude hazes typically appear blurry, with enhanced brightness over the equatorial region. With Webb, finer details are resolved within the bright hazy band.
The newly discovered jet stream travels at about 320 miles per hour (515 kilometers per hour), twice the sustained winds of a Category 5 hurricane here on Earth. It is located around 25 miles (40 kilometers) above the clouds, in Jupiter's lower stratosphere.

By comparing the winds observed by Webb at high altitudes, to the winds observed at deeper layers from Hubble, the team could measure how fast the winds change with altitude and generate wind shears.
While Webb's exquisite resolution and wavelength coverage allowed for the detection of small cloud features used to track the jet, the complementary observations from Hubble taken one day after the Webb observations were also crucial to determine the base state of Jupiter's equatorial atmosphere and observe the development of convective storms in Jupiter's equator not connected to the jet.
""We knew the different wavelengths of Webb and Hubble would reveal the three-dimensional structure of storm clouds, but we were also able to use the timing of the data to see how rapidly storms develop,"" added team member Michael Wong of the University of California, Berkeley, who led the associated Hubble observations.
The researchers are looking forward to additional observations of Jupiter with Webb to determine if the jet's speed and altitude change over time.
""Jupiter has a complicated but repeatable pattern of winds and temperatures in its equatorial stratosphere, high above the winds in the clouds and hazes measured at these wavelengths,"" explained team member Leigh Fletcher of the University of Leicester in the United Kingdom. ""If the strength of this new jet is connected to this oscillating stratospheric pattern, we might expect the jet to vary considerably over the next 2 to 4 years -- it'll be really exciting to test this theory in the years to come.""
""It's amazing to me that, after years of tracking Jupiter's clouds and winds from numerous observatories, we still have more to learn about Jupiter, and features like this jet can remain hidden from view until these new NIRCam images were taken in 2022,"" continued Fletcher.
The researchers' results were recently published in Nature Astronomy.

","score: 16.448568789259763, grade_level: '16'","score: 18.38847764503017, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41550-023-02099-2,"The atmosphere of Jupiter has east–west zonal jets that alternate as a function of latitude as tracked by cloud motions at tropospheric levels. Above and below the cold tropopause at ~100 mbar, the equatorial atmosphere is covered by hazes at levels where thermal infrared observations used to characterize the dynamics of the stratosphere lose part of their sensitivity. James Webb Space Telescope observations of Jupiter in July 2022 show these hazes in higher detail than ever before and reveal the presence of an intense (140 m s−1) equatorial jet at 100–200 mbar (70 m s−1 faster than the zonal winds at the cloud level) that is confined to ±3° of the equator and is located below stratospheric thermal oscillations that extend at least from 0.1 to 40 mbar and repeat in multiyear cycles. This suggests that the new jet is a deep part of Jupiter’s Equatorial Stratospheric Oscillation and may therefore vary in strength over time."
"
An international team has spotted a remote blast of cosmic radio waves lasting less than a millisecond. This 'fast radio burst' (FRB) is the most distant ever detected. Its source was pinned down by the European Southern Observatory's (ESO) Very Large Telescope (VLT) in a galaxy so far away that its light took eight billion years to reach us. The FRB is also one of the most energetic ever observed; in a tiny fraction of a second it released the equivalent of our Sun's total emission over 30 years.

The discovery of the burst, named FRB 20220610A, was made in June last year by the ASKAP radio telescope in Australia [1] and it smashed the team's previous distance record by 50 percent.
""Using ASKAP's array of dishes, we were able to determine precisely where the burst came from,"" says Stuart Ryder, an astronomer from Macquarie University in Australia and the co-lead author of the study published today in Science. ""Then we used [ESO's VLT] in Chile to search for the source galaxy, [2] finding it to be older and further away than any other FRB source found to date and likely within a small group of merging galaxies.""
The discovery confirms that FRBs can be used to measure the 'missing' matter between galaxies, providing a new way to 'weigh' the Universe.
Current methods of estimating the mass of the Universe are giving conflicting answers and challenging the standard model of cosmology. ""If we count up the amount of normal matter in the Universe -- the atoms that we are all made of -- we find that more than half of what should be there today is missing,"" says Ryan Shannon, a professor at the Swinburne University of Technology in Australia, who also co-led the study. ""We think that the missing matter is hiding in the space between galaxies, but it may just be so hot and diffuse that it's impossible to see using normal techniques.""
""Fast radio bursts sense this ionised material. Even in space that is nearly perfectly empty they can 'see' all the electrons, and that allows us to measure how much stuff is between the galaxies,"" Shannon says.
Finding distant FRBs is key to accurately measuring the Universe's missing matter, as shown by the late Australian astronomer Jean-Pierre ('J-P') Macquart in 2020. ""J-P showed that the further away a fast radio burst is, the more diffuse gas it reveals between the galaxies. This is now known as the Macquart relation. Some recent fast radio bursts appeared to break this relationship. Our measurements confirm the Macquart relation holds out to beyond half the known Universe,"" says Ryder.

""While we still don't know what causes these massive bursts of energy, the paper confirms that fast radio bursts are common events in the cosmos and that we will be able to use them to detect matter between galaxies, and better understand the structure of the Universe,"" says Shannon.
The result represents the limit of what is achievable with telescopes today, although astronomers will soon have the tools to detect even older and more distant bursts, pin down their source galaxies and measure the Universe's missing matter. The international Square Kilometre Array Observatory is currently building two radio telescopes in South Africa and Australia that will be capable of finding thousands of FRBs, including very distant ones that cannot be detected with current facilities. ESO's Extremely Large Telescope, a 39-metre telescope under construction in the Chilean Atacama Desert, will be one of the few telescopes able to study the source galaxies of bursts even further away than FRB 20220610A.
Notes
[1] The ASKAP telescope is owned and operated by CSIRO, Australia's national science agency, on Wajarri Yamaji Country in Western Australia.
[2] The team used data obtained with the FOcal Reducer and low dispersion Spectrograph 2 (FORS2), the X-shooter and the High Acuity Wide-field K-band Imager (HAWK-I) instruments on ESO's VLT. Data from the Keck Observatory in Hawai'i, US, was also used in the study.

","score: 13.658289855072464, grade_level: '14'","score: 14.411434782608701, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adf2678,"Fast radio bursts (FRBs) are millisecond-duration pulses of radio emission originating from extragalactic distances. Radio dispersion is imparted on each burst by intervening plasma, mostly located in the intergalactic medium. In this work, we observe the burst FRB 20220610A and localize it to a morphologically complex host galaxy system at redshift 1.016 ± 0.002. The burst redshift and dispersion measure are consistent with passage through a substantial column of plasma in the intergalactic medium and extend the relationship between those quantities measured at lower redshift. The burst shows evidence for passage through additional turbulent magnetized plasma, potentially associated with the host galaxy. We use the burst energy of 2 × 10 42 erg to revise the empirical maximum energy of an FRB."
"
An advanced new three-dimensional (3D) computer simulation of the light emitted following a merger of two neutron stars has produced a similar sequence of spectroscopic features to an observed kilonova. ""The unprecedented agreement between our simulations and the observation of kilonova AT2017gfo indicates that we understand broadly what has taken place in the explosion and aftermath,"" says Luke Shingles, scientist at GSI/FAIR and the leading author of the publication in The Astrophysical Journal Letters. Recent observations that combine both gravitational waves and visible light have pointed to neutron star mergers as the major site of this element production. The research was performed by scientists at GSI Helmholtzzentrum für Schwerionenforschung and Queen's University Belfast.

The interactions between electrons, ions, and photons within the material ejected from a neutron-star merger determine the light that we can see through telescopes. These processes and the emitted light can be modelled with computer simulations of radiative transfer. Researchers have recently produced, for the first time, a three-dimensional simulation that self-consistently follows the neutron-star merger, neutron-capture nucleosynthesis, energy deposited by radioactive decay, and radiative transfer with tens of millions of atomic transitions of heavy elements.
Being a 3D model, the observed light can be predicted for any viewing direction. When viewed nearly perpendicular to the orbital plane of the two neutron stars (as observational evidence indicates for the kilonova AT2017gfo) the model predicts a sequence of spectral distributions that look remarkably similar to what has been observed for AT2017gfo. ""Research in this area will help us to understand the origins of elements heavier than iron (such as platinum and gold) that were mainly produced by the rapid neutron capture process in neutron star mergers,"" says Shingles.
About half of the elements heavier than iron are produced in an environment of extreme temperatures and neutron densities, as achieved when two neutron stars merge with each other. When they eventually spiral in toward each other and coalesce, the resulting explosion leads to the ejection of matter with the appropriate conditions to produce unstable neutron-rich heavy nuclei by a sequence of neutron captures and beta-decays. These nuclei decay to stability, liberating energy that powers an explosive 'kilonova' transient, a bright emission of light that rapidly fades in about a week.
The 3D simulation combines together several areas of physics, including the behavior of matter at high densities, the properties of unstable heavy nuclei, and atom-light interactions of heavy elements. Further challenges remain, such as accounting for the rate at which the spectral distribution changes, and the description of material ejected at late times. Future progress in this area will increase the precision with which we can predict and understand features in the spectra and will further our understanding of the conditions in which heavy elements were synthesized. A fundamental ingredient for these models is high quality atomic and nuclear experimental data as will be provided by the FAIR facility.

","score: 17.196743480897513, grade_level: '17'","score: 19.19128320194057, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/acf29a,"We present 3D radiative transfer calculations for the ejecta from a neutron star merger that include line-by-line opacities for tens of millions of bound–bound transitions, composition from an r-process nuclear network, and time-dependent thermalization of decay products from individual α and β − decay reactions. In contrast to expansion opacities and other wavelength-binned treatments, a line-by-line treatment enables us to include fluorescence effects and associate spectral features with the emitting and absorbing lines of individual elements. We find variations in the synthetic observables with both the polar and azimuthal viewing angles. The spectra exhibit blended features with strong interactions by Ce iii, Sr ii, Y ii, and Zr ii that vary with time and viewing direction. We demonstrate the importance of wavelength calibration of atomic data using a model with calibrated Sr, Y, and Zr data, and find major differences in the resulting spectra, including a better agreement with AT2017gfo. The synthetic spectra for a near-polar inclination show a feature at around 8000 Å, similar to AT2017gfo. However, they evolve on a more rapid timescale, likely due to the low ejecta mass (0.005 M ☉) as we take into account only the early ejecta. The comparatively featureless spectra for equatorial observers gives a tentative prediction that future observations of edge-on kilonovae will appear substantially different from AT2017gfo. We also show that 1D models obtained by spherically averaging the 3D ejecta lead to dramatically different direction-integrated luminosities and spectra compared to full 3D calculations."
"
A global team of scientists have announced the results of an unprecedented collaboration to search for the source of the largest ever seismic event recorded on Mars. The study, led by the University of Oxford, rules out a meteorite impact, suggesting instead that the quake was the result of enormous tectonic forces within Mars' crust.

The quake, which had a magnitude of 4.7 and caused vibrations to reverberate through the planet for at least six hours, was recorded by NASA's InSight lander on May 4 2022. Because its seismic signal was similar to previous quakes known to be caused by meteoroid impacts, the team believed that this event (dubbed 'S1222a') might have been caused by an impact as well, and launched an international search for a fresh crater.
Although Mars is smaller than Earth, it has a similar land surface area because it has no oceans. In order to survey this huge amount of ground -- 144 million km2 -- study lead Dr Benjamin Fernando of the University of Oxford sought contributions from the European Space Agency, the Chinese National Space Agency, the Indian Space Research Organisation, and the United Arab Emirates Space Agency. This is thought to be the first time that all missions in orbit around Mars have collaborated on a single project. Each group examined data from their satellites orbiting Mars to look for a new crater, or any other tell-tale signature of an impact (e.g. a dust cloud appearing in the hours after the quake).
After several months of searching, the team announced today that no fresh crater was found. They conclude that the event was instead caused by the release of enormous tectonic forces within Mars' interior. The results, published today in the journal Geophysical Research Letters, indicate that the planet is much more seismically active than previously thought.
Dr Fernando said: 'We still think that Mars doesn't have any active plate tectonics today, so this event was likely caused by the release of stress within Mars' crust. These stresses are the result of billions of years of evolution; including the cooling and shrinking of different parts of the planet at different rates. We still do not fully understand why some parts of the planet seem to have higher stresses than others, but results like these help us to investigate further. One day, this information may help us to understand where it would be safe for humans to live on Mars and where you might want to avoid!'
He added: 'This project represents a huge international effort to help solve the mystery of S1222a, and I am incredibly grateful to all the missions who contributed. I hope this project serves as a template for productive international collaborations in deep space.'
Dr Daniela Tirsch, Science Coordinator for the High Resolution Stereo Camera on board the European Space Agency's Mars Express Spacecraft said: 'This experiment shows how important it is to maintain a diverse set of instruments at Mars, and we are very glad to have played our part in completing the multi-instrumental and international approach of this study.'

From China, Dr Jianjun Liu (National Astronomical Observatories, Chinese Academy of Sciences) added: 'We are willing to collaborate with scientists around the world to share and apply this scientific data to get more knowledge about Mars, and are proud to have provided data from the colour imagers on Tianwen-1 to contribute to this effort.'
Dr Dimitra Atri, Group Leader for Mars at New York University Abu Dhabi and contributor of data from the UAE's Hope Spacecraft, said: 'This has been a great opportunity for me to collaborate with the InSight team, as well as with individuals from other major missions dedicated to the study of Mars. This really is the golden age of Mars exploration!'
Dr Constantinos Charalambous of Imperial College London, a co-author on the study, said: 'The absence of a crater in our image search for S1222a marks a significant milestone in interpreting seismic signals on Mars, crucial for distinguishing impact events from tectonic forces on the Red Planet.'
S1222a was one of the last events recorded by InSight before its end of mission was declared in December 2022. The team are now moving forward by applying knowledge from this study to future work, including upcoming missions to the Moon and Saturn's moon Titan.
About InSight InSight was a NASA mission dedicated to the study of the martian interior through geophysics, especially seismology (the study of Earthqukes). It launched from California in May 2018 and landed on Mars in November of that year. The last data were returned in December 2022, after the spacecraft lost power due to increasing dust accumulation on its solar panels. External partners to the InSight mission included the UK, France, Germany, and Switzerland. Within the UK, Imperial College London and the University of Oxford are lead institutions. During its time on Mars, InSight recorded over 1,300 marsquake events. Of these, at least 8 were from meteoroid impact events. The largest two formed craters around 150m in diameter. If the S1222a event was formed by an impact, we would expect the crater to be at least 300m in diameter.This project involved all other active missions currently orbiting Mars, who contributed their data and expertise. These include: The MAVEN, Mars Reconnaissance Orbiter (MRO), and Mars Odyssey spacecraft of NASA The ExoMars Trace Gas Orbiter (TGO) and Mars Express (MEX) spacecraft of ESA The Emirates Mars Mission (Hope) of the United Arab Emirates Space Agency The Tianwen-1 Mission of the Chinese National Space Agency The Mangalyaan (MOM) mission of the Indian Space Research Organisation, which ended in September 2022. The MOM data were searched but no relevant images were taken before the end of mission

","score: 13.733048552754436, grade_level: '14'","score: 15.10474323062558, grade_levels: ['college_graduate'], ages: [24, 100]",10.1029/2023GL103619,"The S1222a marsquake detected by InSight on 4 May 2022 was the largest of the mission, at 4.7. Given its resemblance to two other large seismic events (S1000a and S1094b), which were associated with the formation of fresh craters, we undertook a search for a fresh crater associated with S1222a. Such a crater would be expected to be ∼300 m in diameter and have a blast zone on the order of 180 km across. Orbital images were targeted and searched as part of an international, multi‐mission effort. Comprehensive analysis of the area using low‐ and medium‐resolution images reveals no relevant transient atmospheric phenomena and no fresh blast zone. High‐resolution coverage of the epicentral area from most spacecraft are more limited, but no fresh crater or other evidence of a new impact have been identified in those images either. We thus conclude that the S1222a event was highly likely of tectonic origin."
"
The Space Age is leaving fingerprints on one of the most remote parts of the planet -- the stratosphere -- which has potential implications for climate, the ozone layer and the continued habitability of Earth.

Using tools hitched to the nose cone of their research planes and sampling more than 11 miles above the planet's surface, researchers have discovered significant amounts of metals in aerosols in the atmosphere, likely from increasingly frequent launches and returns of spacecraft and satellites. That mass of metal is changing atmospheric chemistry in ways that may impact Earth's atmosphere and ozone layer.
""We are finding this human-made material in what we consider a pristine area of the atmosphere,"" said Dan Cziczo, one of a team of scientists who published a study on these results in the Proceedings of the National Academy of Sciences. ""And if something is changing in the stratosphere -- this stable region of the atmosphere -- that deserves a closer look."" Cziczo, professor and head of the Department of Earth, Atmospheric, and Planetary Sciences in Purdue's College of Science, is an expert in atmospheric science who has spent decades studying this rarefied region.
Led by Dan Murphy, an adjunct professor in the Department of Earth, Atmospheric, and Planetary Sciences and a researcher at the National Oceanic and Atmospheric Administration, the team detected more than 20 elements in ratios that mirror those used in spacecraft alloys. They found that the mass of lithium, aluminum, copper and lead from spacecraft reentry far exceeded those metals found in natural cosmic dust. Nearly 10% of large sulfuric acid particles -- the particles that help protect and buffer the ozone layer -- contained aluminum and other spacecraft metals.
Scientists estimate that as many as 50,000 more satellites may reach orbit by 2030. The team calculates that means that, in the next few decades, up to half of stratospheric sulfuric acid particles would contain metals from reentry. What effect that could have on the atmosphere, the ozone layer and life on Earth is yet to be understood.
Scientists have long suspected that spacecraft and satellites were changing the upper atmosphere, but studying the stratosphere, where we don't live and even the highest flights enter only briefly, is challenging.
As part of NASA's Airborne Science Program, Murphy and his group fly a WB-57 airplane to sample the atmosphere 11.8 miles (19 km) above the ground in Alaska, where circumpolar clouds tend to form. Similar measurements were made by Cziczo and his group from an ER-2 aircraft over the continental United States. Both groups use instruments hitched to the nose cone to ensure that only the freshest, most undisturbed air is sampled.

The sheltering sky
Like the view of the unruffled surface of the ocean, the stratosphere appears untroubled -- at least to human eyes. Life and civilization take place mostly on the planet's surface and in the troposphere, the atmosphere's very lowest layer. The stratosphere is a surprisingly stable and seemingly serene layer of the atmosphere.
The stratosphere is also the realm of the ozone layer: that gaseous marvel that acts as a global tent to shield the planet and all life on it from the searing, scorching rays of ultraviolet radiation. Without the ozone layer, life would likely never have arisen on Earth. And without it, life is unlikely to be able to continue.
The last decades have been eventful for the stratosphere. The ozone layer came under threat from chlorofluorocarbons in the 1980s, and only coordinated, sustained global efforts of governments and corporations have begun to bear fruit in repairing and replenishing it.
""Shooting stars streak through the atmosphere,"" Cziczo said. ""Often, the meteor burns up in the atmosphere and doesn't even become a meteorite and reach the planet. So the material it was made from stays in the atmosphere in the form of ions. They form very hot gas, which starts to cool and condense as molecules and fall into the stratosphere. The molecules find each other and knit together and form what we call meteorite smoke. Scientists recently started noticing that the chemical fingerprint of these meteoritic particles was starting to change, which made us ask, 'Well, what changed?' because meteorite composition hasn't changed. But the number of spacecraft has.""
What goes up
Spacecraft launches, and returns, were once international events. The launches of Sputnik and the Mercury missions were front-page news. Now, a quickening tide of innovation and loosening regulation means that dozens of countries and corporations are able to launch satellites and spacecraft into orbit. All those satellites have to be sent up on rockets -- and most of that material, eventually, comes back down.

Like the wakes of great ships trolling through the ocean, rockets leave behind them a trail of metals that may change the atmosphere in ways scientists don't yet understand.
""Just to get things into orbit, you need all this fuel and a huge body to support the payload,"" Cziczo said. ""There are so many rockets going up and coming back and so many satellites falling back through the atmosphere that it's starting to show up in the stratosphere as these aerosol particles.""
Of course, shooting stars were the first space-delivery system. Meteorites fall through the atmosphere every day. The heat and friction of the atmosphere peel material off them, just as they do off human-made artifacts. However, while hundreds of meteors enter the Earth's atmosphere every day, they are increasingly being rivaled by the mass of metals that comprise the tons of Falcon, Ariane and Soyuz rockets that boost spacecraft into space and return again to Earth's surface.
""Changes to the atmosphere can be difficult to study and complex to understand,"" Cziczo said. ""But what this research shows us is that the impact of human occupation and human spaceflight on the planet may be significant -- perhaps more significant than we have yet imagined. Understanding our planet is one of the most urgent research priorities there is.""

","score: 11.57331940636288, grade_level: '12'","score: 12.983410366888627, grade_levels: ['college'], ages: [18, 24]",10.1073/pnas.2313374120,"Large increases in the number of low earth orbit satellites are projected in the coming decades [L. Schulz, K.-H. Glassmeier, Adv. Space Res. 67 , 1002–1025 (2021)] with perhaps 50,000 additional satellites in orbit by 2030 [GAO, Large constellations of satellites: Mitigating environmental and other effects (2022)]. When spent rocket bodies and defunct satellites reenter the atmosphere, they produce metal vapors that condense into aerosol particles that descend into the stratosphere. So far, models of spacecraft reentry have focused on understanding the hazard presented by objects that survive to the surface rather than on the fate of the metals that vaporize. Here, we show that metals that vaporized during spacecraft reentries can be clearly measured in stratospheric sulfuric acid particles. Over 20 elements from reentry were detected and were present in ratios consistent with alloys used in spacecraft. The mass of lithium, aluminum, copper, and lead from the reentry of spacecraft was found to exceed the cosmic dust influx of those metals. About 10% of stratospheric sulfuric acid particles larger than 120 nm in diameter contain aluminum and other elements from spacecraft reentry. Planned increases in the number of low earth orbit satellites within the next few decades could cause up to half of stratospheric sulfuric acid particles to contain metals from reentry. The influence of this level of metallic content on the properties of stratospheric aerosol is unknown."
"
A paper in the journal Proceedings of the National Academy of Sciences today describes ""a missing law of nature,"" recognizing for the first time an important norm within the natural world's workings.

In essence, the new law states that complex natural systems evolve to states of greater patterning, diversity, and complexity. In other words, evolution is not limited to life on Earth, it also occurs in other massively complex systems, from planets and stars to atoms, minerals, and more.
Authored by a nine-member team -- leading scientists from the Carnegie Institution for Science, the California Institute of Technology (Caltech) and Cornell University, and philosophers from the University of Colorado -- the work was funded by the John Templeton Foundation.
""Macroscopic"" laws of nature describe and explain phenomena experienced daily in the natural world. Natural laws related to forces and motion, gravity, electromagnetism, and energy, for example, were described more than 150 years ago.
The new work presents a modern addition -- a macroscopic law recognizing evolution as a common feature of the natural world's complex systems, which are characterised as follows: They are formed from many different components, such as atoms, molecules, or cells, that can be arranged and rearranged repeatedly Are subject to natural processes that cause countless different arrangements to be formed Only a small fraction of all these configurations survive in a process called ""selection for function.""Regardless of whether the system is living or nonliving, when a novel configuration works well and function improves, evolution occurs.
The authors' ""Law of Increasing Functional Information"" states that the system will evolve ""if many different configurations of the system undergo selection for one or more functions.""
""An important component of this proposed natural law is the idea of 'selection for function,'"" says Carnegie astrobiologist Dr. Michael L. Wong, first author of the study.

In the case of biology, Darwin equated function primarily with survival -- the ability to live long enough to produce fertile offspring.
The new study expands that perspective, noting that at least three kinds of function occur in nature.
The most basic function is stability -- stable arrangements of atoms or molecules are selected to continue. Also chosen to persist are dynamic systems with ongoing supplies of energy.
The third and most interesting function is ""novelty"" -- the tendency of evolving systems to explore new configurations that sometimes lead to startling new behaviors or characteristics.
Life's evolutionary history is rich with novelties -- photosynthesis evolved when single cells learned to harness light energy, multicellular life evolved when cells learned to cooperate, and species evolved thanks to advantageous new behaviors such as swimming, walking, flying, and thinking.
The same sort of evolution happens in the mineral kingdom. The earliest minerals represent particularly stable arrangements of atoms. Those primordial minerals provided foundations for the next generations of minerals, which participated in life's origins. The evolution of life and minerals are intertwined, as life uses minerals for shells, teeth, and bones.

Indeed, Earth's minerals, which began with about 20 at the dawn of our Solar System, now number almost 6,000 known today thanks to ever more complex physical, chemical, and ultimately biological processes over 4.5 billion years.
In the case of stars, the paper notes that just two major elements -- hydrogen and helium -- formed the first stars shortly after the big bang. Those earliest stars used hydrogen and helium to make about 20 heavier chemical elements. And the next generation of stars built on that diversity to produce almost 100 more elements.
""Charles Darwin eloquently articulated the way plants and animals evolve by natural selection, with many variations and traits of individuals and many different configurations,"" says co-author Robert M. Hazen of Carnegie Science, a leader of the research.
""We contend that Darwinian theory is just a very special, very important case within a far larger natural phenomenon. The notion that selection for function drives evolution applies equally to stars, atoms, minerals, and many other conceptually equivalent situations where many configurations are subjected to selective pressure.""
The co-authors themselves represent a unique multi-disciplinary configuration: three philosophers of science, two astrobiologists, a data scientist, a mineralogist, and a theoretical physicist.
Says Dr. Wong: ""In this new paper, we consider evolution in the broadest sense -- change over time -- which subsumes Darwinian evolution based upon the particulars of 'descent with modification.'""
""The universe generates novel combinations of atoms, molecules, cells, etc. Those combinations that are stable and can go on to engender even more novelty will continue to evolve. This is what makes life the most striking example of evolution, but evolution is everywhere.""
Among many implications, the paper offers: Understanding into how differing systems possess varying degrees to which they can continue to evolve. ""Potential complexity"" or ""future complexity"" have been proposed as metrics of how much more complex an evolving system might become Insights into how the rate of evolution of some systems can be influenced artificially. The notion of functional information suggests that the rate of evolution in a system might be increased in at least three ways: (1) by increasing the number and/or diversity of interacting agents, (2) by increasing the number of different configurations of the system; and/or 3) by enhancing the selective pressure on the system (for example, in chemical systems by more frequent cycles of heating/cooling or wetting/drying). A deeper understanding of generative forces behind the creation and existence of complex phenomena in the universe, and the role of information in describing them An understanding of life in the context of other complex evolving systems. Life shares certain conceptual equivalencies with other complex evolving systems, but the authors point to a future research direction, asking if there is something distinct about how life processes information on functionality. Aiding the search for life elsewhere: if there is a demarcation between life and non-life that has to do with selection for function, can we identify the ""rules of life"" that allow us to discriminate that biotic dividing line in astrobiological investigations? At a time when evolving AI systems are an increasing concern, a predictive law of information that characterizes how both natural and symbolic systems evolve is especially welcomeLaws of nature -- motion, gravity, electromagnetism, thermodynamics -- etc. codify the general behavior of various macroscopic natural systems across space and time.
The ""law of increasing functional information"" published today complements the 2nd law of thermodynamics, which states that the entropy (disorder) of an isolated system increases over time (and heat always flows from hotter to colder objects).

","score: 16.478995721783622, grade_level: '16'","score: 17.298464914215145, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2310223120,"Physical laws—such as the laws of motion, gravity, electromagnetism, and thermodynamics—codify the general behavior of varied macroscopic natural systems across space and time. We propose that an additional, hitherto-unarticulated law is required to characterize familiar macroscopic phenomena of our complex, evolving universe. An important feature of the classical laws of physics is the conceptual equivalence of specific characteristics shared by an extensive, seemingly diverse body of natural phenomena. Identifying potential equivalencies among disparate phenomena—for example, falling apples and orbiting moons or hot objects and compressed springs—has been instrumental in advancing the scientific understanding of our world through the articulation of laws of nature. A pervasive wonder of the natural world is the evolution of varied systems, including stars, minerals, atmospheres, and life. These evolving systems appear to be conceptually equivalent in that they display three notable attributes: 1) They form from numerous components that have the potential to adopt combinatorially vast numbers of different configurations; 2) processes exist that generate numerous different configurations; and 3) configurations are preferentially selected based on function. We identify universal concepts of selection—static persistence, dynamic persistence, and novelty generation—that underpin function and drive systems to evolve through the exchange of information between the environment and the system. Accordingly, we propose a “law of increasing functional information”: The functional information of a system will increase (i.e., the system will evolve) if many different configurations of the system undergo selection for one or more functions."
"
For decades, scientists have pondered the mystery of the moon's ancient magnetism. Based on analyses of lunar samples, its now-deceased magnetic field may have been active for more than 1.5 billion years -- give or take a billion years. Scientists believe it was generated like the Earth's via a dynamo process, whereby the spinning and churning of conductive liquid metal within a rocky planet's core generates a magnetic field. However, researchers have grappled with how such a small planetary body could have sustained a long-lived magnetic field. Some have even questioned the legitimacy of return samples that point to the existence of an ancient dynamo, suggesting magnetism may have been acquired via exposure to strong magnetic fields onboard spacecraft during the return mission or from plasmas produced by massive impacts on the moon.

Stanford University scientists have now demonstrated that the magnetism in lunar samples is not adversely altered by the spacecraft journey back to Earth or certain laboratory procedures, disproving one of the two major oppositions to the ancient dynamo theory. The findings, published in Geophysical Research Letters Oct. 11, bode well for research stemming from other sample-return missions from space, since any magnetic contamination acquired during flight or on Earth can likely be easily removed.
""You want to know that the spacecraft returning your sample is not magnetically frying your rock, essentially,"" said lead study author Sonia Tikoo, an assistant professor of geophysics at the Stanford Doerr School of Sustainability. ""We simulated a long-term exposure of a sample to a stronger magnetic field than what the Earth has -- something that might be realistic for a spacecraft -- and found that for nearly all samples, including several we had previously studied in the context of lunar dynamo records, we could remove that contamination quite easily.""
Reproducing contamination
The study authors conducted two sets of lab experiments on eight samples from four different Apollo missions. They used a magnet to expose the samples to a field strength of about 5 millitesla -- about 100 times stronger than the Earth's magnetic field -- for two days to approximately replicate the length of a return journey from the moon. Then, they took the samples into a magnetically shielded lab room to measure how quickly the contamination decayed and test how easily it could be removed using standard techniques. The research shows that basalts (rocks formed by the cooling of lava flows) are generally less susceptible to acquiring magnetic contamination than glass-bearing lunar rocks, but in nearly all cases the resulting contamination could be easily removed using standard methods.
""As a global community, we're starting to send more sample-return missions to other bodies, so it's good to know that as long as we're careful to ensure spacecraft fields are not too high -- and it doesn't have to be zero, necessarily -- we can still do paleomagnetism studies along with other research,"" said Tikoo, who also holds a courtesy appointment in Earth and planetary sciences. ""You don't always have to send up a heavy magnetic shield that's going to take up a lot of room and a lot of mass at the expense of other science.""
Paleomagnetism is a branch of geophysics that uses remanent magnetization in rocks from the time of their formation to reconstruct the direction and/or strength of the geomagnetic field. The magnetic history of the moon is important for understanding the evolution of interior thermal history over time, in addition to how a global dynamo field may have controlled the delivery and retention of volatile substances, such as water, at the lunar surface. ""An ancient lunar field may even have aided atmospheric retention on the early Earth,"" the study authors write.

""Paleomagnetism is a very powerful tool for understanding core processes since we cannot go to the core of the planets, and also to learn about the past behavior of the core,"" said study co-author Ji-In Jung, a PhD student in geophysics.
Dynamo theory
Magnetic fields may protect planets' surfaces from harmful solar radiation and space weather, enabling the long-term preservation of atmospheres. While various other mechanisms for generating a magnetic field have been proposed, the dynamo theory is the widely accepted explanation of this phenomenon on Earth. Scientists think Earth's magnetic field may have been essential for the development of conditions that support life, so learning about their presence around other planets and moons is part of the search for evidence of extraterrestrial life.
""In order to know about the internal structures of planetary bodies and their interaction with the atmosphere or other systems, we need to know about planetary dynamo processes,"" Jung said.
Magnetic fields can also reveal the overall cooling history of a planetary body, which can, in turn, affect its volcanism and its tectonic regime. For asteroids, researchers want to understand how magnetic fields may have helped material come together in the early solar nebula and eventually build up into larger planets.
The moon's magnetic history is of particular interest because geophysicists do not understand how a small planetary body like the moon could have generated a long-lived magnetic field, given that it has a small core that would likely have cooled quickly. As a next step, Tikoo aims to continue ongoing work to discriminate between the dynamo and impact hypotheses.
""This study proves that we can do extraterrestrial paleomagnetism with mission-returned samples,"" Tikoo said. ""I don't think anybody doubts the ability to do Earth paleomagnetism and I'm happy that we can do it for space, too.""
This research was funded by a grant from NASA.

","score: 16.568503925767306, grade_level: '17'","score: 18.261548893647394, grade_levels: ['college_graduate'], ages: [24, 100]",10.1029/2023GL105152,"Numerous paleomagnetic studies attribute the magnetization preserved within Apollo samples to an ancient dynamo. However, other works propose that lunar rocks were instead magnetized by either transient impact‐related magnetic fields on the Moon or by the return spacecraft. To test whether lunar samples could have been magnetized during return to Earth, sample handling, or transport, we exposed lunar rocks to 5–10 mT fields for varying durations. We then determined how easily these magnetic overprints could be removed and how paleointensity estimates are affected by the overprints and their removal. We found that magnetic overprints were cleaned by alternating field (AF) demagnetization to ∼10–30 mT for nearly all samples and that acceptable paleointensities may be obtained from higher AF levels. Therefore, high coercivity (>30 mT) magnetizations observed within lunar rocks are generally not magnetic contamination and were initially acquired on the Moon."
"
Fast radio bursts, or FRBs, are an astronomical mystery, with their exact cause and origins still unconfirmed. These intense bursts of radio energy are invisible to the human eye, but show up brightly on radio telescopes. Previous studies have noted broad similarities between the energy distribution of repeat FRBs, and that of earthquakes and solar flares. However, new research at the University of Tokyo has looked at the time and energy of FRBs and found distinct differences between FRBs and solar flares, but several notable similarities between FRBs and earthquakes. This supports the theory that FRBs are caused by ""starquakes"" on the surface of neutron stars. This discovery could help us better understand earthquakes, the behavior of high-density matter and aspects of nuclear physics.

The vastness of space holds many mysteries. While some people dream of boldly going where no one has gone before, there is a lot we can learn from the comfort of Earth. Thanks to technological advances, we can explore the surface of Mars, marvel at Saturn's rings and pick up mysterious signals from deep space. Fast radio bursts are hugely powerful, bright bursts of energy which are visible on radio waves. First discovered in 2007, these bursts can travel billions of light years but typically last mere thousandths of a second. It has been estimated that as many as 10,000 FRBs may happen every day if we could observe the whole sky. While the sources of most bursts detected so far appear to emit a one-off event, there are about 50 FRB sources which emit bursts repeatedly.
The cause of FRBs is unknown, but some ideas have been put forward, including that they might even be alien in origin. However, the current prevailing theory is that at least some FRBs are emitted by neutron stars. These stars form when a supergiant star collapses, going from eight times the mass of our sun (on average) to a superdense core only 20-40 kilometers across. Magnetars are neutron stars with extremely strong magnetic fields, and these have been observed to emit FRBs.
""It was theoretically considered that the surface of a magnetar could be experiencing a starquake, an energy release similar to earthquakes on Earth,"" said Professor Tomonori Totani from the Department of Astronomy at the Graduate School of Science. ""Recent observational advances have led to the detection of thousands more FRBs, so we took the opportunity to compare the now large statistical data sets available for FRBs with data from earthquakes and solar flares, to explore possible similarities.""
So far, statistical analysis of FRBs has focused on the distribution of wait times between two successive bursts. However, Totani and co-author Yuya Tsuzuki, a graduate student in the same department, point out that calculating only the wait-time distribution does not take into account correlations that might exist across other bursts. So the team decided to calculate correlation across two-dimensional space, analyzing the time and emission energy of nearly 7,000 bursts from three different repeater FRB sources. They then applied the same method to examine the time-energy correlation of earthquakes (using data from Japan) and of solar flares (using records from the Hinode international mission to study the sun), and compared the results of all three phenomena.
Totani and Tsuzuki were surprised that, in contrast to other studies, their analysis showed a striking similarity between FRBs and earthquake data, but a distinct difference between FRBs and solar flares. Totani explained: ""The results show notable similarities between FRBs and earthquakes in the following ways: First, the probability of an aftershock occurring for a single event is 10-50%; second, the aftershock occurrence rate decreases with time, as a power of time; third, the aftershock rate is always constant even if the FRB-earthquake activity (mean rate) changes significantly; and fourth, there is no correlation between the energies of the main shock and its aftershock.""
This strongly suggests the existence of a solid crust on the surface of neutron stars, and that starquakes suddenly occurring on these crusts releases huge amounts of energy which we see as FRBs. The team intends to continue analyzing new data on FRBs, to verify that the similarities they have found are universal. ""By studying starquakes on distant ultradense stars, which are completely different environments from Earth, we may gain new insights into earthquakes,"" said Totani. ""The interior of a neutron star is the densest place in the universe, comparable to that of the interior of an atomic nucleus. Starquakes in neutron stars have opened up the possibility of gaining new insights into very high-density matter and the fundamental laws of nuclear physics.""

","score: 13.61201374570447, grade_level: '14'","score: 15.417508591065292, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnras/stad2532,"The production mechanism of repeating fast radio bursts (FRBs) is still a mystery, and correlations between burst occurrence times and energies may provide important clues to elucidate it. While time correlation studies of FRBs have been mainly performed using wait time distributions, here we report the results of a correlation function analysis of repeating FRBs in the 2D space of time and energy. We analyse nearly 7,000 bursts reported in the literature for the three most active sources of FRB 20121102A, 20201124A, and 20220912A, and find the following characteristics that are universal in the three sources. A clear power-law signal of the correlation function is seen, extending to the typical burst duration (∼ 10 msec) towards shorter time intervals (Δt). The correlation function indicates that every single burst has about a 10–60 per cent chance of producing an aftershock at a rate decaying by a power law as ∝ (Δt)−p with p = 1.5–2.5, like the Omori–Utsu law of earthquakes. The correlated aftershock rate is stable regardless of source activity changes, and there is no correlation between emitted energy and Δt. We demonstrate that all these properties are quantitatively common to earthquakes, but different from solar flares in many aspects, by applying the same analysis method for the data on these phenomena. These results suggest that repeater FRBs are a phenomenon in which energy stored in rigid neutron star crusts is released by seismic activity. This may provide a new opportunity for future studies to explore the physical properties of the neutron star crust."
"
An unexpectedly high number of young stars has been identified in the direct vicinity of a supermassive black hole and water ice has been detected at the center of our galaxy.

An international team led by Dr Florian Peißker at the University of Cologne's Institute of Astrophysics has analysed in detail a young star cluster in the immediate vicinity of the super massive black hole Sagittarius A* (Sgr A*) in the centre of our galaxy and showed that it is significantly younger than expected. This cluster, known as IRS13, was discovered more than twenty years ago, but only now has it been possible to determine the cluster members in detail by combining a wide variety of data -- taken with various telescopes over a period of several decades. The stars are a few 100,000 years old and therefore extraordinarily young for stellar conditions. By comparison, our sun is about 5 billion years old. Due to the high-energy radiation as well as the tidal forces of the galaxy, it should in fact not be possible for such a large number of young stars to be in the direct vicinity of the super massive black hole. 
The study was conducted under the title 'The Evaporating Massive Embedded Stellar Cluster IRS 13 Close to Sgr A*. I. Detection of a Rich Population of Dusty Objects in the IRS13 Cluster' and has now appeared in The Astrophysical Journal.
In connection with the current study, a further outstanding result has also been published. For the first time, the James Webb Space Telescope (JWST) was used to record a spectrum free of atmospheric interference from the Galactic Center. A prism on board the telescope was developed at the Institute of Astrophysics in the working group led by Professor Dr Andreas Eckart, a co-author of the publication. The present spectrum shows that there is water ice in the Galactic Center. This water ice, which is often found in the dusty discs around very young stellar objects, is another independent indicator of the young age of some stars near the black hole.
In addition to the unexpected detection of young stars and water ice by the JWST, the researchers led by Dr Peißker have also found that IRS13 has a turbulent history of formation behind it. The study results suggest that IRS13 migrated toward the super massive black hole through friction with the interstellar medium, collisions with other star clusters, or internal processes. From a certain distance, the cluster was then 'captured' by the gravitation of the black hole. In this process, a bow shock may have formed at the top of the cluster from the dust surrounding the cluster, similar to the tip of a ship in the water. The associated increase in dust density then stimulated further star formation. This is an explanation why these young stars are above all in the top or front of the cluster.
""The analysis of IRS13 and the accompanying interpretation of the cluster is the first attempt to unravel a decade-old mystery about the unexpectedly young stars in the Galactic Center,"" according to Dr Peißker. ""In addition to IRS13, there is a star cluster, the so-called S-cluster, which is even closer to the black hole and also consists of young stars. They are also significantly younger than would be possible according to accepted theories."" The findings on IRS13 provide the opportunity in further research to establish a connection between the direct vicinity of the black hole and regions several light years away. Dr Michal Zajaček, second author of the study and scientist at Masaryk University in Brno (Czech Republic), added: ""The star cluster IRS13 seems to be the key to unravelling the origin of the dense star population at the centre of our galaxy. We have gathered extensive evidence that very young stars within the range of the super massive black hole may have formed in star clusters such as IRS13. This is also the first time we have been able to identify star populations of different ages -- hot main sequence stars and young emerging stars -- in the cluster so close to the centre of the Milky Way.""

","score: 13.233874643874646, grade_level: '13'","score: 13.556709401709405, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acf6b5,"A detailed analysis of the nuclear star cluster not only concedes the existence of the S cluster, with its fast-moving stars and the supermassive black hole Sgr A*. It also reveals an embedded region of gas and dust with an exceptionally high stellar density called IRS 13. The IRS 13 cluster can be divided into the northern and eastern counterparts, called IRS 13N and IRS 13E, respectively. This work will focus on both regions and study their most prominent members using rich infrared and radio/submillimeter data baselines. Applying a multiwavelength analysis enables us to determine a comprehensive photometric footprint of the investigated cluster sample. Using the ray-tracing-based radiative transfer model HYPERION, the spectral energy distribution of the IRS 13 members suggests a stellar nature of the dusty sources. These putative young stellar objects (YSOs) have a comparable spectroscopic identification to the D and G sources in or near the S cluster. Furthermore, we report the existence of a population of dusty sources in IRS 13 that can be mostly identified in the H, K, and L band. We propose that, together with the objects reported in the literature, this population is the outcome of a recent star formation process. Furthermore, we report that these presumably young objects are arranged in a disk structure. Although it cannot be excluded that the intrinsic arrangement of IRS 13 does show a disk structure, we find indications that the investigated cluster sample might be related to the counterclockwise disk."
"
Astronomers have gotten very good at spotting the signs of planet formation around stars. But for a complete understanding of planet formation, we also need to study examples where planet formation has not yet started. Looking for something and not finding it can be even more difficult than finding it sometimes, but new detailed observations of the young star DG Taurus show that it has a smooth protoplanetary disk without signs of planet formation. This successful non-detection of planet formation may indicate that DG Taurus is on the eve of planet formation.

Planets form in disks of gas and dust, known as protoplanetary disks, around protostars, young stars still in the process of forming. Planet growth is so slow that it's not possible to watch the evolution as it happens, so astronomers observe many protostars at slightly different stages of planet formation to build up a theoretical understanding.
This time an international research team led by Satoshi Ohashi at the National Astronomical Observatory of Japan (NAOJ) used the Atacama Large Millimeter/submillimeter Array (ALMA) to conduct high-resolution observations of a protoplanetary disk around a relatively young protostar, DG Taurus located 410 light-years away in the direction of the constellation Taurus. The team found that DG Taurus has a smooth protoplanetary disk, without any rings which would indicate that planets are forming. This led the team to believe that DG Taurus system will start forming planets in the future.
The team found that in this pre-planet-formation stage, the dust grains within 40 AU (about twice the size of the orbit of Uranus in the Solar System) of the central protostar are still small, while beyond this radius the dust grains have started to grow in size, the first step in planet formation. This is contrary to theoretical expectations that planet formation starts in the inner part of the disk.
These results provide surprising new information about the dust distribution and other conditions at the start of planet formation. Future studies of more examples will further improve our understanding of planet formation.

","score: 14.68610859728507, grade_level: '15'","score: 16.08351131221719, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/ace9b9,"Characterizing the physical properties of dust grains in a protoplanetary disk is critical to comprehending the planet formation process. Our study presents Atacama Large Millimeter/submillimeter Array (ALMA) high-resolution observations of the young protoplanetary disk around DG Tau at a 1.3 mm dust continuum. The observations, with a spatial resolution of ≈0.″04, or ≈5 au, revealed a geometrically thin and smooth disk without substantial substructures, suggesting that the disk retains the initial conditions of the planet formation. To further analyze the distributions of dust surface density, temperature, and grain size, we conducted a multiband analysis with several dust models, incorporating ALMA archival data of the 0.87 and 3.1 mm dust polarization. The results showed that the Toomre Q parameter is ≲2 at a 20 au radius, assuming a dust-to-gas mass ratio of 0.01. This implies that a higher dust-to-gas mass ratio is necessary to stabilize the disk. The grain sizes depend on the dust models, and for the DSHARP compact dust, they were found to be smaller than ∼400 μm in the inner region (r ≲ 20 au) while exceeding larger than 3 mm in the outer part. Radiative transfer calculations show that the dust scale height is lower than at least one-third of the gas scale height. These distributions of dust enrichment, grain sizes, and weak turbulence strength may have significant implications for the formation of planetesimals through mechanisms such as streaming instability. We also discuss the CO snowline effect and collisional fragmentation in dust coagulation for the origin of the dust size distribution."
"
A pair of theoretical physicists are reporting that the same observations inspiring the hunt for a ninth planet might instead be evidence within the solar system of a modified law of gravity originally developed to understand the rotation of galaxies.

Researchers Harsh Mathur, a professor of physics at Case Western Reserve University, and Katherine Brown, an associate professor of physics at Hamilton College, made the assertion after studying the effect the Milky Way galaxy would have on objects in the outer solar system -- if the laws of gravity were governed by a theory known as Modified Newtonian Dynamics (or MOND).
MOND proposes Isaac Newton's famous law of gravity is valid up to a point. That is, when the gravitational acceleration predicted by Newton's law becomes small enough, MOND allows for a different gravitational behavior to take over.
The observational success of MOND on galactic scales is why some scientists consider it an alternative to ""dark matter,"" the term physicists use to describe a hypothesized form of matter that would have gravitational effects but not emit any light.
""MOND is really good at explaining galactic-scale observations,"" Mathur said, ""but I hadn't expected that it would have noticeable effects on the outer solar system.""
Their work was recently published in The Astronomical Journal.
A 'striking' alignment
Mathur and Brown had studied MOND's effect on galactic dynamics before. But they became interested in MOND's more local effects after astronomers announced in 2016 that a handful of objects in the outer solar system showed orbital anomalies that could be explained by a ninth planet.

Orbital peculiarities have led to historic discoveries before: Neptune was discovered through its gravitational tug on the orbits of nearby object, the minute precession of Mercury provided early evidence in support of Einstein's theory of general relativity, and astronomers have recently used orbital dynamics to infer the presence of a supermassive black hole at the center of our Galaxy.
Brown realized MOND's predictions might be at odds with the observations that had motivated the search for a ninth planet. ""We wanted to see if the data that support the Planet Nine hypothesis would effectively rule out MOND,"" she said.
Instead, Mathur and Brown found MOND predicts precisely clustering that astronomers have observed. Over millions of years, they argue, the orbits of some objects in the outer solar system would be dragged into alignment with the galaxy's own gravitational field.
When they plotted the orbits of the objects from the Planet Nine dataset against the galaxy's own gravitational field, ""the alignment was striking,"" Mathur said.
The authors caution that the current dataset is small and that that any number of other possibilities might prove to be correct; other astronomers have argued the orbital peculiarities are the result of observational bias, for example.
""Regardless of the outcome,"" Brown said, ""this work highlights the potential for the outer solar system to serve as a laboratory for testing gravity and studying fundamental problems of physics.""

","score: 16.5877402446127, grade_level: '17'","score: 17.625812463599303, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-3881/acef1e,"A new class of Kuiper Belt objects (KBOs) that lie beyond Neptune with semimajor axes greater than 250 astronomical units show orbital anomalies that have been interpreted as evidence for an undiscovered ninth planet. We show that a modified gravity theory known as modified Newtonian dynamics (MOND) provides an alternative explanation for the anomalies using the well-established secular approximation. We predict that the major axes of the orbits will be aligned with the direction toward the Galactic center and that the orbits cluster in phase space, in agreement with observations of KBOs from the new class. Thus, MOND, which can explain galactic rotation without invoking dark matter, might also be observable in the outer solar system."
"
An international team of researchers has developed a new theoretical framework that bridges physics and biology to provide a unified approach for understanding how complexity and evolution emerge in nature. This new work on ""Assembly Theory,"" published today in Nature, represents a major advance in our fundamental comprehension of biological evolution and how it is governed by the physical laws of the universe.

This research builds on the team's previous work developing Assembly Theory as an empirically validated approach to life detection, with implications for the search for alien life and efforts to evolve new life forms in the laboratory. In prior work, the team assigned a complexity score to molecules called the molecular assembly index, based on the minimal number of bond-forming steps required to build a molecule. They showed how this index is experimentally measurable and how high values correlate with life-derived molecules.
The new study introduces mathematical formalism around a physical quantity called ""Assembly"" that captures how much selection is required to produce a given set of complex objects, based on their abundance and assembly indices.
""Assembly Theory provides a completely new lens for looking at physics, chemistry and biology as different perspectives of the same underlying reality,"" explained lead author professor Sara Walker, a theoretical physicist and origin of life researcher from Arizona State University. ""With this theory, we can start to close the gap between reductionist physics and Darwinian evolution -- it's a major step toward a fundamental theory unifying inert and living matter.""
The researchers demonstrated how Assembly Theory can be applied to quantify selection and evolution in systems ranging from simple molecules to complex polymers and cellular structures. It explains both the discovery of new objects and the selection of existing ones, allowing open-ended increases in complexity characteristic of life and technology.
""Assembly Theory provides an entirely new way to look at the matter that makes up our world, as defined not just by immutable particles but by the memory needed to build objects through selection over time,"" said professor Lee Cronin, a chemist from the University of Glasgow and co-lead author. ""With further work, this approach has the potential to transform fields from cosmology to computer science. It represents a new frontier at the intersection of physics, chemistry, biology and information theory.""
The researchers aim to further refine Assembly Theory and explore its applications for characterizing known and unknown life, and testing hypotheses about how life emerges from non-living matter. ""A key feature of the theory is that it is experimentally testable,"" said Cronin. ""This opens up the exciting possibility of using Assembly Theory to design new experiments that could solve the origin of life by creating living systems from scratch in the laboratory.""
The theory opens up many new questions and research directions at the boundary of the physical and life sciences. Overall, Assembly Theory promises to provide profound new insights into the physics underlying biological complexity and evolutionary innovation.

","score: 17.175, grade_level: '17'","score: 17.811488095238097, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06600-9,"Scientists have grappled with reconciling biological evolution1,2 with the immutable laws of the Universe defined by physics. These laws underpin life’s origin, evolution and the development of human culture and technology, yet they do not predict the emergence of these phenomena. Evolutionary theory explains why some things exist and others do not through the lens of selection. To comprehend how diverse, open-ended forms can emerge from physics without an inherent design blueprint, a new approach to understanding and quantifying selection is necessary3–5. We present assembly theory (AT) as a framework that does not alter the laws of physics, but redefines the concept of an ‘object’ on which these laws act. AT conceptualizes objects not as point particles, but as entities defined by their possible formation histories. This allows objects to show evidence of selection, within well-defined boundaries of individuals or selected units. We introduce a measure called assembly (A), capturing the degree of causation required to produce a given ensemble of objects. This approach enables us to incorporate novelty generation and selection into the physics of complex objects. It explains how these objects can be characterized through a forward dynamical process considering their assembly. By reimagining the concept of matter within assembly spaces, AT provides a powerful interface between physics and biology. It discloses a new aspect of physics emerging at the chemical scale, whereby history and causal contingency influence what exists."
"
A new study led by Southwest Research Institute (SwRI) Planetary Scientist and Associate Vice President Dr. Alan Stern posits that the large, approximately 5-kilometer-long mounds that dominate the appearance of the larger lobe of the pristine Kuiper Belt object Arrokoth are similar enough to suggest a common origin. The SwRI study suggests that these ""building blocks"" could guide further work on planetesimal formational models. Stern presented these findings this week at the American Astronomical Society's 55th Annual Division for Planetary Sciences (DPS) meeting in San Antonio. These results are now also published in the peer-reviewed Planetary Science Journal.

NASA's New Horizons spacecraft made a close flyby of Arrokoth in 2019. From those data, Stern and his coauthors identified 12 mounds on Arrokoth's larger lobe, Wenu, which are almost the same shape, size, color and reflectivity. They also tentatively identified three more mounds on the object's smaller lobe, Weeyo.
""It's amazing to see this object so well preserved that its shape directly reveals these details of its assembly from a set of building blocks all very similar to one another,"" said Lowell Observatory's Dr. Will Grundy, co-investigator of the New Horizons mission. ""Arrokoth almost looks like a raspberry, made of little sub-units.""
Arrokoth's geology supports the streaming instability model of planetesimal formation where collision speeds of just a few miles per hour allowed objects to gently accumulate to build Arrokoth in a local area of the solar nebula undergoing gravitational collapse.
""Similarities including in sizes and other properties of Arrokoth's mound structures suggest new insights into its formation,"" Stern, the Principal Investigator of the New Horizons mission, said. ""If the mounds are indeed representative of the building blocks of ancient planetesimals like Arrokoth, then planetesimal formation models will need to explain the preferred size for these building blocks.""
There is a good chance that some of the flyby targets for NASA's Lucy mission to Jupiter's Trojan asteroids and ESA's comet interceptor will be other pristine planetesimals, which could contribute to the understanding of accretion of planetesimals elsewhere in the ancient solar system and whether they differ from processes New Horizons found in the Kuiper Belt.
""It will be important to search for mound-like structures on the planetesimals these missions observe to see how common this phenomenon is, as a further guide to planetesimal formation theories,"" Stern said.
The Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland, designed, built and operates the New Horizons spacecraft, and manages the mission for NASA's Science Mission Directorate. Southwest Research Institute, based in San Antonio, directs the mission via Principal Investigator Stern, who leads the science team, payload operations and encounter science planning. New Horizons is part of the New Frontiers Program managed by NASA's Marshall Space Flight Center in Huntsville, Alabama.

","score: 16.206095118898627, grade_level: '16'","score: 18.037976220275347, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/PSJ/acf317,"We report on a study of the mounds that dominate the appearance of Kuiper Belt Object (486958) Arrokoth's larger lobe, named Wenu. We compare the geological context of these mounds and measure and intercompare their shapes, sizes/orientations, reflectance, and colors. We find the mounds are broadly self-similar in many respects and interpret them as the original building blocks of Arrokoth. It remains unclear why these building blocks are so similar in size—and this represents a new constraint and challenge for solar system formation models. We then discuss the implications of this interpretation."
"
The ability to have access to the Internet or use a mobile phone anywhere in the world is taken more and more for granted, but the brightness of Internet and telecommunications satellites that enable global communications networks could pose problems for ground-based astronomy. University of Illinois Urbana-Champaign aerospace engineer Siegfried Eggl coordinated an international study confirming recently deployed satellites are as bright as stars seen by the unaided eye.

""From our observations, we learned that AST Space Mobile's BlueWalker 3 -- a constellation prototype satellite featuring a roughly 700 square-foot phased-array antenna -- reached a peak brightness of magnitude 0.4, making it one of the brightest objects in the night sky,"" Eggl said. ""Although this is record breaking, the satellite itself is not our only concern. The untracked Launch Vehicle Adapter had an apparent visual magnitude of 5.5, which is also brighter than the International Astronomical Union recommendation of magnitude 7.""
For comparison, the brightness of the stars we can see with an unaided eye is between minus 1 and 6 magnitude, minus 1 being the brightest. Sirius, the brightest star, is minus 1. Planets like Venus can sometimes be a bit brighter -- closer to minus 4, but the faintest stars we can see are roughly magnitude 6.
""One might think if there are bright stars, a few more bright satellites won't make a difference. But several companies plan to launch constellations,"" Eggl said. ""For example, Starlink already has permission to launch thousands of satellites, but they'll probably get their full request of tens of thousands granted eventually.
""And that's just one constellation of satellites. Europe and China want their own constellations and so does Russia. Just those in the United States being negotiated with the FCC amount to 400,000 satellites being launched in the near future. There are only 1,000 stars you can see with the unaided eye. Adding 400,000 bright satellites that move could completely change the night sky.""
Eggl is a member of the International Astronomical Union Centre for the Protection of the Dark and Quiet Sky from Satellite Constellation Interference, IAU.
""BlueWalker 3 is so bright that most of the big telescopes such as the Rubin Observatory believe it could obliterate large parts of exposures,"" Eggl said. ""They already have to avoid observing Mars and Venus for the same reason, but we know where the planets are so we can dodge them. We cannot accurately predict where all the satellites will be years in advance. Just accepting recurring data loss in multi-billion-dollar observatories is not an option either.""
He said although satellites won't necessarily damage the telescope's CCDs, or charge-coupled devices, they will still cause data loss from the streaks. Extremely bright satellites could ruin the entire field of view, like trying to stargaze when someone periodically shines a flashlight into your eyes.

Eggl said several solutions to the problem are being explored in collaboration with the Laboratory for Advanced Space Systems at Illinois and satellite operators such as SpaceX.
""Starlink is looking at making their satellites' surfaces darker, which absorbs more and reflects less visible sunlight. But the absorption generates heat. The satellites then have to emit infrared light which means observations in optical wavelengths don't have as large of a problem, but infrared observations might. And heat is one of the biggest engineering problems that we have in space. So, painting everything black comes with repercussions,"" he said.
Another idea from SpaceX is to make satellites' solar panels more reflective with dielectric mirrors. The mirrors allow the satellites to change the direction of the reflection so that it's not pointing directly at the Earth.
""If SpaceX can make the solar panels point in a different direction to avoid glints, or use these mirror tricks, they might solve a lot of the problems we have with the optical flaring of Starlink satellites,"" Eggl said. ""With other providers, it's not quite as easy. AST has gigantic satellites, with hundreds of square feet of electronic phased arrays, that they need to communicate with cell phones on the ground. If they made satellites smaller more of their radio signals would leak out through so-called 'side lobes' potentially affecting radio astronomy sites.
Eggl said AST also prefers to keep the satellite pointed toward the surface of the Earth to achieve maximum efficiency. Starlink solutions may not easily translate to AST satellites and new mitigation strategies are needed.
""We are trying to work with the space industry, where possible,"" he said. ""We want to solve this together so it's a collaborative effort that everybody can sign onto because that's the fastest route to get things done.""
Ph.D. student Nandakumar analyzed the data for this first international study to be published from the center. Nandakumar works with Jeremy Tregloan-Reed at the Universidad de Atacama in Chile.

","score: 11.581750358680058, grade_level: '12'","score: 12.509895982783355, grade_levels: ['college'], ages: [18, 24]",10.1038/s41586-023-06672-7,"Large constellations of bright artificial satellites in low Earth orbit pose significant challenges to ground-based astronomy1. Current orbiting constellation satellites have brightnesses between apparent magnitudes 4 and 6, whereas in the near-infrared Ks band, they can reach magnitude 2 (ref. 2). Satellite operators, astronomers and other users of the night sky are working on brightness mitigation strategies3,4. Radio emissions induce further potential risk to ground-based radio telescopes that also need to be evaluated. Here we report the outcome of an international optical observation campaign of a prototype constellation satellite, AST SpaceMobile’s BlueWalker 3. BlueWalker 3 features a 64.3 m2 phased-array antenna as well as a launch vehicle adaptor (LVA)5. The peak brightness of the satellite reached an apparent magnitude of 0.4. This made the new satellite one of the brightest objects in the night sky. Additionally, the LVA reached an apparent V-band magnitude of 5.5, four times brighter than the current International Astronomical Union recommendation of magnitude 7 (refs. 3,6); it jettisoned on 10 November 2022 (Universal Time), and its orbital ephemeris was not publicly released until 4 days later. The expected build-out of constellations with hundreds of thousands of new bright objects1 will make active satellite tracking and avoidance strategies a necessity for ground-based telescopes."
"
When scientists viewed the James Webb Space Telescope's (JWST) first images of the universe's earliest galaxies, they were shocked. The young galaxies appeared too bright, too massive and too mature to have formed so soon after the Big Bang. It would be like an infant growing into an adult within just a couple years.

The startling discovery even caused some physicists to question the standard model of cosmology, wondering whether or not it should be upended.
Using new simulations, a Northwestern University-led team of astrophysicists now has discovered that these galaxies likely are not so massive after all. Although a galaxy's brightness is typically determined by its mass, the new findings suggest that less massive galaxies can glow just as brightly from irregular, brilliant bursts of star formation.
Not only does this finding explain why young galaxies appear deceptively massive, it also fits within the standard model of cosmology.
The research will be published on Tuesday (Oct. 3) in the Astrophysical Journal Letters.
""The discovery of these galaxies was a big surprise because they were substantially brighter than anticipated,"" said Northwestern's, Claude-André Faucher-Giguère, the study's senior author. ""Typically, a galaxy is bright because it's big. But because these galaxies formed at cosmic dawn, not enough time has passed since the Big Bang. How could these massive galaxies assemble so quickly? Our simulations show that galaxies have no problem forming this brightness by cosmic dawn.""
""The key is to reproduce a sufficient amount of light in a system within a short amount of time,"" added Guochao Sun, who led the study. ""That can happen either because the system is really massive or because it has the ability to produce a lot of light quickly. In the latter case, a system doesn't need to be that massive. If star formation happens in bursts, it will emit flashes of light. That is why we see several very bright galaxies.""
Faucher-Giguère is an associate professor of physics and astronomy at Northwestern's Weinberg College of Arts and Sciences and a member of the Center for Interdisciplinary Exploration and Research in Astrophysics(CIERA). Sun is a CIERA Postdoctoral Fellow at Northwestern.

A period that lasted from roughly 100 million years to 1 billion years after the Big Bang, cosmic dawn is marked by the formation of the universe's first stars and galaxies. Before the JWST launched into space, astronomers knew very little about this ancient time period.
""The JWST brought us a lot of knowledge about cosmic dawn,"" Sun said. ""Prior to JWST, most of our knowledge about the early universe was speculation based on data from very few sources. With the huge increase in observing power, we can see physical details about the galaxies and use that solid observational evidence to study the physics to understand what's happening.""
In the new study, Sun, Faucher-Giguère and their team used advanced computer simulations to model how galaxies formed right after the Big Bang. The simulations produced cosmic dawn galaxies that were just as bright as those observed by the JWST. The simulations are part of the Feedback of Relativistic Environments(FIRE) project, which Faucher-Giguère co-founded with collaborators at the California Institute of Technology, Princeton University and the University of California at San Diego. The new study includes collaborators from the Flatiron Institute's Center for Computational Astrophysics, Massachusetts Institute of Technology and University of California, Davis.
The FIRE simulations combine astrophysical theory and advanced algorithms to model galaxy formation. The models enable researchers to probe how galaxies form, grow and change shape, while accounting for energy, mass, momentum and chemical elements returned from stars.
When Sun, Faucher-Giguère and their team ran the simulations to model early galaxies formed at cosmic dawn, they discovered that stars formed in bursts -- a concept known as ""bursty star formation."" In massive galaxies like the Milky Way, stars form at a steady rate, with the numbers of stars gradually increasing over time. But so-called bursty star formation occurs when stars form in an alternating pattern -- many stars at once, followed by millions of years of very few new stars and then many stars again.
""Bursty star formation is especially common in low-mass galaxies,"" Faucher-Giguère said. ""The details of why this happens are still the subject of ongoing research. But what we think happens is that a burst of stars form, then a few million years later, those stars explode as supernovae. The gas gets kicked out and then falls back in to form new stars, driving the cycle of star formation. But when galaxies get massive enough, they have much stronger gravity. When supernovae explode, they are not strong enough to eject gas from the system. The gravity holds the galaxy together and brings it into a steady state.""
The simulations also were able to produce the same abundance of bright galaxies as the JWST revealed. In other words, the number of bright galaxies predicted by simulations matches the number of observed bright galaxies.

Although other astrophysicists have hypothesized that bursty star formation could be responsible for the unusual brightness of galaxies at cosmic dawn, the Northwestern researchers are the first to use detailed computer simulations to prove it is possible. And they were able to do so without adding new factors that are unaligned with our standard model of the universe.
""Most of the light in a galaxy comes from the most massive stars,"" Faucher-Giguère said. ""Because more massive stars burn at a higher speed, they are shorter lived. They rapidly use up their fuel in nuclear reactions. So, the brightness of a galaxy is more directly related to how many stars it has formed in the last few million years than the mass of the galaxy as a whole.""

","score: 11.590667521385488, grade_level: '12'","score: 12.096072637087794, grade_levels: ['college'], ages: [18, 24]",10.3847/2041-8213/acf85a,"Recent discoveries of a significant population of bright galaxies at cosmic dawn z ≳ 10 have enabled critical tests of cosmological galaxy formation models. In particular, the bright end of the galaxys’ UV luminosity functions (UVLFs) appear higher than predicted by many models. Using approximately 25,000 galaxy snapshots at 8 ≤ z ≤ 12 in a suite of FIRE-2 cosmological “zoom-in” simulations from the Feedback in Realistic Environments (FIRE) project, we show that the observed abundance of UV-bright galaxies at cosmic dawn is reproduced in these simulations with a multichannel implementation of standard stellar feedback processes, without any fine-tuning. Notably, we find no need to invoke previously suggested modifications, such as a nonstandard cosmology, a top-heavy stellar initial mass function, or a strongly enhanced star formation efficiency. We contrast the UVLFs predicted by bursty star formation in these original simulations to those derived from star formation histories (SFHs) smoothed over prescribed timescales (e.g., 100 Myr). The comparison demonstrates that the strongly time-variable SFHs predicted by the FIRE simulations play a key role in correctly reproducing the observed, bright-end UVLFs at cosmic dawn: the bursty SFHs induce order-or-magnitude changes in the abundance of UV-bright (M UV ≲ −20) galaxies at z ≳ 10. The predicted bright-end UVLFs are consistent with both the spectroscopically confirmed population and the photometrically selected candidates. We also find good agreement between the predicted and observationally inferred integrated UV luminosity densities, which evolve more weakly with redshift in FIRE than suggested by some other models."
"
In recent years, astronomy has seen itself in a bit of crisis: Although we know that the Universe expands, and although we know approximately how fast, the two primary ways to measure this expansion do not agree. Now astrophysicists from the Niels Bohr Institute suggest a novel method which may help resolve this tension.

The Universe expands
We've known this ever since Edwin Hubble and other astronomers, some 100 years ago, measured the velocities of a number of surrounding galaxies. The galaxies in the Universe are ""carried"" away from each other by this expansion, and therefore recedes from each other.
The greater the distance between two galaxies, the faster they move apart, and the precise rate of this movement is one of the most fundamental quantities in modern cosmology. The number that describes the expansion goes by the name ""the Hubble constant,"" appearing in multitude of different equations and models of the Universe and its constituents.
Hubble Trouble
To understand the Universe we must therefore know the Hubble constant as precisely as possible. Several methods exist to measure it; methods that are mutually independent but luckily give almost the same result.
That is, almost…
The intuitively easiest method to understand is, in principle, the same that Edwin Hubble and his colleagues used a century ago: Locate a bunch of galaxies, and measure their distances and speeds. In practise this is done by looking for galaxies with exploding stars, so-called supernovae. This method is complemented by another method that analyzes irregularities in the so-called cosmic background radiation; an ancient form of light dating back to shortly after the Big Bang.

The two methods -- the supernova method and the background radiation method -- always gave slightly different results. But any measurement comes with uncertainties, and a few years back the uncertainties were substantial enough that we could blame those for the disparity.
Nevertheless, as measurement techniques have improved, uncertainties have diminished, and we've now reached a point where we can state with a high degree of confidence that both cannot be correct.
The root of this ""Hubble trouble"" -- whether it is unknown effects systematically biasing one of the results, or if it hints at new physics yet to be discovered -- is currently one of astronomy's hottest topics.
Two methods
The expansion of the Universe is measured in ""speed per distance,"" and is just over 20 km/s per million lightyears. That means that a galaxy located 100 million lightyears away recedes from us at 2,000 km/s, while another galaxy 200 million lightyears away recedes at 4,000 km/s.
But using supernovae to measure distances and velocities of galaxies yields 22.7 ± 0.4 km/s, while analyzing the background radiation of the Universe yields 20.7 ± 0.2 km/s.

It might sound pernickety to care about such a little disagreement, but for instance the number appears in the calculation of the age of the Universe, and the two methods yield an age of 12.8 and 13.8 billion years, respectively.
Crashing neutron stars may help with the answer
One of the greatest challenges lies in accurately determining the distances to galaxies. But in a new study, Albert Sneppen who is a PhD student in astrophysics at the Cosmic Dawn Center at the Niels Bohr Institute in Copenhagen, proposes a novel method for measuring distances, thereby helping to settle the ongoing dispute.
""When two ultra-compact neutron stars -- which in themselves are the remnants of supernovae -- orbit each other and ultimately merge, they go off in a new explosion; a so-called kilonova,"" Albert Sneppen explains. ""We recently demonstrated how this explosion is remarkedly symmetric, and it turns out that this symmetry not only is beautiful, but also incredibly useful.""
In a third study that has just been published, the prolific PhD student shows that kilonovae, despite their complexity, can be described by a single temperature. And it turns out that the symmetry and the simplicity of the kilonovae enable the astronomers to deduce exactly how much light they emit.
Comparing this luminosity with how much light reaches Earth, the researchers can calculate how far away the kilonova is. They have thereby obtained a novel, independent method to calculate the distance to galaxies containing kilonovae.
Darach Watson is an associate professor at the Cosmic Dawn Center and a co-author of the study. He explains: ""Supernovae, which until now have been used to measure the distances of galaxies, don't always emit the same amount of light. Moreover, they first require us to calibrate the distance using another type of stars, the so-called Cepheids, which in turn also must be calibrated. With kilonovae we can circumvent these complications that introduce uncertainties in the measurements.""
Confirms one of the two methods
To demonstrate its potential, the astrophysicists applied the method to a kilonova discovered in 2017. The result is a Hubble constant closer to the background radiation method, but whether the kilonova method can resolve the Hubble trouble, the researchers do not yet dare to state:
""We only have this one case study so far, and need many more examples before we can establish a robust result,"" Albert Sneppen cautions. ""But our method at least bypasses some known sources of uncertainty, and is a very ""clean"" system to study. It requires no calibration, no correction factor.""

","score: 13.986538302277435, grade_level: '14'","score: 14.808265647396084, grade_levels: ['college_graduate'], ages: [24, 100]",10.1051/0004-6361/202346306,"While gravitational wave (GW) standard sirens from neutron star (NS) mergers have been proposed to offer good measurements of the Hubble constant, we show in this paper how a variation of the expanding photosphere method (EPM) or spectral-fitting expanding atmosphere method, applied to the kilonovae (KNe) associated with the mergers, can provide an independent distance measurement to individual mergers that is potentially accurate to within a few percent. There are four reasons why the KN-EPM overcomes the major uncertainties commonly associated with this method in supernovae: (1) the early continuum is very well-reproduced by a blackbody spectrum, (2) the dilution effect from electron scattering opacity is likely negligible, (3) the explosion times are exactly known due to the GW detection, and (4) the ejecta geometry is, at least in some cases, highly spherical and can be constrained from line-shape analysis. We provide an analysis of the early VLT/X-shooter spectra AT2017gfo showing how the luminosity distance can be determined, and find a luminosity distance of DL = 44.5 ± 0.8 Mpc in agreement with, but more precise than, previous methods. We investigate the dominant systematic uncertainties, but our simple framework, which assumes a blackbody photosphere, does not account for the full time-dependent three-dimensional radiative transfer effects, so this distance should be treated as preliminary. The luminosity distance corresponds to an estimated Hubble constant of H0 = 67.0 ± 3.6 km s−1 Mpc−1, where the dominant uncertainty is due to the modelling of the host peculiar velocity. We also estimate the expected constraints on H0 from future KN-EPM-analysis with the upcoming O4 and O5 runs of the LIGO collaboration GW-detectors, where five to ten similar KNe would yield 1% precision cosmological constraints."
"
A global, multidisciplinary team of bioethicists, health policy experts, commercial spaceflight professionals and space health researchers, including Rachael Seidler from the University of Florida, has developed guiding principles and best practices to help ensure human research conducted in space is safe and inclusive.

The proposed ethical guidelines were released Friday in a policy paper published in Science and are the result of a workshop held at the Banbury Center of Cold Spring Harbor Laboratory funded by the Translational Research Institute for Space Health, or TRISH, at Baylor College of Medicine.
""With commercial companies taking more people each year to space, opportunities for human space travel are rapidly expanding,"" said Seidler, a professor of applied physiology and kinesiology at UF, ""and it's important that experiments taking place in space are as safe and productive as possible.""
About 30 individuals participated in the workshop, most of whom were health policy experts, scientists with expertise in bioethics, government regulators, and representatives from private spaceflight companies, Seidler said.
""We outlined potential ethical concerns facing the future of commercial space research and established guidelines for those who are traveling to space on their own dime,"" she said. ""We made our recommendations, and hopefully that will kickstart conversations.""
While there are many government-sponsored research missions in space that operate under clear ethical guidelines, few guidelines and best practices exist for conducting responsible research in the commercial sector, said Dr. Vasiliki Rahimzadeh, first author of the paper and assistant professor at the Center for Medical Ethics and Health Policy at Baylor.
""Now is the time to develop that ethical framework, and it must be a multidisciplinary effort across the private and public sector,"" she said.

In the paper, the team proposes ethical guidelines for commercial space research based on four principles: social responsibility of research participants, scientific excellence in gathering research data, proportionality in balancing risks of spaceflight, and global stewardship in diverse participation. The authors also outline the need for adapting existing research practices and policies to commercial space flight, including informed consent, data protection, and steps to minimize health risks to participants.
The paper's authors point out that what is learned through space health research is valuable not only for future spaceflight but also for informing health issues on Earth.
""That's why it was important to have had the private space companies at the table helping establish best practices,"" Seidler said. ""They are participating in something that is paving the way for everyone and can benefit all mankind.""
The work is supported by the Translational Research Institute for Space Health through NASA Cooperative Agreement NNX16AO69A.

","score: 18.09980738362761, grade_level: '18'","score: 20.616587479935795, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adh9028,Rules are needed for human research in commercial spaceflight
"
Gigatons of greenhouse gas are trapped under the seafloor, and that's a good thing. Around the coasts of the continents, where slopes sink down into the sea, tiny cages of ice trap methane gas, preventing it from escaping and bubbling up into the atmosphere.

While rarely in the news, these ice cage formations, known as methane clathrates, have garnered attention because of their potential to affect climate change. During offshore drilling, methane ice can get stuck in pipes, causing them to freeze and burst. The 2010 Deepwater Horizon oil spill is thought to have been caused by a buildup of methane clathrates.
But until now, the biological process behind how methane gas remains stable under the sea has been almost completely unknown. In a breakthrough study, a cross-disciplinary team of Georgia Tech researchers discovered a previously unknown class of bacterial proteins that play a crucial role in the formation and stability of methane clathrates.
A team led by Jennifer Glass, associate professor in the School of Earth and Atmospheric Sciences, and Raquel Lieberman, professor and Sepcic-Pfeil Chair in the School of Chemistry and Biochemistry, showed that these novel bacterial proteins suppress the growth of methane clathrates as effectively as commercial chemicals currently used in drilling, but are non-toxic, eco-friendly, and scalable. Their study, funded by NASA, informs the search for life in the solar system, and could also increase the safety of transporting natural gas.
The research, published in the journal PNAS Nexus, underscores the importance of fundamental science in studying Earth's natural biological systems and highlights the benefits of collaboration across disciplines.
""We wanted to understand how these formations were staying stable under the seafloor, and precisely what mechanisms were contributing to their stability,"" Glass said. ""This is something no one has done before.""
Sifting Through Sediment
The effort started with the team examining a sample of clay-like sediment that Glass acquired from the seafloor off the coast of Oregon.

Glass hypothesized that the sediment would contain proteins that influence the growth of methane clathrate, and that those proteins would resemble well-known antifreeze proteins in fish, which help them survive in cold environments.
But to confirm her hypothesis, Glass and her research team would first have to identify protein candidates out of millions of potential targets contained in the sediment. They would then need to make the proteins in the lab, though there was no understanding of how these proteins might behave. Also, no one had worked with these proteins before.
Glass approached Lieberman, whose lab studies the structure of proteins. The first step was to use DNA sequencing paired with bioinformatics to identify the genes of the proteins contained in the sediment. Dustin Huard, a researcher in Lieberman's lab and first author of the paper, then prepared candidate proteins that could potentially bind to the methane clathrates. Huard used X-ray crystallography to determine the structure of the proteins.
Creating Seafloor Conditions in the Lab
Huard passed off the protein candidates to Abigail Johnson, a former Ph.D. student in Glass' lab and co-first author on the paper, who is now a postdoctoral researcher at the University of Georgia. To test the proteins, Johnson formed methane clathrates herself by recreating the high pressure and low temperature of the seafloor in the lab. Johnson worked with Sheng Dai, an associate professor in the School of Civil and Environmental Engineering, to build a unique pressure chamber from scratch.
Johnson placed the proteins in the pressure vessel and adjusted the system to mimic the pressure and temperature conditions required for clathrate formation. By pressurizing the vessel with methane, Johnson forced methane into the droplet, which caused a methane clathrate structure to form.

She then measured the amount of gas that was consumed by the clathrate -- an indicator of how quickly and how much clathrate formed -- and did so in the presence of the proteins versus no proteins. Johnson found that with the clathrate-binding proteins, less gas was consumed, and the clathrates melted at higher temperatures.
Once the team validated that the proteins affect the formation and stability of methane clathrates, they used Huard's protein crystal structure to carry out molecular dynamics simulations with the help of James (JC) Gumbart, professor in the School of Physics. The simulations allowed the team to identify the specific site where the protein binds to the methane clathrate.
A Surprisingly Novel System
The study unveiled unexpected insights into the structure and function of the proteins. The researchers initially thought the part of the protein that was similar to fish antifreeze proteins would play a role in clathrate binding. Surprisingly, that part of the protein did not play a role, and a wholly different mechanism directed the interactions.
They found that the proteins do not bind to ice, but rather interact with the clathrate structure itself, directing its growth. Specifically, the part of the protein that had similar characteristics to antifreeze proteins was buried in the protein structure, and instead played a role in stabilizing the protein.
The researchers found that the proteins performed better at modifying methane clathrate than any of the antifreeze proteins that had been tested in the past. They also performed just as well as, if not better than, the toxic commercial clathrate inhibitors currently used in drilling that pose serious environmental threats.
Preventing clathrate formation in natural gas pipelines is a billion-dollar industry. If these biodegradable proteins could be used to prevent disastrous natural gas leaks, it would greatly reduce the risk of environmental damage.
""We were so lucky that this actually worked, because even though we chose these proteins based on their similarity to antifreeze proteins, they are completely different,"" Johnson said. ""They have a similar function in nature, but do so through a completely different biological system, and I think that really excites people.""
Methane clathrates likely exist throughout the solar system -- on the subsurface of Mars, for example, and on icy moons in the outer solar system, such as Europa. The team's findings indicate that if microbes exist on other planetary bodies, they might produce similar biomolecules to retain liquid water in channels in the clathrate that could sustain life.
""We're still learning so much about the basic systems on our planet,"" Huard said. ""That's one of the great things about Georgia Tech -- different communities can come together to do really cool, unexpected science. I never thought I would be working on an astrobiology project, but here we are, and we've been very successful.""

","score: 13.167492193129956, grade_level: '13'","score: 15.13003843382176, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/pnasnexus/pgad268,"Methane clathrates on continental margins contain the largest stores of hydrocarbons on Earth, yet the role of biomolecules in clathrate formation and stability remains almost completely unknown. Here, we report new methane clathrate-binding proteins (CbpAs) of bacterial origin discovered in metagenomes from gas clathrate-bearing ocean sediments. CbpAs show similar suppression of methane clathrate growth as the commercial gas clathrate inhibitor polyvinylpyrrolidone and inhibit clathrate growth at lower concentrations than antifreeze proteins (AFPs) previously tested. Unlike AFPs, CbpAs are selective for clathrate over ice. CbpA3 adopts a nonglobular, extended structure with an exposed hydrophobic surface, and, unexpectedly, its TxxxAxxxAxx motif common to AFPs is buried and not involved in clathrate binding. Instead, simulations and mutagenesis suggest a bipartite interaction of CbpAs with methane clathrate, with the pyrrolidine ring of a highly conserved proline residue mediating binding by filling empty clathrate cages. The discovery that CbpAs exert such potent control on methane clathrate properties implies that biomolecules from native sediment bacteria may be important for clathrate stability and habitability."
"
A newly discovered nearby supernova whose star ejected up to a full solar mass of material in the year prior to its explosion is challenging the standard theory of stellar evolution. The new observations are giving astronomers insight into what happens in the final year prior to a star's death and explosion.

SN 2023ixf is a new Type II supernova discovered in May 2023 by amateur astronomer K?ichi Itagaki of Yamagata, Japan shortly after its progenitor, or origin star, exploded. Located about 20 million light-years away in the Pinwheel Galaxy, SN 2023ixf's proximity to Earth, the supernova's extreme brightness, and its young age make it a treasure trove of observable data for scientists studying the death of massive stars in supernova explosions.
Type II or core-collapse supernovae occur when red supergiant stars at least eight times, and up to about 25 times the mass of the Sun, collapse under their own weight and explode. While SN 2023ixf fit the Type II description, followup multi-wavelength observations led by astronomers at the Center for Astrophysics | Harvard & Smithsonian (CfA), and using a wide range of CfA's telescopes, have revealed new and unexpected behavior.
Within hours of going supernova, core-collapse supernovae produce a flash of light that occurs when the shock wave from the explosion reaches the outer edge of the star. SN 2023ixf, however, produced a light curve that didn't seem to fit this expected behavior. To better understand SN 2023ixf's shock breakout, a team of scientists led by CfA postdoctoral fellow Daichi Hiramatsu analyzed data from the 1.5m Tillinghast Telescope, 1.2m telescope, and MMT at the Fred Lawrence Whipple Observatory, a CfA facility located in Arizona, as well as data from the Global Supernova Project -- a key project of the Las Cumbres Observatory, NASA's Neil Gehrels Swift Observatory, and many others. This multi-wavelength study, which was published this week in The Astrophysical Journal Letters, revealed that, in sharp contradiction to expectations and stellar evolution theory, SN 2023ixf's shock breakout was delayed by several days.
""The delayed shock breakout is direct evidence for the presence of dense material from recent mass loss,"" said Hiramatsu, adding that such extreme mass loss is atypical of Type II supernovae. ""Our new observations revealed a significant and unexpected amount of mass loss -- close to the mass of the Sun -- in the final year prior to explosion.""
SN 2023ixf challenges astronomers' understanding of the evolution of massive stars and the supernovae they become. Although scientists know that core-collapse supernovae are primary origin points for the cosmic formation and evolution of atoms, neutron stars, and black holes, very little is known about the years leading up to stellar explosions. The new observations point to potential instability in the final years of a star's life, resulting in extreme mass loss. This could be related to the final stages of nuclear burn-off of high-mass elements, like silicon, in the star's core.
In conjunction with multi-wavelength observations led by Hiramatsu, Edo Berger, professor of astronomy at Harvard and CfA, and Hiramatsu's advisor, conducted millimeter-wave observations of the supernova using CfA's Submillimeter Array (SMA) on the summit of Maunakea, Hawai'i. These data, which are published in The Astrophysical Journal Letters, directly tracked the collision between the supernova debris and the dense material lost before the explosion. ""SN 2023ixf exploded exactly at the right time,"" said Berger. ""Only a few days earlier we commenced a new ambitious three-year program to study supernova explosions with the SMA, and this nearby exciting supernova was our first target.""
""The only way to understand how massive stars behave in the final years of their lives up to the point of explosion is to discover supernovae when they are very young, and preferably nearby, and then to study them across multiple wavelengths,"" said Berger. ""Using both optical and millimeter telescopes we effectively turned SN 2023ixf into a time machine to reconstruct what its progenitor star was doing up to the moment of its death.""
The supernova discovery itself, and the immediate followup, have significant meaning to astronomers around the world, including those doing science in their own backyards. Itagaki discovered the supernova on May 19, 2023, from his private observatory in Okayama, Japan. Combined data from Itagaki and other amateur astronomers determined the time of the explosion to an accuracy of within two hours, giving professional astronomers at CfA and other observatories a head start in their investigations. CfA astronomers have continued to collaborate with Itagaki on on-going optical observations.
""The partnership between amateur and professional astronomers has a long-standing tradition of success in the supernova field,"" said Hiramatsu. ""In the case of SN 2023ixf, I received an urgent email from K?ichi Itagaki as soon as he discovered SN 2023ixf. Without this relationship, and Itagaki's work and dedication, we would have missed the opportunity to gain critical understanding of the evolution of massive stars and their supernova explosions.""

","score: 16.351139789386746, grade_level: '16'","score: 17.311893041503197, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/ace0c4,"We present 1.3 mm (230 GHz) observations of the recent and nearby Type II supernova, SN 2023ixf, obtained with the Submillimeter Array (SMA) at 2.6–18.6 days after explosion. The observations were obtained as part the SMA Large Program, POETS (Pursuit of Extragalactic Transients with the SMA). We do not detect any emission at the location of SN 2023ixf, with the deepest limits of L ν (230 GHz) ≲ 8.6 × 1025 erg s−1 Hz−1 at 2.7 and 7.7 days, and L ν (230 GHz) ≲ 3.4 × 1025 erg s−1 Hz−1 at 18.6 days. These limits are about a factor of 2 times dimmer than the millimeter emission from SN 2011dh (IIb), about 1 order of magnitude dimmer compared to SN 1993J (IIb) and SN 2018ivc (IIL), and about 30 times dimmer than the most luminous nonrelativistic SNe in the millimeter band (Type IIb/Ib/Ic). Using these limits in the context of analytical models that include synchrotron self-absorption and free–free absorption, we place constraints on the proximate circumstellar medium around the progenitor star, to a scale of ∼2 × 1015 cm, excluding the range M ̇ ∼ few × 10 − 6 − 10 − 2 M ⊙ yr−1 (for a wind velocity, v w = 115 km s−1, and ejecta velocity, v ej ∼ (1 − 2) × 104 km s−1). These results are consistent with an inference of the mass-loss rate based on optical spectroscopy (∼2 × 10−2 M ⊙ yr−1 for v w = 115 km s−1), but are in tension with the inference from hard X-rays (∼7 × 10−4 M ⊙ yr−1 for v w = 115 km s−1). This tension may be alleviated by a nonhomogeneous and confined CSM, consistent with results from high-resolution optical spectroscopy."
"
If you dropped antimatter, would it fall down or up? In a unique laboratory experiment, researchers have now observed the downward path taken by individual atoms of antihydrogen, providing a definitive answer: antimatter falls down.

In confirming antimatter and regular matter are gravitationally attracted, the finding also rules out gravitational repulsion as the reason why antimatter is largely missing from the observable universe.
Researchers from the international Antihydrogen Laser Physics Apparatus (ALPHA) collaboration at CERN in Switzerland published their findings today in the journal Nature, an effort supported by more than a dozen countries and private institutions, including the U.S. through the joint U.S. National Science Foundation/Department of Energy Partnership in Basic Plasma Science and Engineering program.
""The success of the ALPHA collaboration is a testament to the importance of teamwork across continents and scientific communities,"" says Vyacheslav ""Slava"" Lukin, a program director in NSF's Physics Division. ""Understanding the nature of antimatter can help us not only understand how our universe came to be but can enable new innovations never before thought possible -- like positron emission tomography (PET) scans that have saved many lives by applying our knowledge of antimatter to detect cancerous tumors in the body.""
Matter's elusive, volatile twin
Beyond the imagined antimatter-fueled warp drives and photon torpedoes of Star Trek, antimatter is completely real, yet mysteriously scarce.
""Einstein's theory of general relativity says antimatter should behave exactly the same as matter,"" said University of California, Berkeley plasma physicist and ALPHA collaboration member Jonathan Wurtele. ""Many indirect measurements indicate that gravity interacts with antimatter as expected"" he added, ""but until the result today, nobody had actually performed a direct observation that could rule out, for example, antihydrogen moving upwards as opposed to downwards in a gravitational field.""
Our bodies, the Earth, and most everything else scientists know about in the universe are overwhelmingly made of regular matter consisting of protons, neutrons, and electrons, like atoms of oxygen, carbon, iron and the other elements of the periodic table.

Antimatter, on the other hand, is regular matter's twin, though with some opposite properties. For example, antiprotons have a negative charge while protons have a positive charge. Antielectrons (also known as positrons) are positive while electrons are negative.
However, perhaps most challenging for experimenters, ""As soon as antimatter touches matter, it blows up,"" said ALPHA collaboration member and University of California, Berkeley plasma physicist Joel Fajans.
The combined mass of matter and antimatter is transformed entirely into energy in a reaction so powerful that scientists call it an annihilation.
""For a given mass, such annihilations are the densest form of energy release that we know of,"" Fajans added.
But, the amount of antimatter used in the ALPHA experiment is so small that the energy created by antimatter/matter annihilations is perceptible only to sensitive detectors.
""Still, we have to manipulate the antimatter very carefully or we will lose it,"" said Fajans.

Dropping an antimatter banger
""Broadly speaking, we're making antimatter and we're doing a Leaning Tower of Pisa kind of experiment,"" said Wurtele, referring to their experiment's simpler intellectual ancestor, Galileo's perhaps apocryphal 16th century experiment demonstrating identical gravitational acceleration of two simultaneously dropped objects of similar volume but different mass. ""We're letting the antimatter go, and we're seeing if it goes up or down.""
For the ALPHA experiment, the antihydrogen was contained within a tall cylindrical vacuum chamber with a variable magnetic trap, called ALPHA-g. The scientists reduced the strength of the trap's top and bottom magnetic fields until the antihydrogen atoms could escape and the relatively weak influence of gravity became apparent.
As each antihydrogen atom escaped the magnetic trap, it touched the chamber walls either above or below the trap and annihilated, which the scientists could detect and count.
The researchers repeated the experiment more than a dozen times, varying the magnetic field strength at the top and bottom of the trap to rule out possible errors. They observed that when the weakened magnetic fields were precisely balanced at the top and bottom, about 80% of the antihydrogen atoms annihilated beneath the trap -- a result consistent with how a cloud of regular hydrogen would behave under the same conditions.
Thus, gravity was causing the antihydrogen to fall down.
The matter/antimatter mystery
Despite some modest sources of antimatter -- like positrons emitted from the decay of potassium, even within a banana -- scientists do not see much of it in the universe. However, the laws of physics predict antimatter should exist in roughly equal amounts as regular matter. Scientists call that conundrum the baryogenesis problem.
One potential explanation is that antimatter was gravitationally repelled by regular matter during the big bang, although the new findings suggest that theory no longer seems plausible.
""We've ruled out antimatter being repelled by the gravitational force as opposed to attracted,"" said Wurtele. That doesn't mean there isn't a difference in the gravitational force on antimatter, he adds. Only a more precise measurement will tell.
The ALPHA collaboration researchers will continue to probe the nature of antihydrogen. In addition to refining their measurement of the effect of gravity, they are also studying how antihydrogen interacts with electromagnetic radiation through spectroscopy.
""If antihydrogen were somehow different from hydrogen, that would be a revolutionary thing because the physical laws, both in quantum mechanics and gravity, say the behavior should be the same,"" said Wurtele. ""However, one doesn't know until one does the experiment.""

","score: 16.536284948741848, grade_level: '17'","score: 16.726240971575024, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06527-1,"Einstein’s general theory of relativity from 19151 remains the most successful description of gravitation. From the 1919 solar eclipse2 to the observation of gravitational waves3, the theory has passed many crucial experimental tests. However, the evolving concepts of dark matter and dark energy illustrate that there is much to be learned about the gravitating content of the universe. Singularities in the general theory of relativity and the lack of a quantum theory of gravity suggest that our picture is incomplete. It is thus prudent to explore gravity in exotic physical systems. Antimatter was unknown to Einstein in 1915. Dirac’s theory4 appeared in 1928; the positron was observed5 in 1932. There has since been much speculation about gravity and antimatter. The theoretical consensus is that any laboratory mass must be attracted6 by the Earth, although some authors have considered the cosmological consequences if antimatter should be repelled by matter7–10. In the general theory of relativity, the weak equivalence principle (WEP) requires that all masses react identically to gravity, independent of their internal structure. Here we show that antihydrogen atoms, released from magnetic confinement in the ALPHA-g apparatus, behave in a way consistent with gravitational attraction to the Earth. Repulsive ‘antigravity’ is ruled out in this case. This experiment paves the way for precision studies of the magnitude of the gravitational acceleration between anti-atoms and the Earth to test the WEP."
"
Lava worlds, massive exoplanets home to sparkling skies and roiling volcanic seas called magma oceans, are distinctly unlike the planets in our solar system.

To date, nearly 50% of all rocky exoplanets yet discovered have been found capable of maintaining magma on their surfaces, likely because these planets are so close to their host stars they orbit in fewer than 10 days. Being so close causes the planet to be bombarded by harsh weather and forces surface temperatures to the extreme, making it all but completely inhospitable to life as we know it today.
Now, in a new study, scientists have shown that these sweeping molten oceans have a large influence on the observed properties of hot rocky Super-Earths, such as their size and evolutionary path.
Their research, published recently in The Astrophysical Journal, found that due to lava's extremely compressible nature, oceans of magma can cause lava-rich planets without atmospheres to be modestly denser than similarly sized solid planets as well as impact the structure of their mantles, the thick inner layer that surrounds a planet's core.
Even so, since these objects are notoriously under-studied, it can be a difficult task to characterize the fundamental workings of lava planets, said Kiersten Boley, lead author of the study and a graduate student in astronomy at The Ohio State University.
""Lava worlds are very odd, very interesting things and because of the way we detect exoplanets, we're more biased to finding them,"" said Boley, whose research revolves around understanding what essential ingredients makes exoplanets unique and how tweaking those elements, or in the case of lava worlds, their temperatures, can completely change them.
One of the most well-known of these mysterious burning worlds is 55 Cancri e, an exoplanet about 41 light-years away that scientists describe as home to both sparkling skies and roiling lava seas.

While there are objects in our solar system, such as Jupiter's moon Io, that are extremely volcanically active, there aren't true lava planets in our stretch of the cosmos that scientists can get up close and personal to study. However, investigating how the composition of magma oceans contributes to the evolution of other planets, such as for how long they stay molten and for what reasons they eventually cool down, can offer clues into Earth's own fiery history, said Boley.
""When planets initially form, particularly for rocky terrestrial planets, they go through a magma ocean stage as they're cooling down,"" said Boley. ""So lava worlds can give us some insight into what may have happened in the evolution of nearly any terrestrial planet.""
Using the exoplanet interior modeler software Exoplex and data collected from previous studies to construct a module that included information on several types of magma compositions, researchers simulated several evolutionary scenarios of an Earth-like planet with surface temperatures from between 2600 and 3860 degrees Fahrenheit -- the melting point at which the planet's solid mantle would turn to liquid.
From the models they created, the team was able to discern that mantles of magma ocean planets can take on one of three forms: the first in which the entire mantle is completely molten, the second where a magma ocean lies on the surface, and a third sandwich-esque model that consists of a magma ocean at the surface, a solid rock layer in the middle and another layer of molten magma that lies closest to the planet's core.
The results suggest that the second and third forms are slightly more common than planets that are completely molten. Depending on the composition of magma oceans, some atmosphere-free exoplanets are better than others at trapping volatile elements -- compounds such as oxygen and carbon necessary to the formation of early atmospheres -- for billions of years.
For example, the study notes that a basal magma class planet that is 4 times more massive than Earth can trap more than 130 times the mass of water than in Earth's oceans today, and about 1,000 times the amount of carbon currently present in the planet's surface and crust.

""When we're talking about the evolution of a planet and its potential to have different elements that you would need to support life, being able to trap a lot of volatile elements within their mantles could have greater implications for habitability,"" said Boley.
Lava planets are a long way from becoming habitable enough to support life, but it's important to understand the processes that help these worlds to get there. Nevertheless, this study makes clear that measuring their density isn't exactly the best way to characterize these worlds when comparing them to solid exoplanets as a magma ocean neither significantly increases nor decreases its planet's density, said Boley.
Instead, their research reveals that scientists should focus on other terrestrial parameters such as fluctuations in a planet's surface gravity to test their theories about how hot lava worlds operate, especially if future researchers plan on using their data to aid in larger planetary studies.
""This work, which is a combination of earth sciences and astronomy, basically opens up exciting new questions about lava worlds,"" said Boley.
The study was supported by the National Science Foundation. Other co-authors are Wendy Panero, Joseph Schulze, Romy Martinez and Ji Wang, all from Ohio State, as well as Cayman Unterborn from the Southwest Research Institute.

","score: 18.176531531531534, grade_level: '18'","score: 20.980675675675677, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/acea85,"Lava worlds are a potential emerging population of Super-Earths that are on close-in orbits around their host stars, with likely partially molten mantles. To date, few studies have addressed the impact of magma on the observed properties of a planet. At ambient conditions, magma is less dense than solid rock; however, it is also more compressible with increasing pressure. Therefore, it is unclear how large-scale magma oceans affect planet observables, such as bulk density. We update ExoPlex, a thermodynamically self-consistent planet interior software, to include anhydrous, hydrous (2.2 wt% H2O), and carbonated magmas (5.2 wt% CO2). We find that Earth-like planets with magma oceans larger than ∼1.5 R ⊕ and ∼3.2 M ⊕ are modestly denser than an equivalent-mass solid planet. From our model, three classes of mantle structures emerge for magma ocean planets: (1) a mantle magma ocean, (2) a surface magma ocean, and (3) one consisting of a surface magma ocean, a solid rock layer, and a basal magma ocean. The class of planets in which a basal magma ocean is present may sequester dissolved volatiles on billion-year timescales, in which a 4 M ⊕ mass planet can trap more than 130 times the mass of water than in Earth’s present-day oceans and 1000 times the carbon in the Earth’s surface and crust."
"
Astronomers led by a team at Université de Montréal has made important progress in understanding the intriguing TRAPPIST-1 exoplanetary system, which was first discovered in 2016 amid speculation it could someday provide a place for humans to live.

Not only does the new research shed light on the nature of TRAPPIST-1 b, the exoplanet orbiting closest to the system's star, it has also shown the importance of parent stars when studying exoplanets.
Published in Astrophysical Journal Letters, the findings by astronomers at UdeM's Trottier Institute for Research on Exoplanets (iREx) and colleagues in Canada, the U.K. and U.S. shed light on the complex interplay between stellar activity and exoplanet characteristics.
Captured the attention
TRAPPIST-1, a star much smaller and cooler than our sun located approximately 40 light-years away from Earth, has captured the attention of scientists and space enthusiasts alike since the discovery of its seven Earth-sized exoplanets seven years ago. These worlds, tightly packed around their star with three of them within its habitable zone, have fueled hopes of finding potentially habitable environments beyond our solar system.
Led by iREx doctoral student Olivia Lim, the researchers employed the powerful James Webb Space Telescope (JWST) to observe TRAPPIST-1 b. Their observations were collected as part of the largest Canadian-led General Observers (GO) program during the JWST's first year of operations. (This program also included observations of three other planets in the system, TRAPPIST-1 c, g and h.) TRAPPIST-1 b was observed during two transits -- the moment when the planet passes in front of its star -- using the Canadian-made NIRISS instrument aboard the JWST.
""These are the very first spectroscopic observations of any TRAPPIST-1 planet obtained by the JWST, and we've been waiting for them for years"" said Lim, the GO program's principal Investigator.

She and her colleagues used the technique of transmission spectroscopy to peer deeper into the distant world. By analysing the central star's light after it has passed through the exoplanet's atmosphere during a transit, astronomers can see the unique fingerprint left behind by the molecules and atoms found within that atmosphere.
'Just a small subset'
""This is just a small subset of many more observations of this unique planetary system yet to come and to be analysed,"" adds René Doyon, Principal Investigator of the NIRISS instrument and co-author on the study. ""These first observations highlight the power of NIRISS and the JWST in general to probe the thin atmospheres around rocky planets.""
The astronomers' key finding was just how significant stellar activity and contamination are when trying to determine the nature of an exoplanet. Stellar contamination refers to the influence of the star's own features, such as dark spots and bright faculae, on the measurements of the exoplanet's atmosphere.
The team found compelling evidence that stellar contamination plays a crucial role in shaping the transmission spectra of TRAPPIST-1 b and, likely, the other planets in the system. The central star's activity can create ""ghost signals"" that may fool the observer into thinking they have detected a particular molecule in the exoplanet's atmosphere.
This result underscores the importance of considering stellar contamination when planning future observations of all exoplanetary systems, the sceintists say. This is especially true for systems like TRAPPIST-1, since the system is centred around a red dwarf star which can be particularly active with starspots and frequent flare events.

""In addition to the contamination from stellar spots and faculae, we saw a stellar flare, an unpredictable event during which the star looks brighter for several minutes or hours,"" said Lim. ""This flare affected our measurement of the amount of light blocked by the planet. Such signatures of stellar activity are difficult to model but we need to account for them to ensure that we interpret the data correctly.""
A range of models explored
Based on their collected JWST observations, Lim and her team explored a range of atmospheric models for TRAPPIST-1 b, examining various possible compositions and scenarios.
They found they could confidently rule out the existence of cloud-free, hydrogen-rich atmospheres -- in other words, there appears to be no clear, extended atmosphere around TRAPPIST-1 b. However, the data could not confidently exclude thinner atmospheres, such as those composed of pure water, carbon dioxide, or methane, nor an atmosphere similar to that of Titan, a moon of Saturn and the only moon in the Solar System with its own atmosphere.
These results are generally consistent with previous (photometric, and not spectroscopic) JWST observations of TRAPPIST-1 b with the MIRI instrument. The new study also proves that Canada's NIRISS instrument is a highly performing, sensitive tool able to probe for atmospheres on Earth-sized exoplanets at impressive levels.

","score: 16.114721756932813, grade_level: '16'","score: 17.771971896519638, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/acf7c4,"TRAPPIST-1 is a nearby system of seven Earth-sized, temperate, rocky exoplanets transiting a Jupiter-sized M8.5V star, ideally suited for in-depth atmospheric studies. Each TRAPPIST-1 planet has been observed in transmission both from space and from the ground, confidently rejecting cloud-free, hydrogen-rich atmospheres. Secondary eclipse observations of TRAPPIST-1 b with JWST/MIRI are consistent with little to no atmosphere given the lack of heat redistribution. Here we present the first transmission spectra of TRAPPIST-1 b obtained with JWST/NIRISS over two visits. The two transmission spectra show moderate to strong evidence of contamination from unocculted stellar heterogeneities, which dominates the signal in both visits. The transmission spectrum of the first visit is consistent with unocculted starspots and the second visit exhibits signatures of unocculted faculae. Fitting the stellar contamination and planetary atmosphere either sequentially or simultaneously, we confirm the absence of cloud-free, hydrogen-rich atmospheres, but cannot assess the presence of secondary atmospheres. We find that the uncertainties associated with the lack of stellar model fidelity are one order of magnitude above the observation precision of 89 ppm (combining the two visits). Without affecting the conclusion regarding the atmosphere of TRAPPIST-1 b, this highlights an important caveat for future explorations, which calls for additional observations to characterize stellar heterogeneities empirically and/or theoretical works to improve model fidelity for such cool stars. This need is all the more justified as stellar contamination can affect the search for atmospheres around the outer, cooler TRAPPIST-1 planets for which transmission spectroscopy is currently the most efficient technique."
"
Scientists have discovered a simple and reliable test for signs of past or present life on other planets -- ""the holy grail of astrobiology.""

In the journal Proceedings of the National Academy of Sciences, a seven-member team, funded by the John Templeton Foundation and led by Jim Cleaves and Robert Hazen of the Carnegie Institution for Science, reports that, with 90% accuracy, their artificial intelligence-based method distinguished modern and ancient biological samples from those of abiotic origin.
""This routine analytical method has the potential to revolutionize the search for extraterrestrial life and deepen our understanding of both the origin and chemistry of the earliest life on Earth,"" says Dr. Hazen. ""It opens the way to using smart sensors on robotic spacecraft, landers and rovers to search for signs of life before the samples return to Earth.""
Most immediately, the new test could reveal the history of mysterious, ancient rocks on Earth, and possibly that of samples already collected by the Mars Curiosity rover's Sample Analysis at Mars (SAM) instrument. The latter tests could be conducted using an onboard analytical instrument nicknamed ""SAM"" (for Sample Analysis at Mars.
""We'll need to tweak our method to match SAM's protocols, but it's possible that we already have data in hand to determine if there are molecules on Mars from an organic Martian biosphere.""
""The search for extraterrestrial life remains one of the most tantalizing endeavors in modern science,"" says lead author Jim Cleaves of the Earth and Planets Laboratory, Carnegie Institution for Science, Washington, DC.
""The implications of this new research are many, but there are three big takeaways: First, at some deep level, biochemistry differs from abiotic organic chemistry; second, we can look at Mars and ancient Earth samples to tell if they were once alive; and third, it is likely this new method could distinguish alternative biospheres from those of Earth, with significant implications for future astrobiology missions.""
The innovative analytical method does not rely simply on identifying a specific molecule or group of compounds in a sample.

Instead, the researchers demonstrated that AI can differentiate biotic from abiotic samples by detecting subtle differences within a sample's molecular patterns as revealed by pyrolysis gas chromatography analysis (which separates and identifies a sample's component parts), followed by mass spectrometry (which determines the molecular weights of those components).
Vast multidimensional data from the molecular analyses of 134 known abiotic or biotic carbon-rich samples were used to train AI to predict a new sample's origin. With approximately 90% accuracy, AI successfully identified samples that had originated from: Living things, such as modern shells, teeth, bones, insects, leaves, rice, human hair, and cells preserved in fine-grained rock Remnants of ancient life altered by geological processing (e.g. coal, oil, amber, and carbon-rich fossils), or Samples with abiotic origins, such as pure laboratory chemicals (e.g., amino acids) and carbon-rich meteorites.The authors add that until now the origins of many ancient carbon-bearing samples have been difficult to determine because collections of organic molecules, whether biotic or abiotic, tend to degrade over time.
Surprisingly, in spite of significant decay and alteration, the new analytical method detected signs of biology preserved in some instances over hundreds of millions of years.
Says Dr. Hazen: ""We began with the idea that the chemistry of life differs fundamentally from that of the inanimate world; that there are 'chemical rules of life' that influence the diversity and distribution of biomolecules. If we could deduce those rules, we can use them to guide our efforts to model life's origins or to detect subtle signs of life on other worlds.""
""These results mean that we may be able to find a lifeform from another planet, another biosphere, even if it is very different from the life we know on Earth. And, if we do find signs of life elsewhere, we can tell if life on Earth and other planets derived from a common or different origin.""
""Put another way, the method should be able to detect alien biochemistries, as well as Earth life. That is a big deal because it's relatively easy to spot the molecular biomarkers of Earth life, but we cannot assume that alien life will use DNA, amino acids, etc. Our method looks for patterns in molecular distributions that arise from life's demand for ""functional"" molecules.

""What really astonished us was that we trained our machine-learning model to predict only two sample types -- biotic or abiotic -- but the method discovered three distinct populations: abiotic, living biotic, and fossil biotic. In other words, it could tell more recent biological samples from fossil samples -- a newly plucked leaf or vegetable, say, versus something that died long ago. This surprising finding gives us optimism that other attributes such as photosynthetic life or eukaryotes (cells with a nucleus) might also be distinguished.""
To explain the role of AI, co-author Anirudh Prabhu of the Carnegie Institution for Science uses the idea of separating coins using different attributes -- monetary value, metal, year, weight or radius, for example -- then going further to find combinations of attributes that create more nuanced separations and groupings. ""And when hundreds of such attributes are involved, AI algorithms are invaluable to collate the information and create highly nuanced insights.""
Adds Dr. Cleaves: ""From a chemical standpoint, the differences between biotic and abiotic samples relate to things like water solubility, molecular weights, volatility and so on.""
""The simple way I would think about this is that a cell has a membrane and an interior, called the cytosol; the membrane is pretty water-insoluble, while the cell's content is pretty water-soluble. That arrangement keeps the membrane assembled as it tries to minimize its components' contacts with water and also keeps the 'inside components' from leaking across the membrane.""
""The inside components can also stay dissolved in water despite being extremely large molecules like chromosomes and proteins,"" he says.
""So, if one breaks a living cell or tissue into its components, one gets a mix of very water-soluble molecules and very water-insoluble molecules spread across a spectrum. Things like petroleum and coal have lost most of the water-soluble material over their long histories.""
""Abiological samples can have unique distributions across this spectrum relative to each other, but they are also distinct from the biological distributions.""
The technique may soon resolve a number of scientific mysteries on Earth, including the origin of 3.5 billion-year-old black sediments from Western Australia -- hotly debated rocks that some researchers contend hold Earth's oldest fossil microbes, while others claim they are devoid of life signs.
Other samples from ancient rocks in Northern Canada, South Africa, and China evoke similar debates.
""We're applying our methods right now to address these long-standing questions about the biogenicity of the organic material in these rocks,"" Hazen says.
And new ideas have poured forth about the potential contributions of this new approach in other fields such as biology, paleontology and archaeology.
""If AI can easily distinguish biotic from abiotic, as well as modern from ancient life, then what other insights might we gain? For example, could we tease out whether an ancient fossil cell had a nucleus, or was photosynthetic?"" says Dr. Hazen.
""Could it analyze charred remains and discriminate different kinds of wood from an archeological site? It's as if we are just dipping our toes in the water of a vast ocean of possibilities.""

","score: 16.07505320620401, grade_level: '16'","score: 17.331854932408753, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2307149120,"The search for definitive biosignatures—unambiguous markers of past or present life—is a central goal of paleobiology and astrobiology. We used pyrolysis–gas chromatography coupled to mass spectrometry to analyze chemically disparate samples, including living cells, geologically processed fossil organic material, carbon-rich meteorites, and laboratory-synthesized organic compounds and mixtures. Data from each sample were employed as training and test subsets for machine-learning methods, which resulted in a model that can identify the biogenicity of both contemporary and ancient geologically processed samples with ~90% accuracy. These machine-learning methods do not rely on precise compound identification: Rather, the relational aspects of chromatographic and mass peaks provide the needed information, which underscores this method’s utility for detecting alien biology."
"
Astronomers have found a striking link between the amount of dust surrounding a supermassive black hole and the strength of the radio emission produced in extremely bright galaxies. The findings are published in the Monthly Notices of the Royal Astronomical Society.

The team of international astronomers, led by Newcastle University and Durham University, UK, used new data from the Dark Energy Spectroscopic Instrument (DESI), which is conducting a five year survey of large scale structure in the universe that will include optical spectra for ~3 million quasars; extremely bright galaxies powered by supermassive black holes. They found that quasars that contained more dust, and therefore appeared redder, were more likely to have stronger radio emission compared to the quasars that had very little-to-no dust, appearing very blue.
Almost every known galaxy contains a supermassive black hole, which are black holes with a mass millions to billions that of our Sun, at its centre, including our own Milky Way. In some galaxies there is lots of material in the centre, feeding and growing this supermassive black hole, making it very energetic and ""active."" The most powerful type of these active galaxies are called ""quasars,"" which are some of the brightest objects in the Universe. Most quasars appear very blue, due to the bright disc of matter that orbits and feeds the central supermassive black hole which is very bright in optical and ultraviolet wavelengths. However, astronomers have found that a significant fraction of these quasars appear very red, although the nature of these objects is still not well understood.
In order to understand the physics of these red quasars, ""spectroscopic"" measurements are required, which can be used to analyse the quasar light at different wavelengths. The ""shape"" of the quasar's spectrum can indicate the amount of dust present surrounding the central region. Observing the radio emission from quasars can also tell you about the energetics of the central supermassive black hole; whether it is launching powerful ""winds"" or ""jets"" that might shape the surrounding galaxy.
This new study, led by Dr Victoria Fawcett of Newcastle University, and previously Durham University, uses spectroscopic observations from DESI to measure the amount of dust (reddening) in a sample of ~35,000 quasars and link this to the observed radio emission. They find that DESI is capable of observing much more extreme red (dusty) quasars compared to similar/previous spectroscopic surveys, such as the Sloan Digital Sky Survey (SDSS). They also find that redder quasars are much more likely to have strong radio emission compared to typical blue quasars.
Dr Fawcett says: ""It was really exciting to see the amazing quality of the DESI data and to discover thousands of these, previously rare, red quasars. I feel like this study puts lots of the puzzle pieces together in our understanding of red quasars and definitively links the dust in a quasar to its radio emission. I think this is the strongest evidence so far that red quasars are a key element in how galaxies evolve.""
This reddening-radio connection is likely due to powerful outflows of gas driven away from the supermassive black hole, which slam into the surrounding dust, causing shocks and radio emission. These outflows will eventually blow away all the dust and gas in the central region of the galaxy, revealing a blue quasar and resulting in weaker radio emission. This is consistent with the emerging picture that red quasars are a younger, ""blow-out"" phase in the evolution of galaxies. Red quasars may therefore be extremely important for understanding how galaxies evolve over time.
Dr Fawcett continues ""There are still many unanswered questions surrounding red quasars, such as whether black hole winds or radio jets are ultimately responsible for this enhanced radio emission. However, with the sample of DESI red quasars continuing to grow over the next few years of the survey, I am confident that we are on the brink of fully understanding the nature of these red quasars.""

","score: 15.057631058358066, grade_level: '15'","score: 16.119737883283875, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnras/stad2603,"We present the first eight months of data from our secondary target programme within the ongoing Dark Energy Spectroscopic Instrument (DESI) survey. Our programme uses a mid-infrared and optical colour selection to preferentially target dust-reddened quasi-stellar objects (QSOs) that would have otherwise been missed by the nominal DESI QSO selection. So far, we have obtained optical spectra for 3038 candidates, of which ∼70 per cent of the high-quality objects (those with robust redshifts) are visually confirmed to be Type 1 QSOs, consistent with the expected fraction from the main DESI QSO survey. By fitting a dust-reddened blue QSO composite to the QSO spectra, we find they are well-fitted by a normal QSO with up to AV ∼ 4 mag of line-of-sight dust extinction. Utilizing radio data from the LOFAR Two-metre Sky Survey (LoTSS) DR2, we identify a striking positive relationship between the amount of line-of-sight dust extinction towards a QSO and the radio detection fraction, that is not driven by radio-loud systems, redshift and/or luminosity effects. This demonstrates an intrinsic connection between dust reddening and the production of radio emission in QSOs, whereby the radio emission is most likely due to low-powered jets or winds/outflows causing shocks in a dusty environment. On the basis of this evidence, we suggest that red QSOs may represent a transitional ‘blow-out’ phase in the evolution of QSOs, where winds and outflows evacuate the dust and gas to reveal an unobscured blue QSO."
"
Imagine trying to tune a radio to a single station but instead encountering static noise and interfering signals from your own equipment. That is the challenge facing research teams searching for evidence of extremely rare events that could help understand the origin and nature of matter in the universe. It turns out that when you are trying to tune into some of the universe's weakest signals, it helps to make your instruments very quiet.

Around the world more than a dozen teams are listening for the pops and electronic sizzle that might mean they have finally tuned into the right channel. These scientists and engineers have gone to extraordinary lengths to shield their experiments from false signals created by cosmic radiation. Most such experiments are found in very inaccessible places -- such as a mile underground in a nickel mine in Sudbury, Ontario, Canada, or in an abandoned gold mine in Lead, South Dakota -- to shield them from naturally radioactive elements on Earth. However, one such source of fake signals comes from natural radioactivity in the very electronics that are designed to record potential signals.
Radioactive contaminants, even at concentrations as tiny as one part-per-billion, can mimic the elusive signals that scientists are seeking. Now, a research team at the Department of Energy's Pacific Northwest National Laboratory, working with Q-Flex Inc., a small business partner in California, has produced electronic cables with ultra-pure materials. These cables are specially designed and manufactured to have such extremely low levels of the radioactive contaminants that they will not interfere with highly sensitive neutrino and dark matter experiments. The scientists report in the journal EPJ Techniques and Instrumentation that the cables have applications not only in physics experiments, but they may also be useful to reduce the effect of ionizing radiation interfering with future quantum computers.
""We have pioneered a technique to produce electronic cabling that is a hundred times lower than current commercially available options,"" said PNNL principal investigator Richard Saldanha. ""This manufacturing approach and product has broad application across any field that is sensitive to the presence of even very low levels of radioactive contaminants.""
An ultra-quiet choreographed ballet
Small amounts of naturally occurring radioactive elements are found everywhere: in rocks, dirt and dust floating in the air. The amount of radiation that they emit is so low that they do not pose any health hazards, but it's still enough to cause problems for next-generation neutrino and dark matter detectors.
""We typically need to get a million or sometimes a billion times cleaner than the contamination levels you would find in just a little speck of dirt or dust,"" said PNNL chemist Isaac Arnquist, who co-authored the research article and led the measurement team.

For these experiments, Saldanha, Arnquist, and PNNL colleagues Maria Laura di Vacri, Nicole Rocco and Tyler Schlieder evaluated the amount of uranium, thorium and potassium at each step of the dozen or so processing steps that ultimately produce a detector cable. The team then developed special cleaning and fabrication techniques to reduce the contamination down to insignificant levels. Working in an ultraclean, dust and contaminant-free laboratory, the PNNL researchers meticulously plan out their every move.
""I almost think of us as performance athletes because everything, every movement we make, is extremely thought out. It's almost like we're choreographed dancers,"" said Arnquist. ""When we handle a detector sample material, there's no wasted extraneous motion or interaction with the sample because that interaction could impart some contamination that limits how well we can measure the materials.""
After several years of work and hundreds of measurements, the resulting cables are now so free of contaminants that they will not impact the operation of next-generation dark matter and neutrino experiments such as DAMIC-M, OSCURA, and nEXO. The research team points out in their study that low-radioactivity cables can increase the sensitivity of the experiments and even allow more flexibility in detector design.
Getting closer to the a-ha moment
So, exactly what are the researchers looking for in these experiments? In the case of both dark matter and neutrinoless double beta decay, they are hoping to record extremely rare events that could solve two key mysteries of the universe. Both of these mysteries pose fundamental questions about why the universe looks the way it does. The galaxies that fill our universe would not have formed without the existence of dark matter. Dark matter makes up around 85 percent of the matter of the universe, and yet, we have never observed dark matter directly, only its gravitational imprint on the universe. Perhaps more intriguing, the question of why there is matter in the universe at all may hinge on a unique property of the smallest known particles of matter -- the neutrino. Unlike all other fundamental particles, neutrinos could possibly interact as both matter and anti-matter. If true, this could result in an extremely rare nuclear decay called neutrinoless double beta decay. Scientists are building large experiments consisting of many tons of sensitive material with the hope of finding the first evidence of neutrinoless double beta decay within the next decade.
""Every step we take to eliminate interfering radioactivity gets us closer to finding evidence for dark matter or neutrinoless double beta decay,"" said Saldanha.

""These flexible cables have many conductive pathways, which are needed to read out complicated signals,"" added Arnquist. ""When, say, dark matter interacts with the detector or a neutrinoless double beta decay occurs, it's going to create an event that needs to be accurately recorded -- read out -- to make the discovery. We need to put a complex electronic part that is extremely clean of radioactive elements into the heart of the detector.""
""Next generation searches for neutrinoless double beta decay will be among the lowest radioactivity experiments ever constructed,"" said David Moore, a Yale University physicist and PNNL collaborator. ""These detectors use such pure materials that even a small amount of normal cabling materials would overwhelm the radioactivity from the entire rest of the detector, so developing ultra-low-background cables to read out such detectors is a major challenge. This recent work from PNNL and Q-Flex is key to enabling these detectors and will reduce the cabling background to a small fraction of what was possible with previous technologies.""
Planning is already underway to upgrade the highly sensitive DAMIC-M dark matter experiment and the new ultra-pure cables are one of the key improvements scheduled for installation in the detector.
""One component that we can't avoid in our detector are the cables that transmit the signals, which must be of very low radioactivity,"" said Alvaro E Chavarria, a physicist at the University of Washington and a collaborator on the DAMIC-M project. ""Prior to this recent PNNL development, the best solution was microcoax cables, which carry too few signals and would have required a significant redesign of our detector. This development is super exciting, since it enables the use of the industry-standard flex-circuit technology for low-background applications.""
Recent research findings by PNNL scientists and other collaborators indicate that the performance of some quantum computing devices can be affected by the presence of trace radioactive contaminants. While radioactivity is not currently what limits the capabilities of existing quantum computers, it is possible that quantum devices of the future might need low-radioactivity cables to enhance their performance.
""We see the potential for these cables to find applications in a wide range of sensitive radiation detectors and perhaps other applications such as quantum computing,"" Saldanha said.
The research was supported by the Department of Energy, Office of Science, under its Early Career Research and Small Business Innovation Research programs.

","score: 15.778871635610766, grade_level: '16'","score: 16.944547101449274, grade_levels: ['college_graduate'], ages: [24, 100]",10.1140/epjti/s40485-023-00104-6,"Flexible printed cables and circuitry based on copper-polyimide materials are widely used in experiments looking for rare events due to their unique electrical and mechanical characteristics. However, past studies have found copper-polyimide flexible cables to contain 400-4700 pg 238U/g, 16-3700 pg 232Th/g, and 170-2100 ng natK/g, which can be a significant source of radioactive background for many current and next-generation ultralow background detectors. This study presents a comprehensive investigation into the fabrication process of copper-polyimide flexible cables and the development of custom low radioactivity cables for use in rare-event physics applications. A methodical step-by-step approach was developed and informed by ultrasensitive assay to determine the radiopurity in the starting materials and identify the contaminating production steps in the cable fabrication process. Radiopure material alternatives were identified, and cleaner production processes and treatments were developed to significantly reduce the imparted contamination. Through the newly developed radiopure fabrication process, fully-functioning cables were produced with radiocontaminant concentrations of 20-31 pg 238U/g, 12-13 pg 232Th/g, and 40-550 ng natK/g, which is significantly cleaner than cables from previous work and sufficiently radiopure for current and next-generation detectors. This approach, employing witness samples to investigate each step of the fabrication process, can hopefully serve as a template for investigating radiocontaminants in other material production processes."
"
A new Northwestern University-led study is changing the way astrophysicists understand the eating habits of supermassive black holes.

While previous researchers have hypothesized that black holes eat slowly, new simulations indicate that black holes scarf food much faster than conventional understanding suggests.
The study will be published on Wednesday (Sept. 20) in The Astrophysical Journal.
According to new high-resolution 3D simulations, spinning black holes twist up the surrounding space-time, ultimately ripping apart the violent whirlpool of gas (or accretion disk) that encircles and feeds them. This results in the disk tearing into inner and outer subdisks. Black holes first devour the inner ring. Then, debris from the outer subdisk spills inward to refill the gap left behind by the wholly consumed inner ring, and the eating process repeats.
One cycle of the endlessly repeating eat-refill-eat process takes mere months -- a shockingly fast timescale compared to the hundreds of years that researchers previously proposed.
This new finding could help explain the dramatic behavior of some of the brightest objects in the night sky, including quasars, which abruptly flare up and then vanish without explanation.
""Classical accretion disk theory predicts that the disk evolves slowly,"" said Northwestern's Nick Kaaz, who led the study. ""But some quasars -- which result from black holes eating gas from their accretion disks -- appear to drastically change over time scales of months to years. This variation is so drastic. It looks like the inner part of the disk -- where most of the light comes from -- gets destroyed and then replenished. Classical accretion disk theory cannot explain this drastic variation. But the phenomena we see in our simulations potentially could explain this. The quick brightening and dimming are consistent with the inner regions of the disk being destroyed.""
Kaaz is a graduate student in astronomy at Northwestern's Weinberg College of Arts and Sciences and member of the Center for Interdisciplinary Exploration and Research in Astrophysics (CIERA). Kaaz is advised by paper co-author Alexander Tchekhovskoy, an associate professor of physics and astronomy at Weinberg and a CIERA member.

Mistaken assumptions
Accretion disks surrounding black holes are physically complicated objects, making them incredibly difficult to model. Conventional theory has struggled to explain why these disks shine so brightly and then abruptly dim -- sometimes to the point of disappearing completely.
Previous researchers have mistakenly assumed that accretion disks are relatively orderly. In these models, gas and particles swirl around the black hole -- in the same plane as the black hole and in the same direction of the black hole's spin. Then, over a time scale of hundreds to hundreds of thousands of years, gas particles gradually spiral into the black hole to feed it.
""For decades, people made a very big assumption that accretion disks were aligned with the black hole's rotation,"" Kaaz said. ""But the gas that feeds these black holes doesn't necessarily know which way the black hole is rotating, so why would they automatically be aligned? Changing the alignment drastically changes the picture.""
The researchers' simulation, which is one of the highest-resolution simulations of accretion disks to date, indicates that the regions surrounding the black hole are much messier and more turbulent places than previously thought.
More like a gyroscope, less like a plate
Using Summit, one of the world's largest supercomputers located at Oak Ridge National Laboratory, the researchers carried out a 3D general relativistic magnetohydrodynamics (GRMHD) simulation of a thin, tilted accretion disk. While previous simulations were not powerful enough to include all the necessary physics needed to construct a realistic black hole, the Northwestern-led model includes gas dynamics, magnetic fields and general relativity to assemble a more complete picture.

""Black holes are extreme general relativistic objects that affect space-time around them,"" Kaaz said. ""So, when they rotate, they drag the space around them like a giant carousel and force it to rotate as well -- a phenomenon called 'frame-dragging.' This creates a really strong effect close to the black hole that becomes increasingly weaker farther away.""
Frame-dragging makes the entire disk wobble in circles, similar to how a gyroscope precesses. But the inner disk wants to wobble much more rapidly than the outer parts. This mismatch of forces causes the entire disk to warp, causing gas from different parts of the disk to collide. The collisions create bright shocks that violently drive material closer and closer to the black hole.
As the warping becomes more severe, the innermost region of the accretion disk continues to wobble faster and faster until it breaks apart from the rest of the disk. Then, according to the new simulations, the subdisks start evolving independently from one another. Instead of smoothly moving together like a flat plate surrounding the black hole, the subdisks independently wobble at different speeds and angles like the wheels in a gyroscope.
""When the inner disk tears off, it will precess independently,"" Kaaz said. ""It precesses faster because it's closer to the black hole and because it's small, so it's easier to move.""
'Where the black hole wins'
According to the new simulation, the tearing region -- where the inner and outer subdisks disconnect -- is where the feeding frenzy truly begins. While friction tries to keep the disk together, the twisting of space-time by the spinning black hole wants to rip it apart.
""There is competition between the rotation of the black hole and the friction and pressure inside the disk,"" Kaaz said. ""The tearing region is where the black hole wins. The inner and outer disks collide into each other. The outer disk shaves off layers of the inner disk, pushing it inwards.""
Now the subdisks intersect at different angles. The outer disk pours material on top of the inner disk. This extra mass also pushes the inner disk toward the black hole, where it is devoured. Then, the black hole's own gravity pulls gas from the outer region toward the now-empty inner region to refill it.
The quasar connection
Kaaz said these fast cycles of eat-refill-eat potentially explain so-called ""changing-look"" quasars. Quasars are extremely luminous objects that emit 1,000 times more energy than the entire Milky Way's 200 billion to 400 billion stars. Changing-look quasars are even more extreme. They appear to turn on and off over the duration of months -- a tiny amount of time for a typical quasar.
Although classical theory has posed assumptions for how quickly accretion disks evolve and change brightness, observations of changing-look quasars indicate that they actually evolve much, much faster.
""The inner region of an accretion disk, where most of the brightness comes from, can totally disappear -- really quickly over months,"" Kaaz said. ""We basically see it go away entirely. The system stops being bright. Then, it brightens again and the process repeats. Conventional theory doesn't have any way to explain why it disappears in the first place, and it doesn't explain how it refills so quickly.""
Not only do the new simulations potentially explain quasars, they also could answer ongoing questions about the mysterious nature of black holes.
""How gas gets to a black hole to feed it is the central question in accretion-disk physics,"" Kaaz said. ""If you know how that happens, it will tell you how long the disk lasts, how bright it is and what the light should look like when we observe it with telescopes.""
The study, ""Nozzle shocks, disk tearing and streamers drive rapid accretion in 3D GRMHD simulations of warped thin disks,"" was supported by the U.S. Department of Energy and the National Science Foundation.

","score: 11.299002652519896, grade_level: '11'","score: 12.370948878707502, grade_levels: ['college'], ages: [18, 24]",10.3847/1538-4357/ace051,"The angular momentum of gas feeding a black hole (BH) may be misaligned with respect to the BH spin, resulting in a tilted accretion disk. Rotation of the BH drags the surrounding spacetime, manifesting as Lense–Thirring torques that lead to disk precession and warping. We study these processes by simulating a thin (H/r = 0.02), highly tilted (  = 65 ° ) accretion disk around a rapidly rotating (a = 0.9375) BH at extremely high resolutions, which we performed using the general-relativistic magnetohydrodynamic code H-AMR. The disk becomes significantly warped and continuously tears into two individually precessing subdisks. We find that mass accretion rates far exceed the standard α-viscosity expectations. We identify two novel dissipation mechanisms specific to warped disks that are the main drivers of accretion, distinct from the local turbulent stresses that are usually thought to drive accretion. In particular, we identify extreme scale height oscillations that occur twice an orbit throughout our disk. When the scale height compresses, “nozzle” shocks form, dissipating orbital energy and driving accretion. Separate from this phenomenon, there is also extreme dissipation at the location of the tear. This leads to the formation of low-angular momentum “streamers” that rain down onto the inner subdisk, shocking it. The addition of low-angular momentum gas to the inner subdisk causes it to rapidly accrete, even when it is transiently aligned with the BH spin and thus unwarped. These mechanisms, if general, significantly modify the standard accretion paradigm. Additionally, they may drive structural changes on much shorter timescales than expected in α-disks, potentially explaining some of the extreme variability observed in active galactic nuclei."
"
An international research team led by Assistant Professor Takuya Hashimoto (University of Tsukuba, Japan) and Researcher Javier Álvarez-Márquez (El Centro de Astrobiología (CAB, CSIC-INTA), Spain) has used the James Webb Space Telescope and the Atacama Large Millimeter/submillimeter Array to observe the most distant galaxy protocluster to date, 13.14 billion light-years away. The team has successfully captured the ""core region"" of the galaxy protocluster, which corresponds to a metropolitan area with a particularly high number density of galaxies.

The team has revealed that many galaxies are concentrated in a small area and that the growth of galaxies is accelerated. Furthermore, the team used simulations to predict the future of the metropolitan area and found that the region will merge into one larger galaxy within tens of millions of years. These results are expected to provide important clues regarding the birth and growth of galaxies.
The study of how individual stars are born and die in galaxies, how new stars are born from remnants of old stars, and how galaxies themselves grow are important themes in astronomy, as they provide insight into our roots in the Universe. Galaxy clusters, one of the largest structures in the Universe, are the assembly of more than 100 galaxies which are bound together through mutual gravitational force. Observations of nearby galaxies have shown that the growth of a galaxy depends on its environment in the sense that mature stellar populations are commonly seen in regions where galaxies are densely collected. This is referred to as the ""environment effect."" Although the environment effect has been considered an important piece to understand galaxy formation and evolution, it is not well known when the effect initiated in the history of the Universe. One of the keys to understanding this is to observe the ancestors of galaxy clusters shortly after the birth of the Universe; known as galaxy protoclusters (hereafter protoclusters), these are assemblies of about 10 distant galaxies. Fortunately, astronomy allows us to observe the distant Universe as it was in the past. For example, light from a galaxy 13 billion light-years away takes 13 billion years to reach Earth, so what we observe now is what that galaxy looked like 13 billion years ago. However, light that travels 13 billion light-years becomes fainter, so the telescopes that observe it must have high sensitivity and spatial resolution.
An international research team led by Assistant Professor Takuya Hashimoto (University of Tsukuba, Japan) and researcher Javier Álvarez-Márquez (Spanish Center for Astrobiology) has used the James Webb Space Telescope (JWST, observing visible and infrared light) and the Atacama Large Millimeter/submillimeter Array (ALMA, observing radio waves) to study the ""core region"" of the protocluster A2744z7p9OD. The protocluster A2744z7p9OD had been announced as the most distant proto-cluster at 13.14 billion light-years[1] away based on observations with JWST by another research group[2]. ""However, we have not been able to observe the entire core region, the metropolitan area, with the largest number of galaxy candidates in this protocluster. It was unclear whether the environmental effects of galaxies had begun in this protocluster. So we decided to focus our research on the core region,"" says Hashimoto.
The research team first observed the core region of this protocluster using JWST. Using NIRSpec, an instrument that observes spectra at wavelengths ranging from visible to near-infrared, the team made integral field spectroscopy observations that can simultaneously acquire spectra from all locations within the field of view. The team has successfully detected ionized oxygen-ion light ([OIII] 5008 Å) from four galaxies in a quadrangle region measuring 36,000 light-years along a side, which is equivalent to half the radius of the Milky Way galaxy (. Based on the redshift of this light (the elongation of the wavelength due to the cosmic expansion), the distance of the four galaxies from the Earth was identified as 13.14 billion light years. ""I was surprised when we identified four galaxies by detecting oxygen-ion emission at almost the same distance. The 'candidate galaxies' in the core region were indeed members of the most distant protocluster,"" says Yuma Sugahara (Waseda/NAOJ), who led the JWST data analysis.
In addition, the research team paid attention to the archival ALMA data, which had already been acquired for this region. The data captures radio emission from cosmic dust in these distant galaxies. As a result of analyses, they detected dust emissions from three of the four galaxies. This is the first detection of dust emission in member galaxies of a protocluster this far back in time. Cosmic dust in galaxies is thought to be supplied by supernova explosions at the end of the evolution of massive stars in the galaxies, which provide the material for new stars. Therefore, the presence of large amounts of dust in a galaxy indicates that many of the first-generation stars in the galaxy have already completed their lives and that the galaxy is growing. Professor Luis Colina (El Centro de Astrobiología (CAB, CSIC-INTA)) describes the significance of the results: ""Emission from cosmic dust was not detected in member galaxies of the protocluster outside the core region. The results indicate that many galaxies are clustered in a small region and that galaxy growth is accelerated, suggesting that environmental effects existed only ~700 million years after the Big Bang.""
Furthermore, the research team conducted a galaxy formation simulation to theoretically test how the four galaxies in the core region formed and evolved. The results showed that a region of dense gas particles existed around 680 million years after the Big Bang, and shows that four galaxies are formed, similar to the observed core region. To follow the evolution of these four galaxies, the simulation calculated physical processes such as the kinematics of stars and gas, chemical reactions, star formation, and supernovae. The simulations showed that the four galaxies merge and evolve into a single larger galaxy within a few tens of millions of years, which is a short time scale in the evolution of the Universe. ""We successfully reproduced the properties of the galaxies in the core region owing to the high spatial resolution of our simulations and the large number of galaxy samples we have. In the future, we would like to explore the formation mechanism of the core region and its dynamical properties in more detail,"" says Yurina Nakazato, a graduate student at the University of Tokyo, who analyzed the simulation data.

Javier Álvarez-Márquez (Spanish Center for Astrobiology) says, ""We will conduct more sensitive observations of the proto-cluster A2744z7p9OD with ALMA to see if there are any galaxies that were not visible with the previous sensitivity. We will also apply the JWST and ALMA observations, which have proven to be very powerful, to more protoclusters to elucidate the growth mechanism of galaxies, and to explore our roots in the Universe.""
This research was supported by JSPS KAKENHI (grant numbers 20K14516, 22H01257, 22H04939, 23H00131), Leading initiative for Excellent Young Researchers, MEXT, Japan (HJH02007), NAOJ ALMA Scientific Research Grant (2020-16B), the Spanish Ministry of Science and Innovation/State Agency of Research (PIB2021-127718NB-100), Program ""Garantía Juveníl"" from the ""Comunidad de Madrid"" 2021 (CM21 CAB M2 01), Co- munidad de Madrid under Atracción de Talento (2018-T2/TIC-11612), the Ramón y Cajal program of the Spanish Ministerio de Ciencia e Innovación (RYC2021-033094-I ).
[1] The redshift of this object was z = 7.88. Based on this, calculating the distance using the latest cosmological parameters (H0 = 67.7 km/s/Mpc, Ωm = 0.3111, ΩΛ = 0.6899) yields 13.14 billion light years.
[2] The distance for A2744z7p9OD was first determined by the team of Takahiro Morishita (California Institute of Technology).

","score: 15.738142428142428, grade_level: '16'","score: 17.068996996996994, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/acf57c,"The protoclusters in the epoch of reionization, traced by galaxy overdensity regions, are ideal laboratories for studying the process of stellar assembly and cosmic reionization. We present the spectroscopic confirmation of the core of the most distant protocluster at z = 7.88, A2744-z7p9OD, with the James Webb Space Telescope NIRSpec integral field unit spectroscopy. The core region includes as many as four galaxies detected in [O iii] 4960 and 5008 Å in a small area of ∼3″ × 3″, corresponding to ∼11 × 11 kpc, after the lensing magnification correction. Three member galaxies are also tentatively detected in dust continuum in Atacama Large Millimeter/submillimeter Array Band 6, which is consistent with their red ultraviolet continuum slopes, β ∼ −1.3. The member galaxies have stellar masses in the range of log(M */M ⊙) ∼7.6–9.2 and star formation rates of ∼3–50 M ⊙ yr−1, showing a diversity in their properties. FirstLight cosmological simulations reproduce the physical properties of the member galaxies including the stellar mass, [O iii] luminosity, and dust-to-stellar mass ratio, and predict that the member galaxies are on the verge of merging in a few to several tens of Myr to become a large galaxy with M * ∼ 6 × 109 M ⊙. The presence of a multiple merger and evolved galaxies in the core region of A2744-z7p9OD indicates that environmental effects are already at work 650 Myr after the Big Bang."
"
A team including Southwest Research Institute's Dr. Raluca Rufu recently calculated that most of the Moon's permanently shadowed regions (PSRs) are at most around 3.4 billion years old and can contain relatively young deposits of water ice. Water resources are considered key for sustainable exploration of the Moon and beyond, but these findings suggest that current estimates for cold-trapped ices are too high.

The current tilt of the Moon's spin axis combined with its orbital inclination -- the angle to Earth's orbital plane -- and the Sun's low angle creates permanent shadows at its poles. PSRs are some of the coldest spots in the solar system, allowing them to trap volatile chemicals, including water ice, that would immediately transform directly from a solid to a gas in the harsh, airless sunshine that falls in most other places on the Moon.
""We think the Earth-Moon system formed following a giant impact between early Earth and another protoplanet,"" said Rufu, a Sagan Fellow who is the second author of a Science Advances paper. ""The Moon formed from the impact-generated debris disk, migrating away from Earth over time. Around 4.1 billion years ago the Moon experienced a major spin axis reorientation when its tilt reached high angles before it damped down to the configuration we see today. As the axial tilt decreased, PSRs appeared at the poles and grew over time.""
The team used AstroGeo22, a new Earth-Moon evolution simulation tool, to calculate the Moon's axial tilt over time. Together with surface height measurements from the Lunar Orbital Altimeter Laser data (LOLA), the team estimated the evolution of the shadowed areas over time.
""The time evolution of the Moon-Earth distance remained an unsolved problem for half a century,"" Rufu said. ""However, these new geological proxies for the history of the Earth-Moon system allow us to calculate the Moon's axial tilt and the extent of PSRs over time.""
In 2009, NASA crashed the two-ton Atlas Centaur rocket body, part of the Lunar Crater Observation and Sensing Satellite (LCROSS), near the south pole of the Moon. It struck the floor of Cabeus crater, creating a plume of debris examined for the presence of water and other chemicals in the lunar regolith. A shepherding satellite travelling four minutes behind the Centaur and several Earth-orbiting satellites, including the Hubble Space Telescope, monitored the impact.
""Our work suggests that Cabeus crater became a PSR less than a billion years ago. The various volatiles detected in the plume created by LCROSS indicate that ice-trapping continued into relatively recent times,"" said Norbert Schörghofer, the lead author of this paper from the Planetary Science Institute. ""Impacts and outgassing are potential sources of water but peaked early in lunar history, when the present-day PSRs did not yet exist. The age of PSRs largely determines the amount of water ice that could be trapped in the lunar polar regions. Information about the abundance of water ice in PSRs is particularly important in planning for upcoming crewed and uncrewed missions to the Moon searching for water.""
This key resource can be used to create air and rocket fuel and sustain human habitation. NASA and other entities plan to send rovers and humans to characterize the water ice within PSRs.

","score: 13.485964035964038, grade_level: '13'","score: 14.434200799200802, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adh4302,"As the Moon migrated away from Earth, it experienced a major spin axis reorientation. Permanently shadowed regions (PSRs), which are thought to have trapped ices and are a main focus of lunar exploration, appeared and grew after this (Cassini state) transition and are often younger than their host craters. Here, we calculate the lunar spin axis orientation and the extent of PSRs based on recent advances for the time evolution of the Earth-Moon distance. The solar declination reached twice its current value 2.1 billion years (Ga) ago, when the PSR area was about half as large. The PSR area becomes negligible beyond 3.4 Ga ago. The site of an artificial impact in Cabeus Crater, where various volatiles have been detected, became continuously shadowed only about 0.9 Ga ago, and hence, cold-trapping has continued into this relatively recent time period. Overall estimates for the amount of cold-trapped ices have to be revised downward."
"
New research is challenging the scientific status quo on the limits of the nuclear chart in hot stellar environments where temperatures reach billions of degrees Celsius.

The nuclear chart is a way to map out different kinds of atomic nuclei based on their number of protons and neutrons, and the ""drip lines"" can be viewed as the boundaries or edges of this map. Researchers from the University of Surrey and the University of Zagreb have found that these drip lines, which define the maximum number of protons and neutrons within a nucleus, change dynamically with temperature.
The findings challenge the view that drip lines and the number of bound nuclei are not sensitive to the temperature.
Dr Esra Yuksel, co-author of the study from the University of Surrey, argues that the physics community must understand the limits of the nuclear chart. She said:
""Considering that nuclei participating in most of the processes in the universe are hot, understanding how many protons and neutrons bind together in extreme environments is critical. We aim to determine which nuclei can contribute to nuclear reactions and processes, especially in extremely hot stellar environments such as supernovae and neutron star mergers. These extremely hot environments are where most of the chemical elements heavier than iron are produced. Until our study, we didn't know much about these 'drip lines' (limits) at temperatures measured in billions of degrees Celsius.""
The study, published in Nature Communications, found that increasing temperatures significantly alter the limits of the nuclear chart. The discovery shows that more nuclei exist within the drip lines for hot nuclei than for cold nuclei.
The researchers from Surrey and Zagreb used theoretical calculations to predict nuclear properties and drip lines at temperatures up to 20 billion degrees Celsius. They found that at temperatures up to 10 billion Celsius, the drip lines and the number of bound nuclei have already started to change. At higher temperatures, shell effects disappear, and these changes become more visible.
Dr Yuksel concludes:
""Our work demonstrates that the nuclear drip lines should be viewed as evolving limits that dynamically change with temperature. Before this research, nuclear drip lines at finite temperatures were unknown, and knowledge about nuclei in hot stellar environments was limited since most theoretical and experimental studies are restricted to zero temperatures only.
""These new insights help us to understand how temperature changes the stability and structure of atomic nuclei. This knowledge is important not only for nuclear physics but also for understanding the modelling of extreme astrophysical events, such as neutron star mergers and core-collapse supernovae.""

","score: 13.963927291346646, grade_level: '14'","score: 15.608090117767539, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-40613-2,"Properties of nuclei in hot stellar environments such as supernovae or neutron star mergers are largely unexplored. Since it is poorly understood how many protons and neutrons can be bound together in hot nuclei, we investigate the limits of nuclear existence (drip lines) at finite temperature. Here, we present mapping of nuclear drip lines at temperatures up to around 20 billion kelvins using the relativistic energy density functional theory (REDF), including treatment of thermal scattering of nucleons in the continuum. With extensive computational effort, the drip lines are determined using several REDFs with different underlying interactions, demonstrating considerable alterations of the neutron drip line with temperature increase, especially near the magic numbers. At temperatures T ≲ 12 billion kelvins, the interplay between the properties of nuclear effective interaction, pairing, and temperature effects determines the nuclear binding. At higher temperatures, we find a surprizing result that the total number of bound nuclei increases with temperature due to thermal shell quenching. Our findings provide insight into nuclear landscape for hot nuclei, revealing that the nuclear drip lines should be viewed as limits that change dynamically with temperature."
"
A new study published in a Nature Partner Journal, npj Microgravity, finds an engineered compound given to mice aboard the International Space Station (ISS) largely prevented the bone loss associated with time spent in space. The study, led by a transdisciplinary team of professors at the University of California at Los Angeles (UCLA) and the Forsyth Institute in Cambridge, Massachusetts, highlight a promising therapy to mitigate extreme bone loss from long-duration space travel as well as musculoskeletal degeneration on Earth.

Microgravity-induced bone loss has long been a critical concern for long-term space missions. Decreased mechanical loading due to microgravity induces bone loss at a rate 12-times greater than on Earth. Astronauts in low Earth orbit may experience bone loss up to 1% per month, endangering astronaut skeletal health and increasing risk for fractures during long-duration spaceflight and later in life.
The current mitigation strategy for bone loss relies on exercise-induced mechanical loading to promote bone formation but is far from perfect for crewmembers spending up to six months in microgravity. Exercise does not always prevent bone loss, takes up valuable crew time, and may be contraindicated for certain types of injuries. The new study led by Chia Soo, MD, vice chair for research in the Division of Plastic and Reconstructive Surgery, professor in Departments of Surgery and Orthopaedic Surgery at UCLA David Geffen School of Medicine, investigated whether systemic delivery of NELL-like molecule-1 (NELL-1) can reduce microgravity induced bone loss. Discovered by Kang Ting, DMD, DMSc at the Forsyth Institute, NELL-1 is crucial for bone development and bone density maintenance. Professor Ting also led numerous studies to show that local delivery of NELL-1 can regenerate musculoskeletal tissues such as bone and cartilage.
Systemic delivery of NELL-1 aboard the ISS requires the team to minimize the number of injections. Ben Wu, DDS, PhD and Yulong Zhang, PhD at the Forsyth Institute enhanced NELL-1's therapeutic potential by extending the molecule's half-life from 5.5 hours to 15.5 hours without losing bioactivity, and bioconjugated an inert bisphosphonate (BP) to create a ""smart"" BP-NELL-PEG molecule that more specifically targets bone tissues without the common deleterious effects of BP.
The modified molecule was then extensively assessed by the Soo and Ting teams to determine the efficacy and safety of BP-NELL-PEG on earth. They found that BP-NELL-PEG displayed superior specificity for bone tissue without causing observable adverse effects.
To ascertain the practical applicability of BP-NELL-PEG in real space conditions, the researchers worked with Center for the Advancement of Science in Space (CASIS) and National Aeronautics and Space Administration (NASA) Ames to prepare extensively for the SpaceX CRS-11 mission to the ISS, where astronauts Peggy Whitson, PhD and Jack D. Fisher, MS carried out the studies. Half of the ISS mice were exposed to microgravity (""TERM Flight"") for a lengthy 9-week period to simulate the challenges of long-duration space travel, while the remaining mice were flown back to Earth at 4.5 weeks post-launch, for the first ever live animal return (""LAR Flight"") of mice in US history. Both TERM and LAR Flight groups were treated with either BP-NELL-PEG or phosphate buffered saline (PBS) control. An equivalent cohort of mice remained at the Kennedy Space Center and were treated similarly with BP-NELL-PEG or PBS to serve as normal Earth gravity (""Ground"") controls.
Both Flight and Ground mice treated with BP-NELL-PEG exhibited a significant increase in bone formation. The treated mice in space and on Earth displayed no apparent adverse health effects.

""Our findings hold tremendous promise for the future of space exploration, particularly for missions involving extended stays in microgravity,"" said lead corresponding author Chia Soo. ""If human studies bear this out, BP-NELL-PEG could be a promising tool to combat bone loss and musculoskeletal deterioration, especially when conventional resistance training is not feasible due to injuries or other incapacitating factors,"" said co-co-principal investigator, Kang Ting.
""This bioengineering strategy can also have important benefits on Earth, offering a potential therapy for patients suffering from extreme osteoporosis and other bone-related conditions,"" said co-co-principal investigator, Ben Wu.
""As the next step, UCLA project scientist, Pin Ha, MD, DDS, MS, is overseeing analysis of the live animal return data. We hope this will provide some insight on how to help future astronauts recover from longer duration space missions,"" said Chia Soo.
The research is supported by grants from CASIS and National Institutes of Health. Additional funding and support are provided by UCLA Division of Plastic and Reconstructive surgery, UCLA Department of Surgery, UCLA Department of Orthopaedic Surgery and the UCLA Orthopaedic Hospital Research Center, the American Association of Orthodontists Foundation, and the International Orthodontics Foundation. Pin Ha and Yulong Zhang, and associate professor Jin Hee Kwak, DDS, are co-first authors and contributed equally to this project.

","score: 16.81598534345753, grade_level: '17'","score: 18.38289334275119, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41526-023-00319-7,"Microgravity-induced bone loss results in a 1% bone mineral density loss monthly and can be a mission critical factor in long-duration spaceflight. Biomolecular therapies with dual osteogenic and anti-resorptive functions are promising for treating extreme osteoporosis. We previously confirmed that NELL-like molecule-1 (NELL-1) is crucial for bone density maintenance. We further PEGylated NELL-1 (NELL-polyethylene glycol, or NELL-PEG) to increase systemic delivery half-life from 5.5 to 15.5 h. In this study, we used a bio-inert bisphosphonate (BP) moiety to chemically engineer NELL-PEG into BP-NELL-PEG and specifically target bone tissues. We found conjugation with BP improved hydroxyapatite (HA) binding and protein stability of NELL-PEG while preserving NELL-1’s osteogenicity in vitro. Furthermore, BP-NELL-PEG showed superior in vivo bone specificity without observable pathology in liver, spleen, lungs, brain, heart, muscles, or ovaries of mice. Finally, we tested BP-NELL-PEG through spaceflight exposure onboard the International Space Station (ISS) at maximal animal capacity (n = 40) in a long-term (9 week) osteoporosis therapeutic study and found that BP-NELL-PEG significantly increased bone formation in flight and ground control mice without obvious adverse health effects. Our results highlight BP-NELL-PEG as a promising therapeutic to mitigate extreme bone loss from long-duration microgravity exposure and musculoskeletal degeneration on Earth, especially when resistance training is not possible due to incapacity (e.g., bone fracture, stroke)."
"
One of the most interesting and important questions in cosmology is, ""How much matter exists in the universe?"" An international team, including scientists at Chiba University, has now succeeded in measuring the total amount of matter for the second time. Reporting in The Astrophysical Journal, the team determined that matter makes up 31% of the total amount of matter and energy in the universe, with the remainder consisting of dark energy.

""Cosmologists believe that only about 20% of the total matter is made of regular or 'baryonic' matter, which includes stars, galaxies, atoms, and life,"" explains first author Dr. Mohamed Abdullah, a researcher at the National Research Institute of Astronomy and Geophysics-Egypt, Chiba University, Japan. ""About 80% is made of dark matter, whose mysterious nature is not yet known but may consist of some as-yet-undiscovered subatomic particles.""
""The team used a well-proven technique to determine the total amount of matter in the universe, which is to compare the observed number and mass of galaxy clusters per unit volume with predictions from numerical simulations,"" says co-author Gillian Wilson, Abdullah's former graduate advisor and Professor of Physics and Vice Chancellor for research, innovation, and economic development at UC Merced. ""The number of clusters observed at the present time, the so-called 'cluster abundance,' is very sensitive to cosmological conditions and, in particular, the total amount of matter.""
""A higher percentage of the total matter in the universe would result in more clusters being formed,"" says Anatoly Klypin from University of Virginia. ""But it is difficult to measure the mass of any galaxy cluster accurately as most of the matter is dark, and we cannot see it directly with telescopes.""
To overcome this difficulty, the team was forced to use an indirect tracer of cluster mass. They relied upon the fact that more massive clusters contain more galaxies than less massive clusters (mass richness relation: MRR). Because galaxies consist of luminous stars, the number of galaxies in each cluster can be utilized as a way of indirectly determining its total mass. By measuring the number of galaxies in each cluster in their sample from the Sloan Digital Sky Survey, the team was able to estimate the total mass of each of the clusters. They were then able to compare the observed number and mass of galaxy clusters per unit volume against predictions from numerical simulations. The best-fit match between observations and simulations was with a universe consisting of 31% of the total matter, a value that was in excellent agreement with that obtained using cosmic microwave background (CMB) observations from the Planck satellite. Notably, CMB is a completely independent technique.
""We have succeeded in making the first measurement of matter density using the MRR, which is in excellent agreement with that obtained by the Planck team using the CMB method,"" says Tomoaki Ishiyama from Chiba University. ""This work further demonstrates that cluster abundance is a competitive technique for constraining cosmological parameters and complementary to non-cluster techniques such as CMB anisotropies, baryon acoustic oscillations, Type Ia supernovae, or gravitational lensing.""
The team credits their achievement as being the first to successfully utilize spectroscopy, the technique that separates radiation into a spectrum of individual bands or colors, to precisely determine the distance to each cluster and the true member galaxies that are gravitationally bound to the cluster rather than background or foreground interlopers along the line of sight. Previous studies that attempted to use the MRR technique relied on much cruder and less accurate imaging techniques, such as using pictures of the sky taken at some wavelengths, to determine the distance to each cluster and the nearby galaxies that were true members.

","score: 17.543880000000005, grade_level: '18'","score: 18.596567999999998, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/ace773,"The cluster mass–richness relation (MRR) is an observationally efficient and potentially powerful cosmological tool for constraining the matter density Ωm and the amplitude of fluctuations σ 8 using the cluster abundance technique. We derive the MRR relation using GalWCat19, a publicly available galaxy cluster catalog we created from the Sloan Digital Sky Survey-DR13 spectroscopic data set. In the MRR, cluster mass scales with richness as log M 200 = α + β log N 200 . We find that the MRR we derive is consistent with both the IllustrisTNG and mini-Uchuu cosmological numerical simulations, with a slope of β ≈ 1. We use the MRR we derived to estimate cluster masses from the GalWCat19 catalog, which we then use to set constraints on Ωm and σ 8. Utilizing the all-member MRR, we obtain constraints of Ωm = 0.31 − 0.03 + 0.04 and σ 8 = 0.82 − 0.04 + 0.05 , and utilizing the red member MRR only, we obtain Ωm = 0.31 − 0.03 + 0.04 and σ 8 = 0.81 − 0.04 + 0.05 . Our constraints on Ωm and σ 8 are consistent and very competitive with the Planck 2018 results."
"
A group of international astronomers, including researchers from Queen's University, has identified two potential polar ring galaxies, according to results published today in the Monthly Notices of the Royal Astronomical Society.

Queen's researchers Nathan Deg and Kristine Spekkens (Physics, Engineering Physics & Astronomy) led the analysis of data obtained using a telescope owned and operated by CSIRO, Australia's national science agency. Looking at sky maps of hydrogen gas in over 600 galaxies as part of CSIRO's ASKAP radio telescope's WALLABY survey, they identified two potential polar ring galaxies, a type of galaxy that exhibits a ring of stars and gas perpendicular to its main spiral disk.
Although this is not the first time that astronomers have observed polar ring galaxies, they are the first observed using the ASKAP telescope located at Inyarrimanha Ilgari Bundara, CSIRO's Murchison radio astronomy observatory on Wajarri Yamaji Country in Western Australia.
These new detections in gas alone suggest polar ring galaxies might be more common than previously believed.
Understanding how galaxies evolve
Further investigation of polar ring structures can help us better understand how galaxies evolve. For example, one of the main hypotheses to explain the origin of polar rings is a merger where a larger galaxy 'swallows' a smaller one. If polar ring galaxies are more common than previously thought, this could mean that these mergers are more frequent.
In the future, polar ring galaxies can also be used to deepen our understanding of the universe, with potential applications in dark matter research. It is possible to use polar rings to probe the shape of dark matter of the host galaxy, which could lead to new clues about the mysterious properties of the elusive substance.

Visualizing polar ring galaxies
Jayanne English, a member of the WALLABY research team and also an expert in astronomy image-making at the University of Manitoba, developed the first images of these gaseous polar ring galaxies using a combination of optical and radio data from the different telescopes. First, optical and infrared data from the Subaru telescope in Hawaii provided the image for the spiral disk of the galaxy. Then, the gaseous ring was added based on data obtained from the WALLABY survey, an international project using CSIRO's ASKAP radio telescope to detect atomic hydrogen emission from about half a million galaxies.
The creation of this and other astronomical images are all composite because they include information that our eyes can't capture. In this particular case, the cold hydrogen gas component, invisible to the human eye, is seen in radio ""light"" using CSIRO's ASKAP. The subtle colour gradient of this ring represents the orbital motions of the gas, with purple-ish tints at the bottom tracing gas that moves towards the viewer while the top portion moves away. The emission from the ring was separated from the radio emission emanating from the disk of the galaxy using virtual reality tools, in collaboration with Professor Tom Jarrett (University of Cape Town, South Africa).
Over 25 global collaborators from Canada, Australia, South Africa, Ecuador, Burkina Faso, Germany, China, and beyond worked together to analyze the data from the first public data release of the WALLABY survey, resulting in the newly published paper.
The next step for the team is to confirm the polar ring galaxies finding through additional observations using different telescopes, including the MeerKAT radio telescope in South Africa.
""Polar ring galaxies are some of the most spectacular looking galaxies in the Universe. These findings suggest that one to three per cent of nearby galaxies may have gaseous polar rings, which is much higher than suggested by optical telescopes."" Dr. Nathan Deg, researcher, Department of Physics, Engineering Physics & and Astronomy, Queen's University, Canada, and lead author on the study.

","score: 16.911026392961876, grade_level: '17'","score: 17.426392961876836, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnras/stad2312,"We report on the discovery of two potential polar ring galaxies (PRGs) in the WALLABY Pilot Data Release 1 (PDR1). These untargeted detections, cross-matched to NGC 4632 and NGC 6156, are some of the first galaxies where the H i observations show two distinct components. We used the iDaVIE virtual reality software to separate the anomalous gas from the galactic gas and found that the anomalous gas comprises ∼50 per cent of the total H i content of both systems. We have generated plausible 3D kinematic models for each galaxy, assuming that the rings are circular and inclined at 90° to the galaxy bodies. These models show that the data are consistent with PRGs but do not definitively prove that the galaxies are PRGs. By projecting these models at different combinations of main disc inclinations, ring orientations, and angular resolutions in mock data cubes, we have further investigated the detectability of similar PRGs in WALLABY. Assuming that these galaxies are indeed PRGs, the detectability fraction, combined with the size distribution of WALLABY PDR1 galaxies, implies an incidence rate of ∼1–3 per cent. If this rate holds true, the WALLABY survey will detect hundreds of new polar ring galaxies."
"
At the center of every galaxy is a supermassive black hole. Beyond a certain size, these become active, emitting huge amounts of radiation, and are then called quasars. It is thought these are activated by the presence of massive dark matter halos (DMH) surrounding the galaxy, directing matter towards the center, feeding the black hole. A team including researchers from the University of Tokyo have, for the first time, surveyed hundreds of ancient quasars and found this behavior is very consistent throughout history. This is surprising, as many large-scale processes show variation throughout the life of the universe, so the mechanism of quasar activation could have implications for the evolution of the entire universe.

Measuring the mass of DMHs is not easy; it's famously a very elusive substance, if substance is even the right word to use, given the actual nature of dark matter is unknown. We only know it exists at all due to its gravitational impact on large structures such as galaxies. Thus, dark matter can only be measured by making observations about its gravitational effects on things. This includes the way it might pull on something or affect its movement, or through the lensing (bending of light) of objects behind a suspected area of dark matter.
The challenge becomes greater at large distances, given how weak the light from more distant, and therefore ancient, phenomena can be. But this did not stop Professor Nobunari Kashikawa from the Department of Astronomy, and his team, from trying to answer a long-standing question in astronomy: How are black holes born, and how do they grow? The researchers are especially keen to explore this in relation to supermassive black holes, the largest kind, which exist in the heart of every galaxy. These would be very difficult to study were it not for the fact that some grow so massive they begin to output incredibly powerful jets of matter or spheres of radiation that in either case become what we call quasars. These are so powerful that even at large distances, we can now observe them using modern techniques.
""We measured for the first time the typical mass for dark matter halos surrounding an active black hole in the universe about 13 billion years ago,"" said Kashikawa. ""We find the DMH mass of quasars is pretty constant at about 10 trillion times the mass of our sun. Such measurements have been made for more recent DMH around quasars, and those measurements are strikingly similar to what we see for more ancient quasars. This is interesting because it suggests there is a characteristic DMH mass which seems to activate a quasar, regardless of whether it happened billions of years ago or right now.""
Quasars at great distances appear faint, as the light which left them long ago has spread out, was absorbed by intervening matter, and has been stretched into nearly invisible infrared wavelengths due to the universe expanding over time. So Kashikawa and his team, whose project began in 2016, used multiple surveys of the sky which incorporated a range of different instruments, the main one being Japan's Subaru Telescope, located in U.S. state of Hawaii.
""Upgrades allowed Subaru to see farther than ever, but we can learn more by expanding observation projects internationally,"" said Kashikawa. ""The U.S.-based Vera C. Rubin Observatory and even the space-based Euclid satellite, launched by the EU this year, will scan a larger area of the sky and find more DMH around quasars. We can build a more complete picture of the relationship between galaxies and supermassive black holes. That might help inform our theories about how black holes form and grow.""

","score: 13.208340086439765, grade_level: '13'","score: 14.149725823878981, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/ace43a,"We present, for the first time, dark matter halo (DMH) mass measurement of quasars at z ∼ 6 based on a clustering analysis of 107 quasars. Spectroscopically identified quasars are homogeneously extracted from the Hyper Suprime-Cam Strategic Survey Program wide layer over 891 deg2. We evaluate the clustering strength by three different autocorrelation functions: projected correlation function, angular correlation function, and redshift–space correlation function. The DMH mass of quasars at z ∼ 6 is evaluated as 5.0 − 4.0 + 7.4 × 10 12 h − 1 M ⊙ with the bias parameter b = 20.8 ± 8.7 by the projected correlation function. The other two estimators agree with these values; though, each uncertainty is large. The DMH mass of quasars is found to be nearly constant ∼1012.5 h −1 M ⊙ throughout cosmic time, suggesting that there is a characteristic DMH mass where quasars are always activated. As a result, quasars appear in the most massive halos at z ∼ 6, but in less extreme halos thereafter. The DMH mass does not appear to exceed the upper limit of 1013 h −1 M ⊙, which suggests that most quasars reside in DMHs with M halo < 10 13 h - 1 M ⊙ across most of the cosmic time. Our results supporting a significant increasing bias with redshift are consistent with the bias evolution model with inefficient active galactic nucleus feedback at z ∼ 6. The duty cycle (f duty) is estimated as 0.019 ± 0.008 by assuming that DMHs in some mass interval can host a quasar. The average stellar mass is evaluated from stellar-to-halo mass ratio as M * = 6.5 − 5.2 + 9.6 × 10 10 h − 1 M ⊙ , which is found to be consistent with [C ii] observational results."
"
A paper published in the journal Monthly Notices of the Royal Astronomical Society hints at the existence of several black holes in the Hyades cluster -- the closest open cluster to our solar system -- which would make them the closest black holes to Earth ever detected. The study results from a collaboration between a group of scientists led by Stefano Torniamenti, from the University of Padua (Italy), with the significant participation of with Mark Gieles, ICREA professor at the Faculty of Physics, the Institute of Cosmos Sciences of the University of Barcelona (ICCUB) and the Institute of Space Studies of Catalonia (IEEC), and Friedrich Anders (ICCUB-IEEC).

Specifically, the finding took place during a research stay of the expert Stefano Torniamenti at the ICCUB, one of the research units that make up the IEEC.
Black holes in the Hyades star cluster?
Since their discovery, black holes have been one of the most mysterious and fascinating phenomena in the Universe and have become the object of study for researchers all over the world. This is particularly true for small black holes because they have been observed during the detection of gravitational waves. Since the detection of the first gravitational waves in 2015, experts have observed many events that correspond to mergers of low-mass black hole pairs.
For the published study, the team of astrophysicists used simulations that track the motion and evolution of all the stars in the Hyades -- located at a distance from the Sun of about 45 parsecs or 150 light-years -- to reproduce their current state.
Open clusters are loosely bound groups of hundreds of stars that share certain properties such as age and chemical characteristics. The simulation results were compared with the actual positions and velocities of the stars in the Hyades, which are now known precisely from observations made by the European Space Agency's (ESA) Gaia satellite.
""Our simulations can only simultaneously match the mass and size of the Hyades if some black holes are present at the centre of the cluster today (or until recently),"" says Stefano Torniamenti, postdoctoral researcher at the University of Padua and first author of the paper.

The observed properties of the Hyades are best reproduced by simulations with two or three black holes at present, although simulations where all the black holes have been ejected (less than 150 million years ago, roughly the last quarter of the cluster's age) can still give a good match, because the evolution of the cluster could not erase the traces of its previous black hole population.
The new results indicate that the Hyades-born black holes are still inside the cluster, or very close to the cluster. This makes them the closest black holes to the Sun, much closer than the previous candidate (namely the black hole Gaia BH1, which is 480 parsecs from the Sun).
In recent years, the breakthrough of the Gaia space telescope has made it possible for the first time to study the position and velocity of open cluster stars in detail and to identify individual stars with confidence.
""This observation helps us understand how the presence of black holes affects the evolution of star clusters and how star clusters in turn contribute to gravitational wave sources,"" says Mark Gieles, a member of the UB Department of Quantum Physics and Astrophysics and host of the first author in Barcelona. ""These results also give us insight into how these mysterious objects are distributed across the galaxy.""
The new study is the result of close collaboration between the University of Padova, ICUBB-IEEC, the University of Cambridge (United Kingdome), the European Southern Observatory (ESO) and the National Sun Yat-sen University (China).

","score: 17.20086924895436, grade_level: '17'","score: 19.13076559374432, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/mnras/stad1925,"Astrophysical models of binary-black hole mergers in the universe require a significant fraction of stellar-mass black holes (BHs) to receive negligible natal kicks to explain the gravitational wave detections. This implies that BHs should be retained even in open clusters with low escape velocities (≲1 km s−1). We search for signatures of the presence of BHs in the nearest open cluster to the Sun – the Hyades – by comparing density profiles of direct N-body models to data from Gaia. The observations are best reproduced by models with 2–3 BHs at present. Models that never possessed BHs have an half-mass radius $\sim 30~{{\ \rm per\ cent}}$ smaller than the observed value, while those where the last BHs were ejected recently (≲150 Myr ago) can still reproduce the density profile. In 50 per cent of the models hosting BHs, we find BHs with stellar companion(s). Their period distribution peaks at ∼103 yr, making them unlikely to be found through velocity variations. We look for potential BH companions through large Gaia astrometric and spectroscopic errors, identifying 56 binary candidates – none of which is consistent with a massive compact companion. Models with 2–3 BHs have an elevated central velocity dispersion, but observations cannot yet discriminate. We conclude that the present-day structure of the Hyades requires a significant fraction of BHs to receive natal kicks smaller than the escape velocity of $\sim 3 \, \mathrm{km \, s^{-1}}$ at the time of BH formation and that the nearest BHs to the Sun are in, or near, Hyades."
"
After exposure in space aboard the International Space Station, a new kind of surface treatment significantly reduced the growth of biofilms, scientists report. Biofilms are mats of microbial or fungal growth that can clog hoses or filters in water processing systems, or potentially cause illness in people.

In the experiment, researchers investigated a variety of surfaces treated in different ways and exposed to a bacteria called Pseudomonas aeruginosa, which is an opportunistic pathogen than can cause infections in humans, especially in hospitals. The surfaces were incubated for three days aboard the space station, starting in 2019. The results show that textured surfaces impregnated with a lubricant were highly successful at preventing biofilm growth during their long exposure in space. The findings are described in a paper in the journal Nature Microgravity, by Samantha McBride PhD '20 and Kripa Varanasi of MIT, Pamela Flores and Luis Zea at the University of Colorado, and Jonathan Galakza at NASA Ames Research Center.
Clogs in water recovery system hoses aboard the ISS have been so severe at times, the hoses had to be sent back to Earth for cleaning and refurbishing. And while it isn't known whether biofilms have directly contributed to astronaut illnesses, on Earth, biofilms are associated with 65 percent of microbial infections, and 80 percent of chronic infections, the researchers say.
One approach to preventing biofilms is to use surfaces coated with certain metals or oxides that kill microbes, but this approach can fail when a layer of dead microbes builds up on the surface and allows biofilm to form above it. But this was not the case with the liquid-infused surface that performed well in the ISS experiments: Rather than killing the microbes, it prevented them from adhering to the surface in the first place.
The specific surface used was made of silicon that was etched to produce a nanoscale forest of pillars. This spiky surface is then infused with a silicon oil, which is drawn into the texture and held in place by capillary action, leaving a smooth and highly slippery surface that significantly reduces the adhesion of microbes and prevents them from forming a biofilm.
Identical experiments were conducted on Earth as well as on the space station to determine the differences produced by the microgravity environment in orbit. To the researchers' surprise, the liquid-infused surface performed even better in space than it did on Earth at preventing microbial adhesion.
On previous and current space stations, including the USSR's Mir station, Salyut 6, and Salyut 7, as well as the International Space Station, ""they've seen these biofilms, and they jeopardize a variety of instruments or equipment, including space suits, recycling units, radiators, and water treatment facilities, so it's a very important problem that needed to be understood,"" says Varanasi, a professor of mechanical engineering and founder of a company called LiquiGlide, which makes liquid-impregnated surfaces for containers to help their contents slide out.

Previous tests on Earth had shown that these treated surfaces could significantly reduce biofilm adhesion. When the samples from the space station were retrieved and tested, ""we found that these surfaces are extremely good at preventing biofilm formation in the space station as well,"" Varanasi says. This is important because past work has found that microgravity can have a significant influence on biofilm morphologies, attachment behavior, and gene expression, according to McBride. Thus, strategies that work well on Earth for biofilm mitigation may not necessarily be applicable to microgravity situations.
Preventing biofilms will be especially important for future long-duration missions, such as to the moon or Mars, where the option of quickly returning fouled equipment or sick astronauts to Earth will not be available, the team says. If further testing confirms its long-term stability and successful biofilm prevention, coatings based on the liquid-treated surface concept could be applied to a variety of critical components that are known to be susceptible to biofilm fouling, such as water treatment hoses and filters, or to parts that come in close contact with astronauts, such as gloves or food preparation surfaces.
In the terrestrial samples, biofilm formation was reduced by about 74 percent, while the space station samples showed a reduction of about 86 percent, says Flores, who did much of the testing of the ISS-exposed samples. ""The results we got were surprising,"" she says, because earlier tests carried out by others had shown biofilm formation was actually greater in space than on Earth. ""We actually found the opposite on these samples,"" she says.
While the tests used a specific and well-studied gram-negative kind of bacteria, she says, the results should apply to any kind of gram-negative bacteria, and likely to gram-positive bacteria as well. They found that the areas of the surface where no bacterial growth took place were covered by a thin layer of nucleic acids, which have a slight negative electric charge that may have helped to prevent microbes from adhering. Both gram-positive and gram-negative bacteria have a slight negative charge, which could repel them from that negatively charged surface, Flores says.
Other types of anti-fouling surfaces, Varanasi says, ""work mostly on a biocidal property, which usually only works for a first layer of cells because after those cells die they can form a deposit, and microbes can grow on top of them. So, usually it's been a very hard problem."" But with the liquid-impregnated surface, where what is exposed is mostly just the liquid itself, there are very few defects or points where the bacteria can find a footing, he says.
Although the test material was on the space station for more than a year, the actual tests were only performed over a three-day period because they required active participation by the astronauts whose schedules are always very busy. But one recommendation the team has made, based on these initial results, is that longer-duration tests should be carried out on a future mission. In these first tests, Flores says, the results after the third day looked the same as after the first and second days. ""We don't know for how long it will be able to keep up this performance, so we definitely recommend a longer time of incubation, and also, if possible, a continuous analysis, and not just end points.""
Zea, who initiated the project with NASA, says that this was the first time the agency has conducted tests that involved joint participation by two of its science programs, biology and physical sciences. ""I think it stresses the importance of multidisciplinarity because we need to be able to combine these different disciplines to find solutions to real world problems.""
Biofilms are also a significant medical issue on Earth, especially on medical devices or implants including catheters, where they can lead to significant disease problems. The same kind of liquid-impregnated surfaces may have a role to play in helping to address these issues, Varanasi says.
The project was supported by NASA and used facilities provided by several other companies and organizations.

","score: 15.648119658119658, grade_level: '16'","score: 17.715794871794877, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41526-023-00316-w,"The undesirable, yet inevitable, presence of bacterial biofilms in spacecraft poses a risk to the proper functioning of systems and to astronauts’ health. To mitigate the risks that arise from them, it is important to understand biofilms’ behavior in microgravity. As part of the Space Biofilms project, biofilms of Pseudomonas aeruginosa were grown in spaceflight over material surfaces. Stainless Steel 316 (SS316) and passivated SS316 were tested for their relevance as spaceflight hardware components, while a lubricant impregnated surface (LIS) was tested as potential biofilm control strategy. The morphology and gene expression of biofilms were characterized. Biofilms in microgravity are less robust than on Earth. LIS strongly inhibits biofilm formation compared to SS. Furthermore, this effect is even greater in spaceflight than on Earth, making LIS a promising option for spacecraft use. Transcriptomic profiles for the different conditions are presented, and potential mechanisms of biofilm reduction on LIS are discussed."
"
A star like our own Sun in a nearby galaxy is gradually being eaten away by a small but ravenous black hole, losing the equivalent mass of three Earths every time it passes close.

The discovery by University of Leicester astronomers is reported today (7 September) in Nature Astronomy and provides a 'missing link' in our knowledge of black holes disrupting orbiting stars. It suggests a whole menagerie of stars in the process of being consumed that still lie undiscovered.
The team was supported by the UK Space Agency and the UK Science and technology Facilities Council (STFC).
The astronomers were alerted to the star by a bright X-ray flash that seemed to come from the centre of the nearby galaxy 2MASX J02301709+2836050, around 500 million light-years away from the Milky Way. Named Swift J0230, it was spotted the moment it happened for the first time using a new tool developed by the scientists for the Neil Gehrels Swift Observatory. They rapidly scheduled further Swift observations of it, finding that instead of decaying away as expected, it would shine brightly for 7-10 days and then abruptly switch off, repeating this process roughly every 25 days.
Similar behaviour has been observed in what are termed quasi-periodic eruptions and periodic nuclear transients, where a star has material ripped away by a black hole as its orbit takes it close by, but they differ in how often they erupt, and in whether it is in X-rays or optical light that the explosion is predominant. The regularity of Swift J0230's emissions fell between the two, suggesting that it forms the 'missing link' between the two types of outburst.
Using the models proposed for these two classes of event as a guide, the scientists concluded that the Swift J0230 outburst represents a star of a similar size to our own sun in an elliptical orbit around a low-mass black hole at the centre of its galaxy. As the star's orbit takes it close to the intense gravitational pull of the black hole, material equivalent to the mass of three Earths is wrenched from the atmosphere of the star and heated up as it falls into the black hole. The intense heat, around 2 million degrees Celsius, releases a huge amount of X-rays which were first picked up by the Swift satellite.
Lead author Dr Phil Evans of the University of Leicester School of Physics and Astronomy said: ""This is the first time we've seen a star like our Sun being repeatedly shredded and consumed by a low mass black hole. So-called 'repeated, partial tidal disruption' events are themselves quite a new discovery and seem to fall into two types: those that outburst every few hours, and those that outburst every year or so. This new system falls right into the gap between these, and when you run the numbers, you find the types of objects involved fall nicely into place too.""
Dr Rob Eyles-Ferris, who works with Dr Evans on the Swift satellite, recently completed his PhD at Leicester, which included the study of stars being disrupted by black holes. He explains: ""In most of the systems we've seen in the past the star is completely destroyed. Swift J0230 is an exciting addition to the class of partially-disrupted stars as it shows us that the two classes of these objects already found are really connected, with our new system giving us the missing link.""

Dr Kim Page from the University of Leicester, who worked on the data analysis for the study, said: ""Given that we found Swift J0230 within a few months of enabling our new transient-hunting tool, we expect that there are a lot more objects like this out there, waiting to be uncovered.""
Dr Chris Nixon is a theoretical astrophysicist who recently moved from the University of Leicester to the University of Leeds. He led the theoretical interpretation of this event. His research is funded by the UK Science and Technology Facilities Council and the Leverhulme Trust.
They estimate that the black hole is around 10,000 to 100,000 times the mass of our sun, which is quite small for the supermassive black holes usually found at the centre of galaxies. The black hole at the centre of our own galaxy is thought to be 4 million solar masses, while most are in the region of 100 million solar masses.
It is the first discovery to be made using the new transient detector for the Swift satellite, developed by the University of Leicester team and running on their computers. When an extreme event takes place, causing an X-ray burst in a region of the sky where there were previously no X-rays, astronomers call it an astronomical X-ray transient. Despite the extreme events they herald, these events are not easy to find, or at least, not quickly -- and so this new tool was developed to look for new types of transients in real time.
Dr Evans adds: ""This type of object was essentially undetectable until we built this new facility, and soon after it found this completely new, never-before-seen event. Swift is nearly 20 years old and it's suddenly finding brand new events that we never knew existed. I think it shows that every single time you find a new way of looking at space, you learn something new and find there's something out there you didn't know about before.""
Dr Caroline Harper, Head of Space Science at the UK Space Agency, said:""This is yet another exciting discovery from the world-leading Swift mission -- a low mass black hole taking 'bites' from a Sun-like star whenever it orbits close enough.
""The UK Space Agency has been working in partnership with NASA on this mission for many years; the UK led on the development of hardware for two of the key science instruments and we provided funding for the Swift Science Data Centre, which we continue to support. We look forward to even more insights from Swift about gamma ray bursts throughout the cosmos, and the massive events that cause them, in the future.""

","score: 14.074766648876238, grade_level: '14'","score: 15.872010911462965, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41550-023-02073-y,"In recent years, searches of archival X-ray data have revealed galaxies exhibiting nuclear quasi-periodic eruptions with periods of several hours. These are reminiscent of the tidal disruption of a star by a supermassive black hole. The repeated, partial stripping of a white dwarf in an eccentric orbit around an ~105 M⊙ black hole provides an attractive model. A separate class of periodic nuclear transients, with much longer timescales, have recently been discovered optically and may arise from the partial stripping of a main-sequence star by an ~107 M⊙ black hole. No clear connection between these classes has been made. We present the discovery of an X-ray nuclear transient that shows quasi-periodic outbursts with a period of weeks. We discuss possible origins for the emission and propose that this system bridges the two existing classes outlined above. This discovery was made possible by the rapid identification, dissemination and follow-up of an X-ray transient found by the new live Swift-XRT transient detector, demonstrating the importance of low-latency, sensitive searches for X-ray transients."
"
New research has revealed the distribution of dark matter in never before seen detail, down to a scale of 30,000 light-years. The observed distribution fluctuations provide better constraints on the nature of dark matter.

Mysterious dark matter accounts for most of the matter in the Universe. Dark matter is invisible and makes itself know only through its gravitational effects. Dark matter has never been isolated in a laboratory, so researchers must rely on ""natural experiments"" to study it.
One type of natural experiment is a gravitational lens. Sometimes by random chance, two objects at different distances in the Universe will lie along the same line-of-sight when seen from Earth. When this happens, the spatial curvature caused by the matter around the foreground object acts like a lens, bending the path of light from the background object and making a lensed image. However, it is difficult to achieve the high resolution to detect clumps of dark matter which are less massive than galaxies in natural experiments, so the exact nature of dark matter has been poorly constrained.
A team of Japanese researchers led by Professor Kaiki Taro Inoue at Kindai University used ALMA (Atacama Large Millimeter/submillimeter Array) to study the gravitational lens system known as MG J0414+0534 in the direction of the constellation Taurus. In this system, the foreground object forms not one, but four images of the background object due to the gravitational force of a massive galaxy acting on the light. With the help of the bending effect and their new data analysis method, the team was able to detect fluctuations in the dark matter distribution along the line-of-sight in higher resolution than ever before, down to a scale of 30,000 light-years.
The new constraints provided by the observed distribution are consistent with models for slow moving, or ""cold,"" dark matter particles.
In the future the team plans to further constrain the nature of dark matter with additional observations.

","score: 13.349322848405418, grade_level: '13'","score: 14.014626474442991, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/aceb5f,"The lensing power spectra for gravitational potential, astrometric shift, and convergence perturbations are powerful probes to investigate dark matter structures on small scales. We report the first lower and upper bounds of these lensing power spectra on angular scale ∼1″ toward the anomalous quadruply lensed quasar MG J0414+0534 at a redshift z = 2.639. To obtain the spectra, we conducted observations of MG J0414+0534 using the Atacama Large Millimeter/submillimeter Array with high angular resolution (0.″02–0.″05). We developed a new partially nonparametric method in which Fourier coefficients of potential perturbation are adjusted to minimize the difference between linear combinations of weighted mean de-lensed images. Using positions of radio-jet components, extended dust emission on scales >1 kpc, and mid-infrared flux ratios, the range of measured convergence, astrometric shift, and potential powers at an angular scale of ∼1.″1 (corresponding to an angular wavenumber of l = 1.2 × 106 or ∼9 kpc in the primary lens plane) within 1σ are Δ κ = 0.021–0.028, Δ α = 7–9 mas, and Δ ψ = 1.2–1.6 mas2, respectively. Our result is consistent with the predicted abundance of halos in the line of sight and subhalos in cold dark matter models. Our partially nonparametric lens models suggest the presence of a clump in the vicinity of object Y, a possible dusty dwarf galaxy, and some small clumps in the vicinity of other lensed quadruple images. Although much fainter than the previous report, we detected weak continuum emission possibly from object Y with a peak flux of ∼100 μJy beam−1 at the ∼4σ level."
"
Using the Atacama Large Millimeter/submillimeter Array (ALMA), astronomers have detected the magnetic field of a galaxy so far away that its light has taken more than 11 billion years to reach us: we see it as it was when the Universe was just 2.5 billion years old. The result provides astronomers with vital clues about how the magnetic fields of galaxies like our own Milky Way came to be.

Lots of astronomical bodies in the Universe have magnetic fields, whether it be planets, stars or galaxies. ""Many people might not be aware that our entire galaxy and other galaxies are laced with magnetic fields, spanning tens of thousands of light-years,"" says James Geach, a professor of astrophysics at the University of Hertfordshire, UK, and lead author of the study published today in Nature.
""We actually know very little about how these fields form, despite their being quite fundamental to how galaxies evolve,"" adds Enrique Lopez Rodriguez, a researcher at Stanford University, USA, who also participated in the study. It is not clear how early in the lifetime of the Universe, and how quickly, magnetic fields in galaxies form because so far astronomers have only mapped magnetic fields in galaxies close to us.
Now, using ALMA, in which the European Southern Observatory (ESO) is a partner, Geach and his team have discovered a fully formed magnetic field in a distant galaxy, similar in structure to what is observed in nearby galaxies. The field is about 1000 times weaker than the Earth's magnetic field, but extends over more than 16,000 light-years.
""This discovery gives us new clues as to how galactic-scale magnetic fields are formed,"" explains Geach. Observing a fully developed magnetic field this early in the history of the Universe indicates that magnetic fields spanning entire galaxies can form rapidly while young galaxies are still growing.
The team believes that intense star formation in the early Universe could have played a role in accelerating the development of the fields. Moreover, these fields can in turn influence how later generations of stars will form. Co-author and ESO astronomer Rob Ivison says that the discovery opens up ""a new window onto the inner workings of galaxies, because the magnetic fields are linked to the material that is forming new stars.""
To make this detection, the team searched for light emitted by dust grains in a distant galaxy, 9io9. Galaxies are packed full of dust grains and when a magnetic field is present, the grains tend to align and the light they emit becomes polarised. This means that the light waves oscillate along a preferred direction rather than randomly. When ALMA detected and mapped a polarised signal coming from 9io9, the presence of a magnetic field in a very distant galaxy was confirmed for the first time.
""No other telescope could have achieved this,"" says Geach. The hope is that with this and future observations of distant magnetic fields the mystery of how these fundamental galactic features form will begin to unravel.

","score: 13.947563850687622, grade_level: '14'","score: 14.783715231103294, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06346-4,"Magnetic fields are fundamental to the evolution of galaxies, playing a key role in the astrophysics of the interstellar medium and star formation. Large-scale ordered magnetic fields have been mapped in the Milky Way and nearby galaxies1,2, but it is not known how early in the Universe such structures formed3. Here we report the detection of linearly polarized thermal emission from dust grains in a strongly lensed, intrinsically luminous galaxy that is forming stars at a rate more than 1,000 times that of the Milky Way at redshift 2.6, within 2.5 Gyr of the Big Bang4,5. The polarized emission arises from the alignment of dust grains with the local magnetic field6,7. The median polarization fraction is of the order of 1%, similar to nearby spiral galaxies8. Our observations support the presence of a 5-kiloparsec-scale ordered magnetic field with a strength of around 500 μG or lower, oriented parallel to the molecular gas disk. This confirms that such structures can be rapidly formed in galaxies, early in cosmic history."
"
A University of Hawaiʻi-led discovery of an immense bubble 820 million light years from Earth is believed to be a fossil-like remnant of the birth of the universe. Astronomer Brent Tully from the UH Institute for Astronomy and his team unexpectedly found the bubble within a web of galaxies. The entity has been given the name Hoʻoleilana, a term drawn from the Kumulipo, a Hawaiian creation chant evoking the origin of structure.

The new findings published in The Astrophysical Journal, mention these massive structures are predicted by the Big Bang theory, as the result of 3D ripples found in the material of the early universe, known as Baryon Acoustic Oscillations (BAO).
""We were not looking for it. It is so huge that it spills to the edges of the sector of the sky that we were analyzing,"" explained Tully. ""As an enhancement in the density of galaxies it is a much stronger feature than expected. The very large diameter of one billion light years is beyond theoretical expectations. If its formation and evolution are in accordance with theory, this BAO is closer than anticipated, implying a high value for the expansion rate of the universe.""
Astronomers located the bubble using data from Cosmicflows-4, which is to date, the largest compilation of precise distances to galaxies. Tully co-published the exceptional catalog in fall 2022. His team of researchers believe this may be the first time astronomers identified an individual structure associated with a BAO. The discovery could help bolster scientists' knowledge of the effects of galaxy evolution.
Enormous bubbles of matter
In the well-established Big Bang theory, during the first 400,000 years, the universe is a cauldron of hot plasma similar to the interior of the Sun. Within a plasma, electrons were separated from the atomic nuclei. During this period, regions with slightly higher density began to collapse under gravity, even as the intense bath of radiation attempted to push matter apart. This struggle between gravity and radiation made the plasma oscillate or ripple and spread outward.
The largest ripples in the early universe depended on the distance a sound wave could travel. Set by the speed of sound in the plasma, this distance was almost 500 million light years, and was fixed once the universe cooled and stopped being a plasma, leaving vast three-dimensional ripples. Throughout the eons, galaxies formed at the density peaks, in enormous bubble-like structures. Patterns in the distribution of galaxies, properly discerned, could reveal the properties of these ancient messengers.

""I am the cartographer of the group, and mapping Hoʻoleilana in three dimensions helps us understand its content and relationship with its surroundings,"" said researcher Daniel Pomarede of CEA Paris-Saclay University in France. ""It was an amazing process to construct this map and see how the giant shell structure of Hoʻoleilana is composed of elements that were identified in the past as being themselves some of the largest structures of the universe.""
This same team of researchers also identified the Laniākea Supercluster in 2014. That structure, which includes the Milky Way, is small in comparison. Stretching at a diameter of about 500 million light years, Laniākea extends to the near edge of this much larger bubble.
Uncovering a single BAO
Tully's team discovered that Hoʻoleilana had been noted in a 2016 research paper as the most prominent of several shell-like structures seen in the Sloan Digital Sky Survey. However, the earlier work did not reveal the full extent of the structure, and that team did not conclude they had found a BAO.
Using the Cosmicflows-4 catalog, the researchers were able to see a full spherical shell of galaxies, identify its center, and show that there is a statistical enhancement in the density of galaxies in all directions from that center. Hoʻoleilana encompasses many well-known structures previously found by astronomers, such as the Harvard/Smithsonian Great Wall containing the Coma Cluster, the Hercules Cluster and the Sloan Great Wall. The Boötes Supercluster resides at its center. The historic Boötes Void, a massive empty spherical region, lies inside Hoʻoleilana.
The implications of Hoʻoleilana
Tests with simulations have demonstrated that the shell structure identified as Hoʻoleilana has less than 1% probability of being a statistical accident. Hoʻoleilana has the properties of a theoretically anticipated baryon acoustic oscillation, including the prominence at its center of a rich supercluster, however it stands out stronger than expected. In detail, Hoʻoleilana is slightly larger than anticipated from the theory of the standard model of cosmology, and what has been found from prior statistical pair-wise studies of galaxy separations. The size is in accord with observations of the local expansion rate of the universe and of galaxy flows on large scales that also hint at subtle problems with the standard model.

","score: 13.209979785306015, grade_level: '13'","score: 13.857236163390489, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/aceaf3,"Theory of the physics of the early hot universe leads to a prediction of baryon acoustic oscillations (BAOs) that has received confirmation from the pairwise separations of galaxies in samples of hundreds of thousands of objects. Evidence is presented here for the discovery of a remarkably strong individual contribution to the BAO signal at z = 0.068, an entity that is given the name Ho’oleilana. The radius of the 3D structure is 155 h 75 − 1 Mpc. At its core is the Boötes supercluster. The Sloan Great Wall, Center for Astrophysics Great Wall, and Hercules complex all lie within the BAO shell. The interpretation of Ho’oleilana as a BAO structure with our preferred analysis implies a value of the Hubble constant of 76.9 − 4.8 + 8.2 km s − 1 Mpc − 1 ."
"
A planet about 950 light years from Earth could be the Looney Tunes' Yosemite Sam equivalent of planets, blowing its atmospheric 'top' in spectacular fashion.

The planet called HAT-P-32b is losing so much of its atmospheric helium that the trailing gas tails are among the largest structures yet known of an exoplanet, a planet outside our solar system, according to observations by astronomers.
Three-dimensional (3D) simulations on the Stampede2 supercomputer of the Texas Advanced Computing Center (TACC) helped model the flow of the planet's atmosphere, based on data from the Hobby-Eberly Telescope of The University of Texas at Austin's McDonald Observatory. The scientists hope to widen their planet-observing net and survey 20 additional star systems to find more planets losing their atmosphere and learn about their evolution.
""We have monitored this planet and the host star with long time series spectroscopy, observations made of the star and planet over a couple of nights. And what we found is there's a gigantic helium gas tail that is associated with the planet. The tail is large -- about 53 times the planet's radius -- formed by gas that's escaping from the planet,"" said Zhoujian Zhang, a postdoctoral fellow in the Department of Astronomy & Astrophysics, University of California Santa Cruz.
Zhang is the lead author in a study on the helium tail detected from HAT-P 32b that was published in Science Advances June 2023. The science team used data from the Habitable Planet Finder spectrograph, an instrument on the Hobby-Eberly telescope, which provides high spectral resolution of light in near infrared wavelengths.
The planet HAT-P-32b was discovered in 2011 using spectroscopic data from the Hungarian-made Automated Telescope Network. It's known as a 'hot Jupiter,' a gas giant similar to our neighboring planet Jupiter, but with a radius twice as large. This hot Jupiter hugs closely in orbit to its host star, about three percent the distance from the Earth to the Sun. Its orbital period -- what we consider a year here on Earth -- is only 2.15 days, and this proximity to the star scorches it with both long and short wave radiation.
The main motivation for the scientists' interest in studying hot Jupiters is their pursuit of the mystery of the Neptunian desert, the inexplicable relative scarcity on average of intermediate-mass planets, or sub-Jupiters, with short orbital periods.

""One of the potential explanations is that maybe the planets are losing their mass,"" Zhang offered. ""If we can capture planets in the process of losing their atmosphere, then we can study how fast the planet is losing their mass and what are the mechanisms that cause their atmosphere to escape from the planet. It's good to have some examples to see like the HAT-P-32b process in action.""
The light analyzed in the study comes from the star HAT-P-32 A. It's slightly hotter and similar in size to our own sun. The analyzed light is not just straight starlight. As the planet passes in front of the star, for just a couple of hours the starlight gets filtered the most by the planet's gassy atmosphere. This filtering, called absorption, reveals features of the transiting planet, in this case huge outflows of helium when the spectra were analyzed.
Zhang and colleagues used a technique called transmission spectroscopy to separate the starlight into its component frequencies, like a prism separates sunlight into a rainbow spectrum. Gaps in the spectrum indicate light being absorbed by elements in the gaseous atmosphere of HAT-P-32b.
""What we see in our data is that when the planet is transiting the star, we see there's deeper helium absorption lines. The helium absorption is stronger than what we expect from the stellar atmosphere. This excess helium absorption should be caused by the planet's atmosphere. When the planet is transiting, its atmosphere is so huge that it blocks part of the atmosphere that absorbs the helium line, and that causes this excess absorption. That's how we discovered the HAT-P-32b to be an interesting planet,"" Zhang said.
It got more interesting as they developed 3D hydrodynamical simulations of the HAT-P-32b and host star, led by Antonija Oklopčić, Anton Pannekoek Institute for Astronomy, University of Amsterdam; and Morgan MacLeod, Institute for Theory and Computation, Harvard-Smithsonian Center for Astrophysics, Harvard University.
The models examined the interactions between the planetary outflow and stellar winds in the tidal gravitational field of the extrasolar system. The models showed columnar tails of planetary outflow both leading and trailing the planet along its orbital path with excess helium absorption even far from the transit points that matched observations. What is more, the models suggest complete loss of the atmosphere in about 4 x 10e10 Earth years.

""We made use of TACC's Stampede2 system's Intel Skylake nodes for our calculations,"" MacLeod said. ""This computation involves tracking flow as it accelerates from a slow-moving subsonic 'atmosphere' near the planet to a supersonic wind as it moves further away. The HAT-P-32b system was identified to have a large-scale outflow similar in size to the planet's orbit around the star. Taken together, these requirements suggest the need for a stable, high-accuracy algorithm for solving three-dimensional gas dynamics.""
The modelers utilized the Athena++ hydrodynamic software and a custom problem setup to do their calculation on Stampede2. With it they solve the equations of gas dynamics in a rotating frame of reference that matches the planet's orbital motion. Athena++ is a Eulerian code -- the flow is discretized with volume elements -- and they used nested layers of mesh refinement to capture the large-scale star-planet system along with the much smaller scale of the atmosphere near the planet's surface.
""Using the TACC HPC systems is a joy,"" MacLeod said. ""A few things go into this -- the first, and most important is the level of support. Whenever I have a problem, I can call the support line, get help, and get back to doing the science that I am best at. Secondly, the vast majority of my time goes into developing and validating model results, rather than running a single, full-scale calculation. The TACC systems are incredibly well set up for this reality, and it hugely speeds up the pace of development. Being able to run test calculations through the development queues or submit larger calculations of a range of sizes in the lead up to an eventual final model is crucial and effective in these environments.""
Looking ahead, the scientists hope to continue to develop sophisticated 3D models that capture effects such as atmospheric mixing of gases and even winds within the atmosphere on more distant worlds hundreds and even thousands of light years away.
""Now is the time to have supercomputers with the computational power to make this happen,"" Zhang said. ""We need the computers to make real predictions based on recent advances in the theory and to explain the data. Supercomputers bridge the model and the data.""
""The best thing we can do is watch the night sky and try to recreate what we see through computer modeling,"" MacLeod concluded. ""Our universe is complicated. This means we need to have access to the absolute best supercomputing systems.""

","score: 12.545189067474187, grade_level: '13'","score: 13.310906126252036, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adf8736,"Capturing planets in the act of losing their atmospheres provides rare opportunities to probe their evolution history. This analysis has been enabled by observations of the helium triplet at 10,833 angstrom, but past studies have focused on the narrow time window right around the planet’s optical transit. We monitored the hot Jupiter HAT-P-32 b using high-resolution spectroscopy from the Hobby-Eberly Telescope covering the planet’s full orbit. We detected helium escaping HAT-P-32 b at a 14σ significance,with extended leading and trailing tails spanning a projected length over 53 times the planet’s radius. These tails are among the largest known structures associated with an exoplanet. We interpret our observations using three-dimensional hydrodynamic simulations, which predict Roche Lobe overflow with extended tails along the planet’s orbital path."
"
Scientists from The University of New Mexico (UNM), and Massachusetts Institute of Technology (MIT) have detected and validated two of the longest-period exoplanets found by TESS to date. These long period large exoplanets orbit a K dwarf star and belong to a class of planets known as warm Jupiters, which have orbital periods of 10-200 days and are at least six times Earth's radius. This recent discovery offers exciting research opportunities for the future of finding long-period planets that resemble those in our own solar system.

The research titled, TOI-4600 b and c: Two long-period giant planets orbiting an early K dwarf will be published in a future issue of The Astrophysical Journal Letters. The exoplanets, TOI-4600 b and c, were detected using photometric data from the Transiting Exoplanet Survey Satellite (TESS) and followed up with observations using the telescopes on the ground since they provide better resolution.
The observing strategy adopted by NASA's TESS, which divides each hemisphere into 13 sectors that are surveyed for roughly 28 days, is producing the most comprehensive all-sky search for transiting planets. This approach has already proven its capability to detect both large and small planets around different kinds of stars. In the case of TOI-4600, the star is a K dwarf star, also known as an orange dwarf, which are stars slightly smaller and cooler than the Sun.
Exoplanets must transit their host stars at least twice within TESS 's observing span to be detected with the correct period by the Science Processing Operations Center (SPOC) pipeline and the Quick Look Pipeline (QLP), which search the 2-minute and 30-minute cadence TESS data, respectively. Because 74 percent of TESS' total sky coverage is only observed for 28 days, the majority of TESS exoplanets detected have periods less than 40 days. Therefore, TOI-4600 b's 82.69-day, or nearly 3-month, and TOI-4600 c's 482.82-day, or 16-month, periods make their discoveries even more valuable.
The University of New Mexico's Ismael Mireles, the lead author of the paper, along with collaborators including Diana Dragomir, an assistant professor in UNM's Department of Physics and Astronomy, and collaborators from Massachusetts Institute of Technology and University of Bern, analyzed the data in order to measure the periods and sizes of these planets.
After initially detecting the transits, Mireles and team had to confirm that these were actual planets and to determine which signal the star was coming from. The diagnostic tools with TESS indicated that the signals coming from the target site were indeed on point. With help from TESS-Follow-up Observing Program (TFOP) Subgroup 1 (SG1), a global network of professional and amateur astronomers with access to telescopes small and large, they observed and watched a transit happen thus confirming for the researchers that this planet is indeed on target. Another factor that Mireles and his team had to consider were the masses and sizes of the planets. In order to achieve this they substituted the velocity measurements to observe how much the host star wobbles because the host star will pull on the planet.
""When we got the measurements, we were seeing very little movement in the target star. So when you start, you could be responsible for what we were seeing. Those two things together pretty much ruled it out. At that point we were sure that we had two planets,"" Mireles stated.

The researchers found these two planets and the inner planet TOI-4600 b is 82.69 days with a radius that is around just under seven times Earth's radius. It is between the size of Neptune and Saturn. This planet, TOI-4600 b,has an estimated temperature of about 170 degrees Fahrenheit, which is hot, but colder than a lot of the planets that astronomers have found. The second planet found, TOI-4600 c, is about nine and a half times Earth's radius, meaning it is roughly Saturn sized. It initially transited only once the first time TESS observed the star before transiting a second time almost three years later.
""Once you have two transits, you have an idea of what the periods can be. It could be the 965 days separating them, half of that, a third, a quarter, etc. The shorter periods could be ruled out because TESS had observed the star for a long time, so it only left two periods: 965 days or half of that,"" explained Mireles. The researchers used a model developed by collaborator Hugh Osborn at the University of Bern to compare the possible orbital periods and determine which one was most likely, and found that half of 965, or 482.82 days to be precise, was more likely. TOI-4600 c's 482.82 day period makes it the longest-period planet found by TESS to date and with a temperature of around -110 degrees Fahrenheit, it is one of the coldest planets found by TESS.
Katharine Hesse, TOI & Vetting Lead at MIT, collaborated with Mireles and team on the data analysis from TESS. Hesse helped process and analyze the large amount of data and placed the system into the context of other multiple-planet systems that have been found by missions including TESS. The comparison of the TOI-4600 system with other discovered exoplanet systems helps explore features like the formation time and processes and helped the researchers begin to place this system in the broader context of exoplanet systems.
""The main thing is trying to uncover more about planet formation because based on what we know about the exoplanets we found, so far, nothing really looks like the solar system. The interesting thing is that we want to learn about this planet formation. We have over 5,000 exoplanets now, but none of these systems really look like the solar system. And so we want to find out how these different types of systems formed and migrated,"" Mireles said.
Mireles and researchers are interested in these findings because of the discovery of two long period giant planets, which is a configuration that astronomers don't often see, even though the solar system found had four giant long distances or a long period one. This prompts further research discussions and questions as Mireles points out, ""We want to find out how these are formed? Are there other planets in this system? Does that tell us anything about how these giant planets affect smaller planets that might be in there or might not be in there and why they're not there? There's still things that we want to find out and that will tell us a lot about planet formation.""
In closing, Mireles promotes a call to action for citizen scientists, and hobbyists in astronomy, to participate and get involved in this research discovery. On Monday, Oct. 16, there will be another possible transit opportunity coming up for those who are interested and want to observe it to further confirm that the period of the outer planet is indeed 482 days. People with even smaller telescopes could participate if they have the right tools. ""There are definitely people that are citizen scientists or amateur astronomers that have their own telescopes and help us with all these observations. There is a group of people with access to telescopes that are essentially confirming that a transit event is occurring on the star of interest,"" said Mireles.
""People, who are either retired or have a different day job but who are also amateur astronomers, are contributing very useful data to help verify these planets. The results that they are producing are of professional quality. The efforts of these committed citizen scientists are critical to the process of confirming these planets"" Dragomir, assistant professor in UNM's Department of Physics and Astronomy stated.

","score: 12.68137254901961, grade_level: '13'","score: 13.96009728390586, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/2041-8213/aceb69,"We report the discovery and validation of two long-period giant exoplanets orbiting the early K dwarf TOI-4600 (V = 12.6, T = 11.9), first detected using observations from the Transiting Exoplanet Survey Satellite (TESS) by the TESS Single Transit Planet Candidate Working Group. The inner planet, TOI-4600 b, has a radius of 6.80 ± 0.31 R ⊕ and an orbital period of 82.69 days. The outer planet, TOI-4600 c, has a radius of 9.42 ± 0.42 R ⊕ and an orbital period of 482.82 days, making it the longest-period confirmed or validated planet discovered by TESS to date. We combine TESS photometry and ground-based spectroscopy, photometry, and high-resolution imaging to validate the two planets. With equilibrium temperatures of 347 K and 191 K, respectively, TOI-4600 b and c add to the small but growing population of temperate giant exoplanets that bridge the gap between hot/warm Jupiters and the solar system’s gas giants. TOI-4600 is a promising target for further transit and precise RV observations to measure the masses and orbits of the planets as well as search for additional nontransiting planets. Additionally, with Transit Spectroscopy Metric values of ∼30, both planets are amenable for atmospheric characterization with JWST. Together, these will lend insight into the formation and evolution of planet systems with multiple giant exoplanets."
"
With a remarkable observational campaign that involved 12 telescopes both on the ground and in space, including three European Southern Observatory (ESO) facilities, astronomers have uncovered the strange behaviour of a pulsar, a super-fast-spinning dead star. This mysterious object is known to switch between two brightness modes almost constantly, something that until now has been an enigma. But astronomers have now found that sudden ejections of matter from the pulsar over very short periods are responsible for the peculiar switches.

""We have witnessed extraordinary cosmic events where enormous amounts of matter, similar to cosmic cannonballs, are launched into space within a very brief time span of tens of seconds from a small, dense celestial object rotating at incredibly high speeds,"" says Maria Cristina Baglio, researcher at New York University Abu Dhabi, affiliated with the Italian National Institute for Astrophysics (INAF), and the lead author of the paper published today in Astronomy & Astrophysics.
A pulsar is a fast-rotating, magnetic, dead star that emits a beam of electromagnetic radiation into space. As it rotates, this beam sweeps across the cosmos -- much like a lighthouse beam scanning its surroundings -- and is detected by astronomers as it intersects the line of sight to Earth. This makes the star appear to pulse in brightness as seen from our planet.
PSR J1023+0038, or J1023 for short, is a special type of pulsar with a bizarre behaviour. Located about 4500 light-years away in the Sextans constellation, it closely orbits another star. Over the past decade, the pulsar has been actively pulling matter off this companion, which accumulates in a disc around the pulsar and slowly falls towards it.
Since this process of accumulating matter began, the sweeping beam virtually vanished and the pulsar started incessantly switching between two modes. In the 'high' mode, the pulsar gives off bright X-rays, ultraviolet and visible light, while in the 'low' mode it's dimmer at these frequencies and emits more radio waves. The pulsar can stay in each mode for several seconds or minutes, and then switch to the other mode in just a few seconds. This switching has thus far puzzled astronomers.
""Our unprecedented observing campaign to understand this pulsar's behaviour involved a dozen cutting-edge ground-based and space-borne telescopes,"" says Francesco Coti Zelati, a researcher at the Institute of Space Sciences, Barcelona, Spain, and co-lead author of the paper. The campaign included ESO's Very Large Telescope (VLT) and ESO's New Technology Telescope (NTT), which detected visible and near-infrared light, as well as the Atacama Large Millimeter/submillimeter Array (ALMA), in which ESO is a partner. Over two nights in June 2021, they observed the system make over 280 switches between its high and low modes.
""We have discovered that the mode switching stems from an intricate interplay between the pulsar wind, a flow of high-energy particles blowing away from the pulsar, and matter flowing towards the pulsar,"" says Coti Zelati, who is also affiliated with INAF.
In the low mode, matter flowing towards the pulsar is expelled in a narrow jet perpendicular to the disc. Gradually, this matter accumulates closer and closer to the pulsar and, as this happens, it is hit by the wind blowing from the pulsating star, causing the matter to heat up. The system is now in a high mode, glowing brightly in the X-ray, ultraviolet and visible light. Eventually, blobs of this hot matter are removed by the pulsar via the jet. With less hot matter in the disc, the system glows less brightly, switching back into the low mode.
While this discovery has unlocked the mystery of J1023's strange behaviour, astronomers still have much to learn from studying this unique system and ESO's telescopes will continue to help astronomers observe this peculiar pulsar. In particular, ESO's Extremely Large Telescope (ELT), currently under construction in Chile, will offer an unprecedented view of J1023's switching mechanisms. ""The ELT will allow us to gain key insights into how the abundance, distribution, dynamics, and energetics of the inflowing matter around the pulsar are affected by the mode switching behavior,"" concludes Sergio Campana, Research Director at the INAF Brera Observatory and coauthor of the study.

","score: 14.610678862684594, grade_level: '15'","score: 16.035670046286093, grade_levels: ['college_graduate'], ages: [24, 100]",10.1051/0004-6361/202346418,"Transitional millisecond pulsars are an emerging class of sources that link low-mass X-ray binaries to millisecond radio pulsars in binary systems. These pulsars alternate between a radio pulsar state and an active low-luminosity X-ray disc state. During the active state, these sources exhibit two distinct emission modes (high and low) that alternate unpredictably, abruptly, and incessantly. X-ray to optical pulsations are observed only during the high mode. The root cause of this puzzling behaviour remains elusive. This paper presents the results of the most extensive multi-wavelength campaign ever conducted on the transitional pulsar prototype, PSR J1023+0038, covering from the radio to X-rays. The campaign was carried out over two nights in June 2021 and involved 12 different telescopes and instruments, including XMM-Newton, HST, VLT/FORS2 (in polarimetric mode), ALMA, VLA, and FAST. By modelling the broadband spectral energy distributions in both emission modes, we show that the mode switches are caused by changes in the innermost region of the accretion disc. These changes trigger the emission of discrete mass ejections, which occur on top of a compact jet, as testified by the detection of at least one short-duration millimetre flare with ALMA at the high-to-low mode switch. The pulsar is subsequently re-enshrouded, completing our picture of the mode switches."
"
The field of quantum physics is rife with paths leading to tantalising new areas of study, but one rabbit hole offers a unique vantage point into a world where particles behave differently -- through the proverbial looking glass.

Dubbed the 'Alice ring' after Lewis Carroll's world-renowned stories on Alice's Adventures in Wonderland, the appearance of this object verifies a decades-old theory on how monopoles decay. Specifically, that they decay into a ring-like vortex, where any other monopoles passing through its centre are flipped into their opposite magnetic charges.
Published in Nature Communications on August 29, these findings mark the latest discovery in a string of work that has spanned the collaborative careers of Aalto University Professor Mikko Möttönen and Amherst College Professor David Hall.
'This was the first time our collaboration was able to create Alice rings in nature, which was a monumental achievement,' Möttönen said.
'This fundamental research opens new doors into understanding how these structures and their analogues in particle physics function in the universe,' Hall added.
The long-standing relationship, titled the Monopole Collaboration, initially proved the existence of a quantum analogue of the magnetic monopole in 2014, isolated quantum monopoles in 2015, and eventually observed one decay into the other in 2017.
Monopoles remain an elusive concept in the arena of quantum physics. As the name suggests, monopoles are the solitary counterpart of dipoles, which carry a positive charge at their north pole and a negative charge at the south. In contrast, a monopole carries only either a positive or negative charge.

While the concept sounds simple, realising a true monopole has proven to be a career-defining task. Here's how the Monopole Collaboration has done it: they manipulated a gas of rubidium atoms prepared in a nonmagnetic state near absolute zero temperature. Under these extreme conditions, they were then able to create a monopole by steering a zero point of a three-dimensional magnetic field into the quantum gas.
Laying theoretical groundwork
These quantum monopoles are ephemeral by nature, decaying a few milliseconds after their creation. It is within this instability that the Alice ring takes shape.
'Think of the monopole as an egg teetering at the top of a hill,' Möttönen said. 'The slightest perturbations can send it crashing down. In the same way, monopoles are subject to noise that triggers their decay into Alice rings.'
While monopoles are short-lived, the research group simulated stable Alice rings for as long as 84 milliseconds -- over 20 times longer than the monopole lifespan. This leads researchers to be optimistic that future experiments will reveal even more peculiar properties of Alice rings.
'From a distance, the Alice ring just looks like a monopole, but the world takes a different shape when peering through the centre of the ring,' Hall said.

'It is from this perspective that everything seems to be mirrored, as if the ring were a gateway into a world of antimatter instead of matter,' Möttönen added.
In theory, a monopole passing through the centre of an Alice ring would be transformed into an anti-monopole of opposite charge. Correspondingly, the Alice ring's charge would change as well. While this phenomenon has not yet been experimentally observed, Möttönen said the topological structure of Alice rings necessitates this behaviour.
The experimental work was conducted at Amherst College primarily by PhD candidate Alina Blinova and Hall, while Möttönen and his team were responsible for running matching simulations. This way, the two teams were able to confirm the interpretation of the experimental observations.
'It is simply amazing to have such a major discovery as the finale of my PhD work,' Blinova said.
The simulations conducted at Aalto University were made possible by support from the CSC -- IT Center for Science and the Research Council of Finland through its Centre of Excellence in Quantum Technology, and the experiments in the US by the financial support of the National Science Foundation.

","score: 13.900483827853517, grade_level: '14'","score: 14.452875701684043, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-40710-2,"Monopoles and vortices are fundamental topological excitations that appear in physical systems spanning enormous scales of size and energy, from the vastness of the early universe to tiny laboratory droplets of nematic liquid crystals and ultracold gases. Although the topologies of vortices and monopoles are distinct from one another, under certain circumstances a monopole can spontaneously and continuously deform into a vortex ring with the curious property that monopoles passing through it are converted into anti-monopoles. However, the observation of such Alice rings has remained a major challenge, due to the scarcity of experimentally accessible monopoles in continuous fields. Here, we present experimental evidence of an Alice ring resulting from the decay of a topological monopole defect in a dilute gaseous 87Rb Bose–Einstein condensate. Our results, in agreement with detailed first-principles simulations, provide an unprecedented opportunity to explore the unique features of a composite excitation that combines the topological features of both a monopole and a vortex ring."
"
A new study led by researchers at Karolinska Institutet in Sweden has examined how T cells of the immune system are affected by weightlessness. The results, which are published in the journal Science Advances, could explain why astronauts' T cells become less active and less effective at fighting infection.

The next steps in the exploration of space are human missions to the moon and to Mars. Space is an extremely hostile environment that poses threats to human health. One such threat is changes to the immune system that occur in astronauts while in space and that persist after their return to Earth. This immune deficiency can leave them more vulnerable to infection and lead to the reactivation of latent viruses in the body.
""If astronauts are to be able to undergo safe space missions, we need to understand how their immune systems are affected and try to find ways to counter harmful changes to it,"" says study leader Lisa Westerberg, principal researcher at the Department of Microbiology, Tumor and Cell Biology, Karolinska Institutet. ""We've now been able to investigate what happens to T cells, which are a key component of the immune system, when exposed to weightless conditions.""
In the study, the researchers have tried to simulate weightlessness in space using a method called dry immersion. This involves a custom-made waterbed that tricks the body into thinking it is in a weightless state. The researchers examined T cells in the blood of eight healthy individuals for three weeks of exposure to simulated weightlessness. Blood analyses were performed before the experiment started, at 7, 14 and 21 days after the start, and at 7 days after the experiment ended.
They found that the T cells significantly changed their gene expression -- that is to say, which genes were active and which were not -- after 7 and 14 days of weightlessness and that the cells became more immature in their genetic programme. The greatest effect was seen after 14 days.
""The T cells began to resemble more so-called naïve T cells, which have not yet encountered any intruders. This could mean that they take longer to be activated and thus become less effective at fighting tumour cells and infections. Our results can pave the way for new treatments that reverse these changes to the immune cells' genetic programme,"" says Carlos Gallardo Dodd, PhD student at the Department of Microbiology, Tumor and Cell Biology, Karolinska Institutet and shared first author with researchers Christian Oertlin and Julien Record at the same department.
After 21 days, the T cells had ""adapted"" their gene expression to weightlessness so that it had almost returned to normal, but analyses carried out seven days after the experiment ended showed that the cells had regained some of the changes.
The researchers now plan to use Esrange Space Centre's sounding rocket platform in Kiruna, Sweden, to study how T cells behave in weightless conditions and how their function is affected.
The study was financed by the Swedish National Space Agency, the Swedish Research Council and Karolinska Institutet and was conducted in close collaboration with Claudia Kutter's research group at Karolinska Institutet/SciLifeLab and collaboration partners at IBMP Moscow and New York University Abu Dhabi. There are no reported conflicts of interest.

","score: 13.550508400800908, grade_level: '14'","score: 15.143809523809523, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adg1610,"The next steps of deep space exploration are manned missions to Moon and Mars. For safe space missions for crew members, it is important to understand the impact of space flight on the immune system. We studied the effects of 21 days dry immersion (DI) exposure on the transcriptomes of T cells isolated from blood samples of eight healthy volunteers. Samples were collected 7 days before DI, at day 7, 14, and 21 during DI, and 7 days after DI. RNA sequencing of CD3 + T cells revealed transcriptional alterations across all time points, with most changes occurring 14 days after DI exposure. At day 21, T cells showed evidence of adaptation with a transcriptional profile resembling that of 7 days before DI. At 7 days after DI, T cells again changed their transcriptional profile. These data suggest that T cells adapt by rewiring their transcriptomes in response to simulated weightlessness and that remodeling cues persist when reexposed to normal gravity."
"
Researchers from Queen Mary University of London have made a discovery that could change our understanding of the universe. In their study published in Science Advances, they reveal, for the first time, that there is a range in which fundamental constants can vary, allowing for the viscosity needed for life processes to occur within and between living cells. This is an important piece of the puzzle in determining where these constants come from and how they impact life as we know it.

In 2020, the same team found that the viscosity of liquids is determined by fundamental physical constants, setting a limit on how runny a liquid can be. Now this result is taken into the realm of life sciences.
Fundamental physical constants shape the fabric of the universe we live in. Physical constants are quantities with a value that is generally believed to be both universal in nature and to remain unchanged over time -- for example the mass of the electron. They govern nuclear reactions and can lead to the formation of molecular structures essential to life, but their origin is unknown. This research might bring scientists one step closer to determining where these constants come from.
""Understanding how water flows in a cup turns out to be closely related to the grand challenge to figure out fundamental constants. Life processes in and between living cells require motion and it is viscosity that sets the properties of this motion. If fundamental constants change, viscosity would change too impacting life as we know it. For example, if water was as viscous as tar life would not exist in its current form or not exist at all. This applies beyond water, so all life forms using the liquid state to function would be affected.""
""Any change in fundamental constants including an increase or decrease would be equally bad news for flow and for liquid-based life. We expect the window to be quite narrow: for example, viscosity of our blood would become too thick or too thin for body functioning with only a few per cent change of some fundamental constants such as the Planck constant or electron charge."" Professor of Physics Kostya Trachenko said.
Surprisingly, the fundamental constants were thought to be tuned billions of years ago to produce heavy nuclei in stars and back then life as we know it today didn't exist. There was no need for these constants to be fine-tuned at that point to also enable cellular life billions of years later, and yet these constants turn out to be bio-friendly to flow in and between living cells.
An accompanying conjecture is that multiple tunings may have been involved and this then suggests a similarity to biological evolution where traits were acquired independently. Through evolutionary mechanisms, fundamental constants may be the result of nature arriving at sustainable physical structures. It remains to be seen how the principles of evolution can be helpful to understand the origin of fundamental constants.

","score: 11.890579178885634, grade_level: '12'","score: 12.974904692082113, grade_levels: ['college'], ages: [18, 24]",10.1126/sciadv.adh9024,"The problem of understanding fundamental physical constants and their values was discussed in particle physics, astronomy, and cosmology. Here, I show that an additional unexpected insight comes from condensed matter physics and liquid physics in particular: Fundamental constants have a biofriendly window constrained by biofriendly viscosity and diffusion setting the motion in essential life processes in and across cells. I also show that bounds on viscosity, diffusion, and the fundamental velocity gradient in a biochemical machine can all be varied while keeping the fine-structure constant and the proton-to-electron mass ratio intact, with no implication for the production of heavy nuclei in stars. This leads to a conjecture of multiple tuning and an evolutionary mechanism."
"
New research has improved the accuracy of the parameters governing the expansion of the Universe. More accurate parameters will help astronomers determine how the Universe grew to its current state, and how it will evolve in the future.

It is well established that the Universe is expanding. But with no landmarks in space, it is difficult to accurately measure how fast it is expanding. So, astronomers search for reliable landmarks. The same way a candle looks fainter as it gets farther away, even though the candle itself hasn't changed, distant objects in the Universe look fainter. If we know the intrinsic (initial) brightness of an object, we can calculate its distance based on its observed brightness. Objects of known brightness in the Universe that allow us to calculate the distance are called ""standard candles.""
An international team led by Maria Giovanna Dainotti, Assistant Professor at the National Astronomical Observatory of Japan (NAOJ), and Giada Bargiacchi, PhD student at the Scuola Superiore Meridionale in Naples, with the aid of the supercomputing facilities at NAOJ run by Kazunari Iwasaki, Assistant Professor at NAOJ and member of the Center for Computational Astrophysics, ushered in a new research field by leveraging the use of a variety of new statistical methods to analyze data for various standard candles such as Supernovae, Quasars (powerful black holes consuming matter in the distant Universe), and Gamma Ray Bursts (sudden flashes of powerful radiation). Different standard candles are useful in different distant ranges, so combining multiple standard candles allowed the team to map larger areas of the Universe.
The new results reduce the uncertainty of key parameters by up to 35 percent. More accurate parameters will help determine whether the Universe will continue expanding forever, or eventually fall back in on itself.

","score: 15.151666666666667, grade_level: '15'","score: 15.497361581920906, grade_levels: ['college_graduate'], ages: [24, 100]",10.3847/1538-4357/accea0,"Currently, the Λ cold dark matter model, which relies on the existence of cold dark matter and a cosmological constant Λ, best describes the universe. However, we lack information in the high-redshift (z) region between Type Ia supernovae (SNe Ia; up to z = 2.26) and the cosmic microwave background (z = 1100), an interval crucial to test cosmological models and their possible evolution. We have defined a sample of 983 quasars up to z = 7.54 with a reduced intrinsic dispersion δ = 0.007, which determines the matter density parameter Ω M with the same precision of SNe Ia. Although previous analysis have used quasars as cosmological tools, this is the first time that high-redshift sources, in this case quasars, as standalone cosmological probes yield such tight constraints on Ω M . Our results show the importance of correcting cosmological relationships for selection biases and redshift evolution and how the choice of a golden sample reduces considerably the intrinsic scatter. This proves the reliability of quasars as standard cosmological candles."
"
Magnetars are the strongest magnets in the Universe. These super-dense dead stars with ultra-strong magnetic fields can be found all over our galaxy but astronomers don't know exactly how they form. Now, using multiple telescopes around the world, including European Southern Observatory (ESO) facilities, researchers have uncovered a living star that is likely to become a magnetar. This finding marks the discovery of a new type of astronomical object -- massive magnetic helium stars -- and sheds light on the origin of magnetars.

Despite having been observed for over 100 years, the enigmatic nature of the star HD 45166 could not be easily explained by conventional models, and little was known about it beyond the fact that it is one of a pair of stars [1], is rich in helium and is a few times more massive than our Sun.
""This star became a bit of an obsession of mine,"" says Tomer Shenar, the lead author of a study on this object published today in Science and an astronomer at the University of Amsterdam, the Netherlands. ""Tomer and I refer to HD 45166 as the 'zombie star',"" says co-author and ESO astronomer Julia Bodensteiner, based in Germany. ""This is not only because this star is so unique, but also because I jokingly said that it turns Tomer into a zombie.""
Having studied similar helium-rich stars before, Shenar thought magnetic fields could crack the case. Indeed, magnetic fields are known to influence the behaviour of stars and could explain why traditional models failed to describe HD 45166, which is located about 3000 light-years away in the constellation Monoceros. ""I remember having a Eureka moment while reading the literature: 'What if the star is magnetic?',"" says Shenar, who is currently based at the Centre for Astrobiology in Madrid, Spain.
Shenar and his team set out to study the star using multiple facilities around the globe. The main observations were conducted in February 2022 using an instrument on the Canada-France-Hawaii Telescope that can detect and measure magnetic fields. The team also relied on key archive data taken with the Fiber-fed Extended Range Optical Spectrograph (FEROS) at ESO's La Silla Observatory in Chile.
Once the observations were in, Shenar asked co-author Gregg Wade, an expert on magnetic fields in stars at the Royal Military College of Canada, to examine the data. Wade's response confirmed Shenar's hunch: ""Well my friend, whatever this thing is -- it is definitely magnetic.""
Shenar's team had found that the star has an incredibly strong magnetic field, of 43,000 gauss, making HD 45166 the most magnetic massive star found to date [2]. ""The entire surface of the helium star has a magnetic field almost 100,000 times stronger than Earth's,"" explains co-author Pablo Marchant, an astronomer at KU Leuven's Institute of Astronomy in BelgiumThis observation marks the discovery of the very first massive magnetic helium star. ""It is exciting to uncover a new type of astronomical object,"" says Shenar, ""especially when it's been hiding in plain sight all along.""
Moreover, it provides clues to the origin of magnetars, compact dead stars laced with magnetic fields at least a billion times stronger than the one in HD 45166. The team's calculations suggest that this star will end its life as a magnetar. As it collapses under its own gravity, its magnetic field will strengthen, and the star will eventually become a very compact core with a magnetic field of around 100 trillion gauss [3] -- the most powerful type of magnet in the Universe.

Shenar and his team also found that HD 45166 has a mass smaller than previously reported, around twice the mass of the Sun, and that its stellar pair orbits at a far larger distance than believed before. Furthermore, their research indicates that HD 45166 formed through the merger of two smaller helium-rich stars. ""Our findings completely reshape our understanding of HD 45166,"" concludes Bodensteiner.
Notes
[1] While HD 45166 is a binary system, in this text HD 45166 refers to the helium-rich star, not to both stars.
[2] The magnetic field of 43,000 gauss is the strongest magnetic field ever detected in a star that exceeds the Chandrasekhar mass limit, which is the critical limit above which stars may collapse into neutron stars (magnetars are a type of neutron star).
[3] In this text, a billion refers to one followed by nine zeros and a trillion refers to one followed by 12 zeros.

","score: 13.054932573083537, grade_level: '13'","score: 13.935175128970947, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.ade3293,"Magnetars are highly magnetized neutron stars, the formation mechanism of which is unknown. Hot helium-rich stars with spectra dominated by emission lines are known as Wolf-Rayet stars. We observed the binary system HD 45166 using spectropolarimetry and reanalyzed its orbit using archival data. We found that the system contains a Wolf-Rayet star with a mass of 2 solar masses and a magnetic field of 43 kilogauss. Stellar evolution calculations indicate that this component will explode as a supernova, and that its magnetic field is strong enough for the supernova to leave a magnetar remnant. We propose that the magnetized Wolf-Rayet star formed by the merger of two lower-mass helium stars."
"
The largest storm in the solar system, a 10,000-mile-wide anticyclone called the Great Red Spot, has decorated Jupiter's surface for hundreds of years.

A new study now shows that Saturn -- though much blander and less colorful than Jupiter -- also has long-lasting megastorms with impacts deep in the atmosphere that persist for centuries.
The study was conducted by astronomers from the University of California, Berkeley, and the University of Michigan, Ann Arbor, who looked at radio emissions from the planet, which come from below the surface, and found long-term disruptions in the distribution of ammonia gas.
The study was published today (Aug. 11) in the journal Science Advances.
Megastorms occur approximately every 20 to 30 years on Saturn and are similar to hurricanes on Earth, although significantly larger. But unlike Earth's hurricanes, no one knows what causes megastorms in Saturn's atmosphere, which is composed mainly of hydrogen and helium with traces of methane, water and ammonia.
""Understanding the mechanisms of the largest storms in the solar system puts the theory of hurricanes into a broader cosmic context, challenging our current knowledge and pushing the boundaries of terrestrial meteorology,"" said lead author Cheng Li, a former 51 Peg b Fellow at UC Berkeley who is now an assistant professor at the University of Michigan.
Imke de Pater, a UC Berkeley professor emerita of astronomy and of earth and planetary sciences, has been studying gas giants for over four decades to better understand their composition and what makes them unique, employing the Karl G. Jansky Very Large Array in New Mexico to probe the radio emissions from deep inside the planet.

""At radio wavelengths, we probe below the visible cloud layers on giant planets. Since chemical reactions and dynamics will alter the composition of a planet's atmosphere, observations below these cloud layers are required to constrain the planet's true atmospheric composition, a key parameter for planet formation models,"" she said. ""Radio observations help characterize dynamical, physical and chemical processes including heat transport, cloud formation and convection in the atmospheres of giant planets on both global and local scales.""
As reported in the new study, de Pater, Li and UC Berkeley graduate student Chris Moeckel found something surprising in the radio emissions from the planet: anomalies in the concentration of ammonia gas in the atmosphere, which they connected to the past occurrences of megastorms in the planet's northern hemisphere.
According to the team, the concentration of ammonia is lower at midaltitudes, just below the uppermost ammonia-ice cloud layer, but has become enriched at lower altitudes, 100 to 200 kilometers deeper in the atmosphere. They believe that the ammonia is being transported from the upper to the lower atmosphere via the processes of precipitation and reevaporation. What's more, that effect can last for hundreds of years.
The study further revealed that although both Saturn and Jupiter are made of hydrogen gas, the two gas giants are remarkably dissimilar. While Jupiter does have tropospheric anomalies, they have been tied to its zones (whitish bands) and belts (darkish bands) and are not caused by storms like they are on Saturn. The considerable difference between these neighboring gas giants is challenging what scientists know about the formation of megastorms on gas giants and other planets and may inform how they're found and studied on exoplanets in the future.
The National Radio Astronomy Observatory (NRAO) is a facility of the National Science Foundation, operated under cooperative agreement by Associated Universities Inc.

","score: 16.73680483592401, grade_level: '17'","score: 18.650261794382324, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adg9419,"Planetary-scale giant storms erupt on Saturn quasiperiodically. There have been at least six recorded occurrences of past eruptions, and the most recent one was in 2010, with its whole life span captured by the Cassini mission. In 2015, we used the Very Large Array to probe the deep response of Saturn’s troposphere to the giant storms. In addition to the remnant effect of the storm in 2010, we have found long-lasting signatures of all mid-latitude giant storms, a mixture of equatorial storms up to hundreds of years old, and potentially an unreported older storm at 70°N. We derive an ammonia anomaly map that shows an extended meridional migration of the storm’s aftermath and vertical transport of ammonia vapor by storm dynamics. Intriguingly, the last storm in 2010 splits into two distinct components that propagate in opposite meridional directions, leaving a gap at 43°N planetographic latitude."
"
With methods of so-called geoengineering, the climate could theoretically be artificially influenced and cooled. Bernese researchers have now investigated whether it would be possible to prevent the melting of the West Antarctic ice sheet by artificially ""dimming the sun."" The results show that artificial influence does not work without decarbonization and entails high risks.

Is there an emergency solution that could stop climate change? Technical methods that artificially influence the climate have been discussed for some time under the term geoengineering. However, the majority of climate researchers have been critical of them: high risks, incalculable consequences for future generations.
In a study just published in the journal Nature Climate Change, researchers led by Johannes Sutter of the Climate and Environmental Physics Division (KUP) at the Institute of Physics and the Oeschger Center for Climate Research at the University of Bern investigate the question of whether the melting of ice in West Antarctica could be prevented by artificially influencing solar radiation. The researchers also warn of unforeseeable side effects of geoengineering.
Avoiding a key climate tipping point 
""The window of opportunity to limit the global temperature increase to below 2 degrees is closing fast,"" says ice modeling specialist Johannes Sutter, ""so it is possible that technical measures to influence the climate will be seriously considered in the future."" That is why, he says, it is necessary to use theoretical models to study the effects and risks of ""solar radiation management."" Solar Radiation Management (SRM) is a term used to describe various methods of blocking solar radiation in order to make the Earth cooler.
A key reason for the increased interest in geoengineering is the avoidance of tipping points at which the climate could change abruptly and irreversibly. These include the melting of the West Antarctic and Greenland ice sheets and the associated meter-high sea level rise. ""Observations of ice flows in West Antarctica indicate that we are very close to a so-called tipping point or have already passed it,"" explains Johannes Sutter, ""with our study, we therefore wanted to find out whether a collapse of the ice sheet could theoretically be prevented with solar radiation management.""
Artificially dimming the sun
Specifically, Sutter and his colleagues have investigated what would happen if so-called aerosols -- suspended particles in a gas -- introduced into the stratosphere succeeded in blocking solar radiation from the earth -- a dimming of the sun, so to speak. So far, research has focused on the global effects of solar radiation management (SRM). The Bern study is the first to use ice model simulations to show what effect such a measure would have on the Antarctic ice sheet. The study examines the possible development of the ice sheet under different future greenhouse gas scenarios and yields differentiated results: If emissions continue unabated and the SRM occurs in the middle of this century, the collapse of the West Antarctic Ice Sheet could be delayed somewhat, but not prevented. In a medium emissions scenario, SRM deployed by mid-century could prove to be an ""effective tool"" to slow or even prevent ice sheet collapse.

According to the model calculations, SRM works best when it occurs as early as possible and is combined with ambitious climate mitigation measures. But, the study authors emphasize, ""our simulations show that the most effective way to prevent long-term collapse of the West Antarctic Ice Sheet is rapid decarbonization."" The chances of a longer-term stable ice sheet are greatest if greenhouse gas emissions were reduced to net zero ""without delay.""
Possible side effects still hardly studied
But how should one imagine a dimming of the sun in practical terms? According to Johannes Sutter, a whole fleet of extremely high-flying airplanes would have to spread millions of tons of aerosols in the stratosphere. However, this technical intervention in the climate would have to be maintained without interruption and for centuries. If the intervention were stopped as long as the greenhouse concentration in the atmosphere remained high, the temperature on earth would quickly rise by several degrees.
The consequences of such a termination shock, Johannes Sutter points out, are only one of the possible dangers posed by SRM. The potential side effects are still insufficiently researched and range from a shift in the monsoon regime to changes in ocean and atmospheric circulation. Ocean acidification would also continue. Critical voices also caution political and social effects: The use of techniques such as solar dimming could lead to climate protection measures being slowed down or even prevented. Thomas Stocker, professor of climate and environmental physics at the University of Bern and co-author of the study, says: ""Geoengineering would be another global experiment and a potentially dangerous human intervention in the climate system, which should in any case be prevented according to Article 2 of the UN Framework Convention on Climate Change.""

","score: 15.238563766858586, grade_level: '15'","score: 16.37301048978626, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41558-023-01738-w,"Solar radiation modification (SRM) is increasingly discussed as a tool to reduce or avert global warming and concomitantly the risk of ice-sheet collapse, as is considered possible for the West Antarctic Ice Sheet (WAIS). Here we analyse the impact of stratospheric aerosol injections on the centennial-to-millennial Antarctic sea-level contribution using an ice-sheet model. We find that mid-twenty-first-century large-scale SRM could delay but ultimately not prevent WAIS collapse in a high-emissions scenario. On intermediate-emissions pathways, SRM could be an effective tool to delay or even prevent an instability of WAIS if deployed by mid-century. However, SRM interventions may be associated with substantial risks, commitments and unintended side effects; therefore, emissions reductions to prevent WAIS collapse seem to be the more practical and sensible approach at the current stage."
"
A classic movie was once promoted with the punchline: ""In space, no one can hear you scream."" Physicists Zhuoran Geng and Ilari Maasilta from the Nanoscience Center at the University of Jyväskylä, Finland, have demonstrated, on the contrary, that in certain situations sound can be transmitted strongly across a vacuum region!

In a recent publication they show that in some cases a sound wave can jump or ""tunnel"" fully across a vacuum gap between two solids if the materials in question are piezoelectric. In such materials, vibrations (sound waves) produce an electrical response, as well, and since an electric field can exist in vacuum, it can transmit the sound waves across. The requirement is that the size of the gap is smaller than the wavelength of the sound wave. This effect works not only in audio range of frequencies (Hz-kHz), but also in ultrasound (MHz) and hypersound (GHz) frequencies, as long as the vacuum gap is made smaller as the frequencies increase.
- In most cases the effect is small, but we also found situations, where the full energy of the wave jumps across the vacuum with 100 % efficiency, without any reflections. As such, the phenomenon could find applications in microelectromechanical components (MEMS, smartphone technology) and in the control of heat, says professor Ilari Maasilta from the Nanoscience Center at the University of Jyväskylä.
The study was funded by the Academy of Finland and European Union's Horizon 2020 program, and was published in the journal Communications Physics, on 15th July 2023.

","score: 14.088775153105864, grade_level: '14'","score: 15.952961504811903, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s42005-023-01293-y,"The mechanical displacements in piezoelectric materials carry along macroscopic electric fields, allowing tunneling of acoustic waves across a vacuum gap beyond the charge-charge interaction distance. However, no rigorous proof of complete acoustic wave tunneling has been presented, and the conditions to achieve complete tunneling have not been identified. Here, we demonstrate analytically the condition for such phenomenon for arbitrary anisotropic crystal symmetries and orientations, and that complete transmission of the incoming wave occurs at the excitation frequency of leaky surface waves. We also show that the complete transmission condition can be related to the surface electric impedance and the effective surface permittivity of the piezoelectric material, relevant to realize the complete tunneling experimentally. We support our findings with numerical results for the maximum power transmittance of a slow transverse wave tunneling between identical ZnO crystals. The results show that complete tunneling can be achieved for a large range of orientations."
