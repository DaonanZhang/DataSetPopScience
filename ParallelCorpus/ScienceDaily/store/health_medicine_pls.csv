pls,fk_score,ari_score,reference,abstract
"
If you are one of the 30% to 50% of women experiencing urinary incontinence, new research suggests that it could turn into a bigger health issue.

Having more frequent urinary incontinence and leakage amounts is associated with higher odds of disability, according to RUSH researchers in a study published in the January issue of Menopause.
""Often symptoms from urinary incontinence are ignored until they become bothersome or limit physical or social activities,"" said Sheila Dugan, MD, chair of the Department of Physical Medicine and Rehabilitation at RUSH. ""Because this study suggests that urinary incontinence is associated with disability, exploring treatment options in the early stages may help decrease this outcome in midlife women.""
Urinary incontinence affects many women at some point during their lifetime, she said. Some women will leak urine when they sneeze or cough, which is called stress incontinence.
""When you sneeze or cough, there is a mechanical pressure from your belly that overwhelms the sphincter and you leak,"" she said.
Others suffer from urge incontinence, which is an overwhelming urge to urinate, such as when they get close to a restroom. Women who experience both have what's called mixed urinary incontinence, Dugan said.
Researchers considered the amount and frequency of the incontinence and whether the study participant had stress incontinence, urge incontinence, or both.

Researchers then measured disability by the World Health Organization disability assessment scale as the outcome of interest.
""We found that mixed incontinence was the most highly correlated with disability, along with daily incontinence and larger amounts of incontinence,"" Dugan said.
Dugan helped create the Program for Abdominal and Pelvic Health at RUSH, which treats several types of conditions, including urinary incontinence. Each patient is examined to determine the causes and treatment options. For example, muscles are evaluated to uncover whether tight bands in the muscles are causing incontinence or whether weak muscles are to blame.
""In a case of tight muscles, a woman may try to tighten the muscles further with more exercise, not knowing that it may make the incontinence worse,"" Dugan said. ""Pelvic floor muscles support pelvic organs and organ problems can lead to muscle problems or vice versa. One patient may have incontinence due to hip arthritis, another from a difficult delivery, or it can be caused by cancer treatment, for example, radiation in the pelvic area.""
There are a number of potential causes, or even a combination of causes, of incontinence. The data used was from a larger clinical trial called SWAN (the Study of Women Across the Nation) that included more than 1,800 participants. SWAN was initiated in 1994 with seven sites across the U.S. to identify changes that occur during the menopause transition in midlife women and their effects on subsequent health and risk for age-related diseases.
""More studies are needed to show what causes this association, with a focus on prevention,"" Dugan said.

","score: 13.414279379157431, grade_level: '13'","score: 13.895354767184038, grade_levels: ['college_graduate'], ages: [24, 100]",10.1097/GME.0000000000002282,"The aim of the study is to examine whether urinary incontinence (UI) type, frequency, and amount are associated with self-reported disability in a racially/ethnically diverse cohort of community-dwelling midlife women. Data were from longitudinal analyses of questionnaires from the multicenter, prospective cohort Study of Women's Health Across the Nation (SWAN). We used multivariable ordinal logistic regression to examine whether urinary incontinence type, frequency, and amount at the 13th follow-up were associated with the World Health Organization Disability Assessment Schedule at the 15th follow-up controlling for other factors (menopause status, body mass index, lifestyle and psychosocial factors, and disability at follow-up 13). Urinary incontinence was associated with subsequent reports of disability in participants, particularly in the World Health Organization Disability Assessment Schedule domains of mobility (P < 0.0001), communication (P = 0.0057), and life activities (P = 0.0407). Associations were strongest for mixed UI type compared with stress UI or urgency UI (odds ratio [OR] = 1.66, 95% confidence interval [CI] = 1.26-2.17, P < 0.001), daily frequency of UI compared with monthly or less than weekly frequency of UI (OR = 1.61, 95% CI = 1.04-2.47, P < 0.001), and larger amounts of urine leakage compared with drops of leakage (OR = 2.98, 95% CI = 1.58-5.62, P < 0.0001) for mobility/getting around domain. Urinary incontinence seems to have a strong association with multiple domains of disability, including mobility and interacting with others, after approximately 3.7 years. Thus, UI may be an important factor limiting social engagement among women. Screening for mixed UI and UI that occurs greater than weekly and in amounts requiring pads may yield better information regarding an individual's future disability risk and may preserve social interaction."
"
Individuals with obesity are more likely to have monoclonal gammopathy of undetermined significance (MGUS), a benign blood condition that often precedes multiple myeloma, according to new research published in Blood Advances.

Multiple myeloma is a blood cancer of the plasma cells, a type of white blood cells that produce antibodies to fight infection. MGUS, characterized by an abnormal protein produced by plasma cells, is a known precursor to multiple myeloma. Most people with MGUS exhibit no significant symptoms and are not immediately ill. Rather, the presence of MGUS serves as a warning to monitor for the potential development of more critical conditions, like multiple myeloma, that MGUS can turn into.
The Centers for Disease Control and Prevention reported in 2020 that nearly 42% of the US population is classified as obese, defined by a body mass index (BMI) of 30 or higher. Yet, little research exists to suggest how obesity may impact cancer outcomes.
""While significant advancements have been made in therapeutics for multiple myeloma, it remains an incurable disease, often diagnosed after patients have already experienced end-organ damage,"" explained David Lee, MD, MPH, MMSc, an internal medicine resident at Massachusetts General Hospital. ""It's preceded by premalignant conditions including MGUS. Our research group is focused on investigating risk factors and etiology of MGUS to better understand who may be at increased risk for developing MGUS and its progression to multiple myeloma.""
Investigators enrolled 2,628 individuals from across the United States who were at elevated risk of developing multiple myeloma, based on self-identified race and family history of hematologic malignancies, between February 2019 and March 2022. Participants were screened for MGUS, defined by the presence of monoclonal proteins at serum concentrations of 0.2g/L or greater. Investigators measured MGUS using mass spectrometry -- a novel, highly sensitive method of identifying and quantifying monoclonal proteins in the blood.
After controlling for age, sex, race, education, and income, the team found that being obese was associated with 73% higher odds of having MGUS, compared to individuals with normal weights. This association remained unchanged when accounting for physical activity. However, highly active individuals (defined as doing the equivalent of running or jogging 45-60 minutes per day or more) were less likely to have MGUS even after adjusting for BMI class, whereas those who reported heavy smoking and short sleep were more likely to also have detectable levels of MGUS.
Limitations include that this was a cross sectional study -- a snapshot of how certain variables or characteristics may relate to one another at a single point in time. While investigators found a strong correlation between MGUS, obesity, and lifestyle factors, they do not have enough evidence to assume causation.
Additionally, the American Medical Association recently voted to adopt a new policy that no longer uses BMI alone to assess whether someone is of a healthy weight, as previous research suggests the metric does not effectively distinguish between fat and lean mass and does not account for how fat is distributed throughout the body. The formula was created based on data from non-Hispanic white populations, suggesting its implications cannot accurately be generalized across Black, Asian, and Hispanic groups.
Going forward, researchers will aim to validate these findings in other study cohorts, including individuals who are followed longitudinally, to further explore the mechanisms through which obesity and other modifiable risk factors might influence the development and progression of MGUS.
""These results guide our future research in understanding the influence of modifiable risk factors, such as weight, exercise, and smoking, on cancer risk,"" explained Dr. Lee. ""Before we can develop effective preventative health strategies to lower the risk of serious diseases like multiple myeloma, we first need to better understand the relationship between MGUS and potentially modifiable risk factors like obesity.""

","score: 17.37565192335399, grade_level: '17'","score: 18.58824665033857, grade_levels: ['college_graduate'], ages: [24, 100]",10.1182/bloodadvances.2023010843,"Monoclonal gammopathy of undetermined significance (MGUS) is a premalignant condition of multiple myeloma with few known risk factors. The emergence of mass spectrometry (MS) for the detection of MGUS has provided new opportunities to evaluate its risk factors. 2628 individuals at elevated risk for multiple myeloma were enrolled in a screening study and completed an exposure survey (PROMISE; ClinicalTrials.gov, #NCT03689595). Participant samples were screened by MS, and monoclonal proteins (M-proteins) with concentrations &gt;0.2 g/L were categorized as MS-MGUS. Multivariable logistic models evaluated associations between exposures and MS outcomes. Compared to normal weight (BMI: 18.5 to &lt;25 kg/m2), obesity (BMI: &gt;30 kg/m2) was associated with MS-MGUS, adjusting for age, sex, Black race, education, and income (odds ratio [OR] = 1.73, 95% confidence interval [CI] = 1.21 to 2.47, P = .003). High physical activity (&gt;73.5 MET-hours/week vs. &lt;10.5 MET-hours/week) had a decreased likelihood of MS-MGUS (OR = 0.45, 95% CI = 0.24 to 0.80, P = .009), whereas heavy smoking and short sleep had increased likelihood of MS-MGUS (&gt;30 pack-years vs. never smoker: OR = 2.19, 95% CI = 1.24 to 3.74, P = .005 and sleep &lt;6 vs. &gt;6 hours/day: OR = 2.11, 95% CI = 1.26 to 3.42, P = .003). In the analysis of all MS-detected monoclonal gammopathies, which are inclusive of M-proteins with concentrations &lt;0.2 g/L, elevated BMI and smoking were associated with all MS-positive cases. Findings suggest MS-detected monoclonal gammopathies are associated with a broader range of modifiable risk factors than what has been previously identified."
"
Wastewater surveillance is a potent tool in understanding COVID-19 transmission within school settings, according to a ground-breaking study led by epidemiologist David Larsen from Syracuse University.

The research team's work that was published recently in PLOS Global Public Health establishes the pivotal role of wastewater analysis in managing the public health response to COVID-19 at schools.
The study focused on a middle and high school campus in Jefferson County, New York, serving 600 students and compared results from wastewater surveillance to COVID-19 case trends. The surveillance demonstrated high levels of sensitivity, positive predictive value (PPV), and negative predictive value (NPV) in wastewater surveillance. While the specificity of wastewater surveillance at the school was observed to be lower, the strong correlation between the amount of SARS-CoV-2 RNA recovered in wastewater and COVID-19 cases highlighted its potential in understanding transmission risk within the school.
""By analyzing wastewater samples, we observed a robust correlation between SARS-CoV-2 RNA levels and the number of confirmed COVID-19 cases within the school, providing critical insights into potential transmission,"" says research team member Haley Kappus-Kron, an epidemiologist at the CDC Foundation.
The published study acknowledges the limitations of a one-day lead time of wastewater surveillance to predict clinical COVID-19 cases.
""The practicality of wastewater surveillance as an early warning tool heavily relies on timely reporting and swift actions following a positive sample,"" says Kappus-Kron. ""Nevertheless, in the absence of mass asymptomatic testing, wastewater surveillance presents an appealing and cost-effective approach to understand disease trends within school environments.""
While wastewater surveillance would not prevent all transmission, its role in understanding the extent of transmission could be critical in ensuring schools stay open as much as possible during a public health emergency due to an infectious disease. Applying wastewater surveillance in schools could potentially prevent unnecessary school closures and keep children in school longer.
""Wastewater surveillance will probably work for most infectious diseases, including the next public health emergency threat. With wastewater surveillance in schools, we may be able to keep the schools open longer and respond specifically to outbreaks rather than implement broad closures,"" says Larsen, Professor and Chair of the Department of Public Health at Syracuse University's Falk College of Sport and Human Dynamics who at outset of COVID in 2020 led an interdisciplinary team of experts in coordination with the New York State Department of Health to create a wastewater surveillance system throughout New York State.
As the world moves beyond the COVID-19 pandemic, schools may consider integrating wastewater surveillance into their emergency preparedness plans. The study advocates for school-specific plans that include access points, laboratory contacts, and protocols for effective wastewater sampling and analysis, especially during public health emergencies.

","score: 18.739855072463772, grade_level: '19'","score: 21.282768115942027, grade_levels: ['college_graduate'], ages: [24, 100]",10.1371/journal.pgph.0001803,"Wastewater surveillance provides a cost-effective and non-invasive way to gain an understanding of infectious disease transmission including for COVID-19. We analyzed wastewater samples from one school site in Jefferson County, New York during the 2021–2022 school year. We tested for SARS-CoV-2 RNA once weekly and compared those results with the clinical COVID-19 cases in the school. The amount of SARS-CoV-2 RNA correlated with the number of incident COVID-19 cases, with the best correlation being one day lead time between the wastewater sample and the number of COVID-19 cases. The sensitivity and positive predictive value of wastewater surveillance to correctly identify any COVID-19 cases up to 7 days after a wastewater sample collection ranged from 82–100% and 59–78% respectively, depending upon the amount of SARS-CoV-2 RNA in the sample. The specificity and negative predictive value of wastewater surveillance to correctly identify when the school was without a case of COVID-19 ranged from 67–78% and 70–80%, respectively, depending upon the amount of SARS-CoV-2 RNA in the sample. The lead time observed in this study suggests that transmission might occur within a school before SARS-CoV-2 is identified in wastewater. However, wastewater surveillance should still be considered as a potential means of understanding school-level COVID-19 trends and is a way to enable precision public health approaches tailored to the epidemiologic situation in an individual school."
"
The protein HOXA9 is overexpressed in most acute myeloid leukemia (AML) cases and is associated with poor patient outcomes. However, HOXA9 is a difficult protein to target therapeutically, so researchers at St. Jude Children's Research Hospital looked for ways to extinguish it indirectly. Using CRISPR/Cas9 screening, the researchers identified RBM5, demonstrating a causative link between RBM5 expression and leukemia cell proliferation. This link is driven by a novel dual function of RBM5 as both a DNA and RNA handler in gene expression. The research was published today in Genome Biology.

Overexpression of the protein HOXA9 is a hallmark of AML, present in over 70% of cases, often with poor prognosis. While this would implicate it as a useful drug target, the protein's role as a transcription factor has left it ""undruggable"" because a drug that interferes with HOXA9 would likely have numerous other off-target effects. This inspired researchers to approach the problem from a different angle by investigating the proteins HOXA9 works alongside and relies on to function. Chunliang Li, PhD, St. Jude Department of Tumor Cell Biology, co-corresponding author on this paper, is one such researcher. Through his recent work devising an unbiased CRISPR screening strategy to identify targets of HOXA9, he uncovered a network of opportunities.
""This has been a continued effort since my lab was established in 2017,"" said Li, ""We built up this unique reporter system in early 2019, which is the first reporter authentically representing HOXA9 expression in these leukemia systems.""
The CRISPR/Cas9 screening approach is elegantly simple in design but incredibly effective. It involves attaching a fluorescent tag to the HOXA9 gene and inserting it into leukemia cell lines. This enables researchers to track differences in expression levels by looking at fluorescence in cells.
""We wanted to identify a more targetable or novel regulator. So, we conducted an unbiased whole genome CRISPR screening to target all the genes expressed in cells,"" Li stated. This allowed the researchers to examine different pathways where HOXA9 left its fluorescent fingerprint.
To the researchers' surprise, splicing factors appeared to be the most represented pathway.
""This was quite surprising to us because splicing factors regulate different combinations of the transcript, but not usually the level. Our data suggested these proteins control the HOXA9 expression level,"" said Li. ""So, we hypothesized maybe the splicing factors have another function, like a dual function.""
The protein that stood out was the RNA-binding protein RBM5. The researchers found that RBM5 is highly expressed in leukemia cells as opposed to other cell types and that both the DNA- and RNA-binding sites are vital to its oncogenic functions. While the RBM family comprises vital RNA splicing factors, their function in DNA transcription was unknown. To address the direct transcriptional regulation of RBM5/HOXA9, the researchers generated a system to allow the acute degradation of RBM5.

""Immediately after RBM5 protein was removed from cells, HOXA9 mRNA levels were significantly reduced,"" Li explained, ""This reduction happened as early as two hours later but did not impact splicing events of HOXA9."" Additionally, leukemia cells stripped of their ability to produce RBM5 were rescued through overexpression of HOXA9, further demonstrating the link between the two proteins.
These results have Li looking to explore the protein as a drug target to treat AML.
""We think RBM5 is a very good dependency gene, which should be a good target based on our functional assays,"" he said. ""If we can specifically target the DNA binding affinity of these proteins, we should be able to combine with other existing therapies in synergy to target HOXA9-driven leukemia.""
Authors and funding
The study's first author is Mengli Zhang, Soochow University. The co-corresponding author is Peng Xu, Soochow University. Other authors include Judith Hyle, Shaela Wright, Zhenling Liu, Wojciech Rosikiewicz, Beisi Xu and Liusheng He of St. Jude; Xiaowen Chen of Shenzhen Children's Hospital; Ye Xin, Yingcai Jin, Jianxiang Zhang, Xue Yang and Xinfeng Chen of Soochow University; Hong Liu, Nana Ping and Depei Wu of The First Affiliated Hospital of Soochow University; and Feiqiu Wen of Shenzhen Children's Hospital.
The study was initially supported by grants from ALSAC, the fundraising and awareness organization of St. Jude.

","score: 12.899861871874258, grade_level: '13'","score: 12.953496070492974, grade_levels: ['college'], ages: [18, 24]",10.1186/s13059-023-03149-8,"The oncogenic protein HOXA9 plays a critical role in leukemia transformation and maintenance, and its aberrant expression is a hallmark of most aggressive acute leukemia. Although inhibiting the upstream regulators of HOXA9 has been proven as a significant therapeutic intervention, the comprehensive regulation network controlling HOXA9 expression in leukemia has not been systematically investigated. Here, we perform genome-wide CRISPR/Cas9 screening in the HOXA9-driven reporter acute leukemia cells. We identify a poorly characterized RNA-binding protein, RBM5, as the top candidate gene required to maintain leukemia cell fitness. RBM5 is highly overexpressed in acute myeloid leukemia (AML) patients compared to healthy individuals. RBM5 loss triggered by CRISPR knockout and shRNA knockdown significantly impairs leukemia maintenance in vitro and in vivo. Through domain CRISPR screening, we reveal that RBM5 functions through a noncanonical transcriptional regulation circuitry rather than RNA splicing, such an effect depending on DNA-binding domains. By integrative analysis and functional assays, we identify HOXA9 as the downstream target of RBM5. Ectopic expression of HOXA9 rescues impaired leukemia cell proliferation upon RBM5 loss. Importantly, acute protein degradation of RBM5 through auxin-inducible degron system immediately reduces HOXA9 transcription. We identify RBM5 as a new upstream regulator of HOXA9 and reveal its essential role in controlling the survival of AML. These functional and molecular mechanisms further support RBM5 as a promising therapeutic target for myeloid leukemia treatment."
"
A recent study has reported that changes in mice sperm microRNAs brought about by aging may affect the growth and development of offspring. The finding adds to the growing literature on the effects of paternal aging on offspring.

Details of the study were published in the journal Scientific Reports on December 7, 2023.
Marriages and childbearing later in life are increasingly becoming the norm. Whilst the impacts of maternal age on offspring, such as a higher risk of miscarriage and Down syndrome, are widely understood, the impacts from the paternal side are less so.
Yet this is changing. Recent epidemiological studies have demonstrated that paternal aging exerts a more substantial influence on the heightened risk of neurodevelopmental disorders such as autism spectrum disorder.
A research team led by Professor Noriko Osumi from the Department of Developmental Neuroscience at the Tohoku University Graduate School of Medicine has previously revealed that epigenetic factors, including histone modifications in spermatogenesis and DNA methylation in mice sperm, undergo changes with age. These alterations might lead to transgenerational effects.
However, the impact of paternal aging on microRNAs (miRNAs), small, non-coding RNA molecules that play a crucial role in regulating gene expression, remains under explored.
To rectify this, the same research team has conducted a comprehensive analysis of age-related variations in microRNAs in mice sperm. They compared microRNAs in sperm from mice aged 3, 12, and 20 months and identified the microRNAs that had changed in quantity.

The researchers discovered significant age-associated differences in the microRNAs. Some changes were in microRNAs responsible for regulating the nervous system and genes related to autism spectrum disorder, and these altered microRNAs included those transferred to fertilized eggs.
""Our study reveals the potential association between alteration in sperm microRNAs caused by paternal aging, underscoring the significance of investigating the impact of sperm microRNAs on offspring, an aspect that has been relatively overlooked in previous research,"" states Osumi.
The anticipation is that further exploration of epigenetic factors, specifically microRNAs, will not only contribute to unraveling the pathogenic mechanisms underlying neurodevelopmental disorders but will also offer insights into promoting the health and disease prevention of successive generations.
Osumi points out that their study widens the net when it comes to exploring the link between paternal age and potential health complications in children. ""While the age-related changes in oocytes are well-documented, the focus has predominantly centered on the fertility of sperm. Recognizing the myriad epigenetic transformations associated with sperm aging, as exemplified by the microRNAs examined in this study, becomes imperative.""
The findings also gain relevance in the context of Japan's rapidly declining birthrate, which necessitates incorporating the perspective on sperm-related factors in advancing reproductive medicine.

","score: 16.378170403587447, grade_level: '16'","score: 17.27244394618834, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41598-023-47878-z,"Paternal aging has consistently been linked to an increased risk of neurodevelopmental disorders, including autism spectrum disorder (ASD), in offspring. Recent evidence has highlighted the involvement of epigenetic factors. In this study, we aimed to investigate age-related alterations in microRNA (miRNA) profiles of mouse sperm and analyze target genes regulated by differentially expressed miRNAs (DEmiRNAs). Microarray analyses were conducted on sperm samples from mice at different ages: 3 months (3 M), over 12 M, and beyond 20 M. We identified 26 miRNAs with differential expression between the 3 and 20 M mice, 34 miRNAs between the 12 and 20 M mice, and 2 miRNAs between the 3 and 12 M mice. The target genes regulated by these miRNAs were significantly associated with apoptosis/ferroptosis pathways and the nervous system. We revealed alterations in sperm miRNA profiles due to aging and suggest that the target genes regulated by these DEmiRNAs are associated with apoptosis and the nervous system, implying a potential link between paternal aging and an increased risk of neurodevelopmental disorders such as ASD. The observed age-related changes in sperm miRNA profiles have the potential to impact sperm quality and subsequently affect offspring development."
"
Researchers from the Infection Biology Lab at the Department of Medicine and Life Sciences (MELIS) at Pompeu Fabra University and the HIV Unit at Hospital del Mar Research Institute have shown that intradermal vaccination with the JYNNEOS vaccine against smallpox is the best option to protect people living with HIV from contracting the monkeypox virus. This route of vaccine administration requires less material to inject each patient, extending the available vaccine doses by a factor of five. The results of this observational study also indicate that individuals with a low level of CD4 T cells, a type of white blood cell essential to properly fight new infections, need a booster dose 28 days after the first dose to compensate for their immunosuppressed status.

Monkeypox (mpox) is a zoonotic virus of the variola virus family that causes smallpox. Mpox causes an infectious disease that can spread autochthonously between humans through direct contact and respiratory routes. The most common symptoms of monkeypox infection are fever, headache, muscle pain, swollen lymph nodes, rash, respiratory and rectal symptoms, and exhaustion. Its severity depends on age and the response of the immune system to resist pathogens and parasites.
Prior to the spring of 2022, monkeypox used to appear in the form of single outbreaks in endemic areas of Central and West Africa, but at this time a global outbreak occurred that facilitated human-to-human transmission. Transmission was mainly between men who had sex with men, a population group with many HIV-infected individuals, who are particularly susceptible to monkeypox virus infection and pathogenicity.
Although there is no specific vaccine against monkeypox, the smallpox vaccine protects eight out of ten people from monkeypox infection due to the antigenic relatedness between the two viruses.
Fighting monkeypox while living with HIV
Results of the study published today in Journal of Medical Virology indicate that the activity of T cells, responsible for the response against pathogens, homeostasis and the system's memory, in HIV-1-infected individuals, whose viral load was controlled by antiretroviral therapy, was enhanced after vaccination with the JYNNEOS smallpox vaccine. T cell responses were equivalent to those of healthy control individuals.
Among individuals living with HIV infection, there is an at-risk group that deserves special attention. It comprises so-called immunological non-responders (INR), individuals who control their viral loads after antiretroviral therapy but only partially recover their CD4 T-lymphocyte count.

""Our study shows that these INRs may need a booster dose 28 days after the first vaccination to generate an efficient T cell response and thus be protected against monkeypox,"" explains Robert Güerri, the Hospital del Mar clinician who coordinated the vaccination study and is also an associate professor at UPF. Together, the new findings underscore the importance of specific studies on the immune response among people with HIV, especially those with lower CD4 white blood cells.
Vaccine administration routes modulate the immune response
Before the monkeypox outbreak in the spring of 2022, the JYNNEOS vaccine was administered subcutaneously to protect the population. But due to the increased vaccine demands, in August 2022, American and European health authorities proposed the intradermal administration route of the JYNNEOS vaccine. Via this route, the vaccine is released into the upper layer of the skin where many immune cells are located. But most importantly, this procedure extends the available vaccine doses by a factor of five, increasing vaccine availability without compromising its efficacy.
In contrast to the T-cell response of HIV-1-infected individuals who received the JYNNEOS vaccine subcutaneously, all individuals who received the vaccine intradermally generated a significant T-cell response. Therefore, intradermal vaccination was more effective in activating specific antiviral immunity.
""Our results clearly support the proposed dose-sparing vaccination route also for the protection of immunocompromised individuals who need the vaccine the most,"" adds Andreas Meyerhans, an ICREA researcher and UPF full professor, who coordinated the experimental part of the study.
This study provides an early indication of how best to proceed with preventive vaccination against monkeypox in a group of individuals at high risk of infection. However, further studies should confirm and expand on the observations derived from a small number of vaccinated individuals.

","score: 17.04405348837209, grade_level: '17'","score: 18.6594476744186, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/jmv.29317,"People living with human immunodeficiency virus (HIV) are the individuals most affected by the current Monkeypox virus outbreak that was first announced in May 2022. Here we report Pan‐pox‐specific T‐cell responses in a cohort of HIV‐1‐infected individuals after receiving the nonreplicative, attenuated smallpox vaccine JYNNEOS from Bavarian Nordic. Intradermal (i.d.) and subcutaneous (s.c.) vaccination was safe without major side effects. Dose‐sparing i.d. vaccination was superior to s.c. vaccination and promoted T‐cell polyfunctionality, and the expression of the gut‐homing marker α4β7 integrin on lymphocytes. HIV‐1‐infected individuals with CD4 T‐cell counts ≤500/mm3 blood required at least a booster vaccination to exhibit efficient virus‐specific T‐cell responses. The magnitude of the Th1 response after this booster directly correlated with the CD4 T‐cell count of the vaccinees. Further studies with a larger number of participants are warranted to confirm and expand our observations."
"
Proteins do the heavy lifting of performing biochemical functions in our bodies by binding to metabolites or other proteins to complete tasks. To do this successfully, protein molecules often shape-shift to allow specific binding interactions that are needed to perform complex, precise chemical processes.

A better understanding of the shapes proteins take on would give researchers important insight into stopping or treating diseases, but current methods for revealing these dynamic, three-dimensional forms offer scientists limited information. To address this knowledge gap, a team from the Advanced Science Research Center at the CUNY Graduate Center (CUNY ASRC) designed an experiment to test whether performing X-ray crystallography imaging using elevated temperature versus elevated pressure would reveal distinct shapes. The results of the team's work appear in the journal Communications Biology.
""Protein structures don't sit still; they shift between several similar shapes much like a dancer,"" said the study's principal investigator Daniel Keedy, Ph.D., a professor with the CUNY ASRC's Structural Biology Initiative and a chemistry and biochemistry professor at The City College of New York and the CUNY Graduate Center. ""Unfortunately, existing approaches for viewing proteins only reveal one shape, or suggest the presence of multiple shapes without providing specific details. We wanted to see if different ways of poking at a protein could give a us a more detailed view of how it shape-shifts.""
For their experiment, the team obtained crystals of STEP, also known as PTPN5 -- a drug target protein for the treatment of several diseases, including Alzheimer's -- and agitated them using either high pressure (2,000 times the Earth's atmospheric pressure) or high temperature (body temperature), both of which are very different from typical crystallography experiments at atmospheric pressure and cryogenic temperature (-280 F, -173 C). The researchers viewed the samples using X-ray crystallography and observed that high temperature and high pressure had different effects on the protein, revealing distinct shapes.
While high pressure isn't a condition that proteins experience inside the body, Keedy said the agitation method exposed different structural states of the protein that may be relevant to its activity in human cells.
""Having the ability to use perturbations such as heat and pressure to elucidate these different states could give drug developers tools for determining how they can trap a protein in a particular shape using a small-molecule drug to diminish its function,"" Keedy added.

","score: 18.40454545454546, grade_level: '18'","score: 21.082045454545458, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s42003-023-05609-0,"Protein function hinges on small shifts of three-dimensional structure. Elevating temperature or pressure may provide experimentally accessible insights into such shifts, but the effects of these distinct perturbations on protein structures have not been compared in atomic detail. To quantitatively explore these two axes, we report the first pair of structures at physiological temperature versus. high pressure for the same protein, STEP (PTPN5). We show that these perturbations have distinct and surprising effects on protein volume, patterns of ordered solvent, and local backbone and side-chain conformations. This includes interactions between key catalytic loops only at physiological temperature, and a distinct conformational ensemble for another active-site loop only at high pressure. Strikingly, in torsional space, physiological temperature shifts STEP toward previously reported active-like states, while high pressure shifts it toward a previously uncharted region. Altogether, our work indicates that temperature and pressure are complementary, powerful, fundamental macromolecular perturbations."
"
Scientists from Yale and the University of Cologne were able to show that statistical models created by artificial intelligence (AI) predict very accurately whether a medication responds in people with schizophrenia. However, the models are highly context-dependent and cannot be generalized.

In a recent study, scientists have been investigating the accuracy of AI models that predict whether people with schizophrenia will respond to antipsychotic medication.
Statistical models from the field of artificial intelligence (AI) have great potential to improve decision-making related to medical treatment. However, data from medical treatment that can be used for training these models are not only rare, but also expensive. Therefore, the predictive accuracy of statistical models has so far only been demonstrated in a few data sets of limited size. In the current work, the scientists are investigating the potential of AI models and testing the accuracy of the prediction of treatment response to antipsychotic medication for schizophrenia in several independent clinical trials.
The results of the new study, in which researchers from the Faculty of Medicine of the University of Cologne and Yale were involved, show that the models were able to predict patient outcomes with high accuracy within the trial in which they were developed. However, when used outside the original trial, they did not show better performance than random predictions. Pooling data across trials did not improve predictions either.The study 'Illusory generalizability of clinical prediction models' was published in Science.
The study was led by leading scientists from the field of precision psychiatry. This is an area of psychiatry in which data-related models, targeted therapies and suitable medications for individuals or patient groups are supposed to be determined.
""Our goal is to use novel models from the field of AI to treat patients with mental health problems in a more targeted manner,"" says Dr Joseph Kambeitz, Professor of Biological Psychiatry at the Faculty of Medicine of the University of Cologne and the University Hospital Cologne. ""Although numerous initial studies prove the success of such AI models, a demonstration of the robustness of these models has not yet been made.""
And this safety is of great importance for everyday clinical use.
""We have strict quality requirements for clinical models and we also have to ensure that models in different contexts provide good predictions,"" says Kambeitz. The models should provide equally good predictions, whether they are used in a hospital in the USA, Germany or Chile.
The results of the study show that a generalization of predictions of AI models across different study centres cannot be ensured at the moment. This is an important signal for clinical practice and shows that further research is needed to actually improve psychiatric care. In ongoing studies, the researchers hope to overcome these obstacles. In cooperation with partners from the USA, England and Australia, they are working on the one hand to examine large patient groups and data sets in order to improve the accuracy of AI models and on the use of other data modalities such as biological samples or new digital markers such as language, motion profiles and smartphone usage.

","score: 15.17298534798535, grade_level: '15'","score: 15.823375457875457, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adg8538,"It is widely hoped that statistical models can improve decision-making related to medical treatments. Because of the cost and scarcity of medical outcomes data, this hope is typically based on investigators observing a model’s success in one or two datasets or clinical contexts. We scrutinized this optimism by examining how well a machine learning model performed across several independent clinical trials of antipsychotic medication for schizophrenia. Models predicted patient outcomes with high accuracy within the trial in which the model was developed but performed no better than chance when applied out-of-sample. Pooling data across trials to predict outcomes in the trial left out did not improve predictions. These results suggest that models predicting treatment outcomes in schizophrenia are highly context-dependent and may have limited generalizability."
"
Physicians who are notified that a patient has died of a drug overdose are more judicious in issuing controlled substances if the notification includes a plan for what to do during subsequent patient visits, according to a study published today in Nature Communications.

Compared to a letter with demonstrated effectiveness at improving prescribing safety, physicians who received notifications with additional planning guidance reduced prescriptions of opioids by nearly 13%. They also reduced prescriptions of the anxiety medications benzodiazepines and by more than 8%. Together these drugs constitute the bulk of prescription drug overdoses.
The results suggest that the guidance, known as if/when planning prompts, may lower risks to patients by reducing the intensity and frequency of these prescriptions. The findings also indicate that letters notifying a physician that a patient has fatally overdosed are more effective when they include the guidance prompts.
The letter with planning prompts asked the doctor to carry out a specific plan: ""When your next patient presents with pain, keep… [these] ... recommendations close at hand to assist with their safe care. Also, be comfortable voicing your concern about prescribing safety with them so that they are also aware of the dangers associated with scheduled drugs.""
""Providing physicians a simple plan that will guide them at a patient visit appears to help temper their use of these drugs,"" said Jason Doctor, lead author of the study and co-director of the Behavioral Sciences Program at the USC Schaeffer Center for Health Policy and Economics. ""This represents a promising approach to reducing fatal drug overdoses, one that is both affordable and scalable.""
The study builds on two previous ones conducted by Doctor and his colleagues. The first one found that physicians reduced opioid prescriptions by 10% in the three months following notification of a fatal overdose. A second study found that physicians reduced opioid prescriptions by 7% one year after receiving notification. The letter used in these previous studies served as the control in this study.
""This latest study is part of an evolution toward better understanding how to enact behavior change among physicians whose patients have suffered negative consequences from care by the medical community,"" said Doctor, who is also chair of the Department of Health Policy and Management at the USC Sol Price School of Public Policy.

The latest randomized study involved sending letters to 541 clinicians in Los Angeles County: 284 received a standard letter notifying them that a patient had died of an overdose; 257 received a letter with the additional guidance.
About the Study
In addition to Doctor, the study's authors included Emily Stewart, staff at the USC Price School; Marcella A. Kelley of Edwards Lifesciences; Noah J. Goldstein of the UCLA Anderson School of Management and UCLA Geffen School of Medicine; and Jonathan Lucas of the Los Angeles County's Department of Medical Examiner-Coroner.
The study was supported by the National Institutes on Aging (P30AG024968).

","score: 15.5963787674314, grade_level: '16'","score: 16.9005420602789, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44573-5,"Prior work has demonstrated that personalized letters are effective at reducing opioid and benzodiazepine prescribing, but it is unclear whether If/when-then planning prompts would enhance this effect. We conducted a decedent-clustered trial which randomized 541 clinicians in Los Angeles County to receive a standard (n = 284), or comparator (n = 257) version of a letter with If/when-then prompts. We found a significant 12.85% (6.83%, 18.49%) and 8.32% (2.34%, 13.93%) decrease in the primary outcomes morphine (MME) and diazepam milligram equivalents (DME), respectively. This study confirms the benefit of planning prompts, and repeat letter exposure among clinicians with poor patient outcomes. Limitations include lack of generalizability and small sample size. Clinicaltrials.gov registration: NCT03856593."
"
Tuberculosis (TB) is the leading infectious killer worldwide, with 10.6 million cases and 1.6 million deaths in 2021 alone. One in five incident TB cases were attributable to malnutrition, more than double the number attributed to HIV/AIDS. Like HIV/AIDS, malnutrition is a cause of secondary immunodeficiency, known as nutritionally acquired immunodeficiency syndrome (N-AIDS). However, N-AIDS remains the neglected cousin of HIV/AIDS in global TB elimination efforts.

In a review paper led by Madolyn Dauphinais, MPH, researchers at Boston University Chobanian & Avedisian School of Medicinealong with collaborators from Cornell University, University of Virginia, and the International Union Against Tuberculosis & Lung Disease, and Jawaharlal Institute of Postgraduate Medical Education and Research, reviewed decades of data and make the case that N-AIDS, just like HIV/AIDS, also deserves special consideration in the effort to eliminate TB.
""While there have been important technological advancements to detect and treat TB, our interpretation of the existing literature is that we won't be able to make substantive changes in TB incidence and mortality rates without action on malnutrition,"" explains corresponding author Pranay Sinha, MD, assistant professor of medicine at the school.
After reading more than 75 papers on nutrition and TB, the researchers briefly recount the impact that actions on HIV had on the global TB pandemic. They point out that malnutrition is the leading cause of immunodeficiency worldwide. ""People with severe malnutrition, like people with HIV, are at increased risk of TB. We can leverage what we already know about malnutrition to aid us in detecting, treating and preventing TB,"" says Sinha, who also is an infectious disease physician at Boston Medical Center.
While the researchers believe it is urgent to continue to develop newer tools, approaches should not be limited to the biomedical realm. For example, a study included in their review found that TB incidence among household contacts of persons with tuberculosis was reduced by 40% by providing them with an inexpensive food basket. ""It is important for the lay audience to understand that TB is not simply a medical disease, it's a social one and our elimination efforts must recognize that,"" he adds.
According to the researchers, action on malnutrition will have several benefits beyond TB as well. Throughout their paper, they explore the idea of leveraging nutritional interventions to detect, prevent, and treat TB more effectively. They believe this paper will help advocates, clinicians, policymakers and voters think differently about the management of persons with TB as well as the needed global health investments to eradicate it.
This paper appears online in BMC Global & Public Health.

","score: 15.781202282298604, grade_level: '16'","score: 16.486933840510794, grade_levels: ['college_graduate'], ages: [24, 100]",10.1186/s44263-023-00035-0,"Tuberculosis (TB) is the leading infectious killer worldwide, with 10.6 million cases and 1.6 million deaths in 2021 alone. One in 5 incident TB cases were attributable to malnutrition, more than double the fraction attributed to HIV. Like HIV, malnutrition is a cause of secondary immunodeficiency and has even been dubbed nutritionally acquired immunodeficiency syndrome (N-AIDS). However, malnutrition remains the neglected cousin of HIV in global TB elimination efforts. Malnutrition increases the risk for TB progression, increases disease severity, and worsens TB treatment outcomes. Thus, it is both a TB determinant and comorbidity. In this perspective, we discuss decades of data to make the case that N-AIDS, just like HIV/AIDS, also deserves special consideration in the TB elimination discourse. Fortunately, malnutrition is a modifiable risk factor and there is now empirical evidence that addressing nutrition can help us curb the TB pandemic. Recognizing malnutrition as a key determinant and comorbidity is key to detecting and treating the missing millions while also preventing additional millions from suffering TB disease."
"
Did smokers do better than non-smokers in a clinical trial for an experimental cancer treatment? That was the intriguing question that led University of Iowa researchers and their colleagues to develop a drinkable, carbon monoxide-infused foam that boosted the effectiveness of the therapy, known as autophagy inhibition, in mice and human cells. The findings were recently published in the journal Advanced Science. 

Looking for ways to exploit biological differences between cancer cells and healthy cells is a standard approach for devising new cancer treatments. But it is a painstaking process that requires a deep understanding of complex cancer biology and often a dose of unexpected insight.
The potential of autophagy inhibitors 
Researchers have known for several decades that autophagy, which is the cell's natural recycling system, is increased in cancer cells relative to healthy cells, suggesting that inhibiting autophagy might be a way to target cancer cells. However, results from almost 20 clinical trials testing autophagy inhibitors have been inconclusive.
""Within those clinical trials they found mixed results; there was some benefit, but for many patients there was no benefit, which really pushed researchers back to the drawing board,"" says James Byrne, MD, PhD, UI assistant professor of radiation oncology and biomedical engineering and senior author on the new study.
Searching for insight into why autophagy inhibition only seems to work some of the time, the researchers made the surprising discovery that smokers in two of the previous trials of autophagy inhibitors seemed to do better than non-smokers.
""When we looked at how the smokers did in those trials, we saw an increase in overall response in smokers that received the autophagy inhibitors, compared to (non-smoker) patients, and we also saw a pretty robust decrease in the target lesion size,"" Byrne says.

This was an exciting finding for Byrne and his team because smoking is also associated with increased levels of carbon monoxide, a gas molecule that can increase autophagy in cells in a way that researchers think might enhance the anti-cancer effect of autophagy inhibitors.
""We know also that smokers have higher carbon monoxide levels and while we definitely don't recommend smoking, this suggested that elevated carbon monoxide might improve the effectiveness of autophagy inhibitors. We want to be able to harness that benefit and take it into a therapeutic platform,"" says Byrne, who also is a member of University of Iowa Holden Comprehensive Cancer Center.
Carbon monoxide boosts anti-cancer activity of autophagy inhibition
The team already had just such a ""platform"" to test their ideas. Byrne specializes in crafting gas-entrapping materials (GEMs) -- foams, gels, and solids made from safe, edible substances that can be infused with different gas molecules. For this study, the researchers created a drinkable foam infused with carbon monoxide.
When mice with pancreatic and prostate cancers were fed the carbon monoxide foam and simultaneously treated with an autophagy inhibitor, tumor growth and progression was significantly reduced in the animals. The team also showed that combining carbon monoxide with autophagy inhibitors had a significant anti-cancer effect in human prostate, lung, and pancreatic cancer cells in petri dishes.
Ultimately, Byrne hopes to test this approach in human clinical trials.
""The results from this study support the idea that safe, therapeutic levels of CO, which we can deliver using GEMs, can increase the anti-cancer activity of autophagy inhibitors, opening a promising new approach that might improve therapies for many different cancers,"" he says.
In addition to Byrne, the research team included UI researchers Jianling Bi, Emily Witt, Megan McGovern, Arielle Cafi, Lauren Rosenstock, Lucas Absler, Srija Machkanti, Kellie Bodeker, Scott Shaw, Vitor Lira, and Michael Henry.
The research team also included scientists from MIT, Harvard Medical School, University of Pennsylvania, Rutgers Cancer Institute of New Jersey, University of North Carolina Wilmington, and Oregon Health and Science University.

","score: 17.165482954545457, grade_level: '17'","score: 18.461142045454544, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202308346,"Modulation of autophagy, specifically its inhibition, stands to transform the capacity to effectively treat a broad range of cancers. However, the clinical efficacy of autophagy inhibitors has been inconsistent. To delineate clinical and epidemiological features associated with autophagy inhibition and a positive oncological clinical response, a retrospective analysis of patients is conducted treated with hydroxychloroquine, a known autophagy inhibitor. A direct correlation between smoking status and inhibition of autophagy with hydroxychloroquine is identified. Recognizing that smoking is associated with elevated circulating levels of carbon monoxide (CO), it is hypothesized that supplemental CO can amplify autophagy inhibition. A novel, gas‐entrapping material containing CO in a pre‐clinical model is applied and demonstrated that CO can dramatically increase the cytotoxicity of autophagy inhibitors and significantly inhibit the growth of tumors when used in combination. These data support the notion that safe, therapeutic levels of CO can markedly enhance the efficacy of autophagy inhibitors, opening a promising new frontier in the quest to improve cancer therapies."
"
A study published in Nature Nanotechnology presents an innovative graphene-based neurotechnology with the potential for a transformative impact in neuroscience and medical applications. This research, spearheaded by the Catalan Institute of Nanoscience and Nanotechnology (ICN2) together with the Universitat Autònoma de Barcelona (UAB) and other national and international partners, is currently being developed for therapeutic applications through the spin-off INBRAIN Neuroelectronics.

Key Features of Graphene Technology
Following years of research under the European Graphene Flagship project, ICN2 spearheaded in collaboration with the University of Manchester the development of EGNITE (Engineered Graphene for Neural Interfaces), a novel class of flexible, high-resolution, high-precision graphene-based implantable neurotechnology. The results published today in Nature Neurotechnology aim to contribute with innovative technologies to the blooming landscape of neuroelectronics and brain-computer interfaces.
EGNITE builds on the vast experience of its inventors in fabrication and medical translation of carbon nanomaterials. This innovative technology based on nanoporous graphene integrates fabrication processes standard in the semiconductor industry to assemble graphene microelectrodes of a mere 25 µm in diameter. The graphene microelectrodes exhibit low impedance and high charge injection, essential attributes for flexible and efficient neural interfaces.
Preclinical Validation of Functionality
Preclinical studies by various neuroscience and biomedical experts that partnered with ICN2, using different models for both the central and peripheral nervous system, demonstrated the capacity of EGNITE in recording high-fidelity neural signals with exceptional clarity and precision and, more importantly, afford highly targeted nerve modulation. The unique combination of high-fidelity signal recording and precise nerve stimulation offered by EGNITE technology represents a potentially critical advancement in neuroelectronic therapeutics.
This innovative approach addresses a critical gap in neurotechnology, which has seen little advancement in materials over the last two decades. The development of EGNITE electrodes has the capacity to place graphene at the forefront of neurotechnological materials.

International Collaboration and Scientific Leadership
The technology presented today builds on the legacy of the Graphene Flagship, a European initiative that during the last decade strived to advance European strategic leadership in technologies that rely on graphene and other 2D materials. Behind this scientific breakthrough is a collaborative effort led by ICN2 researchers Damià Viana (now at INBRAIN Neuroelectronics), Steven T. Walston (now at University of Southern California), and Eduard Masvidal-Codina, under the guidance of ICREA Jose A. Garrido, leader of the ICN2Advanced Electronic Materials and Devices Group, and ICREA Kostas Kostarelos, leader of the ICN2Nanomedicine Lab and the Faculty of Biology, Medicine & Health at the University of Manchester (UK). The research has had the participation of Xavier Navarro, Natàlia de la Oliva, Bruno Rodríguez-Meana and Jaume del Valle, from the Institute of Neurosciences and the Department of Cellular Biology, Physiology and Immunology of the Universitat Autònoma de Barcelona (UAB).
The collaboration includes the contribution from leading national and international institutions, such as the Institut de Microelectrònica de Barcelona -- IMB-CNM (CSIC), the National Graphene Institute in Manchester (UK), and the Grenoble Institut des Neurosciences -- Université Grenoble Alpes (France) and the University of Barcelona. The technology integration into the standard semiconductor fabrication processes has been performed at the Micro and Nanofabrication cleanroom of the IMB-CNM (CSIC), under the supervision of CIBER researcher Dr Xavi Illa.
Clinical Translation: Next Steps
The EGNITE technology described in the Nature Nanotechnology article has been patented and licensed to INBRAIN Neuroelectronics, a spin-off based in Barcelona from ICN2 and ICREA, with support from IMB-CNM (CSIC). The company, also a partner in the Graphene Flagship project, is leading the translation of the technology into clinical applications and products. Under the direction of CEO Carolina Aguilar, INBRAIN Neuroelectronics is gearing up for the first-in-human clinical trials of this innovative graphene technology.
The industrial and innovation landscape on semiconductor engineering in Catalonia, where ambitious national strategies plan to build state-of-the-art facilities to produce semiconductor technologies based on emerging materials, offer an unprecedented opportunity to accelerate the translation of such results presented today into clinical applications.
Closing Remarks
The Nature Nanotechnology article describes an innovative graphene-based neurotechnology that can be upscaled using established semiconductor fabrication processes, holding the potential for a transformative impact. ICN2 and its partners continue to advance and mature the described technology with the aim to translate it into a real efficacious and innovative therapeutic neurotechnology.

","score: 22.597485493230177, grade_level: '23'","score: 24.402684719535777, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41565-023-01570-5,"One of the critical factors determining the performance of neural interfaces is the electrode material used to establish electrical communication with the neural tissue, which needs to meet strict electrical, electrochemical, mechanical, biological and microfabrication compatibility requirements. This work presents a nanoporous graphene-based thin-film technology and its engineering to form flexible neural interfaces. The developed technology allows the fabrication of small microelectrodes (25 µm diameter) while achieving low impedance (∼25 kΩ) and high charge injection (3–5 mC cm−2). In vivo brain recording performance assessed in rodents reveals high-fidelity recordings (signal-to-noise ratio >10 dB for local field potentials), while stimulation performance assessed with an intrafascicular implant demonstrates low current thresholds (<100 µA) and high selectivity (>0.8) for activating subsets of axons within the rat sciatic nerve innervating tibialis anterior and plantar interosseous muscles. Furthermore, the tissue biocompatibility of the devices was validated by chronic epicortical (12 week) and intraneural (8 week) implantation. This work describes a graphene-based thin-film microelectrode technology and demonstrates its potential for high-precision and high-resolution neural interfacing."
"
To combat viruses, bacteria and other pathogens, synthetic biology offers new technological approaches whose performance is being validated in experiments. Researchers from the Würzburg Helmholtz Institute for RNA-based Infection Research and the Helmholtz AI Cooperative applied data integration and artificial intelligence (AI) to develop a machine learning approach that can predict the efficacy of CRISPR technologies more accurately than before. The findings were published today in the journal Genome Biology.

The genome or DNA of an organism incorporates the blueprint for proteins and orchestrates the production of new cells. Aiming to combat pathogens, cure genetic diseases or achieve other positive effects, molecular biological CRISPR technologies are being used to specifically alter or silence genes and inhibit protein production.
One of these molecular biological tools is CRISPRi (from ""CRISPR interference""). CRISPRi blocks genes and gene expression without modifying the DNA sequence. As with the CRISPR-Cas system also known as ""gene scissors,"" this tool involves a ribonucleic acid (RNA), which serves as a guide RNA to direct a nuclease (Cas). In contrast to gene scissors, however, the CRISPRi nuclease only binds to the DNA without cutting it. This binding results in the corresponding gene not being transcribed and thus remaining silent.
Until now, it has been challenging to predict the performance of this method for a specific gene. Researchers from the Würzburg Helmholtz Institute for RNA-based Infection Research (HIRI) in cooperation with the University of Würzburg and the Helmholtz Artificial Intelligence Cooperation Unit (Helmholtz AI) have now developed a machine learning approach using data integration and artificial intelligence (AI) to improve such predictions in the future.
The approach
CRISPRi screens are a highly sensitive tool that can be used to investigate the effects of reduced gene expression. In their study, published today in the journal Genome Biology, the scientists used data from multiple genome-wide CRISPRi essentiality screens to train a machine learning approach. Their goal: to better predict the efficacy of the engineered guide RNAs deployed in the CRISPRi system.
""Unfortunately, genome-wide screens only provide indirect information about guide efficiency. Hence, we have applied a new machine learning method that disentangles the efficacy of the guide RNA from the impact of the silenced gene,"" explains Lars Barquist. The computational biologist initiated the study and heads a bioinformatics research group at the Würzburg Helmholtz Institute, a site of the Braunschweig Helmholtz Centre for Infection Research in cooperation with the Julius-Maximilians-Universität Würzburg.

Supported by additional AI tools (""Explainable AI""), the team established comprehensible design rules for future CRISPRi experiments. The study authors validated their approach by conducting an independent screen targeting essential bacterial genes, showing that their predictions were more accurate than previous methods.
""The results have shown that our model outperforms existing methods and provides more reliable predictions of CRISPRi performance when targeting specific genes,"" says Yanying Yu, PhD student in Lars Barquist's research group and first author of the study.
The scientists were particularly surprised to find that the guide RNA itself is not the primary factor in determining CRISPRi depletion in essentiality screens. ""Certain gene-specific characteristics related to gene expression appear to have a greater impact than previously assumed,"" explains Yu.
The study also reveals that integrating data from multiple data sets significantly improves the predictive accuracy and enables a more reliable assessment of the efficiency of guide RNAs. ""Expanding our training data by pulling together multiple experiments is essential to create better prediction models. Prior to our study, lack of data was a major limiting factor for prediction accuracy,"" summarizes junior professor Barquist. The approach now published will be very helpful in planning more effective CRISPRi experiments in the future and serve both biotechnology and basic research. ""Our study provides a blueprint for developing more precise tools to manipulate bacterial gene expression and ultimately help to better understand and combat pathogens,"" says Barquist.
The results at a glance
• Gene features matter: The characteristics of targeted genes have a significant impact on guide RNA depletion in genome-wide screens.

• Data integration improves predictions: Combining data from multiple CRISPRi screens significantly improves the accuracy of prediction models and enables more reliable estimates of guide RNA efficiency.
• Designing better CRISPRi experiments: The study provides valuable insights for designing more effective CRISPRi experiments by predicting guide RNA efficiency, enabling precise gene-silencing strategies.
Funding
The study was supported by funds from the Bavarian State Ministry of Science and Art through the bayresq.net research network.

","score: 15.601106927710845, grade_level: '16'","score: 17.35432479919678, grade_levels: ['college_graduate'], ages: [24, 100]",10.1186/s13059-023-03153-y,"CRISPR interference (CRISPRi) is the leading technique to silence gene expression in bacteria; however, design rules remain poorly defined. We develop a best-in-class prediction algorithm for guide silencing efficiency by systematically investigating factors influencing guide depletion in genome-wide essentiality screens, with the surprising discovery that gene-specific features substantially impact prediction. We develop a mixed-effect random forest regression model that provides better estimates of guide efficiency. We further apply methods from explainable AI to extract interpretable design rules from the model. This study provides a blueprint for predictive models for CRISPR technologies where only indirect measurements of guide activity are available."
"
Researchers have been studying the transcription factor SREBP, a critical regulator of lipid biosynthesis. Precursor SREBP proteins, located in the endoplasmic reticulum (ER) of the cell, are transported through the golgi apparatus to the nucleus. Here, they promote the transcription of genes associated with lipid biosynthesis, playing a pivotal role in regulating cholesterol. SREBP-1c, a specific member of the SREBP family, is known to activate fatty acid synthesis. Interestingly, this process is inhibited by polyunsaturated fatty acids. The exact mechanism behind this regulation, however, remains to be elucidated.

The research team elucidated a novel cleavage mechanism of SREBP-1c, a protein involved in fatty acid synthesis, and confirmed its regulation by fatty acids. The cleavage of SREBP-1c occurs in the endoplasmic reticulum, with the rhomboid protease RHBDL4, located in the ER membrane, identified as a new cleavage enzyme for SREBP-1c. This cleavage process is activated by saturated fatty acids and deactivated by polyunsaturated fatty acids, suggesting that RHBDL4's activity is modulated by the type of fatty acid. Additionally, the team discovered a unique mechanism where the VCP complex extracts the cleaved SREBP-1c protein from the endoplasmic reticulum. In the livers of mice deficient in the RHBDL4 gene and fed a high-fat and high-cholesterol diet, the activation of SREBP-1c cleavage was suppressed. This inhibited the expression of a group of target genes involved in fatty acid synthesis, polyunsaturated fatty acid synthesis and uptake, and lipoprotein secretion, which improved fatty liver pathophysiology, as observed in wild-type mice.
The RHBDL4-SREBP-1c pathway, uncovered in this study, represents a lipid homeostasis mechanism regulated by fatty acids. This groundbreaking discovery is anticipated to pave the way for developing new therapeutic strategies for metabolic disorders and lifestyle-related diseases stemming from abnormal lipid metabolism.
This work was supported by Grants-in-Aid for Scientific Research on Innovative Areas program (Inflammation Cellular Sociology) JP17H06395 (to H.S.), Scientific Research (A) 15H02541 and 18H04051 (to H.S.), and Scientific Research (C) 16K01811 and 19K11737 (to S.-I.H.) from the Ministry of Science, Education, Culture, and Technology of Japan; AMED-CREST Grant Number 16gm0910003h0002 (to H.S.) from the Japan Agency for Medical Research and Development, AMED; and Ono Medical Research Foundation (to S.-I.H.).

","score: 13.907800000000002, grade_level: '14'","score: 13.856279999999998, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/pnasnexus/pgad351,"The endoplasmic reticulum (ER)–embedded transcription factors, sterol regulatory element-binding proteins (SREBPs), master regulators of lipid biosynthesis, are transported to the Golgi for proteolytic activation to tune cellular cholesterol levels and regulate lipogenesis. However, mechanisms by which the cell responds to the levels of saturated or unsaturated fatty acids remain underexplored. Here, we show that RHBDL4/RHBDD1, a rhomboid family protease, directly cleaves SREBP-1c at the ER. The p97/VCP, AAA-ATPase complex then acts as an auxiliary segregase to extract the remaining ER-embedded fragment of SREBP-1c. Importantly, the enzymatic activity of RHBDL4 is enhanced by saturated fatty acids (SFAs) but inhibited by polyunsaturated fatty acids (PUFAs). Genetic deletion of RHBDL4 in mice fed on a Western diet enriched in SFAs and cholesterol prevented SREBP-1c from inducing genes for lipogenesis, particularly for synthesis and incorporation of PUFAs, and secretion of lipoproteins. The RHBDL4-SREBP-1c pathway reveals a regulatory system for monitoring fatty acid composition and maintaining cellular lipid homeostasis."
"
The number of infections by the tick-borne TBE virus that are not detected by health services is far higher than previously assumed. This has been shown in a new study of Swedish blood donors from Uppsala University and the University Hospital in Uppsala. The results have been published in the journal Eurosurveillance, which is associated with the EU's Centre for Disease Prevention and Control.

""We were very surprised that such a high proportion of the blood donors showed traces of a previous TBE virus infection. This is far more than could have been suspected based on the number of reported cases,"" says Bo Albinsson, doctoral student at Uppsala University, one of the first authors of the article.
Tick-borne encephalitis (TBE) is a very serious disease that is increasingly common in large parts of Europe. According to statistics from the Public Health Agency of Sweden, 597 cases of the disease had been reported in Sweden by November 2023, the highest number ever registered in a single year.
TBE has been a notifiable disease since 2004 under the Communicable Diseases Act and all cases must therefore be reported to the regional infection control doctor and the Public Health Agency of Sweden. However, people who only develop mild symptoms or no symptoms at all are not detected by the health services and therefore do not show up in the statistics. Until now, the relationship between the number of reported cases and the proportion of people infected was unknown.
Traditional methods of investigating whether someone has previously been infected by the virus are not completely reliable as individuals who have been vaccinated against TBE can also test positive. On top of this, it is not known exactly how many people have been vaccinated, since Sweden has no national vaccination register for TBE.
In the new study, the result of a Swedish collaboration, the researchers have investigated blood tests from 2,700 anonymous blood donors from nine regions in Sweden. The method they used is called TBE-SMIA (suspension multiplex immunoassay) and was developed at the Zoonosis Science Center (ZSC) at Uppsala University in collaboration with the Clinical Microbiology Department at Uppsala University Hospital. It makes it possible for the first time to effectively distinguish the antibody response after TBE virus infection from the response after TBE vaccination. This has enabled the researchers to identify how many people have had the infection. They were also able to estimate the proportion of the population in each region that is vaccinated.
The results showed that the proportion of blood donors with a history of TBE virus infection varied from 1 per cent to 7 per cent between the different regions. Based on the population sizes of the regions, the researchers estimated that this corresponds to a total of more than 160,000 people aged 15-65, which is significantly higher than previous estimates.
The researchers also found that the proportion of blood donors vaccinated against TBE varied between 8.7 per cent and 57 per cent in the different regions. In total, this translates to over 1.6 million Swedes (aged 15-65) in the regions investigated.
""It is noteworthy that the number of confirmed TBE cases is increasing despite relatively good vaccination coverage. Further research is therefore needed, for example by carefully mapping the distribution of the virus in different tick populations. Our results provide an important background for future vaccination strategies and we believe it would be well worth considering establishing a national vaccination register for TBE,"" says Tove Hoffman, researcher at the ZSC and the study's other first author.

","score: 14.473198198198201, grade_level: '14'","score: 15.17733671171171, grade_levels: ['college_graduate'], ages: [24, 100]",10.2807/1560-7917.ES.2024.29.2.2300221,"In Sweden, information on seroprevalence of tick-borne encephalitis virus (TBEV) in the population, including vaccination coverage and infection, is scattered. This is largely due to the absence of a national tick-borne encephalitis (TBE) vaccination registry, scarcity of previous serological studies and use of serological methods not distinguishing between antibodies induced by vaccination and infection. Furthermore, the number of notified TBE cases in Sweden has continued to increase in recent years despite increased vaccination. The aim was to estimate the TBEV seroprevalence in Sweden. In 2018 and 2019, 2,700 serum samples from blood donors in nine Swedish regions were analysed using a serological method that can distinguish antibodies induced by vaccination from antibodies elicited by infection. The regions were chosen to reflect differences in notified TBE incidence. The overall seroprevalence varied from 9.7% (95% confidence interval (CI): 6.6–13.6%) to 64.0% (95% CI: 58.3–69.4%) between regions. The proportion of vaccinated individuals ranged from 8.7% (95% CI: 5.8–12.6) to 57.0% (95% CI: 51.2–62.6) and of infected from 1.0% (95% CI: 0.2–3.0) to 7.0% (95% CI: 4.5–10.7). Thus, more than 160,000 and 1,600,000 individuals could have been infected by TBEV and vaccinated against TBE, respectively. The mean manifestation index was 3.1%. A difference was observed between low- and high-incidence TBE regions, on the overall TBEV seroprevalence and when separated into vaccinated and infected individuals. The estimated incidence and manifestation index argue that a large proportion of TBEV infections are not diagnosed."
"
Salmonella is notorious for surviving and replicating in macrophages, which are normally lethal to invading bacteria because of their inhospitable environment. In a new study, researchers have discovered how a system of proteins, called TamAB, helps Salmonella survive under the harsh conditions inside macrophages.

Salmonella is a foodborne pathogen that causes more than a million infections each year in the U.S. Concerningly, it can kill young, old, and immunocompromised individuals. What makes these bacteria especially dangerous is their ability to evade our immune responses.
Macrophages are designed to kill bacteria by spraying them with antibacterial products, exposing them to acidic environments, and withholding magnesium, all of which target the outer layers of the bacteria. Salmonella, however, has evolved mechanisms to survive and grow in this environment.
Under normal conditions, Salmonella uses a complex called Bam to assemble certain proteins that are transported to its outer membrane layer. In previous studies, the group have shown that inside macrophages, the complex is compromised and, as a result, Salmonella depends on the PhoPQ system to sense the environment and orchestrate necessary changes in the outer membrane.
Studies in other bacteria have shown that the TamAB complex performs similar functions to Bam, which led the researchers of the present study to ask whether it might be important in Salmonella. They found that the genes that were responsible for producing TamAB were being controlled by PhoPQ.
""We knew from other studies that TamA was similar to BamA in its structure. When we realized that PhoPQ was controlling this TamAB complex, we hypothesized that the Bam complex struggles in the macrophage and TamA is induced by PhoPQ to help,"" said James Slauch (IGOH), a professor of microbiology.
To test their hypothesis, the researchers first removed TamAB from Salmonella. To their surprise, these mutants were still able to cause an infection in mice. However, when they also crippled the Bam complex, the mutants that lacked TamAB struggled.

The researchers also saw similar results when they recreated the macrophage-like conditions in test tubes and tested the different Salmonella mutants. They observed that mutants that lacked both the Bam and TamAB complexes were sensitive to vancomycin. This result is particularly intriguing because vancomycin is not used to treat Salmonella since it can't cross the outer membrane. This sensitivity suggests that the two complexes have a function in creating or maintaining the outer membrane, although the mechanism is not clear.
""Basically, TamAB helps create favorable conditions for the Bam complex to work but it's indirect,"" said Yekaterina Golubeva, a research scientist in the Slauch lab.
It is still unclear what the indirect effect might be. ""The problem is that studying the outer membrane is complicated because everything is interconnected. If you mess up the Bam complex, it disrupts additional machineries required for synthesis of the outer membrane. As a result, understanding the contributions of these proteins is difficult,"" Slauch said.
Nonetheless, the researchers are now interested in figuring out how TamAB helps. To do so, they will be using suppressor mutants that have accumulated different types of mutations that can help them grow even if their Bam and Tam complexes are defective, providing insights into Salmonella's outer membrane structure and function.
""There are efforts underway in biotechnology companies that are targeting the Bam complex as a way to treat Salmonella infections,"" Slauch said. ""Understanding the structure of the outer membrane when Salmonella is in a macrophage can help us understand what will affect its sensitivity to drugs and our results with vancomycin is consistent with that.""
The study ""TamAB is regulated by PhoPQ and functions in outer membrane homeostasis during Salmonella pathogenesis"" was published in the Journal of Bacteriology. The work was funded by the National Institutes of Health.

","score: 13.345396624472574, grade_level: '13'","score: 14.203459915611816, grade_levels: ['college_graduate'], ages: [24, 100]",10.1128/jb.00183-23,"Salmonella survive and replicate in macrophages, which normally kill bacteria by exposing them to a variety of harsh conditions and antimicrobial effectors, many of which target the bacterial cell envelope. The PhoPQ two-component system responds to the phagosome environment and induces factors that protect the outer membrane, allowing adaptation and growth in the macrophage. We show that PhoPQ induces the transcription of the tamAB operon both in vitro and in macrophages. The TamA protein is structurally similar to BamA, an essential protein in the Bam complex that assembles β-barrel proteins in the outer membrane, while TamB is an AsmA-family protein implicated in lipid transport between the inner and outer membranes. We show that the Bam machinery is stressed in vitro under low Mg 2+ , low pH conditions that mimic the phagosome. Not surprisingly, mutations affecting Bam function confer significant virulence defects. Although loss of TamAB alone confers no virulence defect, a tamAB deletion confers a synthetic phenotype in bam mutant backgrounds in animals and macrophages, and in vitro upon treatment with vancomycin or sodium dodecyl sulfate. Mutations affecting YhdP, which functions in partial redundancy with TamB, also confer synthetic phenotypes with bam mutations in the animal, but this interaction is not evident in vitro . Thus, in the harsh phagocytic environment of the macrophage, the outer membrane Bam machinery is compromised, and the TamAB system, and perhaps other PhoPQ-regulated factors, is induced to compensate. It is most likely that TamAB and other systems assist the Bam complex indirectly by affecting outer membrane properties. The TamAB system has been implicated in both outer membrane protein localization and phospholipid transport between the inner and outer membranes. We show that the β-barrel protein assembly complex, Bam, is stressed under conditions thought to mimic the macrophage phagosome. TamAB expression is controlled by the PhoPQ two-component system and induced in macrophages. This system somehow compensates for the Bam complex as evidenced by the fact that mutations affecting the two systems confer synthetic phenotypes in animals, macrophages, and in vitro in the presence of vancomycin or SDS. This study has implications concerning the role of TamAB in outer membrane homeostasis. It also contributes to our understanding of the systems necessary for Salmonella to adapt and reproduce within the macrophage phagosome."
"
Pancreatic cancer presents a challenging prognosis, marked by a five-year overall survival rate of merely 12.5%. Diagnosis frequently occurs at an advanced stage, characterized by metastasis to distant sites. The intricate molecular mechanisms governing pancreatic cancer metastasis remain a subject of ongoing research and exploration. In a recent article published in Nature Communications, Moffitt Cancer Center researchers, in collaboration with The Tisch Cancer Institute; St. Jude Children's Research Hospital; the Agency for Science, Technology and Research in Singapore; and the University of Otago in New Zealand, demonstrate that deregulation of a protein called RBFOX2, involved in RNA splicing, contributes to the progression and metastasis of pancreatic cancer.

RNA is a nucleic acid that promotes the synthesis of proteins. While the nucleotide sequence of RNA is encoded by the DNA of the genome, RNA molecules undergo several modifications before eventually entering the ribosome to make protein. An important process that modifies RNA sequences is alternative splicing, whereby specific sequences within the RNA molecule may be rearranged, included or excluded. This process results in different versions of RNA molecules generated from a single DNA sequence that will produce protein variants with potentially different activities. Alternative RNA splicing is critical for many cellular processes; however, the involvement of alternative RNA splicing in cancer development is not entirely understood.
The research team wanted to assess whether alternative RNA splicing is involved in the development and progression of pancreatic cancer. Through molecular-based laboratory experiments and mouse models, they discovered that RNA-binding proteins involved in splicing regulation were involved in pancreatic cancer progression. One of the key proteins they identified is RBFOX2.
Results showed RBFOX2 protein levels were lower in pancreatic cancer cells that had metastasized to other sites. These observations suggest that RBFOX2 may be a tumor suppressor protein that normally functions to inhibit cancer metastasis. The researchers confirmed this hypothesis by demonstrating that loss of RBFOX2 in pancreatic cell lines and mouse models increased cell migration, invasion, tumor development and metastasis.
The researchers performed additional experiments to determine the downstream pathways impacted by RBFOX2 that lead to pancreatic cancer progression. They found that RBFOX2 regulates the splicing of RNA molecules that code for proteins involved in cytoskeletal remodeling, with one of the critical molecules being RNA that codes for the protein ABI1. In cells without RBFOX2, the location of ABI1 is redistributed to the cell periphery, where it impacts the cell cytoskeleton and promotes cell migration.
These combined observations demonstrate the importance of alternative RNA splicing to pancreatic cancer progression and suggest the need for additional studies to understand the mechanisms regulating RBFOX2 splicing activity fully.
""While analyses to date have identified few splicing regulators with prognostic implications in pancreatic cancer, the incidence of exon splicing events conserved across pancreatic tumors and other cancers suggests the processes regulated by alternatively spliced transcripts are integral to cancer progression,"" said Karen Mann, Ph.D., assistant member of the Department of Molecular Oncology at Moffitt.
This study was supported by a Skip Viragh Career Development Award from the Pancreatic Cancer Action Network, the National Cancer Institute (R01CA279713, R01CA244780, R01CA244780, R03CA270679, R61CA278402, P30 CA196521), the Irma T. Hirschl Trust, the Emerging Leader Award from the Mark Foundation and the Ramon Areces Foundation.

","score: 17.39036214851571, grade_level: '17'","score: 19.182182467136762, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44126-w,"RNA splicing is an important biological process associated with cancer initiation and progression. However, the contribution of alternative splicing to pancreatic cancer (PDAC) development is not well understood. Here, we identify an enrichment of RNA binding proteins (RBPs) involved in splicing regulation linked to PDAC progression from a forward genetic screen using Sleeping Beauty insertional mutagenesis in a mouse model of pancreatic cancer. We demonstrate downregulation of RBFOX2, an RBP of the FOX family, promotes pancreatic cancer progression and liver metastasis. Specifically, we show RBFOX2 regulates exon splicing events in transcripts encoding proteins involved in cytoskeletal remodeling programs. These exons are differentially spliced in PDAC patients, with enhanced exon skipping in the classical subtype for several RBFOX2 targets. RBFOX2 mediated splicing of ABI1, encoding the Abelson-interactor 1 adapter protein, controls the abundance and localization of ABI1 protein isoforms in pancreatic cancer cells and promotes the relocalization of ABI1 from the cytoplasm to the periphery of migrating cells. Using splice-switching antisense oligonucleotides (AONs) we demonstrate the ABI1 ∆Ex9 isoform enhances cell migration. Together, our data identify a role for RBFOX2 in promoting PDAC progression through alternative splicing regulation."
"
A Johns Hopkins Children's Center study of children and youth with diabetes concludes that so-called autonomous artificial intelligence (AI) diabetic eye exams significantly increase completion rates of screenings designed to prevent potentially blinding diabetes eye diseases (DED). During the exam, pictures are taken of the backs of the eyes without the need to dilate them, and AI is used to provide an immediate result.

The study noted that the AI-driven technology used in the exams may close ""care gaps"" among racial and ethnic minority youth with diabetes, populations with historically higher rates of DED and less access to or adherence with regular screening for eye damage.
In a report on the study published Jan. 11 in Nature Communications, investigators examined diabetic eye exam completion rates in people under age 21 with type 1 and type 2 diabetes, and found that 100% of patients who underwent AI exams completed the eye assessment.
DED primarily refers to diabetic retinopathy, a potentially blinding complication of diabetes that occurs when poorly controlled sugar levels cause the overgrowth of, or damage to, blood vessels and nerve tissues in the light-sensitive retina at the back of the eye. According to the study researchers, retinopathy affects between 4% and 9% of youth with type 1 diabetes, and 4% to 15% of youth with type 2 diabetes. About 238,000 children, adolescents and young adults under age 20 are estimated to have diagnosed diabetes, according to the American Diabetes Association. Frequent screenings for DED facilitate early detection and treatment, and can help prevent progression of DED.
Generally, diabetes specialists and eye doctors recommend annual screenings, which typically require an additional, separate visit to an eye care provider, such as an optometrist or ophthalmologist, and the use of drops to dilate the pupil so that a clear view of the retina is visible through specialized instruments. However, studies show only 35% to 72% of youth with diabetes undergo recommended screenings, with even higher care gap rates among minority and poor youth. Previous studies also show that barriers to screenings include confusion about the need for screenings, inconvenience, and lack of time, access to specialists and transportation.
Previous studies by Risa Wolf, M.D., a pediatric endocrinologist at Johns Hopkins Children's Center, and her team have found autonomous AI screening that uses cameras produce results that enable accurate DED diagnosis.
In the new study, researchers enrolled 164 participants, ranging in age from 8 to 21 years and all from the Johns Hopkins Pediatric Diabetes Center, between Nov. 24, 2021, and June 6, 2022. Some 58% were female and 41% were from minority groups (35% Black; 6% Hispanic). Some 47% of participants had Medicaid insurance. The subjects were randomly assigned to one of two groups. A group of 83 patients received the standard screening instructions and care, and were referred to either an optometrist or ophthalmologist for an eye exam. A second group of 81 patients underwent a five-to-10-minute autonomous AI system diabetic eye exam during a visit to their endocrinologist (the specialists who typically care for people with diabetes), and received their results at the same visit.

The AI system takes four pictures of the eye without dilation, and runs the images through an algorithm that determines the presence or absence of diabetic retinopathy, Wolf says. If it is present, a referral is made to an eye doctor for further evaluation. If it is absent, ""you're good for the year, and you just saved yourself time,"" she adds.
Researchers found that 100% of patients in the group offered the autonomous AI screening completed their eye exam that day, while 22% of patients from the second group followed through within six months to complete an eye exam with an optometrist or ophthalmologist. The researchers found no statistical differences based on race, gender or socioeconomic status for whether participants in the second group scheduled the separate screening with an eye doctor.
The researchers also found that 25 out of 81 participants, or 31%, in the autonomous AI group had a result indicating that DED was present. Sixteen of those participants, or 64%, followed through in scheduling a secondary appointment with an eye care provider. Further analysis showed those who did not schedule the appointment were more likely to be Black and have Medicaid insurance.
""With AI technology, more people can get screened, which could then help identify more people who need follow-up evaluation,"" says Wolf. ""If we can offer this more conveniently at the point of care with their diabetes doctor, then we can also potentially improve health equity, and prevent the progression of diabetic eye disease.""
The investigators caution that the autonomous AI used in their study is not approved by the U.S. Food and Drug Administration for those under 21 years old. And they say a potential source of bias in the study was that some of the participants were familiar with autonomous AI diabetic eye exams from a prior study, and therefore may have been more willing to participate in the new one.
Along with Wolf, the study authors from Johns Hopkins include Alvin Liu, Anum Zehra, Lee Bromberger, Dhruva Patel, Ajaykarthik Ananthakrishnan, Elizabeth Brown, Laura Prichett and Harold Lehmann. Other authors are Roomasa Channa from University of Wisconsin and Michael D. Abramoff from the University of Iowa.
The study was funded by the National Eye Institute of the National Institutes of Health (Award Number R01EY033233) and the Diabetes Research Connection.
The authors associated with The Johns Hopkins University declared no conflicts of interest related to this press release.

","score: 14.92755850727388, grade_level: '15'","score: 16.277599620493355, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44676-z,"Diabetic retinopathy can be prevented with screening and early detection. We hypothesized that autonomous artificial intelligence (AI) diabetic eye exams at the point-of-care would increase diabetic eye exam completion rates in a racially and ethnically diverse youth population. AI for Children’s diabetiC Eye ExamS (NCT05131451) is a parallel randomized controlled trial that randomized youth (ages 8-21 years) with type 1 and type 2 diabetes to intervention (autonomous artificial intelligence diabetic eye exam at the point of care), or control (scripted eye care provider referral and education) in an academic pediatric diabetes center. The primary outcome was diabetic eye exam completion rate within 6 months. The secondary outcome was the proportion of participants who completed follow-through with an eye care provider if deemed appropriate. Diabetic eye exam completion rate was significantly higher (100%, 95%CI: 95.5%, 100%) in the intervention group (n = 81) than the control group (n = 83) (22%, 95%CI: 14.2%, 32.4%)(p < 0.001). In the intervention arm, 25/81 participants had an abnormal result, of whom 64% (16/25) completed follow-through with an eye care provider, compared to 22% in the control arm (p < 0.001). Autonomous AI increases diabetic eye exam completion rates in youth with diabetes."
"
As they grow, children increasingly focus their attention on social elements in their environment, such as faces or social interactions. However, children with autism are often more interested in non-social stimuli, such as textures or geometric shapes. By tracking where children look while viewing a cartoon, a team from the University of Geneva (UNIGE) has revealed that attention in autistic children does not follow the same developmental trajectory as that of typically developing children. Instead, they each gradually develop their own unique attentional preferences. These results, published in eLife, argue in favour of early interventions aimed at enhancing social attention, which could help guide autistic children onto developmental courses more akin to their peers, paving the way for tailored, individualized support.

Right from birth, babies are endowed with innate abilities that are crucial for their survival and adaptation. Among these innate abilities is a complex attentional system, finely tuned to detect the presence of others. Thus, from the very beginning of their lives, newborns show fascination for faces and face-like configurations, especially moving ones. Such preference for biological movement early in life is vital for development, serving as the primary driver of exploration and interaction with the environment, eventually setting the stage for more complex social interactions.
This fundamental, widely shared social attention can, however, be impaired in children with autism spectrum disorders (ASD). This highly diverse neurodevelopmental condition is characterized by repetitive behaviors and specific interests accompanied by significant challenges in communication and social interactions.
Eye-tracking
Are these social challenges expressed in the same way in all children with ASD? Do they vary according to the intensity of the disorder and/or age? Using an eye-tracking device that records eye movements in real time, a UNIGE team analysed the visual preferences of 166 children with ASD and 51 typically developing children (TD) while they freely viewed a short cartoon. The participants, all boys for sample homogeneity, ranged from two to seven years old, and were repeatedly tested as they developed.
''Each child watched a three-minute cartoon featuring a little donkey in various social situations, without any specific instructions. This was not a cartoon specially designed for our study, but rather one that is very popular among children in this age group,'' explains Nada Kojovic, a postdoctoral scholar in the Department of Psychiatry at the UNIGE Faculty of Medicine and first author of the study.
Desynchronised attention in ASD
Typically developing children are observed to focus their attention on social interactions between characters, and as they grow older, to increasingly look at the very same social elements in a scene. This phenomenon of ''synchronisation'' observed in typically developing children is absent in ASD children. The latter show an interest in other types of stimuli -- such as objects or certain irregularities in the cartoon scenery -- and over time each ASD child develops his or her own unique visual preferences.

''It is likely that we could identify sub-groups with common preferences among ASD children, but there is no real synchronisation of attention over the course of their development, unlike what is observed in TD children. This is the first time that a study has highlighted this developmental phenomenon,'' states Daphné Bavelier, a full professor in the Psychology Section of the UNIGE's Faculty of Psychology and Educational Sciences, and a co-author of the study.
The researchers also observed that the autistic children whose gaze was most alike that of typically developing ones function better in everyday life and have better cognitive skills. And crucially, the way in which a child views a social scene, such as the cartoon used here, can be used to predict future social difficulties.
In favour of early intervention
''These findings show how important it is for therapeutic interventions to target social attention at a very early stage in ASD children, especially those with the greatest developmental delay. Indeed, this work shows that if autistic children do not show interest in social interactions early on, they will become increasingly disinterested in them,'' explains Marie Schaer, associate professor in the Department of Psychiatry at the UNIGE Faculty of Medicine, who led this research.
Moving forward, the UNIGE research team plans to apply its eye-tracking method to evaluate children who have benefited from a behavioural intervention known as the Early Start Denver Model (ESDM). This intensive behavioural intervention, developed in the United States, is designed to enhance communication skills in young autistic children through playful interactions. Since 2012, over a hundred autistic children under the age of three have benefited from this method in Geneva, showing encouraging outcomes. The researchers hope that their innovative eye-tracking technique will shed light on how this behavioural intervention contributes to the progress of ASD children, providing a unique tool to to improve on strategies for supporting their development.

","score: 16.53635220125786, grade_level: '17'","score: 17.763509433962263, grade_levels: ['college_graduate'], ages: [24, 100]",10.7554/eLife.85623,"Atypical deployment of social gaze is present early on in toddlers with autism spectrum disorders (ASDs). Yet, studies characterizing the developmental dynamic behind it are scarce. Here we used a data-driven method to delineate the developmental change in visual exploration of social interaction over childhood years in autism. Longitudinal eye-tracking data were acquired as children with ASD and their typically developing (TD) peers freely explored a short cartoon movie. We found divergent moment-to-moment gaze patterns in children with ASD compared to their TD peers. This divergence was particularly evident in sequences that displayed social interactions between characters and even more so in children with lower developmental and functional levels. The basic visual properties of the animated scene did not account for the enhanced divergence. Over childhood years, these differences dramatically increased to become more idiosyncratic. These findings suggest that social attention should be targeted early in clinical treatments."
"
As global life expectancies rise, the World Health Organization projects that by 2050, the global population aged 60 years and older will double to 2.1 billion from 1 billion in 2020 -- a trend particularly notable in Japan, which has the highest percentage of people aged 65 years and older. In 2022, 29.1% of the population was 65 years or older (expected to rise to 34.8% by 2040). The increase in the aging population comes with new health challenges, such as the need to assess muscular health.

""The loss of muscle mass and strength could lead to a higher risk of falls, inactivity, confinement to bed, and metabolic problems,"" says Professor Ryota Akagi from Shibaura Institute of Technology, who has been researching ways to quickly and non-invasively measure muscle response and coordination.
Now, Prof. Akagi, along with Dr. Kosuke Hirata from the University of Tsukuba; Dr. Yosuke Yamada from the National Institutes of Biomedical Innovation, Health and Nutrition; and Dr. Tsukasa Yoshida from the National Institutes of Biomedical Innovation have shown that bioelectrical impedance analysis (BIA), a technique widely used to assess body composition can also be used for measuring voluntary and evoked muscle contractions, which are integral to our ability to move, maintain stability, and respond to external stimuli. Their study lays the foundations for a convenient muscular health monitoring system; the corresponding findings were published on 23 November 2023 in Volume 14 of the journal Frontiers in Physiology.
BIA involves sending a safe electrical current through the body and measuring the impedance, characterized by resistance and reactance, where higher water and electrolyte concentrations lead to lower resistance and healthy cell membranes show higher reactance; these components are represented as phase angles calculated as a ratio of reactance and resistance [arctangent (reactance/resistance) × (180°/π)], where larger angles indicate higher muscle content.
To explore if the phase angle can serve as an indicator for other neuromuscular factors, the researchers examined its relationship with the neuromuscular properties of the leg, including a rapid force generation ability, intrinsic contractile properties, and overall neuromuscular activity in the plantar flexors of 60 participants aged 21-83 years.
Plantar flexors are a group of muscles located in the calf region and are essential for walking, running, jumping, and maintaining balance. ""We aimed to clarify the association of phase angle obtained from the leg using BIA with voluntary muscle strength, twitch contractile properties, and neuromuscular activity,"" says Assistant Prof. Hirata.
Muscle strength is the maximum force that muscles can generate during a voluntary contraction, while twitch contractile refers to how a muscle responds to an electrical stimulus. These measurements represent the ability of a muscle to contract, generate force, and contribute to movement. The findings revealed that the leg phase angle could estimate muscle contractile properties. Individuals with larger phase angles had better muscle function and generated more force. However, the researchers did not observe any between phase angle and neuromuscular activity.
These results indicate that the phase angle can be a valuable tool for estimating muscular health among individuals -- such a system could find use in weight scales for a quick and easy physical assessment.
""Because phase angle can be measured even by impedance analyzer for home use, such as weighing scales with body composition analyzer, phase angle may be the way to monitor muscular health easily and quickly. If possible, segment-level phase angle measurement can be conducted even by impedance analyzer for home use,"" says Prof. Akagi.
As the population ages and conditions like sarcopenia, involving muscle loss, become more prevalent, insights into muscular health will assist individuals in taking proactive measures and enable countries to develop policies prioritizing the muscular health of the older population.

","score: 18.738856682769725, grade_level: '19'","score: 20.525100432240016, grade_levels: ['college_graduate'], ages: [24, 100]",10.3389/fphys.2023.1292778,"Introduction: Bioelectrical impedance analysis (BIA) can noninvasively and quickly assess electrical properties of the body, such as the phase angle. Phase angle is regarded as the quantity and/or quality of skeletal muscle and is associated with exercise performance, such as jump height and walking speed. Although the phase angle derived from BIA is assumed to be a useful way to assess muscle function, the relationship between the phase angle and neuromuscular properties has not been fully investigated. The purpose of this study was to investigate the association of phase angle with voluntary and evoked contractile properties in 60 adults (age, 21–83 years; 30 females and 30 males). Methods: The phase angle of the right leg at 50 kHz was evaluated using BIA. The twitch contractile properties (peak twitch torque [PTtwitch], rate of twitch torque development [RTDtwitch], and time-to-PTtwitch [TPTtwitch]) of the plantar flexors were measured using tibial nerve electrical stimulation. Maximal voluntary isometric contractions (MVICs) were performed to measure the maximal muscle strength and explosive muscle strength, from which the peak MVIC torque (PTMVIC) and rate of torque development (RTD) over a time interval of 0–200 ms were assessed, respectively. The root mean square (RMS) values of electromyographic (EMG) activity during the PTMVIC and RTD measurements (EMG-RMSMVIC and EMG-RMSRTD, respectively) were calculated. The RTD and EMG-RMSRTD were normalized using PTMVIC and EMG-RMSMVIC, respectively. Results and discussion: Phase angle significantly correlated with twitch contractile properties (|r| ≥ 0.444, p &lt; 0.001), PTMVIC (r = 0.532, p &lt; 0.001), and RTD (r = 0.514, p &lt; 0.001), but not with normalized RTD (r = 0.242, p = 0.065) or normalized EMG-RMSRTD (r = −0.055, p = 0.676). When comparing measurement variables between the low- and high-phase angle groups while controlling for sex and age effects, the high-phase angle group showed greater PTtwitch, RTDtwitch, PTMVIC, and RTD (p &lt; 0.001) and shorter TPTtwitch (p &lt; 0.001) but not normalized RTD (p = 0.184) or normalized EMG-RMSRTD (p = 0.317). These results suggest that the leg phase angle can be an indicator of voluntary and evoked muscle contractile properties but not the neuromuscular activity of the plantar flexors, irrespective of sex and age."
"
Researchers at The University of Texas at El Paso have identified a novel pharmaceutical compound that successfully kills leukemia and lymphoma cancer cells, potentially paving the way for new forms of therapy.

Renato Aguilera, Ph.D., a professor in the Department of Biological Sciences, is the principal investigator on the project that identified the promising compound, called thiophene F-8. His team's findings were recently published in the research journal PLOS One.
""The main goal of my research is to discover new anticancer drugs that can eventually treat distinct cancer types,"" Aguilera explained. ""This research not only had amazing results, it also led to the training of five Ph.D. students who are now working as postdoctoral fellows in research laboratories across the nation.""
Leukemia is a cancer of the blood cells while lymphoma is a cancer of the immune system. As part of their research into potential treatment of these cancers, Aguilera's lab screened drug compounds to determine their impact on various cancer cell types. Pharmaceutical companies generate millions of compounds and their full range of uses is often unclear or unknown, Aguilera said. Some of these companies sell the generated compounds as chemical libraries, which researchers like Aguilera can then study to determine the precise effect of the compounds on human cells.
""The hardest part of this kind of research is figuring out what exactly a drug does,"" said Aguilera who also serves as director of the Research Infrastructure Core of UTEP's Border Biomedical Research Center.
As part of the project, the UTEP team tested 1,300 different compounds on cultures of human cancer cells. Thiophene F-8 was very successful at inducing programmed cell death in the leukemia and lymphoma cells, essentially sending a message to the cells causing them to kill themselves and inhibiting the growth of new cancer cells.
Mia Swain, Ph.D., helped discover and conduct research on thiophene F-8 as a doctoral student at UTEP. Swain graduated from UTEP in December of 2022 with a doctoral degree in biological sciences and is currently a postdoctoral fellow at Texas Tech University Health Sciences Center El Paso.
""Engaging in such a groundbreaking discovery has been truly fulfilling,"" Swain said. ""The compound's potential to work in conjunction with existing therapies could be life-changing for leukemia and lymphoma patients.""
The UTEP team will continue studying the effectiveness of Thiophene F-8. If the drug is successful in further testing, Aguilera said, pharmaceutical companies may one day launch clinical studies to determine the compound's effect on patients.

","score: 13.765967365967366, grade_level: '14'","score: 14.640512820512825, grade_levels: ['college_graduate'], ages: [24, 100]",10.1371/journal.pone.0295441,"In an effort to identify novel anti-cancer agents, we employed a well-established High Throughput Screening (HTS) assay to assess the cytotoxic effect of compounds within the ChemBridge DIVERSet Library on a lymphoma cell line. This screen revealed a novel thiophene, F8 (methyl 5-[(dimethylamino)carbonyl]-4-methyl-2-[(3-phenyl-2-propynoyl) amino]-3-thiophenecarboxylate), that displays anti-cancer activity on lymphoma, leukemia, and other cancer cell lines. Thiophenes and thiophene derivatives have emerged as an important class of heterocyclic compounds that have displayed favorable drug characteristics. They have been previously reported to exhibit a broad spectrum of properties and varied uses in the field of medicine. In addition, they have proven to be effective drugs in various disease scenarios. They contain anti-inflammatory, anti-anxiety, anti-psychotic, anti-microbial, anti-fungal, estrogen receptor modulating, anti-mitotic, kinase inhibiting and anti-cancer activities, rendering compounds with a thiophene a subject of significant interest in the scientific community. Compound F8 consistently induced cell death at a low micromolar range on a small panel of cancer cell lines after a 48 h period. Further investigation revealed that F8 induced phosphatidylserine externalization, reactive oxygen species generation, mitochondrial depolarization, kinase inhibition, and induces apoptosis. These findings demonstrate that F8 has promising anti-cancer activity."
"
A new study by researchers at University of Limerick in Ireland has found high rates of anaemia among patients in the Irish health system, while screening for common causes was found to be low.

The research study carried out by a team at University of Limerick School of Medicine found that substantial numbers of men and women in the health system had anaemia, the presence of which is strongly associated with high rates of hospitalisation, death, and poor quality of life.
Anaemia (a low level of haemoglobin in the body) is a common but treatable condition that predicts adverse clinical outcomes. It affects nearly two billion people across the globe and is the third-leading cause of years with lived disability in the world.
While the study revealed a high burden of patients with the condition, it found that there were relatively low rates of screening for treatable causes of anaemia, including deficiencies in vitamin B12, folate, and iron, which highlights an important gap in care delivery programs and emphasises the need for quality improvement initiatives.
Prior to the large population-based study, the prevalence of anaemia and information on its underlying causes was largely unknown as data at the national or regional level was limited.
The research, published in the journal BJGP Open, is the largest study ever to explore the burden of anaemia and the extent of investigation for underlying common causes in Ireland.
The study found that 12% of Irish patients had anaemia with 1 in 8 women (13.2%) affected and 1 in 10 men (10.5%). Most of these patients were found to have had mild anaemia (9.1% of total), with moderate to severe anaemia present in the remaining 2.9%.

The percentage of patients with anaemia was particularly high in elderly patients, and in patients with underlying medical conditions such as kidney disease, diabetes and for patients undergoing treatment in specific clinical settings.
Despite the high burden of anaemia, less than 20% of anaemic patients were tested for deficiencies of vitamin B12 and folic acid, and only one third of all patients were screened for iron deficiency during follow-up.
Although there was some improvement in screening rates with increasing severity of anaemia, approximately 50% of patients with severe anaemia did not undergo screening.
""This is the largest study to address the magnitude of anaemia and the extent to which it is investigated in the Irish health system,"" according to senior investigator Professor Austin Stack, Foundation Chair of Medicine at UL's School of Medicine and Consultant Nephrologist, University Hospital Limerick.
""Our study reveals a significant burden of anaemia that was present in several high-risk groups, including patients with diabetes, chronic kidney disease, and the elderly. The prevalence of anaemia increased exponentially in older men and women, highlighting their increased vulnerability.
""Patients with advanced kidney disease had nearly eight-fold higher prevalence compared to patients with normal kidney function. Patients who attended the emergency room, outpatient departments or admitted to hospital were found to be particularly affected, with prevalence ranging from 18 % to 29 %,"" Professor Stack explained.

Anaemia is a condition in which the body does not have enough healthy red blood cells or haemoglobin (an iron-rich protein) to carry oxygen to the cells around the body.
Haemoglobin is essential for red blood cells to carry oxygen from the lungs to the rest of the body. When someone suffers from anaemia, the body does not get enough oxygen in the blood, and this can cause tiredness, shortness of breath, and dizziness.
The researchers assembled a cohort of 112,181 patients using data from the National Kidney Disease Surveillance System to assess for anaemia and followed them for up to one year to explore the use of screening tests that check for iron deficiency, B12, and folate deficiency.
Co-author Dr Leonard Browne, Senior Research Fellow in Biostatistics at the UL School of Medicine, highlighted the low level of screening for treatable causes of anaemia.
""What is remarkable is that less than 20% of anaemic patients were screened for vitamin B12 and folate deficiency, and only one third were screened for iron deficiency at three-months follow-up,"" he explained.
""Despite some improvement with increasing severity of anaemia, approximately 50% of patients with severe anaemia did not undergo screening. Indeed, when we followed patients for up to 12 months, screening rates did increase although modestly for B12 and folate deficiency -- 30% -- and doubled for iron deficiency -- 46%. These findings reveal that common causes of anaemia are inadequately tested for in the wider health system especially among high-risk groups.""
Professor Stack emphasised the importance of screening for and identifying the underlying cause of anaemia.
""We found that one in three patients had evidence of absolute iron deficiency, 6.3% had B12 deficiency, and a further 5.8% were folate deficient. All these deficiencies are easily treated in modern day clinical practice leading to significant improvement in the degree of anaemia. This study provides a valuable starting point from which we can begin to understand practice patterns in care delivery and the development of quality improvement programmes in the health system.
""Iron deficiency is the main cause of anaemia affecting women more than men. The findings from our study correlate well with the international body of evidence, which shows that investigation of anaemia subtype is uncommon and that the standards of anaemia management vary considerably,"" Professor Stack added.
The research was funded by the Health Research Board (HRB) and Dr Mairéad O'Driscoll, Chief Executive of the HRB said: ""Professor Stack's research is a really nice example of how intelligent and targeted secondary-data analysis can make important contributions to our knowledge base. The data-driven insights from his work have obvious potential to inform and improve health service delivery.
""The HRB is committed to working with all of our partners to advance the use of primary and secondary data to enhance health policy, to improve healthcare delivery and to drive innovation in our health services.""

","score: 15.95854334431867, grade_level: '16'","score: 17.302967473850124, grade_levels: ['college_graduate'], ages: [24, 100]",10.3399/BJGPO.2023.0126,"Anaemia is a common but treatable condition that predicts adverse clinical outcomes. Estimate the prevalence of anaemia and extent of screening for common underlying causes in the Irish healthcare system. We conducted a retrospective cohort study of 112,181 adult patients, age ≥18 years who had a full blood count performed in 2013 using data from the National Kidney Disease Surveillance System. The prevalence of anaemia was determined across demographic and clinical subgroups according to World Health Organisation definitions. The proportion screened for iron, vitamin B12 and folate deficiency was determined within a 3-month follow-up period and the corresponding prevalence for each deficiency determined. The overall prevalence of anaemia was 12.0% (95%CI 11.8–12.2) and was higher in women than men (13.2% vs 10.5%,P<0.001). Anaemia increased with advancing age (40.1% for those >80 years) and worsening kidney function (8.2%, 10.9%, 33.2% and 63.8% for each eGFR categories >90, 60–89, 30–59 and <30 mL/min/1.73 m² respectively,P<0.001). After 3-months follow-up, the proportion screened for iron deficiency was 11.2% based on transferrin saturation and 33.7% using serum ferritin. Screening for folate and B12 deficiency was 17.6% and 19.8% respectively. Among screened patients, the prevalence of iron deficiency, B12 and folate deficiency was 37%, 6.3%, and 5.8% respectively. The burden of anaemia in the healthcare system is substantial especially for elderly patients and those with advanced kidney disease. Low screening rates for iron, B12 and folate deficiency are common and warrant quality improvement initiatives."
"
Data from the St. Jude lifetime cohort study (St. JudeLIFE) revealed that two common biomarkers of cardiac function and damage could better predict cardiomyopathy within five years than routine clinical evaluations in high-risk, asymptomatic childhood cancer survivors. Early detection through screening using these two biomarkers may lead to earlier treatment to prevent and protect against further heart damage. The findings were published today in the Journal of Clinical Oncology.

Cardiomyopathy is often asymptomatic at onset and thus ""invisible"" to routine clinical evaluations. St. Jude Children's Research Hospital scientists found that two common biomarkers, global longitudinal strain (GLS) and N-terminal-pro-B-type natriuretic peptide (NT-proBNP), could identify survivors with otherwise normal appearing heart function who are at elevated risk of decline in heart muscle function.
""This may be a much more sensitive way to identify childhood cancer survivors that might benefit from intervention at an earlier stage,"" said first and corresponding author Matthew Ehrhardt, MD, MS, St. Jude Department of Oncology. ""We were somewhat surprised by the magnitude of risk for declining heart function over such a relatively short period in individuals with abnormal GLS and NT-proBNP, suggesting a need for early and effective interventions that we hope will prevent progression to heart failure over time.""
The results showed an increase in predicting asymptomatic heart damage in patients treated with potent anthracycline chemotherapy drugs, such as doxorubicin. The study found that these biomarkers did not improve prediction models in patients who only received radiation. This knowledge may help physicians limit testing to only anthracycline-exposed survivors, saving time and resources while maximizing utility.
""This means doing more for patients at greatest risk while avoiding unnecessary tests for patients who will not benefit from them,"" Ehrhardt said.
Two signs point to invisible heart problems 
The key to helping survivors with asymptomatic cardiomyopathy is to detect dysfunction early. Cardiac function is typically assessed using echocardiograms, which look at the volume of blood pumped through part of the heart. The most common measure of that volume is called left ventricular ejection fraction. Many childhood cancer survivors appear to have a normal ejection fraction, only to later develop cardiomyopathy. Findings showed that even in survivors with normal ejection fraction, abnormal GLS and NT-proBNP improved the ability to predict cardiomyopathy risk.

""A survivor with a normal ejection fraction at baseline with abnormal ranges of both biomarkers was at a fourfold increased risk for a worsening ejection fraction in the next five years,"" Ehrhardt said.
GLS is an additional measure of heart function obtained from an echocardiogram. GLS is more sensitive for detecting cardiac muscle injury than the traditionally reported ejection fraction. It is a software-derived mathematical estimation of the heart muscle fibers' ability to contract, rather than the more rudimentary measure of ejection fraction, or blood volume pumped at a specific time. An institution that performs echocardiograms to measure ejection fraction can theoretically also routinely measure GLS.
NT-proBNP is a serum biomarker, a chemical released into the bloodstream in greater quantities when the heart is injured or overworked. It is frequently used in adult cardiac patients to identify potential heart injury and is thus widely available, though its application in pediatric oncology is relatively novel.
Practical measures to predict and protect the heart earlier 
""One of the promising aspects of our findings is that both of these measures are readily available and, therefore, have the potential to impact care more immediately. Most cardiologists are already using GLS,"" Ehrhardt said, ""and NT-proBNP has been around for a long time.""
Together, these two common and easy-to-implement measures may help identify survivors at elevated risk of cardiomyopathy earlier, leading to earlier therapeutic interventions. Early detection helps protect against cardiac damage in adults with other diseases; it may extend the same benefits to childhood cancer survivors.

""The exciting part of this study is that it potentially helps to identify a population that we would have otherwise looked at and said, 'You're at risk for abnormal heart function, but everything looks good today. We'll reevaluate your heart in two to five years,'"" Ehrhardt said. ""Whereas now we have reason to believe those with abnormal biomarkers are a particularly high-risk group that may benefit from closer follow-up or more proactive interventions to reduce risk. The findings set the stage for future studies evaluating novel screening and early intervention strategies that we hope will ultimately improve survivors' cardiac health and well-being.""
Authors and funding 
The study's other authors are Qi Liu, University of Alberta; Isaac B. Rhea, University of Tennessee Health Science Center; Daniel Mulrooney, Stephanie Dixon, John Lucas, Yadav Sapkota, Kyla Shelton, Kirsten Ness, Deo Kumar Srivastava, Aaron McDonald, Leslie Robison, Melissa Hudson, Yutaka Yasui and Gregory Armstrong, of St. Jude.
The study was supported by grants from the National Cancer Institute (Cancer Center Support (CORE) grant (P30CA21765), U01CA195547 and R01CA216354) and ALSAC, the fundraising and awareness organization of St. Jude.

","score: 15.780038246543103, grade_level: '16'","score: 17.337105766401883, grade_levels: ['college_graduate'], ages: [24, 100]",10.1200/JCO.23.01796,"To leverage baseline global longitudinal strain (GLS) and N-terminal-pro-B-type natriuretic peptide (NT-proBNP) to identify childhood cancer survivors with a normal left ventricular ejection fraction (LVEF) at highest risk of future treatment-related cardiomyopathy. St Jude Lifetime Cohort participants ≥5 years from diagnosis, at increased risk for cardiomyopathy per the International Guideline Harmonization Group (IGHG), with an LVEF ≥50% on baseline echocardiography (n = 1,483) underwent measurement of GLS (n = 1,483) and NT-proBNP (n = 1,052; 71%). Multivariable Cox regression models estimated hazard ratios (HRs) and 95% CIs for postbaseline cardiomyopathy (modified Common Terminology Criteria for Adverse Events ≥grade 2) incidence in association with echocardiogram-based GLS (≥–18) and/or NT-proBNP (>age-sex-specific 97.5th percentiles). Prediction performance was assessed using AUC in models with and without GLS and NT-proBNP and compared using DeLong's test for IGHG moderate- and high-risk individuals treated with anthracyclines. Among survivors (median age, 37.6; range, 10.2-70.4 years), 162 (11.1%) developed ≥grade 2 cardiomyopathy 5.1 (0.7-10.0) years from baseline assessment. The 5-year cumulative incidence of cardiomyopathy for survivors with and without abnormal GLS was, respectively, 7.3% (95% CI, 4.7 to 9.9) versus 4.4% (95% CI, 3.0 to 5.7) and abnormal NT-proBNP was 9.9% (95% CI, 5.8 to 14.1) versus 4.7% (95% CI, 3.2 to 6.2). Among survivors with a normal LVEF, abnormal baseline GLS and NT-proBNP identified anthracycline-exposed, IGHG-defined moderate-/high-risk survivors at a four-fold increased hazard of postbaseline cardiomyopathy (HR, 4.39 [95% CI, 2.46 to 7.83]; P < .001), increasing to a HR of 14.16 (95% CI, 6.45 to 31.08; P < .001) among survivors who received ≥250 mg/m2 of anthracyclines. Six years after baseline, AUCs for individual risk prediction were 0.70 for models with and 0.63 for models without GLS and NT-proBNP ( P = .022). GLS and NT-proBNP should be considered for improved identification of survivors at high risk for future cardiomyopathy."
"
Compared to adult cancers, pediatric cancers often have distinctive genetic causes. This means there is an opportunity to develop pediatric-focused diagnostic strategies and treatments. Research by St. Jude Children's Research Hospital published today in Nature Genetics clarifies the genomic landscape of pediatric acute myeloid leukemia (pAML). The work offers novel insight into this cancer's causes and unique biological characteristics.

The findings establish 23 distinct molecular categories (including 12 categories not covered by the current classification systems) that can be used to classify cases of pAML on an individual basis. This marks a vital step towards understanding the molecular background and improving treatment strategies in the future. The classification of these cancers and appreciation of their uniqueness is not just a helpful tool for doctors to diagnose patients more accurately. It is also critical to identify the most effective therapeutic route and to ultimately save lives.
Identifying the blind spot 
Just over 4 per every 100,000 people develop AML yearly; the vast majority are adults. This conceals the effect of pediatric cases, which account for about 500 new cases each year. Due to this, a disparity in how we understand this cancer has grown. ""Most of what we know about classifications of AML really comes from the adult field,"" said Jeffery Klco, MD, PhD, St. Jude Department of Pathology. ""AML is more common in adults than it is in children.""
Klco, along with first authors Masayuki Umeda, MD, PhD, and Jing Ma, PhD, first demonstrated the unique features of pAML in 2022 with the discovery of a novel alteration in the UBTF gene.
""That put forth a new entity in pediatric AML that had not been described before,"" explained Klco. ""We decided to take a deeper dive into the overall classification of pediatric AML, recognizing that there are very significant differences between AML in adults and kids.""
To do this, they amassed a cohort of 887 unique pAML cases and examined what was driving the cancers through transcriptome and gene profiling.

""A lot of the types of AML that we see here at St. Jude, you just don't see in adults,"" Klco emphasized.
AML classification provides biological insight and potential clinical guidance 
The reasons why different features give rise to AML in children and adults have yet to be fully understood. The normal accumulation of mutations during aging may explain many adult AML cases. In contrast, fusion oncoproteins, aberrant proteins resulting in the fusion of two separate genes, are major drivers for many pAML cases and were shown to account for over 70% of cases in this new study. Although each molecular category has a unique driver, some show very similar transcriptional and mutational profiles, which stood out to the researchers. ""Some categories show very similar transcriptional profiles, indicating that the background biology is similar and can be potentially treated by similar drugs,"" said Umeda.
This work offers a clear path forward for clinicians to identify distinct pAML sub-types and for larger collaborative groups to define cancer more accurately. ""The World Health Organization [WHO] issued new classifications for hematological cancers in 2022, mostly based on adults,"" Klco explained. ""We recognized that many of the recurrent alterations we found in pAML aren't even mentioned. Some of these sub-types have a significant impact on outcomes.""
Correct classification will allow clinicians worldwide to understand their pAML patients better and offer guidance to treat cases as low-risk or high-risk. In fact, through their analysis, they determined a strong association between the new sub-types and clinical outcomes. ""The study definitely fills a lot of gaps in the current classification of pAML,"" Ma confirmed. ""It provides a risk stratification strategy that we hope will provide clinicians with a simpler road to accurate diagnosis and optimal treatment in the future.""
Authors and funding 
The study's other authors include Tamara Westover, Yonghui Ni, Guangchun Song, Jamie Maciaszek, Michael Rusch, Delaram Rahbarinia, Scott Foy, Michael Walsh, Priydarshini Kumar, Yanling Liu, Yiping Fan, Gang Wu, Xiaotu Ma, Lu Wang, Jeffrey Rubnitz, and Stanley Pounds of St. Jude; Benjamin Huang of the University of California San Francisco, Sharyn Baker of the Comprehensive Cancer Center, The Ohio State University, and Todd Alonzo of Keck School of Medicine, University of Southern California.
The study was supported by grants from The National Institutes of Health (P30 CA021765, Cancer Center Support Grant and Developmental Fund Award and U54 CA243124), the Fund for Innovation in Cancer Informatics, the Burroughs Wellcome Fund, the V Foundation, and ALSAC, the fundraising and awareness organization of St. Jude.

","score: 13.99571068290184, grade_level: '14'","score: 14.622867557236866, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41588-023-01640-3,"Recent studies on pediatric acute myeloid leukemia (pAML) have revealed pediatric-specific driver alterations, many of which are underrepresented in the current classification schemas. To comprehensively define the genomic landscape of pAML, we systematically categorized 887 pAML into 23 mutually distinct molecular categories, including new major entities such as UBTF or BCL11B, covering 91.4% of the cohort. These molecular categories were associated with unique expression profiles and mutational patterns. For instance, molecular categories characterized by specific HOXA or HOXB expression signatures showed distinct mutation patterns of RAS pathway genes, FLT3 or WT1, suggesting shared biological mechanisms. We show that molecular categories were strongly associated with clinical outcomes using two independent cohorts, leading to the establishment of a new prognostic framework for pAML based on these updated molecular categories and minimal residual disease. Together, this comprehensive diagnostic and prognostic framework forms the basis for future classification of pAML and treatment strategies."
"
Antibiotic overuse can lead to antibiotic resistance, but classic antibiotic resistance might not completely explain why antibiotics sometimes fail. Sub-populations of bacteria called persister cells are capable of surviving in the presence of lethal doses of antibiotics for prolonged periods. Although persister cells have been intensively researched, evidence linking them to poor patient outcomes has been limited.

Scientists led by UNC School of Medicine microbiologist Brian Conlon, PhD, and Duke School of Medicine infectious diseases fellow Josh Parsons, MD, PhD, have now shown that E. coli can evolve in patients to produce increased persister cells and this leads to increased survival to antibiotics. Publishing their work in the Proceedings of the National Academy of Sciences (PNAS), Conlon and colleagues used a combination of patient data, clinical isolates and animal models to show that persister cells contribute to antibiotic failure when classic antibiotic resistance does not explain such failure.
""For decades, many scientists around the world have studied persister formation, and we have continually been challenged to provide evidence for real-world importance,"" said Conlon, senior author and associate professor of microbiology and immunology. ""We think our paper is the strongest evidence supporting the importance of persister cells in the clinic.""
Scientists and doctors have been sounded the alarm that overusing antibiotics -- especially when doctors are not certain a patient is suffering from a bacterial infection -- is making our arsenal of antibiotics less effective, leading to what we call antibiotic resistance, a global concern.
But some scientists have long thought antibiotic failure might not be that simple and that additional factors were required to understand antibiotic treatment failure, particularly where antibiotic resistance was not identified. Some of these scientists study persister cells, which are sub-populations of bacteria that can withstand antibiotics for a prolonged period of time. Despite a wealth of scientific literature on the subject, Conlon said it remained unclear how much, if at all, this persister phenomenon contributed to antibiotic treatment failure in the clinic. Through a collaboration with Duke researchers Josh Thaden, MD, PhD, and Vance Fowler, Jr., MD, Conlon's lab decided to conduct stepwise research to investigate the possible role of persister cells in antibiotic failure.
Using clinical E. coli bacteremia isolates -- bacteria from the blood of patients -- Conlon, first author Joshua Parsons, MD, PhD, an infectious diseases fellow at Duke University, and colleagues found that high-persister mutants evolved in patients. The researchers then documented a 100-fold increase in persisters in one such mutant when challenged with the exact antibiotic doctors had used to treat patient from which the E. coli had been isolated.
The mutant bacteria showed no loss of fitness in a mouse infection model and displayed a 10-fold increase in survival following antibiotic challenge.

Importantly, Conlon said his team documented the infections and treatment protocols of patients who had been prescribed antibiotics to clear E. coli infections. In patients who did not clear infection with antibiotics, Conlon said that classical antibiotic resistance was not responsible for the poor outcomes.
""Because of this research, we think persister formation is likely a significant contributor to antibiotic treatment failure in patients,"" Conlon said. ""Our research strongly suggests that persister formation is an important metric to consider when treating patients with antibiotics.""
He also said that researchers should develop techniques to identify mutants that are likely to respond poorly to antibiotics because such information would influence treatment choices or duration of treatment. Additionally, the development of new therapeutic approaches to target and kill persisters may improve treatment outcomes in patients.
Along with Conlon and Parsons, authors of the PNAS paper are Ashelyn Sidders, Amanda Velez, Michelle Angeles-Solano, and Sarah Rowe at the UNC School of Medicine; Blake Hanson at the University of Texas Health Science Center; Felicia Ruffin, Joshua Thaden, and Vance Fowler Jr. at Duke University; and Cesar Arias at Cornell University.

","score: 17.5761829474873, grade_level: '18'","score: 19.703770468661773, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2314514121,"Gram-negative bacterial bloodstream infections (GNB-BSI) are common and frequently lethal. Despite appropriate antibiotic treatment, relapse of GNB-BSI with the same bacterial strain is common and associated with poor clinical outcomes and high healthcare costs. The role of persister cells, which are sub-populations of bacteria that survive for prolonged periods in the presence of bactericidal antibiotics, in relapse of GNB-BSI is unclear. Using a cohort of patients with relapsed GNB-BSI, we aimed to determine how the pathogen evolves within the patient between the initial and subsequent episodes of GNB-BSI and how these changes impact persistence. Using Escherichia coli clinical bloodstream isolate pairs (initial and relapse isolates) from patients with relapsed GNB-BSI, we found that 4/11 (36%) of the relapse isolates displayed a significant increase in persisters cells relative to the initial bloodstream infection isolate. In the relapsed E. coli strain with the greatest increase in persisters (100-fold relative to initial isolate), we determined that the increase was due to a loss-of-function mutation in the ptsI gene encoding Enzyme I of the phosphoenolpyruvate phosphotransferase system. The ptsI mutant was equally virulent in a murine bacteremia infection model but exhibited 10-fold increased survival to antibiotic treatment. This work addresses the controversy regarding the clinical relevance of persister formation by providing compelling data that not only do high-persister mutations arise during bloodstream infection in humans but also that these mutants display increased survival to antibiotic challenge in vivo."
"
Restricting calories is known to improve health and increase lifespan, but much of how it does so remains a mystery, especially in regard to how it protects the brain. Buck scientists have uncovered a role for a gene called OXR1 that is necessary for the lifespan extension seen with dietary restriction and is essential for healthy brain aging.

""When people restrict the amount of food that they eat, they typically think it might affect their digestive tract or fat buildup, but not necessarily about how it affects the brain,"" said Kenneth Wilson, Ph.D., Buck postdoc and first author of the study, published online on January 11, 2024 in Nature Communications. ""As it turns out, this is a gene that is important in the brain.""
The team additionally demonstrated a detailed cellular mechanism of how dietary restriction can delay aging and slow the progression of neurodegenerative diseases. The work, done in fruit flies and human cells, also identifies potential therapeutic targets to slow aging and age-related neurodegenerative diseases.
""We found a neuron-specific response that mediates the neuroprotection of dietary restriction,"" said Buck Professor Pankaj Kapahi , Ph.D., co-senior author of the study. ""Strategies such as intermittent fasting or caloric restriction, which limit nutrients, may enhance levels of this gene to mediate its protective effects.""
""The gene is an important brain resilience factor protecting against aging and neurological diseases,"" said Buck Professor Lisa Ellerby, Ph.D., co-senior author of the study.
Understanding variability in response to dietary restriction
Members of the team have previously shown mechanisms that improve lifespan and healthspan with dietary restriction, but there is so much variability in response to reduced calories across individuals and different tissues that it is clear there are many yet to be discovered processes in play. This project was started to understand why different people respond to diets in different ways.

The team began by scanning about 200 strains of flies with different genetic backgrounds. The flies were raised with two different diets, either with a normal diet or with dietary restriction, which was only 10% of normal nutrition. Researchers identified five genes which had specific variants that significantly affected longevity under dietary restriction. Of those, two had counterparts in human genetics.
The team chose one gene to explore thoroughly, called ""mustard"" (mtd) in fruit flies and ""Oxidation Resistance 1"" (OXR1) in humans and mice. The gene protects cells from oxidative damage, but the mechanism for how this gene functions was unclear. The loss of OXR1 in humans results in severe neurological defects and premature death. In mice, extra OXR1 improves survival in a model of amyotrophic lateral sclerosis (ALS).
The link between brain aging, neurodegeneration and lifespan
To figure out how a gene that is active in neurons affects overall lifespan, the team did a series of in-depth tests. They found that OXR1 affects a complex called the retromer, which is a set of proteins necessary for recycling cellular proteins and lipids. ""The retromer is an important mechanism in neurons because it determines the fate of all proteins that are brought into the cell,"" said Wilson. Retromer dysfunction has been associated with age-related neurodegenerative diseases that are protected by dietary restriction, specifically Alzheimer's and Parkinson's diseases.
Overall, their results told the story of how dietary restriction slows brain aging by the action of mtd/OXR1 in maintaining the retromer. ""This work shows that the retromer pathway, which is involved in reusing cellular proteins, has a key role in protecting neurons when nutrients are limited,"" said Kapahi. The team found that mtd/OXR1 preserves retromer function and is necessary for neuronal function, healthy brain aging, and lifespan extension seen with dietary restriction.
""Diet is influencing this gene. By eating less, you are actually enhancing this mechanism of proteins being sorted properly in your cells, because your cells are enhancing the expression of OXR1,"" said Wilson.

The team also found that boosting mtd in flies caused them to live longer, leading researchers to speculate that in humans excess expression of OXR1 might help extend lifespan. ""Our next step is to identify specific compounds that increase the levels of OXR1 during aging to delay brain aging,"" said Ellerby.
""Hopefully from this we can get more of an idea of why our brains degenerate in the first place,"" said Wilson.
""Diet impacts all the processes in your body,"" he said. ""I think this work supports efforts to follow a healthy diet, because what you eat is going to affect more than you know.""
Other Buck researchers involved in the study are: Sudipta Bar, Enrique Carrera, Brian Hodge, Tyler Hilsabeck, Joanna Bons, George Brownridge III, Jennifer Beck, Jacob Rose, Melia Granath-Panelo, Christopher Nelson, Grace Qi, Akos Gerencser, Jianfeng Lan, Rachel Brem and Birgit Schilling.
Acknowledgements: This work was supported in part through funds from the National Institutes of Health (NIH), the Larry L. Hillblom Foundation, and the National Centerrs of Competence in Research (NCCR).
COI: Kapahi is founder and a member of the scientific advisory board at Juvify Bio. The other authors have no conflicts of interest.

","score: 13.291078618481809, grade_level: '13'","score: 14.215536846641633, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44343-3,"Dietary restriction (DR) delays aging, but the mechanism remains unclear. We identified polymorphisms in mtd, the fly homolog of OXR1, which influenced lifespan and mtd expression in response to DR. Knockdown in adulthood inhibited DR-mediated lifespan extension in female flies. We found that mtd/OXR1 expression declines with age and it interacts with the retromer, which regulates trafficking of proteins and lipids. Loss of mtd/OXR1 destabilized the retromer, causing improper protein trafficking and endolysosomal defects. Overexpression of retromer genes or pharmacological restabilization with R55 rescued lifespan and neurodegeneration in mtd-deficient flies and endolysosomal defects in fibroblasts from patients with lethal loss-of-function of OXR1 variants. Multi-omic analyses in flies and humans showed that decreased Mtd/OXR1 is associated with aging and neurological diseases. mtd/OXR1 overexpression rescued age-related visual decline and tauopathy in a fly model. Hence, OXR1 plays a conserved role in preserving retromer function and is critical for neuronal health and longevity."
"
With human retinas grown in a petri dish, researchers discovered how an offshoot of vitamin A generates the specialized cells that enable people to see millions of colors, an ability that dogs, cats, and other mammals do not possess.

""These retinal organoids allowed us for the first time to study this very human-specific trait,"" said author Robert Johnston, an associate professor of biology. ""It's a huge question about what makes us human, what makes us different.""
The findings, published in PLOS Biology, increase understanding of color blindness, age-related vision loss, and other diseases linked to photoreceptor cells. They also demonstrate how genes instruct the human retina to make specific color-sensing cells, a process scientists thought was controlled by thyroid hormones.
By tweaking the cellular properties of the organoids, the research team found that a molecule called retinoic acid determines whether a cone will specialize in sensing red or green light. Only humans with normal vision and closely related primates develop the red sensor.
Scientists for decades thought red cones formed through a coin toss mechanism where the cells haphazardly commit to sensing green or red wavelengths -- and research from Johnston's team recently hinted that the process could be controlled by thyroid hormone levels. Instead, the new research suggests red cones materialize through a specific sequence of events orchestrated by retinoic acid within the eye.
The team found that high levels of retinoic acid in early development of the organoids correlated with higher ratios of green cones. Similarly, low levels of the acid changed the retina's genetic instructions and generated red cones later in development.
""There still might be some randomness to it, but our big finding is that you make retinoic acid early in development,"" Johnston said. ""This timing really matters for learning and understanding how these cone cells are made.""
Green and red cone cells are remarkably similar except for a protein called opsin, which detects light and tells the brain what colors people see. Different opsins determine whether a cone will become a green or a red sensor, though the genes of each sensor remain 96% identical. With a breakthrough technique that spotted those subtle genetic differences in the organoids, the team tracked cone ratio changes over 200 days.

""Because we can control in organoids the population of green and red cells, we can kind of push the pool to be more green or more red,"" said author Sarah Hadyniak, who conducted the research as a doctoral student in Johnston's lab and is now at Duke University. ""That has implications for figuring out exactly how retinoic acid is acting on genes.""
The researchers also mapped the widely varying ratios of these cells in the retinas of 700 adults. Seeing how the green and red cone proportions changed in humans was one of the most surprising findings of the new research, Hadyniak said.
Scientists still don't fully understand how the ratio of green and red cones can vary so greatly without affecting someone's vision. If these types of cells determined the length of a human arm, the different ratios would produce ""amazingly different"" arm lengths, Johnston said.
To build understanding of diseases like macular degeneration, which causes loss of light-sensing cells near the center of the retina, the researchers are working with other Johns Hopkins labs. The goal is to deepen their understanding of how cones and other cells link to the nervous system.
""The future hope is to help people with these vision problems,"" Johnston said. ""It's going to be a little while before that happens, but just knowing that we can make these different cell types is very, very promising.""
Other Johns Hopkins authors include: Kiara C. Eldred, Boris Brenerman, Katarzyna A. Hussey, Joanna F. D. Hagen, Rajiv C. McCoy, Michael E. G. Sauria, and James Taylor; as well as James A. Kuchenbecker, Thomas Reh, Ian Glass, Maureen Neitz, Jay Neitz of the University of Washington.

","score: 12.921545338441891, grade_level: '13'","score: 14.267069243156193, grade_levels: ['college_graduate'], ages: [24, 100]",10.1371/journal.pbio.3002464,"Trichromacy is unique to primates among placental mammals, enabled by blue (short/S), green (medium/M), and red (long/L) cones. In humans, great apes, and Old World monkeys, cones make a poorly understood choice between M and L cone subtype fates. To determine mechanisms specifying M and L cones, we developed an approach to visualize expression of the highly similar M- and L-opsin mRNAs. M-opsin was observed before L-opsin expression during early human eye development, suggesting that M cones are generated before L cones. In adult human tissue, the early-developing central retina contained a mix of M and L cones compared to the late-developing peripheral region, which contained a high proportion of L cones. Retinoic acid (RA)-synthesizing enzymes are highly expressed early in retinal development. High RA signaling early was sufficient to promote M cone fate and suppress L cone fate in retinal organoids. Across a human population sample, natural variation in the ratios of M and L cone subtypes was associated with a noncoding polymorphism in the NR2F2 gene, a mediator of RA signaling. Our data suggest that RA promotes M cone fate early in development to generate the pattern of M and L cones across the human retina."
"
The quest for personalized medicine, a medical approach in which practitioners use a patient's unique genetic profile to tailor individual treatment, has emerged as a critical goal in the health care sector. But a new Yale-led study shows that the mathematical models currently available to predict treatments have limited effectiveness.

In an analysis of clinical trials for multiple schizophrenia treatments, the researchers found that the mathematical algorithms were able to predict patient outcomes within the specific trials for which they were developed, but failed to work for patients participating in different trials.
The findings are published Jan. 11 in the journal Science.
""This study really challenges the status quo of algorithm development and raises the bar for the future,"" said Adam Chekroud, an adjunct assistant professor of psychiatry at Yale School of Medicine and corresponding author of the paper. ""Right now, I would say we need to see algorithms working in at least two different settings before we can really get excited about it.""
""I'm still optimistic,"" he added, ""but as medical researchers we have some serious things to figure out.""
Chekroud is also president and co-founder of Spring Health, a private company that provides mental health services.
Schizophrenia, a complex brain disorder that affects about 1% of the U.S. population, perfectly illustrates the need for more personalized treatments, the researchers say. As many as 50% of patients diagnosed with schizophrenia fail to respond to the first antipsychotic drug that is prescribed, but it is impossible to predict which patients will respond to therapies and which will not.

Researchers hope that new technologies using machine learning and artificial intelligence might yield algorithms that better predict which treatments will work for different patients, and help improve outcomes and reduce costs of care.
Due to the high cost of running a clinical trial, however, most algorithms are only developed and tested using a single clinical trial. But researchers had hoped that these algorithms would work if tested on patients with similar profiles and receiving similar treatments.
For the new study, Chekroud and his Yale colleagues wanted to see if this hope was really true. To do so, they aggregated data from five clinical trials of schizophrenia treatments made available through the Yale Open Data Access (YODA) Project, which advocates for and supports responsible sharing of clinical research data. In most cases, they found, the algorithms effectively predicted patient outcomes for the clinical trial in which they were developed. However, they failed to effectively predict outcomes for schizophrenia patients being treated in different clinical trials.
""The algorithms almost always worked first time around,"" Chekroud said. ""But when we tested them on patients from other trials the predictive value was no greater than chance.""
The problem, according to Chekroud, is that most of the mathematical algorithms used by medical researchers were designed to be used on much bigger data sets. Clinical trials are expensive and time consuming to conduct, so the studies typically enroll fewer than 1,000 patients. Applying the powerful AI tools to analysis of these smaller data sets, he said, can often result in ""over-fitting,"" in which a model has learned response patterns that are idiosyncratic, or specific just to that initial trial data, but disappear when additional new data are included.
""The reality is, we need to be thinking about developing algorithms in the same way we think about developing new drugs,"" he said. ""We need to see algorithms working in multiple different times or contexts before we can really believe them.""
In the future, the inclusion of other environmental variables may or may not improve the success of algorithms in the analysis of clinical trial data, researchers added. For instance, does the patient abuse drugs or have personal support from family or friends? These are the kinds of factors that can affect outcomes of treatment.

Most clinical trials use precise criteria to improve chances for success, such as guidelines for which patients should be included (or excluded), careful measurement of outcomes, and limits on the number of doctors administering treatments. Real world settings, meanwhile, have a much wider variety of patients and greater variation in the quality and consistency of treatment, the researchers say.
""In theory, clinical trials should be the easiest place for algorithms to work. But if algorithms can't generalize from one clinical trial to another, it will be even more challenging to use them in clinical practice,'' said co-author John Krystal, the Robert L. McNeil, Jr. Professor of Translational Research and professor of psychiatry, neuroscience, and psychology at Yale School of Medicine. Krystal is also chair of Yale's Department of Psychiatry.
Chekroud suggests that increased efforts to share data among researchers and the banking of additional data by large-scale health care providers might help increase the reliability and accuracy of AI-driven algorithms.
""Although the study dealt with schizophrenia trials, it raises difficult questions for personalized medicine more broadly, and its application in cardiovascular disease and cancer,"" said Philip Corlett, an associate professor of psychiatry at Yale and co-author of the study.
Other Yale authors of the study are Hieronimus Loho; Ralitza Gueorguieva, a senior research scientist at Yale School of Public Health; and Harlan M. Krumholz, the Harold H. Hines Jr. Professor of Medicine (Cardiology) at Yale.

","score: 14.049660421900068, grade_level: '14'","score: 15.305731061408558, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adg8538,"It is widely hoped that statistical models can improve decision-making related to medical treatments. Because of the cost and scarcity of medical outcomes data, this hope is typically based on investigators observing a model’s success in one or two datasets or clinical contexts. We scrutinized this optimism by examining how well a machine learning model performed across several independent clinical trials of antipsychotic medication for schizophrenia. Models predicted patient outcomes with high accuracy within the trial in which the model was developed but performed no better than chance when applied out-of-sample. Pooling data across trials to predict outcomes in the trial left out did not improve predictions. These results suggest that models predicting treatment outcomes in schizophrenia are highly context-dependent and may have limited generalizability."
"
The repair of damage to genetic material (DNA) in the human body is carried out by highly efficient mechanisms that have not yet been fully researched. A scientific team led by Christian Seiser from MedUni Vienna's Center for Anatomy and Cell Biology has now discovered a previously unrecognised control point for these processes. This could lead to a new approach for the development of cancer therapies aimed at inhibiting the repair of damaged cancer cells. The research work was recently published in the journal ""Nucleic Acids Research."" 

GSE1-CoREST is the name of the newly discovered complex, which contains three enzymes that control DNA repair processes and could form the basis for novel cancer therapeutics. ""In research, these proteins are already associated with cancer, but not in the context that we have now found,"" emphasises Christian Seiser, who led the study in close collaboration with researchers from the Max Perutz Labs Vienna. The new complex was identified as a controller of DNA repair processes using a precise measurement method (affinity purification mass spectrometry). ""This also showed that the inhibition of these enzymes can prevent the repair of genetic material and cause the death of cells,"" says first author Terezia Vcelkova from MedUni Vienna's Center for Anatomy and Cell Biology describing a highly desirable effect in tumour cells.
Stopping repair mechanisms
The genetic material, the DNA, is exposed to various harmful influences such as UV light or environmental pollutants on a daily basis. These influences can lead to changes in the DNA sequence, so-called mutations. To repair this damage to genetic material, various highly efficient biochemical repair mechanisms are normally activated. If these processes do not succeed in repairing the damage, programmed cell death (apoptosis) is ultimately initiated to protect against malignant cells.
To ensure their survival, cells react to DNA damage by activating and integrating signalling pathways or signalling cascades. This is achieved in particular through the activation of signalling pathways known as DNA damage response (or DDR). These signalling cascades are responsible for bringing repair factors to the right place in the genome at the right time in order to repair the mutated DNA efficiently and promptly. The control instances and regulators in this interaction are better defined thanks to the current research work. ""The effectiveness of the novel cancer therapeutics based on this, which are intended to improve the response of tumour cells to cancer therapies, is now being tested in preclinical studies,"" says Christian Seiser about the next steps.

","score: 14.589709375436637, grade_level: '15'","score: 15.710618974430623, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/nar/gkad911,"Post-translational modifications of histones are important regulators of the DNA damage response (DDR). By using affinity purification mass spectrometry (AP-MS) we discovered that genetic suppressor element 1 (GSE1) forms a complex with the HDAC1/CoREST deacetylase/demethylase co-repressor complex. In-depth phosphorylome analysis revealed that loss of GSE1 results in impaired DDR, ATR signalling and γH2AX formation upon DNA damage induction. Altered profiles of ATR target serine-glutamine motifs (SQ) on DDR-related hallmark proteins point to a defect in DNA damage sensing. In addition, GSE1 knock-out cells show hampered DNA damage-induced phosphorylation on SQ motifs of regulators of histone post-translational modifications, suggesting altered histone modification. While loss of GSE1 does not affect the histone deacetylation activity of CoREST, GSE1 appears to be essential for binding of the deubiquitinase USP22 to CoREST and for the deubiquitination of H2B K120 in response to DNA damage. The combination of deacetylase, demethylase, and deubiquitinase activity makes the USP22-GSE1-CoREST subcomplex a multi-enzymatic eraser that seems to play an important role during DDR. Since GSE1 has been previously associated with cancer progression and survival our findings are potentially of high medical relevance."
"
Researchers at the Francis Crick Institute, working with University of Oxford, University of York and Oxford Archaeology, have developed a new technique to measure the number of chromosomes in ancient genomes more precisely, using it to identify the first prehistoric person with mosaic Turner syndrome (characterised by one X chromosome instead of two [XX]), who lived about 2500 years ago.

As part of their research published today in Communications Biology, they also identified the earliest known person with Jacob's syndrome (characterised by an extra Y chromosome -- XYY) in the Early Medieval Period, three people with Klinefelter syndrome (characterised by an extra X chromosome -- XXY) across a range of time periods and an infant with Down Syndrome from the Iron Age.
Most cells in the human body have 23 pairs of DNA molecules called chromosomes, and the sex chromosomes are typically XX (female) or XY (male), although there are differences in sexual development. 'Aneuploidy' occurs when a person's cells have an extra or missing chromosome. If this occurs in the sex chromosomes, a few differences like delayed development or changes in height can be seen around puberty.
Ancient DNA samples can erode over time and can be contaminated by DNA from other ancient samples or from people handling them. This makes it difficult to accurately capture differences in the number of sex chromosomes.
The team at the Crick developed a computational method which aims to pick up more variation in sex chromosomes. For the sex chromosomes, it involves counting the number of copies of X and Y chromosomes, and comparing the outcome to a predicted baseline (what you would expect to see).
The team used the new method to analyse ancient DNA from a large dataset of individuals collected as part of their Thousand Ancient British Genomes project across British history, identifying six individuals with aneuploidies across five sites in Somerset, Yorkshire, Oxford and Lincoln2. The individuals lived across a range of time periods, from the Iron Age (2500 years ago) up to the Post-Medieval Period (about 250 years ago).
They identified five people who had sex chromosomes which fell outside of the XX or XY categories. All were buried according to their society's customs although no possessions were found with them to shed more light on their lives.

The three individuals with Klinefelter syndrome lived across very different time periods, but they shared some similarities -- all were slightly taller than average and showed signs of delayed development in puberty.
By investigating details on the bones, the research team could see that it was unlikely that the individual with Turner syndrome had gone through puberty and started menstruation, despite their estimated age of 18-22. Their syndrome was shown to be mosaic -some cells had one copy of chromosome X and some had two.
Kakia Anastasiadou, PhD student in the Ancient Genomics Laboratory at the Crick, and first author of the study, said: ""Through precisely measuring sex chromosomes, we were able to show the first prehistoric evidence of Turner syndrome 2500 years ago, and the earliest known incidence of Jacob's syndrome around 1200 years ago. It's hard to see a full picture of how these individuals lived and interacted with their society, as they weren't found with possessions or in unusual graves, but it can allow some insight into how perceptions of gender identity have evolved over time.""
Pontus Skoglund, Group Leader of the Ancient Genomics Laboratory at the Crick, said: ""Our method is also able to classify DNA contamination in many cases, and can help to analyse incomplete ancient DNA, so it could be applied to archaeological remains which have been difficult to analyse.
""Combining this data with burial context and possessions can allow for a historical perspective of how sex, gender and diversity were perceived in past societies. I hope this type of approach will be applied as the common resource of ancient DNA data continues to grow.""
The team worked with archaeologists from the University of Oxford, the Wells and Mendip Museum, University of York, University of Bradford, Oxford Archaeology, York Osteoarchaeology and Network Archaeology, acknowledging support from Lincolnshire County Council, Magdalen College and Balfour Beatty for National Highways.
Rick Schulting, Professor of Scientific and Prehistoric Archaeology at the University of Oxford, said: ""The results of this study open up exciting new possibilities for the study of sex in the past, moving beyond binary categories in a way that would be impossible without the advances being made in ancient DNA analysis.""

","score: 17.139135060129508, grade_level: '17'","score: 18.950100023126737, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s42003-023-05642-z,"Ancient DNA is a valuable tool for investigating genetic and evolutionary history that can also provide detailed profiles of the lives of ancient individuals. In this study, we develop a generalised computational approach to detect aneuploidies (atypical autosomal and sex chromosome karyotypes) in the ancient genetic record and distinguish such karyotypes from contamination. We confirm that aneuploidies can be detected even in low-coverage genomes ( ~ 0.0001-fold), common in ancient DNA. We apply this method to ancient skeletal remains from Britain to document the first instance of mosaic Turner syndrome (45,X0/46,XX) in the ancient genetic record in an Iron Age individual sequenced to average 9-fold coverage, the earliest known incidence of an individual with a 47,XYY karyotype from the Early Medieval period, as well as individuals with Klinefelter (47,XXY) and Down syndrome (47,XY, + 21). Overall, our approach provides an accessible and automated framework allowing for the detection of individuals with aneuploidies, which extends previous binary approaches. This tool can facilitate the interpretation of burial context and living conditions, as well as elucidate past perceptions of biological sex and people with diverse biological traits."
"
Through the Strong Heart Family Study, National Institutes of Health-supported researchers found that small declines in blood lead levelswere associated with long-term cardiovascular health improvements in American Indian adults. Participants who had the greatest reductions in blood lead levels saw their systolic blood pressure fall by about 7 mm Hg, an amount comparable to the effects of blood pressure-lowering medication.

The findings as reported from researchers at Columbia University Mailman School of Public Health and NIEHS and NHLBI are published in the Journal of the American Heart Association.
""This is a huge win for public health,"" said Anne E. Nigra, PhD, assistant professor of environmental health sciences at Columbia Mailman School of Public Health, and senior author. ""We saw that even small decreases in a person's blood lead levels can have meaningful health outcomes.""
Nigra and her co- authors, including Wil Lieberman-Cribbin, MPH, also at Columbia Mailman School, credit these improvements in large part to public health and policy changes that have occurred over the last few decades.
In addition to seeing improvements in systolic blood pressure, the investigators found that reductions in blood lead levels were associated with reductions in a marker associated with hypertrophic cardiomyopathy and heart failure.
To conduct this research, investigators partnered with 285 American Indian adults through an extension of the Strong Heart Study, the largest study following cardiovascular health outcomes and risk factors among American Indian adults. Participants lived in one of four tribal communities in Arizona, Oklahoma, North Dakota, or South Dakota.
The researchers looked at blood lead levels and blood pressure readings over time. Lead was first measured in blood collected during the 1997-1999 study visit and again in blood collected during a follow-up visit between 2006-2009. During this time, participants had their blood pressure taken and participated in medical exams, including having echocardiographs to assess their heart's structure and function. To support similar comparisons among participants, researchers controlled for multiple factors, including social variables, cardiovascular disease risks, and medical history.

At the start of the study, the average blood lead level was 2.04 µg/dL. Throughout the study, the average blood lead level fell by 0.67 µg/dL, or 33 percent. The most significant changes, categorized by participants with average starting blood lead levels of 3.21 µg/dL and who experienced reductions of about 1.78 µg/dL, or 55 percent, were linked to a 7 mm Hg reduction in systolic blood pressure.
""This is a sign that whatever is happening in these communities to reduce blood lead levels is working,"" said Mona Puggal, MPH, an epidemiologist in the Division of Cardiovascular Sciences at the National Heart, Lung, and Blood Institute (NHLBI). ""The reductions in blood pressure are also comparable to improvements you would see with lifestyle changes, such as getting 30 minutes of daily exercise, reducing salt intake, or losing weight.""
The reductions in blood lead levels observed in the study are similar to those seen in the general U.S. population following policies and efforts implemented within the past 50 years to reduce lead exposure through paint, gasoline, water, plumbing, and canned items.
""Recognizing that American Indian communities are disproportionately exposed to elevated levels of lead and other metals compared to the general U.S. population, more research needs to be done to determine how environmental agents exacerbate cardiovascular and other diseases, and more needs to be done to improve the environmental health of American Indians,"" said Lindsey A. Martin, PhD, a health science administrator at the National Institute of Environmental Health Sciences (NIHES).
The researchers point out that it is also important to investigate these findings in other communities and to look for additional ways to reduce lead exposure, especially in other populations with elevated risks for exposure and cardiovascular disease.
Co-authors are: Zheng Li, Michael Lewin, Patricia Ruiz, Agency for Toxic Substances and Disease Registry; Jeffery M. Jarrett, Centers for Disease Control and Prevention;Shelley A. Cole, Marcia O'Leary, Texas Biomedical Research Institute; Gernot Pichler, Clinic Floridsdorf, Vienna; Daichi Shimbo, Columbia University Irving Medical Center; Richard B. Devereux, Weill Cornell Medical College; Jason G. Umans, MedStar Health Research Institute and Georgetown-Howard Universities Center for Clinical and Translational Science; and Allison Kupsco and Ana Navas-Acien, Columbia Mailman School of Public Health.
The research was funded by NIEHS and NHLBI.

","score: 17.77509661835749, grade_level: '18'","score: 20.15988224637681, grade_levels: ['college_graduate'], ages: [24, 100]",10.1161/JAHA.123.031256,"Chronic lead exposure is associated with both subclinical and clinical cardiovascular disease. We evaluated whether declines in blood lead were associated with changes in systolic and diastolic blood pressure in adult American Indian participants from the SHFS (Strong Heart Family Study). Lead in whole blood was measured in 285 SHFS participants in 1997 to 1999 and 2006 to 2009. Blood pressure and measures of cardiac geometry and function were obtained in 2001 to 2003 and 2006 to 2009. We used generalized estimating equations to evaluate the association of declines in blood lead with changes in blood pressure; cardiac function and geometry measures were considered secondary. Mean blood lead was 2.04 μg/dL at baseline. After ≈10 years, mean decline in blood lead was 0.67 μg/dL. In fully adjusted models, the mean difference in systolic blood pressure comparing the highest to lowest tertile of decline (>0.91 versus <0.27 μg/dL) in blood lead was −7.08 mm Hg (95% CI, −13.16 to −1.00). A significant nonlinear association between declines in blood lead and declines in systolic blood pressure was detected, with significant linear associations where blood lead decline was 0.1 μg/dL or higher. Declines in blood lead were nonsignificantly associated with declines in diastolic blood pressure and significantly associated with declines in interventricular septum thickness. Declines in blood lead levels in American Indian adults, even when small (0.1–1.0 μg/dL), were associated with reductions in systolic blood pressure. These findings suggest the need to further study the cardiovascular impacts of reducing lead exposures and the importance of lead exposure prevention."
"
The effects of aging and external factors like UV exposure on skin are well documented. As people age or spend more time in the sun, their skin tends to become drier and more wrinkled,

Recent findings have identified an exciting potential new link to signs of skin aging -- the skin microbiome, the collection of microorganisms that inhabits our skin. The results come from a collaborative study carried out by researchers at the Center for Microbiome Innovation (CMI) at the University of California San Diego (UC San Diego) and L'Oréal Research and Innovation.
Their work was published in Frontiers in Aging on January 11, 2024, in an article entitled ""A multi-study analysis enables identification of potential microbial features associated with skin aging signs."" To the best of the team's knowledge, the study is the first to isolate microbes associated specifically with signs of skin aging and skin health, rather than chronological age.
Combining CMI's sophisticated data analysis abilities with L'Oréal's knowledge and expertise in skin health assessment, the study comprehensively examined data collected during 13 studies that L'Oréal had carried out in the past, consisting of 16S rRNA amplicon sequence data and corresponding skin clinical data for over 650 female participants, aged 18 -- 70. While each of the studies included in the analysis had focused on one particular area of interest -- for example, crow's feet wrinkles or moisture loss -- this multi-study analysis collated the data to search for trends related to specific microbes while accounting for other variables, such as age.
""Previous studies have shown that the types of microbes on our skin change fairly predictably with age,"" said corresponding author Se Jin Song, the CMI Director of Research. ""Our skin also changes physiologically with age; for example, we gain wrinkles and our skin gets drier. But there is variation in what this looks like in people -- you've probably noticed that there are some people who have younger or older looking skin than many others their age. Using advanced statistical methods, we were able to tease apart the microbes that are associated with these types of aging signs for skin, like crow's feet wrinkles, from those that are associated with simply age as a chronological number.""
Two notable trends emerged from the analysis. First, the team found a positive association between skin microbiome diversity and lateral cantonal lines (crow's feet wrinkles), which are generally viewed as one of the key signs of skin aging. Second, they observed a negative correlation between microbiome diversity and transepidermal water loss, which is the amount of moisture that evaporates through the skin. In further exploring the trends, the researchers identified several potential biomarkers that warrant investigation as microorganisms of interest. It would be premature to infer causation or actionable insights, but the study's results have provided researchers with directions on the next steps to hone in on better understanding microbial associations with skin aging.
""At L'Oréal, our commitment is to create beauty products that meet the unique needs of each individual. Our recent collaboration with the Center for Microbiome Innovation has shed light on the role of the skin microbiome in aging, particularly in how it affects wrinkles and overall skin quality,"" said co-author Qian Zheng, Head of Advanced Research, North America at L'Oréal. ""This research is groundbreaking in identifying new microbial biomarkers linked to visible signs of aging like crow's feet wrinkles. It marks a significant step towards developing technologies for healthier, more youthful skin. We look forward to sharing new results as they become available, furthering the scientific community's understanding and contributing to advancing new skincare solutions.""
Future paths of investigation the team has suggested include metabolomics work to discover chemical biomarkers related to skin aging, as well as meta-transcriptomics research into potential targets for genetic engineering. Research into other layers of the skin has also been considered, as many studies focus on the outer skin due to the ease of sample collection.

""While the study's findings represent an advance of our knowledge of the skin microbiome, we view them as just the beginning of a new phase of research,"" said co-author Rob Knight, the CMI Faculty Director and Professor of Pediatrics, Bioengineering, Computer Science & Engineering and Data Science at UC San Diego. ""By confirming a link between the microbiome and skin health, we've laid the groundwork for further studies that discover specific microbiome biomarkers related to skin aging, and, one day, show how to modify them to generate novel and highly targeted recommendations for skin health.""
Additional co-authors include Tyler Myers, Shi Huang, and Shalisa T. Hansen, all at UC San Diego; and Amina Bouslimani, Cecile Clavaud, Anissa Azouaoui, Alban Ott, Audrey Gueniche, Charbel Bouez, Luc Aguilar, and Magali Moreau, all at L'Oréal Research and Innovation.
The study was funded through a sponsored research agreement between L'Oréal Research and Innovation and the Center for Microbiome Innovation at UC San Diego.
Disclosure: Amina Bouslimani, Cecile Clavaud, Anissa Azouaoui, Alban Ott, Audrey Gueniche, Charbel Bouez, Qian Zheng, Luc Aguilar, and Magali Moreau are all employees of L'Oréal Research and Innovation. The other authors declare no potential conflict of interest.

","score: 16.80695636465818, grade_level: '17'","score: 18.394337842720084, grade_levels: ['college_graduate'], ages: [24, 100]",10.3389/fragi.2023.1304705,"Introduction: During adulthood, the skin microbiota can be relatively stable if environmental conditions are also stable, yet physiological changes of the skin with age may affect the skin microbiome and its function. The microbiome is an important factor to consider in aging since it constitutes most of the genes that are expressed on the human body. However, severity of specific aging signs (one of the parameters used to measure “apparent” age) and skin surface quality (e.g., texture, hydration, pH, sebum, etc.) may not be indicative of chronological age. For example, older individuals can have young looking skin (young apparent age) and young individuals can be of older apparent age. Methods: Here we aim to identify microbial taxa of interest associated to skin quality/aging signs using a multi-study analysis of 13 microbiome datasets consisting of 16S rRNA amplicon sequence data and paired skin clinical data from the face. Results: We show that there is a negative relationship between microbiome diversity and transepidermal water loss, and a positive association between microbiome diversity and age. Aligned with a tight link between age and wrinkles, we report a global positive association between microbiome diversity and Crow’s feet wrinkles, but with this relationship varying significantly by sub-study. Finally, we identify taxa potentially associated with wrinkles, TEWL and corneometer measures. Discussion: These findings represent a key step towards understanding the implication of the skin microbiota in skin aging signs."
"
Endocrine-disrupting chemicals (EDCs) in plastics pose a serious threat to public health and cost the U.S. an estimated $250 billion in increased health care costs in 2018, according to new research published in the Journal of the Endocrine Society.

Plastics contain many hazardous, endocrine-disrupting chemicals that leach and contaminate humans and the environment. These chemicals disturb the body's hormone systems and can cause cancer, diabetes, reproductive disorders, neurological impairments of developing fetuses and children, and death.
Potential options under discussion as part of a Global Plastics Treaty include interventions to reduce EDC exposure to protect public health and the environment, and data on the health costs of EDCs could help move this initiative forward.
""Our study found plastics contribute substantially to disease and associated social costs in the U.S., about $250 billion in 2018 alone. These costs are equivalent to 1.22% of the Gross Domestic Product. The diseases due to plastics run the entire life course from preterm birth to obesity, heart disease and cancers,"" said study author Leonardo Trasande, M.D., M.P.P., of NYU Grossman School of Medicine and NYU Wagner Graduate School of Public Service in New York, N.Y. Trasande has represented the Society at intergovernmental meetings to address plastic pollution and its health effects.
""Our study drives home the need to address chemicals used in plastic materials as part of the Global Plastics Treaty,"" Trasande said. ""Actions through the Global Plastics Treaty and other policy initiatives will reduce these costs in proportion to the actual reductions in chemical exposures achieved.""
The researchers analyzed existing studies on EDCs to identify how many diseases and disabilities were attributed to chemicals in plastics. The chemicals they studied commonly found in plastics included polybrominated diphenyl ethers (PBDE), phthalates, bisphenols, and poly- and perfluoroalkyl substances (PFAS).
The researchers updated previously published data on disease burden and cost estimates for these chemicals in the United States to 2018. They combined the data and estimated $250 billion in disease burden from plastic exposure in 2018.

""This study shows that preventing plastic pollution can reduce the incidence of disease, disability and early death, and its attendant human suffering and health care costs,"" said co-author Michael Belliveau, Executive Director of Defend Our Health based in Portland, Maine. ""Policymakers and market leaders must detoxify and slash the use of petrochemical plastics and endocrine-disrupting chemicals. We urge negotiators to finalize a Global Plastics Treaty that caps and reduces plastic production and eliminate EDCs as plastics additives.""
Most of the cost burden was from polybrominated diphenyl ethers (PBDE) exposure which is associated with diseases such as cancer. Sixty-seven billion in health costs was due to phthalate exposure which is linked to preterm birth, reduced sperm count and childhood obesity, and $22 billion was due to PFAS exposure which is associated with kidney failure and gestational diabetes.
The other authors of this study are Roopa Krithivasan of Defend Our Health; Kevin Park of NYU Grossman School of Medicine; and Vladislav Obsekov of Children's Hospital of Philadelphia in Philadelphia, Pa.
The study was funded by the National Institutes of Health's National Institute of Environmental Health Sciences and The Passport Foundation.

","score: 15.63689887640449, grade_level: '16'","score: 17.58685393258427, grade_levels: ['college_graduate'], ages: [24, 100]",10.1210/jendso/bvad163,"Chemicals used in plastics have been described to contribute to disease and disability, but attributable fractions have not been quantified to assess specific contributions. Without this information, interventions proposed as part of the Global Plastics Treaty cannot be evaluated for potential benefits. To accurately inform the tradeoffs involved in the ongoing reliance on plastic production as a source of economic productivity in the United States, we calculated the attributable disease burden and cost due to chemicals used in plastic materials in 2018. We first analyzed the existing literature to identify plastic-related fractions (PRF) of disease and disability for specific polybrominated diphenylethers (PBDE), phthalates, bisphenols, and polyfluoroalkyl substances and perfluoroalkyl substances (PFAS). We then updated previously published disease burden and cost estimates for these chemicals in the United States to 2018. By uniting these data, we computed estimates of attributable disease burden and costs due to plastics in the United States. We identified PRFs of 97.5% for bisphenol A (96.25-98.75% for sensitivity analysis), 98% (96%-99%) for di-2-ethylhexylphthalate, 100% (71%-100%) for butyl phthalates and benzyl phthalates, 98% (97%-99%) for PBDE-47, and 93% (16%-96%) for PFAS. In total, we estimate $249 billion (sensitivity analysis: $226 billion-$289 billion) in plastic-attributable disease burden in 2018. The majority of these costs arose as a result of PBDE exposure, though $66.7 billion ($64.7 billion-67.3 billion) was due to phthalate exposure and $22.4 billion was due to PFAS exposure (sensitivity analysis: $3.85-$60.1 billion). Plastics contribute substantially to disease and associated social costs in the United States, accounting for 1.22% of the gross domestic product. The costs of plastic pollution will continue to accumulate as long as exposures continue at current levels. Actions through the Global Plastics Treaty and other policy initiatives will reduce these costs in proportion to the actual reductions in chemical exposures achieved."
"
Scientists have long known that some viruses and bacteria begin infections by latching first onto sugar molecules on the surfaces of cells lining the sinuses and throat of mammals, including humans. Viral particles, for instance, can attach to these molecules, called sialic acids, or SAs, like keys fitting into locks.

Now, a new study in infant mice shows that keeping virus particles from attaching to SAs limits more than just the entry of influenza A viral infections, but also hinders their exit (shedding) and transmission from mouse to mouse. Such infections are the main cause of the seasonal flu that kills more than 36,000 Americans annually. While vaccines to guard against infection and symptom treatments exist, they are not foolproof, scientists say, and more strategies are needed to prevent infection from spreading.
Led by researchers from NYU Grossman School of Medicine, the study team stripped away, or desialylated, SA receptors by placing directly into mouse nasal cavities a neuraminidase enzyme known to loosen the acids' ability to remain attached to cell surfaces. The infant mice were then infected with influenza A. Results showed treatment with the neuraminidase enzyme dramatically cut mouse-to-mouse transmission rates by more than half (from 51% to 100% ) in a half-dozen influenza strains tested.
Publishing in the American Society for Microbiology journal mBio online Jan.11, the work was conducted in infant mice, which unlike those even a few months older or adult mice, were found by the research team to have many sialic acids in the upper portion of their respiratory tract. Specifically, the team blocked two SAs, technically called alpha-2,3 SA and alpha-2,6 SA receptors (the locks). These are known to be widely present in the human respiratory tract, which researchers say makes infant mice a strong comparable model for studying the spread of the infectious disease in children, who are also recognized as important ""drivers"" of flu transmission among people.
""If further experiments in humans prove successful, desialylating neuraminidase enzymes may prevent the flu from spreading,"" said Ortigoza,"" said lead study investigator and infectious disease specialist Mila Ortigoza, MD. PhD.
""While current approaches with vaccines and treatments target the virus, ours is the first study to demonstrate that treating the host, either infected mice or potentially infected humans, to prevent them from transmitting the virus to another host could be another effective strategy for combating pervasive infectious diseases,"" said Ortigoza, who is also an assistant professor in the Departments of Medicine and Microbiology at NYU Langone.
Ortigoza cautions that extensive clinical research is needed before neuraminidases can be considered for approval as a treatment in humans. She says the team already has plans for more experiments to examine why infants are more susceptible to infection from respiratory viruses and whether blocking sialic acids in children can also prevent the spread of influenza.
Funding support for this study was provided by National Institutes of Health grants P30CA016087, S10OD021747, K08AI141759, and R01AI150893. Ansun Biopharma of San Diego, Calif., provided the experimental neuraminidase drug used in these experiments but was otherwise not involved in the study.
In addition to Ortigoza, other NYU Langone researchers involved in this study are Catherina Mobini; Hedy Rocha; Stacey Bartlett, PhD; Cynthia Loomis, MD, PhD; and Jeffrey Weiser, MD. Weiser is the Jan T. Vilcek Professor of Molecular Pathogenesis in the Department of Microbiology at NYU Langone Health and chair of the department.

","score: 16.024561403508773, grade_level: '16'","score: 17.89868421052632, grade_levels: ['college_graduate'], ages: [24, 100]",10.1128/mbio.02203-23,"The ongoing transmission of influenza A viruses (IAV) for the past century continues to be a burden to humans. IAV binds terminal sialic acids (SA) of sugar molecules present within the upper respiratory tract (URT) in order to successfully infect hosts. The two most common SA structures that are important for IAV infection are those with α2,3- and α2,6-linkages. While mice were once considered to be an unsuitable system for studying IAV transmission due to their lack of α2,6-SA in the trachea, we have successfully demonstrated that IAV transmission in infant mice is remarkably efficient. This finding led us to re-evaluate the SA composition of the URT of mice using in situ immunofluorescence and examine its in vivo contribution to transmission for the first time. We demonstrate that mice express both α2,3- and α2,6-SA in the URT and that the difference in expression between infants and adults contributes to the variable transmission efficiencies observed. Furthermore, selectively blocking α2,3-SA or α2,6-SA within the URT of infant mice using lectins was necessary but insufficient at inhibiting transmission, and simultaneous blockade of both receptors was crucial in achieving the desired inhibitory effect. By employing a broadly acting neuraminidase to indiscriminately remove both SA moieties in vivo , we effectively suppressed viral shedding and halted the transmission of different strains of influenza viruses. These results emphasize the utility of the infant mouse model for studying IAV transmission and strongly indicate that broadly targeting host SA is an effective approach that inhibits IAV contagion. Influenza virus transmission studies have historically focused on viral mutations that alter hemagglutinin binding to sialic acid (SA) receptors in vitro . However, SA binding preference does not fully account for the complexities of influenza A virus transmission in humans. Our previous findings reveal that viruses that are known to bind α2,6-SA in vitro have different transmission kinetics in vivo , suggesting that diverse SA interactions may occur during their life cycle. In this study, we examine the role of host SA on viral replication, shedding, and transmission in vivo . We highlight the critical role of SA presence during virus shedding, such that attachment to SA during virion egress is equally important as detachment from SA during virion release. These insights support the potential of broadly acting neuraminidases as therapeutic agents capable of restraining viral transmission in vivo . Our study unveils intricate virus-host interactions during shedding, highlighting the necessity to develop innovative strategies to effectively target transmission."
"
Florida's 156-mile-long Indian River Lagoon (IRL) borders five different counties and has five inlets that connect the lagoon with the Atlantic Ocean. In recent years, this estuary has experienced numerous phytoplankton bloom events due to increased seasonal temperatures coupled with environmental impacts.

Algal blooms produce a myriad of small organic molecules, many of which can be toxic to humans and animals. Among these phycotoxin producers is Microcystis aeruginosa, a freshwater cyanobacterium, which can be found in the Southern IRL. Measurable amounts of microcystins have been found in nasal swabs of people who live and work near the area, although finding microcystins in mucosal membranes may be evidence that the body is doing its job to eliminate them.
To help uncover potential human health hazards associated with harmful algae blooms in the IRL, researchers from Florida Atlantic University's Harbor Branch Oceanographic Institute collected water samples from 20 sites within the lagoon during wet and dry seasons over a three-year period. The samples were extracted to concentrate organic molecules and these extracts were used in testing. To identify the presence of known or emerging toxins, researchers used a panel of immortalized human cell lines corresponding to the liver, kidney and brain to measure cytotoxicity. Human cell lines engineered to express ion transporters, red blood cells, and the activity against a protein phosphatase enzyme, also were used in the study. These cells and biological activities were selected as they are known to be affected by algal toxins and show unique patterns of activity for known toxins.
Samples were tested at high concentrations to detect as many metabolites as possible, and those that presented more than 50 percent cytotoxicity were considered active. Samples that exhibited high toxicity were further subjected to liquid chromatography-high resolution mass spectrometry analysis to assess the metabolites present in the sample.
Results of the study, published in the journal Toxins, show that each control toxin induced a consistent pattern of cytotoxicity in the panel of human cell lines assayed. During blooms, cytotoxicity due to a single type of toxin was obvious from this pattern. In the absence of blooms, the observed cytotoxicity reflected either a mixture of toxins or it was caused by an unidentified toxin.
""The most interesting observation from our study is that with the cell lines used, we could follow the patterns of known toxins,"" said Esther Guzmán, Ph.D., corresponding author and a research professor at FAU Harbor Branch. ""Known toxins were seen only during blooms. Because cell toxicity was seen in the absence of blooms, it suggests that there might be either emergent toxins or a combination of toxins present at those times. Our findings suggest that other toxins with the potential to be harmful to human health may be present in the lagoon.""
Among the study findings, the most northern sites of the lagoon exhibited less toxicity than sites to the south. Cytotoxic blooms were seen both in the south (Microcystis) and the north (Pyrodinium) of the lagoon. In the absence of blooms, South Fork, South Fork 2, North Fork and Middle Estuary (sites one to four) in the Southern IRL and Banana River, and North Banana River (NASA) (sites 14 and 15) in the Northern IRL appeared to have the most cytotoxicity during the time of the assessment.

In contrast, Jensen, Fort Pierce Inlet, Harbor Branch Link Port Canal, Vero Beach Land/Ocean Biogeochemical Observatory, and Vero Beach Barber Bridge (sites six to 10) appeared healthier as there were few samples with cytotoxicity above 50 percent in these sites, although there was statistically significant variation in these sites.
""A major question we sought to answer in this study was whether there are unrecognized toxins or other signaling molecules associated with harmful algal blooms in the lagoon,"" said Amy Wright, Ph.D., co-author and a research professor, FAU Harbor Branch. ""The data collected to date suggest that this is indeed the case. Importantly, using an assay panel to assess the presence of toxic materials could allow for better monitoring of human health impacts, especially from emerging toxins within the system.""
The researchers note that microcystins are primarily a threat to human health in the lagoon during blooms, and because of the necessity of active transport, the toxin would need to be ingested or inhaled to present a threat to humans.
""Ingestion can be avoided by filtering water through activated charcoal,"" said Guzmán. ""Similarly, effects due to inhalation are effectively blocked by the mucus membrane, which traps toxins that are subsequently eliminated through coughing. However, pet and wildlife exposures can still occur.""
Study co-authors Tara A. Peterson, coordinator, cancer cell biology, FAU Harbor Branch; Priscilla Winder, Ph.D., a chemistry research associate, FAU Harbor Branch; Kirstie T. Francis, Ph.D., an FAU graduate and current postdoctoral fellow in molecular microbiology, Mote Marine Laboratory; Malcolm McFarland, Ph.D., an assistant research professor in phytoplankton ecology, FAU Harbor Branch; Jill C. Roberts, a chemical scientist, FAU Harbor Branch; and Jennifer Sandle, a chemical scientist, FAU Harbor Branch.
This research was funded by a discretionary grant to the Florida Center for Coastal and Human Health from the Harbor Branch Oceanographic Institute Foundation.

","score: 15.542764561707035, grade_level: '16'","score: 16.65016219723183, grade_levels: ['college_graduate'], ages: [24, 100]",10.3390/toxins15110664,"The Indian River Lagoon (IRL), a 156-mile-long estuary located on the eastern coast of Florida, experiences phytoplankton bloom events due to increased seasonal temperatures coupled with anthropogenic impacts. This study aimed to gather data on the toxicity to human cells and to identify secondary metabolites found in water samples collected in the IRL. Water samples from 20 sites of the IRL were collected during the wet and dry seasons over a three-year period. A panel of cell lines was used to test cytotoxicity. Hemagglutination, hemolysis, and inhibition of protein phosphatase 2A (PP2A) were also measured. Cytotoxic blooms were seen both in the south (Microcystis) and the north (Pyrodinium) of the IRL. Each toxin induced a consistent pattern of cytotoxicity in the panel of human cell lines assayed. During blooms, cytotoxicity due to a single type of toxin is obvious from this pattern. In the absence of blooms, the cytotoxicity seen reflected either a mixture of toxins or it was caused by an unidentified toxin. These observations suggest that other toxins with the potential to be harmful to human health may be present in the IRL. Moreover, the presence of toxins in the IRL is not always associated with blooms of known toxin-producing organisms."
"
Rapid-acting antidepressants, including ketamine, scopolamine and psilocybin, have been found to have immediate and lasting positive effects on mood in patients with major depressive disorder but how these effects arise is unknown. New research led by the University of Bristol explored their neuropsychological effects and found that all three of these drugs can modulate affective biases associated with learning and memory.

The paper, published in Science Translational Medicine today [10 January] was carried out in collaboration with researchers at Compass Pathways, Boehringer Ingelheim, and the University of Cambridge.
Negative affective biases are a core feature of major depressive disorder. Affective biases occur when emotions alter how the brain processes information and negative affective biases are thought to contribute to the development and continuation of depressed mood.
The research team used an affective bias test, based on an associative learning task, to investigate the effects of rapid-acting antidepressants (RAADs) in rats. They found that all the treatments were able to reduce negative affective biases associated with past experiences but there were additional characteristics of the dissociative anaesthetic, ketamine, and the serotonergic psychedelic, investigational COMP360 psilocybin (Compass Pathways' proprietary formulation of synthetic psilocybin), which could explain why the effects of a single treatment can be long-lasting.
The findings suggest that these sustained effects are due to adaptive changes in the brain circuits which control affective biases, and these can influence how past experiences are remembered. The effects at low doses were very specific to affective bias modulation and were localised to the prefrontal cortex of the brain, a region known to play an important role in mood.
Emma Robinson, Professor of Psychopharmacology in the School of Physiology, Pharmacology & Neuroscience at Bristol, and lead author, said: ""Using a behavioural task we showed that drugs that are believed to have rapid and sustained benefits in depressed patients, specifically modulate affective biases associated with past experiences, something which we think is really important for understanding why they can improve a patient's mood so quickly.
""We also found differences in how ketamine, scopolamine and COMP360 psilocybin interact with these neuropsychological mechanisms which may explain why the effects of a single treatment in human patients can be long-lasting, days (ketamine) to months (psilocybin).

""By using an animal model, we have been able to investigate these important interactions with learning and memory processes and neural plasticity and propose a two-stage model that may explain the effects we observe.""
In the task, each animal learnt to associate a specific digging material with a food reward under either treatment or control conditions. The treatment condition is designed to generate a change in the animal's affective state and a choice test is used to quantify the affective bias this generates.
Acute treatment with the RAADs ketamine, scopolamine, or psilocybin prevented the retrieval of the negative affective bias induced in this model. However, the most exciting finding was at 24 hours after treatment when low, but not high, doses of ketamine and psilocybin led to a re-learning effect where the negatively biased memory was retrieved with a more positive affective valence. Only psilocybin, but not ketamine or scopolamine treatment also positively biased new experiences.
Exploring in more detail the re-learning effects of ketamine in our studies, the researchers found they were protein synthesis-dependent, localised to the medial prefrontal cortex and could be modulated by cue-reactivation, consistent with their predictions of experience-dependent neural plasticity.
The study's findings propose a neuropsychological mechanism that may explain both the immediate and sustained effects of RAADs, potentially linking their effects on neural plasticity with mood.

","score: 18.68268456375839, grade_level: '19'","score: 21.154948781349347, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/scitranslmed.adi2403,"How rapid-acting antidepressants (RAADs), such as ketamine, induce immediate and sustained improvements in mood in patients with major depressive disorder (MDD) is poorly understood. A core feature of MDD is the prevalence of cognitive processing biases associated with negative affective states, and the alleviation of negative affective biases may be an index of response to drug treatment. Here, we used an affective bias behavioral test in rats, based on an associative learning task, to investigate the effects of RAADs. To generate an affective bias, animals learned to associate two different digging substrates with a food reward in the presence or absence of an affective state manipulation. A choice between the two reward-associated digging substrates was used to quantify the affective bias generated. Acute treatment with the RAADs ketamine, scopolamine, or psilocybin selectively attenuated a negative affective bias in the affective bias test. Low, but not high, doses of ketamine and psilocybin reversed the valence of the negative affective bias 24 hours after RAAD treatment. Only treatment with psilocybin, but not ketamine or scopolamine, led to a positive affective bias that was dependent on new learning and memory formation. The relearning effects of ketamine were dependent on protein synthesis localized to the rat medial prefrontal cortex and could be modulated by cue reactivation, consistent with experience-dependent neural plasticity. These findings suggest a neuropsychological mechanism that may explain both the acute and sustained effects of RAADs, potentially linking their effects on neural plasticity with affective bias modulation in a rodent model."
"
Soy compounds called isoflavones are among the plant-derived compounds that may significantly reduce the risk of breast cancer recurrence or death, according to a new meta-analysis co-directed by investigators from the Johns Hopkins Kimmel Cancer Center. The results were published Jan. 10 in the journal JNCI Cancer Spectrum.

Investigators in Australia, Denmark, England, Norway and the U.S. reviewed 22 published observational studies that examined the impact of dietary intake of soybeans, lignans (compounds found in a variety of plants including seeds and nuts), cruciferous/cabbage-family vegetables, and green tea -- and these substances' phytonutrients (natural compounds derived from plants) -- on breast cancer recurrence and mortality, as well as on mortality from all causes. This included 11 studies of soy isoflavones, three of cruciferous vegetables, two of green tea, three of lignans, and three of enterolactone, which is formed in the gut when lignans are digested.
Soy isoflavones were associated with a 26% reduced risk of breast cancer recurrence, according to a meta-analysis that included six of the studies (of 11,837 women) reviewed by investigators. The results were most notable among post-menopausal survivors. The greatest risk reduction was seen at 60 milligrams per day. This is equivalent to two to three servings per day, where one serving equates to a cup of soy milk, three ounces of tofu or a half-cup of cooked soybeans. However, the effect of soy consumption on risk of mortality was smaller (12%) and not statistically significant, and was seen mostly at 20-40 mg per day, or one to two servings.
Another finding, reported for the first time in a meta-analysis, relates to enterolactone, a compound metabolized from lignans. Lignans are found in a wide variety of plants, such as seeds, nuts, legumes, whole grains, fruit and vegetables. High levels are found in flaxseeds, cashew nuts, broccoli and brussels sprouts, among other sources. Enterolactone was found to reduce the risk of breast cancer-specific mortality by 28% and death from any cause by 31%, particularly in post-menopausal women (35% reduction in death from any cause). It is not possible to calculate the effective dose of lignans in the diet from these enterolactone findings, because the gut microbiome that plays a role in metabolism of lignans varies among individuals.
""These findings were graded probable, which means there is strong research showing that they contributed to the results we are seeing,"" says lead study author Diana van Die, Ph.D., of NICM Health Research Institute at Western Sydney University, Australia.
The review also found some suggestive results, which means the results are generally consistent but rarely strong enough to justify recommendations: Consumption of green tea suggests an effect of reducing the risk of breast cancer recurrence by 44% in women with stage I or II breast cancer. The greatest effect was seen from consuming three to five cups per day and from five or more cups per day, as documented in two Japanese studies . Among those who consumed lignans prior to breast cancer diagnosis, there was a non-significant 34% risk reduction in cancer-specific mortality and 19% reduction in all causes of death in post-menopausal women. However, consumption of lignans by pre-menopausal women suggests an increased risk of mortality. This result indicates that the effects of lignans are dependent on the hormonal environment, although it was likely driven by one large study and needs further investigation. The highest intake was nine or more servings per day in the studies reviewed. The impact of cruciferous vegetables was inconclusive, possibly influenced by the average intake being quite low (less than a half-cup per day) in the studies reviewed.Investigators also looked into whether consuming soy, lignans, cruciferous vegetables and green tea, or their phytonutrients in the diet before or after breast cancer diagnosis made a difference. However, the data did not provide a concrete answer. All studies on green tea and lignans measured pre-diagnosis intake, while soy results came from studies that measured intake before and after diagnosis.
""It is critically important to stress that these studies were conducted on women who received medical and/or surgical treatment for breast cancer, and that these foods and phytonutrients should not be considered as alternatives to treatment,"" says senior study author Channing Paller, M.D., director of prostate cancer clinical research and an associate professor of oncology at Johns Hopkins.
""This research highlights the need for more robust studies in this area looking at the most effective dosages of these compounds, and whether starting to consume them after diagnosis has the same effect as a lifelong dietary habit before diagnosis. This is what patients are looking for,"" Paller added .
Kala Visvanathan, M.D., M.H.S., director of the Clinical Cancer Genetics and Prevention Service at the Kimmel Cancer Center, was a co-author of the review. Additional co-authors were from Integria (MediHerb) in Australia, the Danish Cancer Institute, Imperial College London, Oslo New University College and The Cancer Registry of Norway.

","score: 15.778406064933428, grade_level: '16'","score: 17.39386912512075, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/jncics/pkad104,"Phytonutrient intakes may improve outcomes following breast cancer, but the impact of postdiagnosis introduction vs established prediagnostic exposure as well as optimum doses has not been established. Evidence from observational studies for key exposures was evaluated, including dosage and intake time frames. MEDLINE, EMBASE, CINAHL, Cochrane Library, ClinicalTrials.gov, and the ISRCTN registry were searched for prospective and retrospective observational studies investigating the impact of soybean, lignans, cruciferous (cabbage-family) vegetables, green tea, or their phytonutrients on breast cancer survival outcomes. A random-effects model was used to calculate summary hazard ratios (HRs) and 95% confidence intervals (CIs). Nonlinear dose-response analyses were conducted using restricted cubic splines. Thirty-two articles were included. Soy isoflavones were associated with a 26% reduced risk of recurrence (HR = 0.74, 95% CI = 0.60 to 0.92), particularly among postmenopausal (HR = 0.72, 95% CI = 0.55 to 0.94) and estrogen receptor–positive survivors (HR = 0.82, 95% CI = 0.70 to 0.97), with the greatest risk reduction at 60 mg/day. In mortality outcomes, the reduction was mostly at 20 to 40 mg/day. Soy protein and products were inversely associated with cancer-specific mortality for estrogen receptor–positive disease (HR = 0.75, 95% CI = 0.60 to 0.92). An inverse association was observed for serum or plasma enterolactone, measured prediagnosis and early postdiagnosis, with cancer-specific mortality (HR = 0.72, 95% CI = 0.58 to 0.90) and all-cause mortality (HR = 0.69, 95% CI = 0.57 to 0.83). No effects were observed for cruciferous vegetables. There was a 44% reduced risk of recurrence with prediagnostic green tea for stage I and II breast cancer (HR = 0.56, 95% CI = 0.38 to 0.83). Soy, enterolactone, and green tea demonstrated significant risk reductions in outcomes following breast cancer. Evidence is needed regarding the impact of postdiagnostic introduction or substantial increase of these exposures."
"
University of Pittsburgh Schools of Medicine researchers uncovered a fundamental mechanism that controls the body's response to limited oxygen and regulates blood vessel disease of the lung.

By combing through genomes of more than 20,000 individuals in the U.S., France, England and Japan and combining the results with molecular studies in the lab, the team discovered a shared genetic trait that could predict a higher risk of small lung vessel disease called pulmonary hypertension and its more severe form, pulmonary arterial hypertension, and influence the development of drug therapies that target the body's response to limited oxygen. The findings were published this week in Science Translational Medicine.
""This new level of knowledge will help identify people who may be at a higher genetic risk of pulmonary hypertension and jump-start precision medicine practices to offer customized treatments,"" said senior author Stephen Chan, M.D., Ph.D., a cardiologist who serves as the Vitalant Chair in Vascular Medicine and director of the Vascular Medicine Institute at Pitt.
Pulmonary hypertension encompasses a range of conditions of various causes that manifest in high blood pressure in the arteries of the lung and the right side of the heart. The disease is accompanied by a decreased supply of oxygen to the lung tissue and the blood, is chronic and deadly, and its molecular origins and genetic background remain unsolved.
Using a combined approach of genomics and biochemistry, the Chan lab found a gene pair that had an important function in regulating blood vessel metabolism and disease. This gene pair included a long non-coding RNA molecule -- a messenger that facilitates the transformation of the body's genetic code into protein products -- and a protein binding partner, and their interaction was frequently active in cells exposed to low oxygen compared to normal cells.
Taking the findings a step further, the team discovered that a single DNA letter change directing expression of this RNA-protein pair under low oxygen conditions was associated with a higher genetic risk of pulmonary hypertension across diverse patient populations.
According to Chan, pulmonary hypertension is a borderline orphan disease, and the limited number of patients with pulmonary hypertension makes it challenging to find genetic variations that are rare but still impactful enough to eclipse individual differences.
With that in mind, Pitt scientists turned to collaborators around the globe and to public research datasets such as All of Us -- a nationwide health registry funded by the National Institutes of Health -- to ensure that the findings are relevant across a diverse global population.
Chan hopes that his findings will spur the development of targeted therapies relevant to oxygen sensitivity in blood vessel lining and that their pending patent application will contribute to the growth on an entirely new field of epigenetic and RNA drug therapeutics that work not by manipulating the genome but by changing how it is being read.
Other authors of the study include Yi-Yin Tai, M.S., Qiujun Yu, M.D., Ph.D., Ying Tang, M.S., Wei Sun, M.D., Neil J. Kelly, M.D., Ph.D., Jingsi Zhao, M.S., Yassmin Al Aaraj M.D., M.P.H., Vinny Negi, Ph.D., Mingjun Liu, Ph.D., Catherine G. Corey, Frances Belmonte, Taijyu Satoh, M.D., Yingze Zhang, Ph.D., Dennis McNamara, M.D., Gang Li, Ph.D., Bing Wang, M.D., Ph.D., Sruti Shiva, Ph.D., Brett Kaufman, Ph.D., Delphine Gomez, Ph.D., Mehdi Nouraie, Ph.D., all of Pitt, as well as centers from the Indiana University School of Medicine, University of Arizona College of Medicine, NHS Blood and Transplant (UK), CNRS (France), and Tohoku University Graduate School of Medicine (Japan).

","score: 22.37891290527654, grade_level: '22'","score: 25.280239033693583, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/scitranslmed.add2029,"Hypoxic reprogramming of vasculature relies on genetic, epigenetic, and metabolic circuitry, but the control points are unknown. In pulmonary arterial hypertension (PAH), a disease driven by hypoxia inducible factor (HIF)–dependent vascular dysfunction, HIF-2α promoted expression of neighboring genes, long noncoding RNA (lncRNA) histone lysine N -methyltransferase 2E-antisense 1 ( KMT2E-AS1 ) and histone lysine N-methyltransferase 2E ( KMT2E ). KMT2E-AS1 stabilized KMT2E protein to increase epigenetic histone 3 lysine 4 trimethylation (H3K4me3), driving HIF-2α–dependent metabolic and pathogenic endothelial activity. This lncRNA axis also increased HIF-2α expression across epigenetic, transcriptional, and posttranscriptional contexts, thus promoting a positive feedback loop to further augment HIF-2α activity. We identified a genetic association between rs73184087, a single-nucleotide variant (SNV) within a KMT2E intron, and disease risk in PAH discovery and replication patient cohorts and in a global meta-analysis. This SNV displayed allele (G)–specific association with HIF-2α, engaged in long-range chromatin interactions, and induced the lncRNA-KMT2E tandem in hypoxic (G/G) cells. In vivo, KMT2E-AS1 deficiency protected against PAH in mice, as did pharmacologic inhibition of histone methylation in rats. Conversely, forced lncRNA expression promoted more severe PH. Thus, the KMT2E-AS1 /KMT2E pair orchestrates across convergent multi-ome landscapes to mediate HIF-2α pathobiology and represents a key clinical target in pulmonary hypertension."
"
By exploiting the technology used in Covid-19 vaccines, a team led by UCL, King's College London and Moderna scientists has created an effective therapy for a rare disease, in a study in mice, demonstrating the technology's potential therapeutic use in people.

The research, published in Science Translational Medicine, found that messenger RNA (mRNA) could be used to correct a rare liver genetic disease known as argininosuccinic aciduria in a mouse model of the disease.
Argininosuccinic aciduria is an inherited metabolic disorder that affects how the body breaks down protein -- potentially leading to high levels of ammonia in the blood. Patients affected by the disease are found to also experience an imbalance of glutathione regulation, which is important for liver detoxification. The condition occurs in approximately one in 100,000 newborns.
Over the coming years, the team aims to trial the therapy in people. Messenger RNA therapies are also currently being investigated in other rare inherited metabolic diseases -- propionic and methylmalonic acidaemias -- in global clinical trials sponsored by Moderna, including at Great Ormond Street Hospital for Children.
Co-lead Principal Investigator, Dr Julien Baruteau (UCL Great Ormond Street Institute of Child Health), said: ""Messenger RNA has revolutionised the field of vaccines during the COVID-19 pandemic. We believe it can now do the same for rare diseases.""
Rare diseases usually result from errors in the patient's DNA and affect around 300 million people worldwide.
However, fewer than 5% of these conditions have approved therapies. Most of these treatments use gene therapy to switch out the faulty gene and replace it with a normal functioning one, to alleviate the disease.

Until recently, gene therapy employed modified viruses to bring the therapeutic gene to the disease cells. However, these viral systems can cause severe adverse effects, such as reactions from the patient's own immune system, meaning that they can't be rolled out widely.
Consequently, the team wanted to investigate the possibility of using mRNA technology as an alternative solution.
Messenger RNA is a molecule that contains instructions that direct the cells to make proteins. By protecting the mRNA in a microdroplet of lipids, scientists were able to inject the mice intravenously with the therapy and target their liver cells.
The researchers tested the therapy on 31 mice both from birth and at a late stage of the disease as a rescue therapy in older mice that had argininosuccinic aciduria. They also used an equal number of untreated mice as a control (comparison) group.
For the mice, the benefit of each mRNA treatment only lasted around seven days, so the procedure was performed weekly over the course of up to eight weeks. However, the researchers expect that translation to humans will allow for longer gaps between treatments.
Over the course of the trial, the mice were given positron emission tomography (PET) scans as a non-invasive way to track the correction of glutathione regulation and the success of the treatment.

Researchers found that the treatment corrected the lethal consequences of the disease. All mice with the disease at birth left untreated died within the first two weeks of life, while the mice that received the mRNA treatment at birth survived for over three months. Additionally, six out of seven mice who received mRNA treatment as rescue therapy survived, while all those that were left untreated died.
The researchers also noted that, mRNA-treated organs were very similar to those in the unaffected, control mice.
Dr Baruteau said: ""We have shown that mRNA holds an unprecedented therapeutic potential for incurable genetic diseases, in particular liver conditions. We aim to apply this approach to other inherited liver diseases and translate mRNA therapy to patients, especially in children.""
Dr Tim Witney, Co-lead PI (School of Biomedical Engineering & Imaging Sciences, King's College London), said: ""This is a great example of collaborative science across multiple areas of expertise, which has yielded remarkable results. By understanding what goes wrong in this disease, we can not only correct the error, but follow this correction in real-time using imaging. We are looking forward to bringing these advances to patients in the near future.""
Dr Paolo Martini, Chief Scientific Officer for International Therapeutics Research Centres at Moderna, said: ""This collaboration has exemplified how academia and industry can work in synergy to explore how mRNA technology can be harnessed against rare diseases and may potentially lead to a treatment for a severe and debilitating disease such as argininosuccinic aciduria.""
The research was funded by Moderna, the Medical Research Council, the consortium London Advanced Therapies, Wellcome, Cancer Research UK, and the National Institute for Health and Care Research (NIHR) Great Ormond Street Hospital Biomedical Research Centre.

","score: 14.25426273039675, grade_level: '14'","score: 15.267511324586067, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/scitranslmed.adh1334,"The urea cycle enzyme argininosuccinate lyase (ASL) enables the clearance of neurotoxic ammonia and the biosynthesis of arginine. Patients with ASL deficiency present with argininosuccinic aciduria, an inherited metabolic disease with hyperammonemia and a systemic phenotype coinciding with neurocognitive impairment and chronic liver disease. Here, we describe the dysregulation of glutathione biosynthesis and upstream cysteine utilization in ASL-deficient patients and mice using targeted metabolomics and in vivo positron emission tomography (PET) imaging using ( S )-4-(3- 18 F-fluoropropyl)- l -glutamate ([ 18 F]FSPG). Up-regulation of cysteine metabolism contrasted with glutathione depletion and down-regulated antioxidant pathways. To assess hepatic glutathione dysregulation and liver disease, we present [ 18 F]FSPG PET as a noninvasive diagnostic tool to monitor therapeutic response in argininosuccinic aciduria. Human hASL mRNA encapsulated in lipid nanoparticles improved glutathione metabolism and chronic liver disease. In addition, hASL mRNA therapy corrected and rescued the neonatal and adult Asl-deficient mouse phenotypes, respectively, enhancing ureagenesis. These findings provide mechanistic insights in liver glutathione metabolism and support clinical translation of mRNA therapy for argininosuccinic aciduria."
"
Increases in symptoms of depression are associated with a subsequent increase in bodyweight when measured one month later, new research from the University of Cambridge has found.

The study, published today in PLOS ONE, found that the increase was only seen among people with overweight or obesity, but found no link between generally having greater symptoms of depression and higher bodyweight.
Research has suggested a connection between weight and mental health -- with each potentially influencing the other -- but the relationship is complex and remains poorly understood, particularly in relation to how changes in an individual's mental health influence their bodyweight over time.
To help answer this question, researchers at Cambridge's Medical Research Council (MRC) Epidemiology Unit examined data from over 2,000 adults living in Cambridgeshire, UK, who had been recruited to the Fenland COVID-19 Study.
Participants completed digital questionnaires on mental wellbeing and bodyweight every month for up to nine months during the COVID-19 pandemic (August 2020 -- April 2021) using a mobile app developed by Huma Therapeutics Limited.
Questions assessed an individual's symptoms of depression, anxiety and perceived stress. A higher score indicated greater severity, with the maximum possible scores being 24 for depression, 21 for anxiety and 40 for stress. The team then used statistical modelling to explore whether having poorer mental wellbeing than usual was related to changes in bodyweight one month later.
The researchers found that for every increment increase in an individual's usual score for depressive symptoms, their subsequent weight one month later increased by 45g. This may seem small but would mean, for example, that in an individual whose depressive symptoms score rose from five to 10 (equal to an increase from 'mild' to 'moderate' depressive symptoms) it would relate to an average weight gain of 225g (0.225kg).

This effect was only observed in those individuals with overweight (defined as BMI 25-29.9kg/m2) or with obesity (BMI of over 30kg/m2). Individuals with overweight had on average an increase of 52g for each increment point increase from their usual depressive symptoms score and for those with obesity the comparable weight gain was 71g. The effect was not seen in those individuals with a healthy weight.
First author Dr Julia Mueller from the MRC Epidemiology Unit said: ""Overall, this suggests that individuals with overweight or obesity are more vulnerable to weight gain in response to feeling more depressed. Although the weight gain was relatively small, even small weight changes occurring over short periods of time can lead to larger weight changes in the long-term, particularly among those with overweight and obesity.
""People with a high BMI are already at greater risk from other health conditions, so this could potentially lead to a further deterioration in their health. Monitoring and addressing depressive symptoms in individuals with overweight or obesity could help prevent further weight gain and be beneficial to both their mental and physical health.""
The researchers found no evidence that perceived stress or anxiety were related to changes in weight.
Senior author Dr Kirsten Rennie from the MRC Epidemiology Unit said: ""Apps on our phones make it possible for people to answer short questions at home more frequently and over extended periods of time, which provides much more information about their wellbeing. This technology could help us understand how changes in mental health influence behaviour among people with overweight or obesity and offer ways to develop timely interventions when needed.""
Although previous studies have suggested that poor mental health is both a cause and consequence of obesity, the research team found no evidence that weight predicted subsequent symptoms of depression.
The research was supported by the Medical Research Council.

","score: 15.32241235888295, grade_level: '15'","score: 17.637571301247768, grade_levels: ['college_graduate'], ages: [24, 100]",10.1371/journal.pone.0295117,"Poor mental health is associated with obesity, but existing studies are either cross-sectional or have long time periods between measurements of mental health and weight. It is, therefore, unclear how small fluctuations in mental wellbeing within individuals predict bodyweight over short time periods, e.g. within the next month. Studying this could identify modifiable determinants of weight changes and highlight opportunities for early intervention. 2,133 UK adults from a population-based cohort completed monthly mental health and weight measurements using a mobile app over a period of 6–9 months. We used random intercept regression models to examine longitudinal associations of depressive symptoms, anxiety symptoms and stress with subsequent weight. In sub-group analyses, we included interaction terms of mental health variables with baseline characteristics. Mental health variables were split into “between-individual” measurements (= the participant’s median score across all timepoints) and “within-individual” measurements (at each timepoint, the difference between the participant’s current score and their median). Within-individual variation in depressive symptoms predicted subsequent weight (0.045kg per unit of depressive symptom severity, 95% CI 0.021–0.069). We found evidence of a moderation effect of baseline BMI on the association between within-individual fluctuation in depressive symptoms and subsequent weight: The association was only apparent in those with overweight/obesity, and it was stronger in those with obesity than those with overweight (BMI<25kg/m2: 0.011kg per unit of depressive symptom severity [95% CI -0.017 to 0.039]; BMI 25–29.9kg/m2: 0.052kg per unit of depressive symptom severity [95%CI 0.010–0.094kg]; BMI≥30kg/m2: 0.071kg per unit of depressive symptom severity [95%CI 0.013–0.129kg]). We found no evidence for other interactions, associations of stress and anxiety with weight, or for a reverse direction of association. In this exploratory study, individuals with overweight or obesity were more vulnerable to weight gain following higher-than-usual (for that individual) depressive symptoms than individuals with a BMI<25kg/m2."
"
An atlas revealing the activity of individual placental cells during childbirth offers insight on what happens at the maternal-fetal interface during term labor, according to a study supported by the National Institutes of Health (NIH). The atlas provides a single-cell analysis of the human placenta and its surrounding membranes and is the first to use this method to understand the communication that occurs between maternal and fetal cells during the process of labor. Studying these processes aids understanding of typical labor and delivery at term, as well as preterm labor and delivery, which occurs before 37 weeks of pregnancy and is a leading cause of infant death and long-term disability. The work, led by researchers at NIH's Eunice Kennedy Shriver National Institute of Child Health and Human Development (NICHD), is published in the latest issue of Science Translational Medicine.

The study team created the placental atlas by using single-cell RNA sequencing (also called single-cell transcriptomics), which examines the activity and signaling patterns of individual cells. The atlas, which is based on samples from 42 term pregnancies, describes changes in gene expression patterns among the different cell types in the placenta and its surrounding membranes, which include both maternal and fetal-derived cells.
The researchers found that cells most affected by labor were in the chorioamniotic membranes, which surround the fetus and rupture as part of the labor and delivery process. They also found that fetal stromal and maternal decidual cells were particularly active in generating inflammatory signaling. These findings are consistent with previous research showing that inflammation (unrelated to infection) is important for sustaining labor.
The study is also a proof-of-concept that placental biomarkers present in maternal blood may be used to identify pregnancies at risk for preterm birth. The researchers used the atlas to classify cell-specific signatures of labor, which were detectable in maternal blood samples from term and preterm pregnancies. However, additional validation is needed in larger studies.
This work was conducted by NICHD's Pregnancy Research Branch and led by Roberto Romero, M.D., D.Med.Sci., NICHD; Nardhy Gomez-Lopez, Ph.D., Washington University School of Medicine; and Roger Pique-Regi, Ph.D., Wayne State University.

","score: 16.65769230769231, grade_level: '17'","score: 18.502842242503256, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/scitranslmed.adh8335,"Labor is a complex physiological process requiring a well-orchestrated dialogue between the mother and fetus. However, the cellular contributions and communications that facilitate maternal-fetal cross-talk in labor have not been fully elucidated. Here, single-cell RNA sequencing (scRNA-seq) was applied to decipher maternal-fetal signaling in the human placenta during term labor. First, a single-cell atlas of the human placenta was established, demonstrating that maternal and fetal cell types underwent changes in transcriptomic activity during labor. Cell types most affected by labor were fetal stromal and maternal decidual cells in the chorioamniotic membranes (CAMs) and maternal and fetal myeloid cells in the placenta. Cell-cell interaction analyses showed that CAM and placental cell types participated in labor-driven maternal and fetal signaling, including the collagen, C-X-C motif ligand (CXCL), tumor necrosis factor (TNF), galectin, and interleukin-6 (IL-6) pathways. Integration of scRNA-seq data with publicly available bulk transcriptomic data showed that placenta-derived scRNA-seq signatures could be monitored in the maternal circulation throughout gestation and in labor. Moreover, comparative analysis revealed that placenta-derived signatures in term labor were mirrored by those in spontaneous preterm labor and birth. Furthermore, we demonstrated that early in gestation, labor-specific, placenta-derived signatures could be detected in the circulation of women destined to undergo spontaneous preterm birth, with either intact or prelabor ruptured membranes. Collectively, our findings provide insight into the maternal-fetal cross-talk of human parturition and suggest that placenta-derived single-cell signatures can aid in the development of noninvasive biomarkers for the prediction of preterm birth."
"
More than 200 genes linked to depression have been newly identified in a worldwide study led by UCL researchers.

The research, published in Nature Genetics, found more than 50 new genetic loci (a locus is a specific position on a chromosome) and 205 novel genes that are associated with depression, in the first large-scale global study of the genetics of major depression in participants of diverse ancestry groups.
The study also showcases potential for drug repurposing, as one of the identified genes encodes a protein targeted by a common diabetes drug, while also pointing to new targets for drugs that may be developed to treat depression.
Depression is very common, yet how it develops is still poorly understood. Genetic research using big data offers new avenues to understand the disease, and has uncovered dozens of genes associated with depression, each which individually confer only a small increase in risk. It can also help find new drug targets, but so far research has mainly focused on people of European ancestry, which the researchers say is a major shortcoming, especially for such a complex condition as depression.
The new paper involved multiple genetic research methods including genome-wide association studies, a meta-analysis of previously published data and a transcriptome-wide association study. The international research team reviewed genetic data from 21 study cohorts from several countries and included nearly one million study participants of African, East Asian, South Asian, and Hispanic/Latin American descent, including 88,316people with major depression.
The study has made major advances identifying genes that are linked to risk of depression, both for newly-identified links and by strengthening prior evidence, and showcases some genes with potential implications for drug development, such as NDUFAF3. The protein that NDUFAF3 encodes has been implicated previously in mood instability, and it is targeted by metformin, the first-line drug for treating type 2 diabetes. Animal studies of metformin have suggested a possible link with reduced depression and anxiety, so this latest finding further suggests that additional research into metformin and depression may be warranted.
Other genes identified in the study may have biologically plausible links with depression, such as a gene linked to a neurotransmitter involved in goal-directed behaviour, and genes encoding a type of protein previously linked with multiple neurological conditions.

Surprisingly, the researchers found less overlap in the genetic hits for depression across ancestry groups than expected, at about 30% (based on a new method developed by the research team, to gauge the degree to which a genetic association found in one ancestry group is applicable to another ancestry group), which is less overlap than previously found for other traits and diseases. Therefore, it is even more important to study depression in diverse samples because some of the findings might be ancestry specific.
Lead author Professor Karoline Kuchenbaecker (UCL Psychiatry and UCL Genetics Institute) said: ""Here we show beyond doubt that our understanding of such complex diseases as depression will remain incomplete until we overcome the Eurocentric bias in genetics research and look for causes in diverse people across the world.
""Many genes previously found to be linked to the risk of depression might only actually affect depression risk in people of European origin, so in order for genetic research to contribute to new drugs that can help people of all ancestries, it is vital that our genetic datasets are suitably diverse.""
Professor Kuchenbaecker led the study alongside Dr Xiangrui Meng, PhD researcher Georgina Navoly and Dr Olga Giannakopoulou, and the collaborative consortia involved in the study included the Psychiatric Genomics Consortium-Major Depressive Disorder Working Group, China Kadoorie Biobank Collaborative Group, the 23andMe Research Team, Genes and Health Research Team, and BioBank Japan Project.
Professor Kuchenbaecker added: ""This is a first stage discovery effort, so more work will be needed to confirm these new targets, but finding them in the first place has been a huge and vital challenge, especially for a disorder where new medications are so urgently needed.""

","score: 19.9485609103079, grade_level: '20'","score: 22.451281793842035, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41588-023-01596-4,"Most genome-wide association studies (GWAS) of major depression (MD) have been conducted in samples of European ancestry. Here we report a multi-ancestry GWAS of MD, adding data from 21 cohorts with 88,316 MD cases and 902,757 controls to previously reported data. This analysis used a range of measures to define MD and included samples of African (36% of effective sample size), East Asian (26%) and South Asian (6%) ancestry and Hispanic/Latin American participants (32%). The multi-ancestry GWAS identified 53 significantly associated novel loci. For loci from GWAS in European ancestry samples, fewer than expected were transferable to other ancestry groups. Fine mapping benefited from additional sample diversity. A transcriptome-wide association study identified 205 significantly associated novel genes. These findings suggest that, for MD, increasing ancestral and global diversity in genetic studies may be particularly important to ensure discovery of core genes and inform about transferability of findings."
"
Exposure therapy for a specific fear can also help reduce other fears. This is the conclusion reached by psychologists at Ruhr University Bochum, Germany, who studied 50 people with a fear of spiders and heights. Although they only treated the fear of spiders, the fear of heights was likewise reduced in the process. Findings are described by a team around Iris Kodzaga and Professor Armin Zlomuzica from the Department of Behavioral and Clinical Neuroscience at Ruhr University Bochum in the journal Translational Psychiatry. 

A number of anxiety disorders are co-morbid
""Anxiety rarely comes alone,"" says Iris Kodzaga, lead author of the study. ""Patients who suffer from one fear often subsequently develop another."" The most effective treatment method is exposure: By confronting the fear-inducing situations or stimuli under psychotherapeutic supervision, patients learn to overcome their fear.
""It was long assumed that if a person had multiple fears, they would require multiple exposure therapies tailored to their specific fear,"" explains Kodzaga. The Bochum-based team is now challenging this assumption. The researchers measured fear of spiders and heights in 50 test subjects before and after exposure therapy targeting spider fear. Measures included subjective data from specific questionnaires for fear of spiders and heights. In addition, the researchers collected quantitative behavioral measures, such as how close the participants dared to approach the spiders or how far they could climb a high church tower.
Therapy methods could become more universal
Exposure therapy for spider fear not only reduced the fear of spiders, but also the fear of heights. A significant effect emerged in both the subjective and behavioral measures: Fear of heights decreased by an average of 15 percent as a result of exposure to spiders.
""The discovery that exposure to spiders also reduces fear of heights opens up new perspectives for the efficient treatment of phobias,"" says Iris Kodzaga. ""It could mean that we can rethink therapeutic approaches and possibly develop more universal methods.""
How exactly this effect is transferred from one fear to another is still unclear. ""The effect can't be fully explained by associative learning processes. The generalization effect might be due to an increase in self-efficacy as a result of exposure therapy,"" says the researcher. ""But perhaps there is also a common denominator between fear of spiders and fear of heights that's not obvious. We'll need to conduct follow-up studies to find out more.""

","score: 12.62046215046215, grade_level: '13'","score: 12.794137124137123, grade_levels: ['college'], ages: [18, 24]",10.1038/s41398-023-02698-7,"Previous research has shown that fear associated with one stimulus often spreads to other stimuli with similar perceptual features as well as across different stimulus categories. Exposure is considered as the most effective intervention to attenuate exaggerated fear. The extent to which exposure treatment effects can generalize to fears not targeted during treatment remains elusive. Previous studies on possible generalization of beneficial effects of exposure used stimuli sharing the same stimulus category and/or stimuli having high perceptual similarity. The current study examined whether exposure treatment generalization can be achieved for untreated stimuli which do not share any perceptual resemblance and belong to a different fear category. An analogue sample of fifty participants with fear of spiders (animal-related fears) and heights (natural environment-related fears) was tested. Participants have been randomly assigned to either an exposure treatment (n = 24) or a control condition (n = 26). Exposure treatment was designed to only target participants’ fear of spiders, leaving their fear of heights untreated. Results demonstrated that the effects of exposure treatment generalized to fear of heights, as indicated by a reduction in behavioral avoidance, as well as self-reported acrophobia symptoms. The present study confutes the assumption that generalization of exposure effects to untreated fears is based on perceptual similarity. Clearly, further research is required to determine the decisive factors, in order to expand the generalization effect permanently to any given type of fear."
"
In people with amyotrophic lateral sclerosis (ALS), changes in neurons appear to activate immune cells. Lowering the inflammation could reduce the symptoms of the disease, according to a study led by Chantelle Sephton, a professor at Université Laval's Faculty of Medicine.

ALS is caused by the loss of upper motor neurons, located in the brain, and lower motor neurons, which extend from the spinal cord to the muscles. Using a genetically modified mouse model, Chantelle Sephton and her team found that structural changes in the upper neurons occurred prior to disease symptoms.
The study suggests that these morphological changes send a signal to microglia and astrocytes, the immune cells of the central nervous system. When they arrive, their effect is protective, but if they stay too long, they become toxic to neurons. This leads to a reduction in synaptic connections between motor neurons in the brain and spinal cord, which in turn results in a reduction in synaptic connections with muscles. These changes lead to atrophy and loss of motor function.
Given this correlation between symptoms and immune response, the research team wondered whether it might be possible to restore synaptic connections by blocking inflammation. "" We tested a semi-synthetic drug based on Withaferin A, an extract of the Ashwagandha plant, which has been used for thousands of years in traditional Indian medicine,"" explains CERVO Research Center affiliate Chantelle Sephton.
The drug blocks inflammation and allows motor neurons to return to a more normal state. ""We have noticed that neurons regenerate in the absence of activated immune cells. The dendrites of motor neurons start to grow and make connections again, increasing the number of synapses between motor neurons and muscles,"" reports the researcher.
This seems a promising way of improving ALS symptoms, whether the disease is familial or sporadic, since both types are associated with inflammation.
Other diseases where inflammation plays a role, such as Alzheimer's, could benefit from this approach.
The study was published in the scientific journal Acta Neuropathologica Communications. The signatories are Mari Carmen Pelaez, Antoine Desmeules, Pauline Gelon, Bastien Glasson, Laetitia Marcadet, Alicia Rodgers, Daniel Phaneuf, Silvia Pozzi, Paul Dutchak, Jean-Pierre Julien and Chantelle Sephton.

","score: 13.298449788755281, grade_level: '13'","score: 14.575594735131624, grade_levels: ['college_graduate'], ages: [24, 100]",10.1186/s40478-023-01671-1,"Amyotrophic lateral sclerosis (ALS) and frontotemporal dementia (FTD) are related neurodegenerative diseases that belong to a common disease spectrum based on overlapping clinical, pathological and genetic evidence. Early pathological changes to the morphology and synapses of affected neuron populations in ALS/FTD suggest a common underlying mechanism of disease that requires further investigation. Fused in sarcoma (FUS) is a DNA/RNA-binding protein with known genetic and pathological links to ALS/FTD. Expression of ALS-linked FUS mutants in mice causes cognitive and motor defects, which correlate with loss of motor neuron dendritic branching and synapses, in addition to other pathological features of ALS/FTD. The role of ALS-linked FUS mutants in causing ALS/FTD-associated disease phenotypes is well established, but there are significant gaps in our understanding of the cell-autonomous role of FUS in promoting structural changes to motor neurons, and how these changes relate to disease progression. Here we generated a neuron-specific FUS-transgenic mouse model expressing the ALS-linked human FUSR521G variant, hFUSR521G/Syn1, to investigate the cell-autonomous role of FUSR521G in causing loss of dendritic branching and synapses of motor neurons, and to understand how these changes relate to ALS-associated phenotypes. Longitudinal analysis of mice revealed that cognitive impairments in juvenile hFUSR521G/Syn1 mice coincide with reduced dendritic branching of cortical motor neurons in the absence of motor impairments or changes in the neuromorphology of spinal motor neurons. Motor impairments and dendritic attrition of spinal motor neurons developed later in aged hFUSR521G/Syn1 mice, along with FUS cytoplasmic mislocalisation, mitochondrial abnormalities and glial activation. Neuroinflammation promotes neuronal dysfunction and drives disease progression in ALS/FTD. The therapeutic effects of inhibiting the pro-inflammatory nuclear factor kappa B (NF-κB) pathway with an analog of Withaferin A, IMS-088, were assessed in symptomatic hFUSR521G/Syn1 mice and were found to improve cognitive and motor function, increase dendritic branches and synapses of motor neurons, and attenuate other ALS/FTD-associated pathological features. Treatment of primary cortical neurons expressing FUSR521G with IMS-088 promoted the restoration of dendritic mitochondrial numbers and mitochondrial activity to wild-type levels, suggesting that inhibition of NF-κB permits the restoration of mitochondrial stasis in our models. Collectively, this work demonstrates that FUSR521G has a cell-autonomous role in causing early pathological changes to dendritic and synaptic structures of motor neurons, and that these changes precede motor defects and other well-known pathological features of ALS/FTD. Finally, these findings provide further support that modulation of the NF-κB pathway in ALS/FTD is an important therapeutic approach to attenuate disease."
"
Teens from larger families have poorer mental health than those with fewer siblings, according to a large analysis of children in the United States and China.

The details of the pattern vary depending on factors such as the spacing of sibling ages and the age of the siblings.
But the fact that the overall pattern was found in both countries is striking, said Doug Downey, lead author of the study and professor of sociology at The Ohio State University.
""Our results couldn't have been easily predicted before we did the study,"" Downey said.
""Other studies have shown that having more siblings is associated with some positive effects, so our results were not a given.""
Downey conducted the study with Rui Cao, a doctoral student in sociology at Ohio State. Their results were published recently in the Journal of Family Issues.
Their Chinese analysis draws on more than 9,400 eighth graders from the China Education Panel Study. In the United States, they analyzed over 9,100 American eighth graders from the Early Childhood Longitudinal Study -- Kindergarten Cohort of 1988.

The average youth in China has nearly .7 fewer siblings than the average American youth (.89 compared to 1.6).
Consistent with what was expected because of China's One Child Policy, about one-third of Chinese children are only children (34%), compared to just 12.6% of American children.
In both countries, researchers asked students (average age of 14) a variety of questions about their mental health, although the questions were different in China and the United States.
In China, teens with no siblings showed the best mental health, while in the United States, those with no or one sibling had similar mental health.
Some issues could only be analyzed using the U.S. data.
Results in the U.S. showed that half and full siblings are both linked to poorer mental health.

And having older siblings and siblings closely spaced in age tended to have the worst impacts on well-being, the U.S. data found. Siblings born within one year of each other had the strongest negative association with mental health.
Why are more siblings linked with poorer mental health?
Downey said the overall findings fits with the ""resource dilution"" explanation.
""If you think of parental resources like a pie, one child means that they get all the pie -- all the attention and resources of the parents,"" he said.
""But when you add more siblings, each child gets fewer resources and attention from the parents, and that may have an impact on their mental health.""
The fact that closely spaced siblings have the most negative impact bolsters that explanation. Children who are near the same age will be competing for the same types of parental resources, he said.
Another possibility, though, is that the families that have many versus few children are different in other ways that may reduce mental health for their kids -- the so-called selectivity explanation.
The differences between China and the U.S. do provide some support for the selectivity explanation. In each country, children from families associated with the most socioeconomic advantage had the best mental health.
In China, that was children in one-child families, while in the U.S. it was children with zero or one sibling.
But the overall results still suggest that selectivity explanation falls short in accounting for what is happening.
""What we found is that when you add all the evidence up, the effect of siblings on mental health is more on the negative side than the positive side,"" Downey said.
Downey noted that the data doesn't get at the quality of sibling relationships. It is likely that higher-quality sibling relationships will be more beneficial to children and may have more positive effects on mental health.
While this study shows a negative impact of siblings, other research has shown that having more brothers and sisters is associated with better social skills among kindergarteners and a lower likelihood of divorce among adults.
""This combination of results is not easily explained. We still have more to learn about the impact of siblings,"" Downey said.
""This is particularly important now as the U.S. and other countries have lower fertility rates. Understanding the consequences of growing up with fewer or no brothers and sisters is an increasingly important social issue.""

","score: 10.993894993894997, grade_level: '11'","score: 11.519435286935284, grade_levels: ['12'], ages: [17, 18]",10.1177/0192513X231220045,"A growing number of children are being raised with few or no siblings yet the consequences of this seismic demographic shift in family forms are not well understood. We investigate this question in the U.S. and China because previous studies highlight how contextual features can play an important role shaping how siblings matter. Our Chinese analyses draw on more than 9,400 eighth graders from the China Education Panel Study (CEPS). In the U.S., we analyze over 9,100 American eighth graders from the Early Childhood Longitudinal Study—Kindergarten Cohort of 1998 (ECLS-K:98), where our data allow us to consider multiple features of the sibship structure (e.g., size, sex composition, and density). We find that number of siblings is negatively associated with mental health in both China and the U.S., although the details of this pattern (non-linear association, sisters versus brothers, and closely versus widely spaced siblings) vary."
"
Researchers at Karolinska Institutet in Sweden have shown that nasal drops with IgA antibodies can protect mice from SARS-CoV-2 infection. The results imply a new way to protect individuals at high risk from different variants of the SARS-CoV-2 virus and possibly other infections. The study is published in the Proceedings of the National Academy of Sciences.

Different types of antibodies have different functions in the body. IgA antibodies are part of the so-called adaptive immune system and reside naturally in the mucosal membranes of the airways. Absence or low levels of mucosal IgA is known to be associated with an increased risk of SARS-CoV-2 breakthrough infections.
The current COVID-19 vaccines mainly stimulate an IgG antibody response in the body, and earlier studies have shown that their ability to protect against infection with the new Omicron variants of the virus is limited.
To overcome this, the group led by professor Qiang Pan-Hammarström at Karolinska Institutet used genetic engineering to create IgA antibodies that bind to the SARS-CoV-2 spike protein in a similar way to the IgG antibodies.
Neutralized the virus effectively
Mice infected with the Omicron variant received the IgA antibody treatment through nasal administration. The nasal drops significantly diminished the virus load in the trachea and lungs of the infected mice. The IgA antibodies were shown to bind stronger to the spike protein of SARS-CoV-2 and were more effective in neutralizing the virus compared to the original IgG antibodies.
""The results show that these genetically engineered antibodies can strengthen the protection against new virus variants, but they are not intended to replace current vaccines,"" says Harold Marcotte, associate professor at the Department of Medical Biochemistry and Biophysics, Karolinska Institutet, and the first author of the paper.

""Traditional vaccines elicit an active immune response from the body, whereas this is a passive immunization strategy,"" he continues. ""An active immunization approach that induces a mucosal immune response would be ideal, but hopefully our approach is suitable for protecting the most vulnerable individuals, like the elderly or immunocompromised persons.""
Promising strategy for other infections
There are also hopes that the method can be used to neutralize other current and emerging variants of the virus.
""We believe that this will be a very promising strategy, not only for COVID-19 and the new variants, but also for other infectious diseases, including influenza and other respiratory infections and gastric mucosal infections such as Helicobacter pylori, where there is no vaccine available at the moment,"" says Qiang Pan-Hammarström, professor at the same department and last author of the paper.
The study was conducted within the European research consortium ATAC and through a collaborative effort between Sweden and China including Linköping University, Peking University, Guangzhou Institutes of Biomedicine and Health, Fudan University, Peking Union Medical College, Wuhan Institute of Virology, and Kunming Institute of Zoology.
It was funded by EU's Horizon 2020 research and innovation program, a joint VR-NCSF funding, the Knut and Alice Wallenberg Foundation and the Swiss National Science Foundation grant BRIDGE. Some of the authors are listed as inventors of patents regarding antibody treatment.

","score: 16.688473282442747, grade_level: '17'","score: 17.83302330253114, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2315354120,"The emergence of Omicron lineages and descendent subvariants continues to present a severe threat to the effectiveness of vaccines and therapeutic antibodies. We have previously suggested that an insufficient mucosal immunoglobulin A (IgA) response induced by the mRNA vaccines is associated with a surge in breakthrough infections. Here, we further show that the intramuscular mRNA and/or inactivated vaccines cannot sufficiently boost the mucosal secretory IgA response in uninfected individuals, particularly against the Omicron variant. We thus engineered and characterized recombinant monomeric, dimeric, and secretory IgA1 antibodies derived from four neutralizing IgG monoclonal antibodies (mAbs 01A05, rmAb23, DXP-604, and XG014) targeting the receptor-binding domain of the spike protein. Compared to their parental IgG antibodies, dimeric and secretory IgA1 antibodies showed a higher neutralizing activity against different variants of concern (VOCs), in part due to an increased avidity. Importantly, the dimeric or secretory IgA1 form of the DXP-604 antibody significantly outperformed its parental IgG antibody, and neutralized the Omicron lineages BA.1, BA.2, and BA.4/5 with a 25- to 75-fold increase in potency. In human angiotensin converting enzyme 2 (ACE2) transgenic mice, a single intranasal dose of the dimeric IgA DXP-604 conferred prophylactic and therapeutic protection against Omicron BA.5. Thus, dimeric or secretory IgA delivered by nasal administration may potentially be exploited for the treatment and prevention of Omicron infection, thereby providing an alternative tool for combating immune evasion by the current circulating subvariants and, potentially, future VOCs."
"
Reducing stimulant use was associated with significant improvement in measures of health and recovery among people with stimulant use disorder, even if they did not achieve total abstinence. This finding is according to an analysis of data from 13 randomized clinical trials of treatments for stimulant use disorders involving methamphetamine and cocaine. Historically, total abstinence has been the standard goal of treatment for substance use disorders, however, these findings support the growing recognition that a more nuanced perspective on measuring treatment success may be beneficial.

The study, published in Addiction, was led by scientists at the Johns Hopkins Bloomberg School of Public Health, Baltimore, in collaboration with researchers at the National Institute on Drug Abuse (NIDA), part of the National Institutes of Health.
Researchers found that transitioning from high use (five or more days a month) to lower use (one to four days a month) was associated with lower levels of drug craving, depression, and other drug-related challenges compared to no change in use. These results suggest that reduction in use of methamphetamine or cocaine, in addition to abstinence, is a meaningful surrogate or intermediate clinical outcome in medication development for stimulant addiction. Unlike other substance use disorders, such as opioid use disorder or alcohol use disorder, there are currently no U.S. Food and Drug Administration-approved pharmacological treatments for stimulant use disorders.
""These findings align with an evolving understanding in the field of addiction, affirming that abstinence should be neither the sole aim nor only valid outcome of treatment,"" said NIDA Director Nora Volkow, M.D. ""Embracing measures of success in addiction treatment beyond abstinence supports more individualized approaches to recovery, and may lead to the approval of a wider range of medications that can improve the lives of people with substance use disorders.""
Temporary returns to use after periods of abstinence are part of many recovery journeys, and relying exclusively on abstinence as an outcome in previous clinical trials may have masked beneficial effects of treatment. To help address this research gap, investigators analyzed data from previous clinical trials to study the effects of transitioning to reduced drug use or abstinence on a broad range of health measures. Researchers analyzed data from 13 randomized clinical trials evaluating the impact of potential pharmacological medications for stimulant use disorders, which included more than 2,000 individuals seeking treatment for cocaine or methamphetamine use disorders at facilities across the United States. The trials were of varying duration and were undertaken from 2001 to 2017.
Researchers compared ""no reduced use,"" ""reduced use,"" and ""abstinence"" in association with multiple health outcomes, such as severity of drug-related symptoms, craving, and depression. The study found that more participants reduced the frequency of primary drug use (18%) than achieved abstinence (14%). While abstinence was associated with the greatest clinical improvement, reduced use was significantly associated with multiple measures of improvements in psychosocial functioning at the end of the trials, such as a 60% decrease in craving for the primary drug, 41% decrease in drug-seeking behaviors, and a 40% decrease in depression severity, compared to the beginning of the trial.
These findings suggest that improvements in health and functioning can occur with reduced use and should be considered in the development and approval of treatments for substance use disorders. Research on alcohol use disorder has shown similar results, with studies finding that transitioning from high-risk to low-risk drinking is associated with functional improvement and fewer mental and general health consequences caused by alcohol. As a result, a reduced number of heavy drinking days is already recognized as a meaningful clinical outcome in medication development for alcohol use disorder.

""With addiction, the field has historically acknowledged only the benefits of abstinence, missing opportunities to celebrate and measure the positive impacts of reduced substance use,"" said Mehdi Farokhina, M.D., M.P.H., a staff scientist in the NIDA Intramural Research Program, and author on the paper. ""This study provides evidence that reducing the overall use of drugs is important and clinically meaningful. This shift may open opportunities for medication development that can help individuals achieve these improved outcomes, even if complete abstinence is not immediately achievable or wanted.""
The authors note that the study did not include behavioral treatment trials, which were too varied to harmonize their data. In addition, the study featured only people who enrolled in clinical trials, which could limit generalizability. Additional research is needed to understand the potential clinical benefits of reduced drug use, along with other harm reduction-based indicators of clinical improvement in real-world populations. The authors highlight that the findings of this study should encourage researchers to re-evaluate treatment outcome measures in their studies and consider non-abstinence treatment outcomes in the development of new medications for the treatment of stimulant use disorders. The authors also write that these new findings need to be replicated in other contexts with additional substance use disorders such as opioid use disorder.
""By promoting an understanding of addiction as a treatable disorder with multifaceted causes, society can work towards providing better support, resources, and care for individuals on their way to recovery,"" said Masoumeh Aminesmaeili, M.D., lead author of the paper. ""This approach is not only compassionate, but also clinically valid in addressing the complex nature of addiction.""
For more information on substance and mental health treatment programs in your area, call the free and confidential National Helpline 1-800-662-HELP (4357) or visit: https://www.findtreatment.gov 

","score: 18.105461426492003, grade_level: '18'","score: 20.09645924308588, grade_levels: ['college_graduate'], ages: [24, 100]",10.1111/add.16409,"Total abstinence has historically been the goal of treatment for substance use disorders; however, there is a growing recognition of the health benefits associated with reduced use as a harm reduction measure in stimulant use disorders treatment. We aimed to assess the validity of reduced stimulant use as an outcome measure in randomized controlled trials (RCTs) of pharmacological interventions for stimulant use disorder. We conducted a secondary analysis of a pooled dataset of 13 RCTs. Participants were individuals seeking treatment for cocaine or methamphetamine use disorders (N = 2062) in a wide range of treatment facilities in the United States. We validated reduced stimulant use against a set of clinical indicators drawn from harmonized measurements, including severity of problems caused by drug use, comorbid depression, global severity of substance use and improvement, severity of drug‐seeking behavior, craving and high‐risk behaviors, all assessed at the end of the trial, as well as follow‐up urine toxicology. A series of mixed effect regression models was conducted to validate reduction in frequency of use against no reduction in use and abstinence. More participants reduced frequency of primary drug use than achieved abstinence (18.0% vs. 14.2%, respectively). Reduced use was significantly associated with decreases in craving for the primary drug [60.1%, 95% confidence interval (CI) = 54.3%–64.7%], drug seeking behaviors (41.0%, 95% CI = 36.6%–45.7%), depression severity (39.9%, 95% CI = 30.9%–48.3%), as well as multiple measures of global improvement in psychosocial functioning and severity of drug‐related problems, albeit less strongly so than abstinence. Moreover, reduced use was associated with sustained clinical benefit at follow‐up, as confirmed by negative urine tests (adjusted odds ratio compared with those with no reduction in use: 0.50, 95% CI = 0.35–0.71). Reduced frequency of stimulant use appears to be associated with meaningful improvement in various clinical indicators of recovery. Assessment of reduced use, in addition to abstinence, could broaden the scope of outcomes measured in randomized controlled trials of stimulant use disorders and facilitate the development of more diverse treatment approaches."
"
Like a criminal entering a witness protection program, cancer cells can shed their past and take on a new identity. Detecting such an identity-switch is particularly challenging when metastatic castration-resistant prostate cancer (CRPC) advances from adenocarcinoma to neuroendocrine prostate cancer (NEPC), a very difficult cancer to treat.

Now, however, researchers at Dana-Farber Cancer Institute and the University of Trento, Italy, have developed a blood test, described in Cancer Discovery, that can reliably detect NEPC and differentiate it from CRPC-adenocarcinoma (CRPC-adeno).
NEPC is currently diagnosed using a biopsy of tumor tissue from a metastatic tumor site. Yet, it isn't always clear to clinicians when to do a biopsy. Further, biopsies may be unreliable since metastatic tumors are often heterogeneous.
""As prostate cancer treatments get more effective, we expect the emergence of different types of treatment resistance like neuroendocrine prostate cancer that help them evade treatment,"" says co-lead author Himisha Beltran, MD, associate professor of medicine, Lank Center for Genitourinary Oncology and the Division of Molecular and Cellular Oncology, Dana-Farber Cancer Institute. ""We hope this blood test can be used by clinicians to determine if a patient is developing neuroendocrine prostate cancer.""
Approximately 10-15% of patients with metastatic prostate cancer develop NEPC. The transition involves a shift from cancer cells that are dependent on hormones called androgens to cancer cells that no longer even recognize androgens.
""They can stop expressing the androgen receptor,"" says Beltran. ""They shut down their hormone-driven identity and they turn on a new identity as a way to develop resistance to treatment.""
In previous research, the international team studied tissue samples from biopsies to identify the genetic and epigenetic changes related to this transition. They found that, across the whole genome, specific epigenetic changes, in the form of DNA methylation changes that switch genes on or off, distinguish CRPC-adeno from NEPC.

These epigenetic changes can be detected in blood because the body is constantly shedding fragments of dead cells into the bloodstream. Those cells come from all over the body, including from tumors. The fragments include bits of DNA, called cell free DNA (cfDNA), along with whatever epigenetic tags and structures were attached to them when the cell died.
Beltran collaborated with a computational team at the University of Trento, led by Francesca Demichelis, PhD, co-lead author on the study, to create a blood panel test, called NEMO (NEuroendocrine MOnitoring panel). ""The test selectively probes cfDNA in blood plasma for relevant DNA fragments and measures their methylation,"" says Demichelis. ""Because the number of methylated regions needed to distinguish between normal, CRPC-adeno, and NEPC cells is small, the panel of genes sequenced by the test is minimal and efficient.""
NEMO reports two measures: the tumor fraction, a measure of disease burden based on the ratio of tumor DNA to normal DNA in the blood; and the tumor type, either CRPC-adeno or NEPC. The tumor type is reported as a score on a continuum because a patient's cancer might be a mix of the two.
""It not only picks up the neuroendocrine phenotype but also can pick up subtypes in the middle, as tumors transition from one subtype to the other,"" says Beltran.
Beltran's team tested NEMO in several preclinical models of prostate cancer and in blood samples from multiple patient cohorts with known prostate cancer subtypes. The NEMO tumor type score identified subtypes with a high level of accuracy.
The team also evaluated NEMO in two clinical trials of patients with aggressive CRPC. The panel's estimation of tumor fraction was consistent with other accepted measures of disease burden, suggesting that the test could be used to monitor response to treatment by revealing if a tumor is shrinking or not. This is especially valuable because, measures of disease burden, such as prostate-specific antigen levels, become unreliable when a tumor switches its identity to NEPC.

NEMO successfully identified patients with NEPC in the two clinical trials based on pathology reports. It also identified patients who had not been diagnosed with NEPC yet had signs of a transition to NEPC in their pathology reports.
""Now that we have robustly shown the accuracy of this panel test, we're excited to apply it to clinical questions,"" says Beltran. ""We'd like to determine if this test can help us predict which patients respond to certain prostate cancer treatments, including precise treatments that target neuroendocrine prostate cancer.""
The information in a NEMO panel may also help clinicians select targeted treatments for patients or help investigators learn more about the disease. Further, adds Beltran, the test's approach could potentially be applied to other forms of cancer to distinguish subtypes.
Longer term, Beltran and colleagues will take steps toward transitioning NEMO into a clinical test that physicians can order and use in practice.
Funding: The Prostate Cancer Foundation, National Cancer Institute, Fondazione AIRC per la Ricerca sul Cancro ETS, Cancer Research UK, United States Department of Defense, the Doris Duke Foundation, the Safeway Foundation, the V Foundation, and the Institute for Prostate Cancer Research.

","score: 14.206566614007375, grade_level: '14'","score: 15.237364402317006, grade_levels: ['college_graduate'], ages: [24, 100]",10.1158/2159-8290.CD-23-0754,"Castration-resistant prostate cancer (CRPC) is a heterogeneous disease associated with phenotypic subtypes that drive therapy response and outcome differences. Histologic transformation to castration-resistant neuroendocrine prostate cancer (CRPC-NE) is associated with distinct epigenetic alterations, including changes in DNA methylation. The current diagnosis of CRPC-NE is challenging and relies on metastatic biopsy. We developed a targeted DNA methylation assay to detect CRPC-NE using plasma cell-free DNA (cfDNA). The assay quantifies tumor content and provides a phenotype evidence score that captures diverse CRPC phenotypes, leveraging regions to inform transcriptional state. We tested the design in independent clinical cohorts (n = 222 plasma samples) and qualified it achieving an AUC &gt; 0.93 for detecting pathology-confirmed CRPC-NE (n = 136). Methylation-defined cfDNA tumor content was associated with clinical outcomes in two prospective phase II clinical trials geared towards aggressive variant CRPC and CRPC-NE. These data support the application of targeted DNA methylation for CRPC-NE detection and patient stratification. Neuroendocrine prostate cancer is an aggressive subtype of treatment-resistant prostate cancer. Early detection is important, but the diagnosis currently relies on metastatic biopsy. We describe the development and validation of a plasma cell–free DNA targeted methylation panel that can quantify tumor fraction and identify patients with neuroendocrine prostate cancer noninvasively."
"
Researchers have created the world's largest ancient human gene bank by analysing the bones and teeth of almost 5,000 humans who lived across western Europe and Asia up to 34,000 years ago.

By sequencing ancient human DNA and comparing it to modern-day samples, the international team of experts mapped the historical spread of genes -- and diseases -- over time as populations migrated.
The 'astounding' results have been revealed in four trailblazing research papers published today (10 January 2024) in the same issue of Nature and provide new biological understanding of debilitating disorders.
The extraordinary study involved a large international team led by Professor Eske Willerslev at the Universities of Cambridge and Copenhagen, Professor Thomas Werge at the University of Copenhagen, and Professor Rasmus Nielsen at University of California, Berkeley and involved contributions from 175 researchers from around the globe.
The scientists found: The startling origins of neurodegenerative diseases including multiple sclerosis Why northern Europeans today are taller than people from southern Europe How major migration around 5,000 years ago introduced risk genes into the population in north-western Europe -- leaving a legacy of higher rates of MS today Carrying the MS gene was an advantage at the time as it protected ancient farmers from catching infectious diseases from their sheep and cattle Genes known to increase the risk of diseases such as Alzheimer's and type 2 diabetes were traced back to hunter gatherers Future analysis is hoped to reveal more about the genetic markers of autism, ADHD, schizophrenia, bipolar disorder, and depressionNorthern Europe has the highest prevalence of multiple sclerosis in the world. A new study has found the genes that significantly increase a person's risk of developing multiple sclerosis (MS) were introduced into north-western Europe around 5,000 years ago by sheep and cattle herders migrating from the east.
By analysing the DNA of ancient human bones and teeth, found at documented locations across Eurasia, researchers traced the geographical spread of MS from its origins on the Pontic Steppe (a region spanning parts of what are now Ukraine, South-West Russia and the West Kazakhstan Region).

They found that the genetic variants associated with a risk of developing MS 'travelled' with the Yamnaya people -- livestock herders who migrated over the Pontic Steppe into North-Western Europe.
These genetic variants provided a survival advantage to the Yamnaya people, most likely by protecting them from catching infections from their sheep and cattle. But they also increased the risk of developing MS.
""It must have been a distinct advantage for the Yamnaya people to carry the MS risk genes, even after arriving in Europe, despite the fact that these genes undeniably increased their risk of developing MS,"" said Professor Eske Willerslev, jointly at the Universities of Cambridge and Copenhagen and a Fellow of St John's College, an expert in analysis of ancient DNA and Director of the project.
He added: ""These results change our view of the causes of multiple sclerosis and have implications for the way it is treated.""
The age of specimens ranges from the Mesolithic and Neolithic through the Bronze Age, Iron Age and Viking period into the Middle Ages. The oldest genome in the data set is from an individual who lived approximately 34,000 years ago.
The findings provide an explanation for the 'North-South Gradient', in which there are around twice as many modern-day cases of MS in northern Europe than southern Europe, which has long been a mystery to researchers.

From a genetic perspective, the Yamnaya people are thought to be the ancestors of the present-day inhabitants of much of North-Western Europe. Their genetic influence on today's population of southern Europe is much weaker.
Previous studies have identified 233 genetic variants that increase the risk of developing MS. These variants, also affected by environmental and lifestyle factors, increase disease risk by around 30 percent. The new research found that this modern-day genetic risk profile for MS is also present in bones and teeth that are thousands of years old.
""These results astounded us all. They provide a huge leap forward in our understanding of the evolution of MS and other autoimmune diseases. Showing how the lifestyles of our ancestors impacted modern disease risk just highlights how much we are the recipients of ancient immune systems in a modern world,"" said Dr William Barrie, a postdoc in the University of Cambridge's Department of Zoology and co-author of the paper.
Multiple sclerosis is a neurodegenerative disease in which the body's immune system mistakenly attacks the 'insulation' surrounding the nerve fibres of the brain and spinal cord. This causes symptom flares known as relapses as well as longer-term degeneration, known as progression.
Professor Lars Fugger, a co-author of the MS study professor and consultant physician at John Radcliffe Hospital, University of Oxford, said: ""This means we can now understand and seek to treat MS for what it actually is: the result of a genetic adaptation to certain environmental conditions that occurred back in our prehistory.""
Professor Astrid Iversen, another co-author based at the University of Oxford, said: ""We now lead very different lives to those of our ancestors in terms of hygiene, diet, and medical treatment options and this combined with our evolutionary history means we may be more susceptible to certain diseases than our ancestors were, including autoimmune diseases such as MS.""
The Lundbeck Foundation GeoGenetics Centre -- the resource underpinning the discoveries
The new findings were made possible by the analysis of data held in a unique gene bank of ancient DNA, created by the researchers over the past five years with funding from the Lundbeck Foundation.
This is the first gene bank of its kind in the world and already it has enabled fascinating new insights in areas from ancient human migrations, to genetically-determined risk profiles for the development of brain disorders.
By analysing the bones and teeth of almost 5,000 ancient humans, held in museum collections across Europe and Western Asia, the researchers generated DNA profiles ranging across the Mesolithic and Neolithic through the Bronze Age, Iron Age and Viking period into the Middle Ages. They compared the ancient DNA data to modern DNA from 400,000 people living in Britain, held in the UK Biobank.
""Creating a gene bank of ancient DNA from Eurasia's past human inhabitants was a colossal project, involving collaboration with museums across the region,"" said Willerslev.
He added: ""We've demonstrated that our gene bank works as a precision tool that can give us new insights into human diseases, when combined with analyses of present-day human DNA data and inputs from several other research fields. That in itself is amazing, and there's no doubt it has many applications beyond MS research.""
The team now plans to investigate other neurological conditions including Parkinson's and Alzheimer's diseases, and psychiatric disorders including ADHD and schizophrenia.
They have received requests from disease researchers across the world for access to the ancient DNA profiles, and eventually aim to make the gene bank open access.
The research was funded by a €8M grant from the Lundbeck Foundation, and conducted at the Lundbeck Foundation Geogenetics Centre at the University of Copenhagen.
Jan Egebjerg, Director of Research at the Lundbeck Foundation, said: ""The rationale for awarding such a large research grant to this project, as the Lundbeck Foundation did back in 2018, was that if it all worked out, it would represent a trail-blazing means of gaining a deeper understanding of how the genetic architecture underlying brain disorders evolved over time. And brain disorders are our specific focus area.""

","score: 17.706751604662646, grade_level: '18'","score: 20.203457913831222, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06618-z,"Multiple sclerosis (MS) is a neuro-inflammatory and neurodegenerative disease that is most prevalent in Northern Europe. Although it is known that inherited risk for MS is located within or in close proximity to immune-related genes, it is unknown when, where and how this genetic risk originated1. Here, by using a large ancient genome dataset from the Mesolithic period to the Bronze Age2, along with new Medieval and post-Medieval genomes, we show that the genetic risk for MS rose among pastoralists from the Pontic steppe and was brought into Europe by the Yamnaya-related migration approximately 5,000 years ago. We further show that these MS-associated immunogenetic variants underwent positive selection both within the steppe population and later in Europe, probably driven by pathogenic challenges coinciding with changes in diet, lifestyle and population density. This study highlights the critical importance of the Neolithic period and Bronze Age as determinants of modern immune responses and their subsequent effect on the risk of developing MS in a changing environment."
"
Adults with posttraumatic stress disorder (PTSD) have smaller cerebellums, according to new research from a Duke-led brain imaging study.

The cerebellum, a part of the brain well known for helping to coordinate movement and balance, can influence emotion and memory, which are impacted by PTSD. What isn't known yet is whether a smaller cerebellum predisposes a person to PTSD or PTSD shrinks the brain region.
""The differences were largely within the posterior lobe, where a lot of the more cognitive functions attributed to the cerebellum seem to localize, as well as the vermis, which is linked to a lot of emotional processing functions,"" said Ashley Huggins, Ph.D., the lead author of the report who helped carry out the work as a postdoctoral researcher at Duke in the lab of psychiatrist Raj Morey, M.D.
Huggins, now an assistant professor of psychology at the University of Arizona, hopes these results encourage others to consider the cerebellum as an important medical target for those with PTSD.
""If we know what areas are implicated, then we can start to focus interventions like brain stimulation on the cerebellum and potentially improve treatment outcomes,"" Huggins said.
The findings, published January 10 in the journal Molecular Psychiatry, have prompted Huggins and her lab to start looking for what comes first: a smaller cerebellum that might make people more susceptible to PTSD, or trauma-induced PTSD that leads to cerebellum shrinkage.
PTSD and the ""Little Brain""
PTSD is a mental health disorder brought about by experiencing or witnessing a traumatic event, such as a car accident, sexual abuse, or military combat.

Though most people who endure a traumatic experience are spared from the disorder, about 6% of adults develop PTSD, which is often marked by increased fear and reliving the traumatizing event.
Researchers have found several brain regions involved in PTSD, including the almond-shaped amygdala that regulates fear, and the hippocampus, a critical hub for processing memories and routing them throughout the brain.
The cerebellum (Latin for ""little brain""), by contrast, has received less attention for its role in PTSD.
A grapefruit-sized lump of cells that look like it was clumsily tacked underneath the back of the brain as an afterthought, the cerebellum is best known for its role in coordinating balance and choreographing complex movements, like walking or dancing. But there is much more to it than that.
""It's a really complex area,"" Huggins said. ""If you look at how densely populated with neurons it is relative to the rest of the brain, it's not that surprising that it does a lot more than balance and movement.""
Dense may be an understatement. The cerebellum makes up just 10% of the brain's total volume but packs in more than half of the brain's 86 billion nerve cells.

Researchers have recently observed changes to the size of the tightly-packed cerebellum in PTSD. Most of that research, however, is limited by either a small dataset (fewer than 100 participants), broad anatomical boundaries, or a sole focus on certain patient populations, such as veterans or sexual assault victims with PTSD.
Subtle and Consistent Reductions
To overcome those limitations, Duke's Dr. Morey, along with over 40 other research groups that are part of a larger data-sharing initiative, pooled together their brain imaging scans to study PTSD as broadly and universally as possible.
The group ended up with images from 4,215 adult MRI scans, about a third of whom had been diagnosed with PTSD.
""I spent a lot of time looking at cerebellums,"" Huggins said.
Even with automated software to analyze the thousands of brain scans, Huggins manually spot-checked every image to make sure the boundaries drawn around the cerebellum and its many subregions were accurate.
The result of this thorough methodology was a fairly simple and consistent finding: PTSD patients had cerebellums about 2% smaller.
When Huggins zoomed in to specific areas within the cerebellum that influence emotion and memory, she found similar cerebellar reductions in people with PTSD.
Huggins also discovered that the worse PTSD was for a person, the smaller their cerebellum was.
""Focusing purely on a yes-or-no categorical diagnosis doesn't always give us the clearest picture,"" Huggins said. ""When we looked at PTSD severity, people who had more severe forms of the disorder had an even smaller cerebellar volume.""
Targeting the Cerebellum for Treatment and More Research
The results are an important first step at looking at how and where PTSD affects the brain.
There are more than 600,000 combinations of symptoms that can lead to a PTSD diagnosis, Huggins explained. Figuring out if different PTSD symptom combinations have different impacts on the brain will also be important to keep in mind.
For now, though, Huggins hopes this work helps others recognize the cerebellum as an important driver of complex behavior and processes beyond gait and balance, as well as a potential target for new and current treatments for people with PTSD.
""While there are good treatments that work for people with PTSD, we know they don't work for everyone,"" Huggins said. ""If we can better understand what's going on in the brain, then we can try to incorporate that information to come up with more effective treatments that are longer lasting and work for more people.""

","score: 13.39921172509408, grade_level: '13'","score: 14.963917607447023, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41380-023-02352-0,"Although the cerebellum contributes to higher-order cognitive and emotional functions relevant to posttraumatic stress disorder (PTSD), prior research on cerebellar volume in PTSD is scant, particularly when considering subregions that differentially map on to motor, cognitive, and affective functions. In a sample of 4215 adults (PTSD n = 1642; Control n = 2573) across 40 sites from the ENIGMA-PGC PTSD working group, we employed a new state-of-the-art deep-learning based approach for automatic cerebellar parcellation to obtain volumetric estimates for the total cerebellum and 28 subregions. Linear mixed effects models controlling for age, gender, intracranial volume, and site were used to compare cerebellum volumes in PTSD compared to healthy controls (88% trauma-exposed). PTSD was associated with significant grey and white matter reductions of the cerebellum. Compared to controls, people with PTSD demonstrated smaller total cerebellum volume, as well as reduced volume in subregions primarily within the posterior lobe (lobule VIIB, crus II), vermis (VI, VIII), flocculonodular lobe (lobule X), and corpus medullare (all p-FDR < 0.05). Effects of PTSD on volume were consistent, and generally more robust, when examining symptom severity rather than diagnostic status. These findings implicate regionally specific cerebellar volumetric differences in the pathophysiology of PTSD. The cerebellum appears to play an important role in higher-order cognitive and emotional processes, far beyond its historical association with vestibulomotor function. Further examination of the cerebellum in trauma-related psychopathology will help to clarify how cerebellar structure and function may disrupt cognitive and affective processes at the center of translational models for PTSD."
"
Respiratory syncytial virus (RSV), a common infection in children and senior adults, can also infect nerve cells and trigger inflammation leading to nerve damage, according to a new Tulane University study.

RSV can cause mild symptoms such as coughing, sneezing and fever or lead to more severe conditions such as pneumonia or bronchiolitis. But since the disease was first discovered in 1956, it has been thought to only infect the respiratory tract.
This study, published in The Journal of Infectious Diseases, is the first to prove that RSV can penetrate nerve cells and may provide the clearest link between RSV and reported neurological symptoms in children.
RSV has been previously detected in the spinal fluid of children with seizures. Additionally, 40% of RSV-positive children under the age of 2 have shown acute encephalopathy, brain damage that can result in confusion, memory loss or cognitive difficulties.
The findings underscore the potential long-term impacts of the disease, as well as the importance of preventative measures such as the two RSV vaccines approved by the FDA in 2023.
""This is the most common respiratory virus in the first years of life as well as an impactful virus among the elderly,"" said Dr. Giovanni Piedimonte, Tulane University vice president for research and professor of pediatrics, biochemistry and molecular biology. ""This adds a new dimension to the importance of RSV vaccines for both the elderly and mothers to protect their babies.""
Researchers studied the virus using 3D peripheral nerve cultures grown from stem cells and rat embryos. After finding they can be infected by RSV, researchers found RSV induced the release of chemokines -- proteins that fight infections by controlling immune cells -- and caused significant inflammation.

With low levels of RSV infection, the nerves became hyperreactive to stimulation. At higher levels, they observed a progressive degeneration of the nerve and increased neurotoxicity due to excess inflammation.
""Until this study, the theory was that the inflammatory response was indirectly activating the nerves,"" Piedimonte said. ""This study shows that not only does that happen, but the virus can penetrate directly into the nerves.""
The nerve hyperreactivity could explain why children who get RSV are later more likely to have asthmatic symptoms, Piedimonte said.
The study also found that RSV could enter the spinal cord via peripheral nerves despite not having the ability to enter the spinal neurons directly. More research is needed to explore that mechanism, but Piedimonte theorizes that by using the peripheral nerves to enter the spinal cord, RSV can bypass the blood-brain barrier, enter the central nervous system and infect the brain.
If confirmed, it could signal a connection between RSV and other neurological or developmental disorders, Piedimonte said.
""If indeed it's confirmed in future studies that viruses like this are able to access the central nervous system, that opens a huge Pandora's box,"" Piedimonte said.
Co-authors on the study include Tulane University researchers Kevin Pollard, Vicki Traina-Dorge, Stephen Medearis, Alexander Bosak, Greg Bix and Michael Moore.

","score: 13.967514703092395, grade_level: '14'","score: 15.207659836843106, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/infdis/jiad596,"Respiratory syncytial virus (RSV) primarily infects the respiratory epithelium, but growing evidence suggests it may also be responsible for neurological sequelae. In 3D microphysiological peripheral nerve cultures, RSV infected neurons, macrophages, and dendritic cells along two distinct trajectories depending on the initial viral load. Low-level infection was transient, primarily involved macrophages, and induced moderate chemokine release with transient neural hypersensitivity. Infection with higher viral loads was persistent, infected neuronal cells in addition to monocytes, and induced robust chemokine release followed by progressive neurotoxicity. In spinal cord cultures, RSV infected microglia and dendritic cells but not neurons, producing a moderate chemokine expression pattern. The persistence of infection was variable but could be identified in dendritic cells as long as 30 days post-inoculation. This study suggests that RSV can disrupt neuronal function directly through infection of peripheral neurons and indirectly through infection of resident monocytes, and inflammatory chemokines likely mediate both mechanisms."
"
A breakthrough study led by Dr. Mehdi Razavi at The Texas Heart Institute (THI), in collaboration with a biomedical engineering team of The University of Texas at Austin (UT Austin) Cockrell School of Engineering led by Dr. Elizabeth Cosgriff-Hernandez, sets the foundation of a ground-breaking treatment regimen for treating ventricular arrhythmia. Their study published in Nature Communications demonstrates the design and feasibility of a new hydrogel-based pacing modality.

The urgent need for an effective therapeutic regimen for ventricular arrhythmia inspired THI's Electrophysiology Clinical Research & Innovations (EPCRI) team, led by its director, Dr. Razavi, to partner with Dr. Cosgriff-Hernandez and her UT Austin Biomedical Engineering (UT Austin BME) team to co-develop an innovative strategy that addresses the pathophysiology of re-entrant arrhythmia.
Ventricular arrhythmia, which occurs in the lower chambers of the heart or ventricles, is the leading cause of sudden cardiac death in the United States. When heart rhythm abnormality occurs in a self-sustained manner, it is called re-entrant arrhythmia, which is usually fatal.
""Re-entry occurs mainly from delayed conduction in scarred heart tissues, usually after coronary artery occlusion during a heart attack, which can be corrected by enabling pacing in these regions,"" said Dr. Razavi, a practicing cardiologist and cardiac electrophysiologist. ""These hydrogels then can access the scarred tissue, thereby enabling direct pacing of the otherwise inaccessible regions of the heart.""
Given hydrogels' biostability, biocompatibility, tunable properties, and the ease of incorporating electrical conductivity, the scientists are exploring them as potential electrodes that can be easily delivered inside coronary veins. A clinical advantage of the unique system is that ischemia can be avoided by delivering the hydrogel using the veins.
The researchers successfully deployed the innovative hydrogel technology through minimally invasive catheter delivery in a pig model.
""The hydrogels have significant conductive properties that enable simultaneous pacing from multiple sites along the length of the hydrogel and create a conduction highway similar to those in Purkinje fibers,"" according to Dr. Cosgriff-Hernandez.

Today, arrhythmia is treatable with medicines and procedures that control the irregular rhythms. The current anti-arrhythmic drugs on the market are not always effective; although the drugs slow the conduction velocity, they facilitate re-entry arrhythmia. Moreover, these drugs can be toxic and can lead to the destruction of tissues near the diseased regions of the heart. Even with the widely used interventional ablation therapies, arrhythmia recurs in a significant proportion of patients. None of these procedures address the mechanism of re-entry.
Cardiac defibrillators implanted to compensate for the shortfalls in the current therapy options are painful when delivering electric shocks to restore heart rhythm and can severely deteriorate the patient's quality of life. If left untreated, arrhythmia can damage the heart, brain, or other organs, leading to stroke or cardiac arrest, during which the heart suddenly and unexpectedly stops beating.
""When injected into target vessels, the conductive hydrogel conforms to the patient's vessel morphology. Adding a traditional pacemaker to this gel allows for pacing that resembles the native conduction in the heart -- effectively mimicking the native electrical rhythm of the heart -- and extinguishes the cause for arrhythmia, providing painless defibrillation,"" added Dr. Cosgriff-Hernandez.
The work demonstrates for the first time the ability to confer direct electrical stimulation of the native and scarred mid-myocardium through injectable hydrogel electrodes as a pacing modality.
With minimally invasive catheter delivery and standard pacemaker technologies, this study indicates the feasibility of a novel pacing modality that resembles native conduction, potentially eliminating lethal re-entrant arrhythmia and providing painless defibrillation, which can be successfully adopted in a clinical workflow.
The scientific advance is significant considering pain management is highly relevant to overall wellness for patients with heart, lung, and blood diseases. Such innovation in painless defibrillation and preventing arrhythmia could revolutionize cardiac rhythm management.
Funding was provided by the National Heart, Lung, and Blood Institute of the National Institutes of Health (R01 HL162741); Ford Pre-Doctoral Fellowship, administered by the National Academy of Science, Engineering and Medicine; Ford Dissertation Fellowship, administered by the National Academy of Science, Engineering and Medicine; Office of Vice President for Research, The University of Texas at Austin; The Roderick D. MacDonald Research Fund Award 19RDM004; and The Sultan Qaboos Chair in Cardiology at the St. Luke's Foundation.

","score: 19.046027272727276, grade_level: '19'","score: 20.59555397727273, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44419-0,"There is an urgent clinical need for a treatment regimen that addresses the underlying pathophysiology of ventricular arrhythmias, the leading cause of sudden cardiac death. The current report describes the design of an injectable hydrogel electrode and successful deployment in a pig model with access far more refined than any current pacing modalities allow. In addition to successful cardiac capture and pacing, analysis of surface ECG tracings and three-dimensional electroanatomic mapping revealed a QRS morphology comparable to native sinus rhythm, strongly suggesting the hydrogel electrode captures the deep septal bundle branches and Purkinje fibers. In an ablation model, electroanatomic mapping data demonstrated that the activation wavefront from the hydrogel reaches the mid-myocardium and endocardium much earlier than current single-point pacing modalities. Such uniform activation of broad swaths of tissue enables an opportunity to minimize the delayed myocardial conduction of heterogeneous tissue that underpins re-entry. Collectively, these studies demonstrate the feasibility of a new pacing modality that most closely resembles native conduction with the potential to eliminate lethal re-entrant arrhythmias and provide painless defibrillation."
"
Like the Greek mythological beast with a snake's tail and two ferocious heads, a potential Parkinson's medicine created in the lab of chemist Matthew Disney, Ph.D., is also a type of chimera bearing two heads. One seeks out a key piece of Parkinson's-causing RNA, while the other goads the cell to chop it to pieces for recycling.

The research is described in the Jan. 9 issue of the Proceedings of the National Academy of Sciences, or PNAS.
Parkinson's is a frustrating and all too common disease. Slowly, people with Parkinson's lose brain cells and other neurons needed to make the neurotransmitter dopamine. This progressive loss leads them to develop rigid, tense muscles and tremors, and causes difficulties with sleep, mood, speech, eating and movement.
Commonly used treatments include drugs that replace the dopamine. Other treatments, such as deep-brain stimulation, help with movement problems that develop as the disease worsens. But while these types of treatments alleviate symptoms, they are not a cure, come with side effects and do not change the trajectory of the disease. An estimated 500,000 people in the United States live with Parkinson's.
""To change the course of this disease, we need to address its cause. For many Parkinson's patients, that apparent cause is the accumulation of a toxic protein called alpha-synuclein, in and around their neurons,"" said Disney, the endowed Institute Professor and chair of the chemistry department at The Herbert Wertheim UF Scripps Institute for Biomedical Innovation & Technology in Jupiter, Florida.
Unfortunately, alpha-synuclein has proven an especially challenging protein to medicate due to its unruly, disorganized form and lack of clear druggable structures, Disney added.
""In situations like this, we have found that targeting the RNA needed to build the toxic protein may be an optimal strategy to slowing or even stopping disease progression,"" he added.

Disney's lab focuses on interfering with or degrading RNA needed to assemble the proteins implicated in disease. This is a relatively new concept. Most drugs on the market work by binding to proteins to change their function. But not all disease-causing proteins can be successfully targeted with drugs. Some are too changeable, some lack druggable structures, some fold in a way that conceals their active sites.
Disney's approach is to prevent the problematic proteins from being made in the first place. To do that requires targeting their RNA. Here's why: Proteins are assembled in cells through a process that involves the reading and translation of a gene, the transport of that information from the cell nucleus to its cytoplasm via messenger RNA, and the assembly of protein-building factories called ribosomes, also built of RNA, in the cytoplasm. The ribosomes stitch the proteins together one amino acid at a time. Disney's potential Parkinson's drug, which he calls Syn-RiboTAC, binds to a section of messenger RNA that tells a ribosome to start protein assembly. Without the ""start"" signal, the toxic protein isn't built.
Disney's first authors on the PNAS study were graduate students in his lab. Yuquan Tong is a current student of the Skaggs Graduate School of Chemical and Biological Sciences on the Jupiter, Florida campus, and Peiyuan Zhang, Ph.D., is a recent graduate, now a postdoctoral researcher at the Massachusetts Institute of Technology.
""In Parkinson's mouse models, we see that reducing alpha-synuclein by even 25% is therapeutically beneficial,"" Tong said. ""In studies from induced neurons of Parkinson's patients, we see the Syn-RiboTAC strategy reduces alpha-synuclein production by about 50%. We saw that adding the RiboTAC produces a significant gain in potency.""
Disney added that the compound also showed good selectivity, important for avoiding unwanted side effects, and improved brain-barrier penetration relative to other compounds they studied.
Other collaborators on the study included physician-scientist M. Maral Mouradian, M.D., of Rutgers University, whose patients donated tissue to create induced neurons.
Much work lies ahead, as the team works to refine the two-headed drug and improve its drug-like properties, the scientists said. Preparing an experimental compound for clinical trials in humans can sometimes take years, as refinements are made and data are gathered.
""The medical need for a truly disease-modifying treatment is significant, and we know that patients are awaiting better options,"" Disney said. ""We're hopeful that we're on the road to a better days for people living with Parkinson's.""

","score: 12.114639846743298, grade_level: '12'","score: 13.157430651340995, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2306682120,"α-Synuclein is an important drug target for the treatment of Parkinson’s disease (PD), but it is an intrinsically disordered protein lacking typical small-molecule binding pockets. In contrast, the encoding SNCA mRNA has regions of ordered structure in its 5′ untranslated region (UTR). Here, we present an integrated approach to identify small molecules that bind this structured region and inhibit α-synuclein translation. A drug-like, RNA-focused compound collection was studied for binding to the 5′ UTR of SNCA mRNA, affording Synucleozid-2.0, a drug-like small molecule that decreases α-synuclein levels by inhibiting ribosomes from assembling onto SNCA mRNA. This RNA-binding small molecule was converted into a ribonuclease-targeting chimera (RiboTAC) to degrade cellular SNCA mRNA. RNA-seq and proteomics studies demonstrated that the RiboTAC (Syn-RiboTAC) selectively degraded SNCA mRNA to reduce its protein levels, affording a fivefold enhancement of cytoprotective effects as compared to Synucleozid-2.0. As observed in many diseases, transcriptome-wide changes in RNA expression are observed in PD. Syn-RiboTAC also rescued the expression of ~50% of genes that were abnormally expressed in dopaminergic neurons differentiated from PD patient–derived iPSCs. These studies demonstrate that the druggability of the proteome can be expanded greatly by targeting the encoding mRNAs with both small molecule binders and RiboTAC degraders."
"
UCLA-led research finds that scooter injuries nearly tripled across the U.S. from 2016 to 2020, with a concurrent increase in severe injuries requiring orthopedic and plastic surgery over the same period.

The study, which compared national trends in scooter and bicycle injuries during the period, also found that costs to treat those injuries rose five-fold, highlighting the financial strain these injuries pose to the healthcare system -- a finding that ""underscores a critical juncture for discerning the underlying causes of injuries and informing policies for injury prevention,"" the researchers note.
The study will be published January 9 in the peer-reviewed Journal of the American College of Surgeons.
""Considering the rise in the number of hospitalizations and major operations for scooter-related injuries, it's crucial to elevate safety standards for riders,"" said lead author Nam Yong Cho, a third-year medical student at UCLA and a research associate at the UCLA Cardiovascular Outcomes Research Laboratories. ""Advocating for improved infrastructure, including enforced speed limits and dedicated lanes, is also vital to minimize risks for vehicles, scooter riders, and pedestrians alike.""
The researchers used the 2016-2020 National Inpatient Sample, a database maintained by the Agency for Healthcare Research and Quality, to compare trends and outcomes for scooter-related and bicycle-related injuries. The database does not, however, differentiate between electric and non-electric scooters. Of nearly 93,000 patients who were hospitalized for injuries, about 6,100 (6.6%) resulted from scooter injuries.
Overall, about 27% of people in the scooter cohort were under age 18 compared with 16% for the bicycle group. In addition, injuries were most frequent in the winter months (24% vs 20%), patients were insured by Medicaid (27% vs 24%); and scooter injuries led to more major operative interventions (56% vs 48%), which mainly included orthopedic and plastic surgery (89% vs 85%) and operations to the head (5% vs 4%).
Scooter riders also had higher odds of experiencing long bone fractures and paralysis than their bicycle riding counterparts, though both groups were similarly likely to suffer traumatic brain injuries.

Finally, the annual healthcare burden of treating scooter-related injuries jumped from about $6.6 million in 2016 to $35.5 million in 2020. For bicycle injuries, the price tag increased from $307 million to $434 million.
The study has some limitations. They include a limited amount of granular data such as helmet use, presence of multiple riders on the vehicles, and use of intoxicants; and an inability to account for objects and other vehicles that might have been involved in the injury incidents, or to determine the kind of terrain where they happened, and speed, time of day and total distance traveled when they occurred. The researchers also could not ascertain the type of scooter or bicycle models involved in the injuries.
Still, the findings indicate a worrisome increase in patient injury, hospitalization and financial burden, the researchers note.
""The progressive exacerbation of injury severity in scooter-related incidents manifested in a substantial proportion of patients necessitating surgical intervention and potentially having long-term morbidity,"" the researchers write. ""Our findings are a call to action for healthcare leaders to empower themselves in promoting scooter-related injury prevention and greater safety in the community.""
Study co-authors are Shineui Kim, Dr. Zachary Tran, Dr. Joseph Hadaya; Konmal Ali, Elsa Kronen and Dr. Peyman Benharash of UCLA, and Dr. Sigrid Burruss of Loma Linda University Health. Tran is also affiliated with Loma Linda University Health.

","score: 16.58581352681178, grade_level: '17'","score: 17.703171545325667, grade_levels: ['college_graduate'], ages: [24, 100]",10.1097/XCS.0000000000000918,"In recent years, the adoption of electric scooters has been accompanied by a surge of scooter-related injuries in the US, raising concerns for their severity and associated healthcare costs. The present study aimed to assess temporal trends and outcomes of scooter-related hospital admissions compared to bicycle-related hospitalizations. This was a retrospective cohort study utilizing the 2016-2020 National Inpatient Sample for patients younger than 65 years old who were hospitalized following bicycle and scooter injuries. The Trauma Mortality Prediction Model (TMPM) was used to quantify injury severity. The primary outcome of interest was temporal trends of micromobility injuries. In-hospital mortality, rates of long bone fracture, traumatic brain injury (TBI), paralysis, length of stay, hospitalization costs, and non-home discharge were secondarily assessed. Among 92,815 patients included in the study, 6,125 (6.6%) were scooter injuries. Compared to those with bicycle injuries, patients with scooter injuries were more commonly younger than 18 years (26.7 vs 16.4%, P<0.001) and frequently underwent major operations (55.8 vs 48.1%, P<0.001). After risk adjustment, scooter injuries were associated with greater risks of long bone fracture (AOR 1.40, 95%CI 1.15-1.70) and paralysis (AOR 2.06, 95%CI 1.16-3.69) compared to bicycle injuries. Additionally, patients with bicycle or scooter injuries had comparable index hospitalization durations of stay and costs. The prevalence and severity of scooter-related injuries have significantly increased in the US, thereby attributing to a substantial cost burden on the healthcare system. Multidisciplinary efforts to inform safety policies and enact targeted interventions are warranted to reduce scooter-related injuries."
"
A combination of only 11 proteins can predict long-term disability outcomes in multiple sclerosis (MS) for different individuals. The identified proteins could be used to tailor treatments to the individual based on the expected severity of the disease. The study, led by researchers at Linköping University in Sweden, has been published in the journal Nature Communications.

""A combination of 11 proteins predicted both short and long-term disease activity and disability outcomes. We also concluded that it's important to measure these proteins in cerebrospinal fluid, which better reflects what's going on in the central nervous system, compared with measuring in the blood,"" says Julia Åkesson, doctoral student at Linköping University and the University of Skövde.
In multiple sclerosis, the immune system attacks the person's own body, damaging nerves in the brain and in the spinal cord. What is attacked primarily is a fatty compound called myelin, which surrounds and insulates the nerve axons so that signals can be transmitted. When myelin is damaged, transmission becomes less efficient.
Disease progression in multiple sclerosis varies considerably from person to person. To those for whom a more severe disease is predicted, it is important not to lose valuable time at the onset of the disease but to get the right treatment quickly. The researchers behind the current study, which is a collaboration between Linköping University, the Karolinska Institute and the University of Skövde, wanted to find out whether it was possible to detect at an early stage of disease which patients would require a more powerful treatment. Being able to do so would be relevant both to physicians and those living with MS.
""I think we've come one step closer to an analysis tool for selecting which patients would need more effective treatment in an early stage of the disease. But such a treatment may have side effects and be relatively expensive, and some patients don't need it,"" says Mika Gustafsson, professor of bioinformatics at the Department of Physics, Chemistry and Biology at Linköping University, who led the study.
Finding markers linked to disease severity many years ahead is a complicated challenge. In their study, the researchers analysed nearly 1,500 proteins in samples from 92 people with suspected or recently diagnosed MS. Data from the protein analyses were combined with a large amount of information from the patients' journals, such as disability, results from MRI scans of the nervous system, and treatments received. Using machine learning, the researchers found a number of proteins that could predict disease progression.
""Having a panel consisting of only 11 proteins makes it easy should anyone want to develop analysis for this. It won't be as costly as measuring 1,500 proteins, so we've really narrowed it down to make it useful for others wanting to take this further,"" says Sara Hojjati, doctoral student at the Department of Biomedical and Clinical Sciences at Linköping University.

The research team also found that a specific protein, leaking from damaged nerve axons, is a reliable biomarker for disease activity in the short term. This protein is called neurofilament light chain, NfL. These findings confirm earlier research on the use of NfL to identify nerve damage and also suggest that the protein indicates how active the disease is.
One of the main strengths of the study is that the combination of proteins found in the patient group from which samples were taken at Linköping University Hospital was later confirmed in a separate group consisting of 51 MS patients sampled at the Karolinska University Hospital in Stockholm.
This study is the first to measure such a large amount of proteins with a highly sensitive method, proximity extension assay, combined with next-generation sequencing, PEA-NGS. This technology allows for high-accuracy measuring also of very small amounts, which is important as these proteins are often present in very low levels.
The study was funded by the Swedish Foundation for Strategic Research, the Swedish Brain Foundation, Knut and Alice Wallenberg Foundation, Margaretha af Ugglas Foundation, the Swedish Research Council, NEURO Sweden and the Swedish Foundation for MS research, and others.

","score: 15.197888921713446, grade_level: '15'","score: 16.731403249630723, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-42682-9,"Sensitive and reliable protein biomarkers are needed to predict disease trajectory and personalize treatment strategies for multiple sclerosis (MS). Here, we use the highly sensitive proximity-extension assay combined with next-generation sequencing (Olink Explore) to quantify 1463 proteins in cerebrospinal fluid (CSF) and plasma from 143 people with early-stage MS and 43 healthy controls. With longitudinally followed discovery and replication cohorts, we identify CSF proteins that consistently predicted both short- and long-term disease progression. Lower levels of neurofilament light chain (NfL) in CSF is superior in predicting the absence of disease activity two years after sampling (replication AUC = 0.77) compared to all other tested proteins. Importantly, we also identify a combination of 11 CSF proteins (CXCL13, LTA, FCN2, ICAM3, LY9, SLAMF7, TYMP, CHI3L1, FYB1, TNFRSF1B and NfL) that predict the severity of disability worsening according to the normalized age-related MS severity score (replication AUC = 0.90). The identification of these proteins may help elucidate pathogenetic processes and might aid decisions on treatment strategies for persons with MS."
"
More than 65,000 men fall ill with prostate cancer each year in Germany. Twelve thousand of them develop a treatment-resistant form which eventually ends in death. Now, a team of researchers from the Medical Faculty at the University of Freiburg has developed an active substance that might in future represent a new treatment option. This substance, known as KMI169, targets an enzyme that plays an important role in the development of prostate cancer. The inhibitor displayed massive potential in among others cancer cells that were resistant to conventional treatments. 

Researchers from the Department of Urology at the Freiburg University Medical Center as well as the Institut für Pharmazeutische Wissenschaften at the University of Freiburg published their study in Nature Communications on 2 January 2024.
""We've had our eye on the enzyme KMT9 as a possible target in prostate cancer for a long time. The development of this specific inhibitor is now a decisive step in combating prostate cancer far more effectively,"" explains study head Professor Roland Schüle, Academic Director of the Department of Urology at the Freiburg University Medical Center and Dr. Eric Metzger, group leader in Schüle's department.The substance's potential use against treatment-resistant forms of cancer makes it especially valuable. ""This treatment-resistance means that the classic antihormonal treatment often fails within a few months and the disease then progresses rapidly. The inhibitor we've developed offers us a highly innovative therapeutic approach here,"" says Schüle.
New approach also relevant to bladder cancer
Using cell cultures, the groups headed by Schüle and co-author Professor Manfred Jung, head of the Chemical Epigeneticsgroup of the Institut für Pharmazeutische Wissenschaften, have shown that the enzyme KMT9, known as a methyltransferase, is a critical factor in the development and progress of certain types of cancer such as prostate or bladder cancer. ""The inhibitor fits snugly like a key in its lock and blocks the functioning of KMT9 and therefore also the growth of both prostate and bladder cancer cells,"" says Jung. The development of KMI169 was guided by crystal structure analysis of KMT9 and numerous other studies. ""We modified the compound many times to increase its potency, selectivity and medicinal properties.""

","score: 15.310154440154438, grade_level: '15'","score: 16.721826254826254, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44243-6,"Inhibition of epigenetic regulators by small molecules is an attractive strategy for cancer treatment. Recently, we characterised the role of lysine methyltransferase 9 (KMT9) in prostate, lung, and colon cancer. Our observation that the enzymatic activity was required for tumour cell proliferation identified KMT9 as a potential therapeutic target. Here, we report the development of a potent and selective KMT9 inhibitor (compound 4, KMI169) with cellular activity through structure-based drug design. KMI169 functions as a bi-substrate inhibitor targeting the SAM and substrate binding pockets of KMT9 and exhibits high potency, selectivity, and cellular target engagement. KMT9 inhibition selectively downregulates target genes involved in cell cycle regulation and impairs proliferation of tumours cells including castration- and enzalutamide-resistant prostate cancer cells. KMI169 represents a valuable tool to probe cellular KMT9 functions and paves the way for the development of clinical candidate inhibitors as therapeutic options to treat malignancies such as therapy-resistant prostate cancer."
"
Models used by scientists to predict how epidemics will spread have a major flaw since they do not take into account the structure of the networks underlying transmission.

According to a new study from the University of Birmingham, modelling used to forecast the effects of diseases, such as Covid-19, can significantly overestimate the number of infections that will occur in an epidemic ""wave.""
The research, published today (9th January) in the Journal of Physics: Complexity¸ comes as the Covid inquiry continues to investigate what went wrong with the Government's handling of the pandemic, and what should be done better in the future.
Currently, epidemic modelling does not usually factor in that people are connected by a network of contacts where transmission might occur. Instead, many of these models, such as the ones that were used to inform decisions concerning Covid-19, make the assumption of ""random mixing.""
Dr Samuel Johnson, Associate Professor in Applied Mathematics at the University of Birmingham, who conducted the study said: ""It has been known for a long time that the properties of social networks are important for epidemic spreading, we can see this in action when those who were exposed to Covid-19 through mixing with infected individuals were contacted to let them know of their exposure. But because we do not have a way of knowing the whole network of millions of people, modellers usually do the best they can and assume random mixing, i.e. that anyone could infect anyone else. The problem is that the properties of this network can completely change the outcomes predicted.""
The research considers that if these networks are heterogeneous, meaning that some people have a lot more contacts than others, then epidemic ""waves"" may be much smaller than predicted by standard models. Dr Johnson continues: ""This is partly because fewer people get infected for a given transmissibility. But also, if you look at data on infections through a random-mixing lens you will overestimate transmissibility, and these two errors compound each other.""
In the paper, a simple version of these models shows two epidemic waves looking initially the same, but in the random-mixing case nearly 90% of people eventually become infected, whereas on a ""scale free"" (heterogeneous) network it is only 20%.

Dr Johnson also explores how changes in networks over time can lead to multiple waves of an epidemic, even after ""herd immunity"" has apparently been reached with previous waves. These findings might explain some of the big mistakes that groups modelling the pandemic seem to have made.
""Not everyone has the same numbers of friends, family, and colleagues, or goes out to places where large groups of people may be present,"" explained Dr Johnson. ""And the fact that superspreader events play such a significant role in the early stages of an epidemic supports the hypothesis that the real network of contacts is, like many other social networks, highly heterogeneous.""
The study argues that the structure of social networks cannot be ignored if epidemic modelling is to make useful predictions.
Dr Johnson concluded: ""Taking social networks into account should be a fundamental part of epidemic modelling. Even if we do not know what the network is like in detail, it still might be better to factor in that it is probably heterogeneous. And it is certainly preferable to realise we have this uncertainty, rather than assuming that, because we have put lots of other ingredients into our models, they will make useful crystal balls.
""As the political psychodrama of the Covid Inquiry continues to be played out in the news, it is important to note that the government, scientists, and wider society should be learning from what went wrong during the pandemic, and what went well. For example, rather than focusing on who said what in the UK, we could be comparing what happened in other countries when different measures were implemented. We need to make improvements so that we are ready for when the next one comes along, and working out how to account for social networks in epidemic modelling would be a big first step.""

","score: 14.894176149834042, grade_level: '15'","score: 15.935050972024655, grade_levels: ['college_graduate'], ages: [24, 100]",10.1088/2632-072X/ad19e0,"‘Compartmental models’ of epidemics are widely used to forecast the effects of communicable diseases such as COVID-19 and to guide policy. Although it has long been known that such processes take place on social networks, the assumption of ‘random mixing’ is usually made, which ignores network structure. However, ‘super-spreading events’ have been found to be power-law distributed, suggesting that the underlying networks may be scale free or at least highly heterogeneous. The random-mixing assumption would then produce an overestimation of the herd-immunity threshold for given R 0; and a (more significant) overestimation of R 0 itself. These two errors compound each other, and can lead to forecasts greatly overestimating the number of infections. Moreover, if networks are heterogeneous and change in time, multiple waves of infection can occur, which are not predicted by random mixing. A simple SIR model simulated on both Erdős–Rényi and scale-free networks shows that details of the network structure can be more important than the intrinsic transmissibility of a disease. It is therefore crucial to incorporate network information into standard models of epidemics."
"
A high-sugar diet is bad news for humans, leading to diabetes, obesity and even cancer. Yet fruit bats survive and even thrive by eating up to twice their body weight in sugary fruit every day.

Now, UC San Francisco scientists have discovered how fruit bats may have evolved to consume so much sugar, with potential implications for the 37 million Americans with diabetes. The findings, published on Tuesday, Jan. 9, 2024 in Nature Communications, point to adaptations in the fruit bat body that prevent their sugar-rich diet from becoming harmful.
Diabetes is the eighth leading cause of death in the United States, according to the Centers for Disease Control and Prevention, and it's responsible for $237 billion in direct medical costs each year.
""With diabetes, the human body can't produce or detect insulin, leading to problems controlling blood sugar,"" said Nadav Ahituv, PhD, director of the UCSF Institute for Human Genetics and co-senior author of the paper. ""But fruit bats have a genetic system that controls blood sugar without fail. We'd like to learn from that system to make better insulin- or sugar-sensing therapies for people.""
Ahituv's team focused on evolution in the bat pancreas, which controls blood sugar, and the kidneys. They found that the fruit bat pancreas, compared to the pancreas of an insect-eating bat, had extra insulin-producing cells as well as genetic changes to help it process an immense amount of sugar. And fruit bat kidneys had adapted to ensure that vital electrolytes would be retained from their watery meals.
""Even small changes, to single letters of DNA, make this diet viable for fruit bats,"" said Wei Gordon, PhD, co-first author of the paper, a recent graduate of UCSF's TETRAD program, and assistant professor of biology at Menlo College. ""We need to understand high-sugar metabolism like this to make progress helping the one in three Americans who are prediabetic.""
A sweet tooth without consequences
Each day, after 20 hours of sleep, fruit bats wake up for four hours to gorge on fruit. Then it's back to the roost.

To understand how a fruit bat pulls off this feat of sugar consumption, Ahituv and Gordon collaborated with scientists from a variety of institutions, ranging from Yonsei University in Korea to the American Museum of Natural History in New York City, to compare the Jamaican fruit bat to the big brown bat, which only eats insects.
The researchers analyzed gene expression (which genes were on or off) and regulatory DNA (the parts of DNA that control gene expression) using a method for measuring both in individual cells.
""This newer single-cell technology can explain not only which types of cells are in which organs, but also how those cells regulate gene expression to manage each diet,"" Ahituv said.
In fruit bats, the compositions of the pancreas and kidneys evolved to accommodate their diet. The pancreas had more cells to produce insulin, which tells the body to lower blood sugar, as well as more cells to produce glucagon, the other major sugar-regulating hormone. The fruit bat kidneys, meanwhile, had more cells to trap scarce salts as they filter blood.
Zooming in, the regulatory DNA in those cells had evolved to turn the appropriate genes for fruit metabolism on or off. The big brown bat, on the other hand, had more cells for breaking down protein and conserving water. And the gene expression in those cells was tuned to handle a diet of bugs.
""The organization of the DNA around the insulin and glucagon genes was very clearly different between the two bat species,"" Gordon said. ""The DNA around genes used to be considered 'junk,' but our data shows that this regulatory DNA likely helps fruit bats react to sudden increases or decreases in blood sugar.""
While some of the biology of the fruit bat resembled what's found in humans with diabetes, the fruit bat appeared to evolve something that humans with a sweet tooth could only dream of: a sweet tooth without consequences.

""It's remarkable to step back from model organisms, like the laboratory mouse, and discover possible solutions for human health crises out in nature,"" Gordon said. ""Bats have figured it out, and it's all in their DNA, the result of natural selection.""
Superheroes of evolution 
The study benefited from a recent groundswell of interest in studying bats to better human health. Gordon and Ahituv traveled to Belize to participate in an annual Bat-a-Thon with nearly 50 other bat researchers, taking a census of wild bats as well as field samples for science. One of the Jamaican fruit bats captured at this event was used in the sugar metabolism study.
As one of the most diverse families of mammals, bats include many examples of evolutionary triumph, from their immune systems to their peculiar diets and beyond.
""For me, bats are like superheroes, each one with an amazing super power, whether it is echolocation, flying, blood sucking without coagulation, or eating fruit and not getting diabetes,"" Ahituv said. ""This kind of work is just the beginning.""
Key collaborators included co-first author Seungbyn Baek, PhD, from Yonsei University (South Korea); co-senior author Martin Hemberg, PhD, from Harvard Medical School; Tony Schountz, PhD, from Colorado State University; Lisa Noelle Cooper, PhD, from Northeast Ohio Medical University; Melissa R. Ingala, PhD, Fairleigh Dickinson University; and Nancy B. Simmons, PhD, American Museum of Natural History. Other UCSF authors are Hai P. Nguyen, PhD, Yien-Ming Kuo, PhD, Rachael Bradley, and Sarah L. Fong, PhD. For all authors see the paper.

","score: 12.682668089647816, grade_level: '13'","score: 13.624571701398644, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44186-y,"Frugivory evolved multiple times in mammals, including bats. However, the cellular and molecular components driving it remain largely unknown. Here, we use integrative single-cell sequencing (scRNA-seq and scATAC-seq) on insectivorous (Eptesicus fuscus; big brown bat) and frugivorous (Artibeus jamaicensis; Jamaican fruit bat) bat kidneys and pancreases and identify key cell population, gene expression and regulatory differences associated with the Jamaican fruit bat that also relate to human disease, particularly diabetes. We find a decrease in loop of Henle and an increase in collecting duct cells, and differentially active genes and regulatory elements involved in fluid and electrolyte balance in the Jamaican fruit bat kidney. The Jamaican fruit bat pancreas shows an increase in endocrine and a decrease in exocrine cells, and differences in genes and regulatory elements involved in insulin regulation. We also find that these frugivorous bats share several molecular characteristics with human diabetes. Combined, our work provides insights from a frugivorous mammal that could be leveraged for therapeutic purposes."
"
Brown fat cells convert energy into heat -- a key to eliminating unwanted fat deposits. In addition, they also protect against cardiovascular diseases. Researchers from the University Hospital Bonn (UKB) and the Transdisciplinary Research Area ""Life & Health"" at the University of Bonn have now identified the protein EPAC1 as a new pharmacological target to increase brown fat mass and activity. The long-term aim is to find medicines that support weight loss. The results of the study have now been published in the journal Nature Cell Biology.

Obesity is defined as a pathological increase in white fat, and has become a major problem worldwide, with a greatly increased risk of cardiovascular diseases such as heart attack and stroke. ""Exercise and dieting are not enough to effectively and permanently shed the pounds,"" says corresponding author Prof. Alexander Pfeifer, Director of the Institute of Pharmacology and Toxicology at the University Hospital Bonn and member of the Transdisciplinary Research Areas (TRA) ""Life & Health"" and ""Sustainable Futures"" at the University of Bonn. ""Our energy-dense foods lead to energy being stored in white fat. But losing weight isn´t that easy, as the body saves energy in response to a low-calorie diet. So our goal is to achieve additional energy release.""
Aim are therapies that keep the energy balance in equilibrium
Brown fat cells, on the other hand, act as a biological oven and ensure, for example, that newborn babies can cope with cold exposure after birth. However, adults hardly have any brown fat, and it can be found mainly in young and slim people. ""We therefore asked how brown fat mass can be increased while simultaneously reducing bad white fat,"" says Bonn postdoctoral researcher and first author Dr. Laia Reverte-Salisa.
Together with researchers from the University Medical Center Hamburg-Eppendorf, Helmholtz Munich and the University of Toulouse-Paul Sabatier, the Bonn team investigated the cAMP signaling pathway in fat metabolism that plays a central role in fat cells. Using a mouse model, they discovered that the relatively unknown protein ""exchange proteins directly activated by cAMP"" (EPAC1), is responsible for the growth of brown fat. In addition, EPAC1 even increases the formation of brown fat cells in white fat, which are also known as ""beige"" cells. Prof. Pfeifer's team also showed that the signaling pathway is also active in human fat cells. In addition, they confirmed the function of EPAC1 in human organoids -- organ-like microstructures that serve as a human brown fat model. 
The Bonn researchers further found that a non-functional human EPAC1 gene variant is associated with an increased body mass index (BMI). ""Our study shows that EPAC1 is an attractive target to increase brown fat mass and thus also energy expenditure,"" says Prof. Pfeifer. In view of the worldwide increase in obesity, he hopes to develop novel therapies that help those affected to combat metabolic diseases. This study was conducted in the context of the DFG Collaborative Research Center Transregio-SFB 333 ""Brown and Beige Fat -- Organ Interactions, Signaling Pathways and Energy Balance (BATenergy),"" which is pursuing a better understanding of the different types of adipose tissue and their role in metabolic diseases.

","score: 14.214991613552503, grade_level: '14'","score: 14.412111707480712, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41556-023-01311-9,"Brown adipose tissue (BAT) is a central thermogenic organ that enhances energy expenditure and cardiometabolic health. However, regulators that specifically increase the number of thermogenic adipocytes are still an unmet need. Here, we show that the cAMP-binding protein EPAC1 is a central regulator of adaptive BAT growth. In vivo, selective pharmacological activation of EPAC1 increases BAT mass and browning of white fat, leading to higher energy expenditure and reduced diet-induced obesity. Mechanistically, EPAC1 coordinates a network of regulators for proliferation specifically in thermogenic adipocytes, but not in white adipocytes. We pinpoint the effects of EPAC1 to PDGFRα-positive preadipocytes, and the loss of EPAC1 in these cells impedes BAT growth and worsens diet-induced obesity. Importantly, EPAC1 activation enhances the proliferation and differentiation of human brown adipocytes and human brown fat organoids. Notably, a coding variant of RAPGEF3 (encoding EPAC1) that is positively correlated with body mass index abolishes noradrenaline-induced proliferation of brown adipocytes. Thus, EPAC1 might be an attractive target to enhance thermogenic adipocyte number and energy expenditure to combat metabolic diseases."
"
Decisions on treatment for patients with acute myeloid leukemia (AML) -- a highly aggressive form of leukemia -- are based, among other things, on a series of certain genetic features of the disease; but at the time when a diagnosis is made, this information is not available. However, evidence of these genetic anomalies is crucial in providing targeted treatment for patients at an early stage. As genetic testing is expensive and time-consuming, there is a great need for inexpensive, fast and broadly accessible tests to predict such anomalies.

A team of IT specialists and physicians at the University of Münster and the University Hospital Münster has now published a study showing how a method based on artificial intelligence (AI) can be used to predict various genetic features on the basis of high-resolution microscopic images of bone marrow smears. As a result, decisions on a more precise treatment can be made in future directly on the day of the diagnosis, without the need to wait for genetic analyses. The results have been published in the journal Blood Advances.
In this new method, the genetic aberrations were extracted directly from extremely high-resolution multi-gigabyte scans from whole bone marrow smears taken from more than 400 AML patients. The scans had a resolution of 270,000 times 135,000 pixels on average, with one image being several gigabytes in size. Proceeding from this enormous dataset, it was possible to extract more than two million single-cell images. ""We developed a new type of Deep Learning method, fully automatic, which was trained for a complex task by means of machine learning technology,"" explains Prof. Benjamin Risse, who headed the work on algorithmic developments on the IT side. ""In our case, the basic algorithm can automatically recognise the genetic features and the very fine patterns in big cytological images. The method then filtered the single-cell images into categories of different cell types, and it also showed any genetic aberrations. Interestingly, several patterns recognized by the algorithm can not be identified by human observers. This is for example because the patterns may be too faint or because extremely fine textures are involved which remain hidden to the human eye, despite excellent imaging,"" says Risse.
One key advantage of the method presented is in the end-to-end AI pipeline which enables monitoring of the (interim) results and reduces to a minimum the manual preliminary work often necessary for machine learning. This is made possible by a combination of so-called unsupervised, self-supervised and supervised learning processes. The first two processes require no manual data selection at all but try to extract relevant content automatically from the image data instead. ""Using a so-called incremental approach, we carried out intermediary steps with a human expert to examine the images. This is necessary for example in cell images categorised as problematic,"" says Dr. Linus Angenendt, who heads the Personalised Cancer Therapy and Digital Medicine working group at Münster University Hospital. Problematic cell images can occur as a result of incorrect staining, for example. The model trained was subsequently evaluated on an independent dataset relating to a further 70 patients with over 440,000 single-cell images -- as a test cohort.
Although the new method cannot replace genetic analyses, it nevertheless helps at a very early stage in the diagnostic clarification process for a leukaemia patient, by providing an idea of which genetic aberrations might underlie the disease. This would be especially helpful in the case of aggressive diseases when there is no time to wait for the complete genetic analyses.
The researchers are confident that in future digital methods and artificial intelligence will become increasingly important for large medical datasets when it is a question of making personalised recommendations for treatment for patients with malignant diseases. This study contributes an important basis for this, for example in the development of similar approaches for other bone marrow diseases.

","score: 15.764937480559876, grade_level: '16'","score: 16.430357698289264, grade_levels: ['college_graduate'], ages: [24, 100]",10.1182/bloodadvances.2023011076,"The detection of genetic aberrations is crucial for early therapy decisions in acute myeloid leukemia (AML) and recommended for all patients. Because genetic testing is expensive and time consuming, a need remains for cost-effective, fast, and broadly accessible tests to predict these aberrations in this aggressive malignancy. Here, we developed a novel fully automated end-to-end deep learning pipeline to predict genetic aberrations directly from single-cell images from scans of conventionally stained bone marrow smears already on the day of diagnosis. We used this pipeline to compile a multiterabyte data set of &gt;2 000 000 single-cell images from diagnostic samples of 408 patients with AML. These images were then used to train convolutional neural networks for the prediction of various therapy-relevant genetic alterations. Moreover, we created a temporal test cohort data set of &gt;444 000 single-cell images from further 71 patients with AML. We show that the models from our pipeline can significantly predict these subgroups with high areas under the curve of the receiver operating characteristic. Potential genotype-phenotype links were visualized with 2 different strategies. Our pipeline holds the potential to be used as a fast and inexpensive automated tool to screen patients with AML for therapy-relevant genetic aberrations directly from routine, conventionally stained bone marrow smears already on the day of diagnosis. It also creates a foundation to develop similar approaches for other bone marrow disorders in the future."
"
Endocrine resistance -- a major cause of breast cancer deaths -- can be underpinned by an epigenetic change called DNA methylation, researchers at the Garvan Institute of Medical Research have discovered. The team successfully reversed this methylation to reduce cancer growth in patient-derived animal models.

Using a low dose of the epigenetic therapy drug decitabine, which is currently used to treat some blood cancers, the researchers significantly suppressed the growth of endocrine-resistant breast tumours in mice and increased survival time by 90%. The finding, which will be tested in a future Phase I clinical trial, is a potential gamechanger for the more than 4,000 people who are diagnosed with endocrine-resistant breast cancer each year in Australia alone.
""This research has uncovered a completely new approach to treating endocrine-resistant breast cancer. In our study, we have not only pinpointed a new molecular mechanism that explains how endocrine resistance might develop -- we have identified a treatment currently used in the clinic that can target this mechanism precisely,"" says Professor Susan Clark, Head of the Cancer Epigenetics Laboratory at Garvan and senior author of the paper published in Nature Structural & Molecular Biology.
Epigenetic change drives breast cancer treatment resistance
An estimated 70% of all diagnosed breast cancers are oestrogen receptor positive (ER+), which means their growth is activated by oestrogen -- a hormone that plays a key role in sexual and reproductive health in women. While endocrine therapy that suppresses oestrogen in the body can slow or stop the growth of these tumours, more than 30% of patients develop resistance, with their tumours no longer requiring oestrogen to grow.
In a 2020 study, the Garvan team investigated the endocrine-resistant cancer's epigenome, the layer of instructions that organises and regulates DNA's activity, and revealed that endocrine resistance is linked to methyl groups attaching to regulatory regions of DNA and changing the 3D structure of DNA inside cancer cells.
New approach to breast cancer therapy
""In this current study, we set out to reverse the abnormal methylation patterns and restore the 3D DNA structure in the endocrine-resistant ER+ breast cancers using epigenetic therapy,"" says first author Dr Joanna Achinger-Kawecka, Head of the 3D Epigenome in Cancer Group at Garvan. ""We found that decitabine removed methyl groups at specific DNA regulatory regions, rewiring the 3D structure of DNA to not only reactivate the production of oestrogen receptors, but also activate tumour suppressor genes that can reduce cancer growth.""

""After treating patient-derived endocrine resistant breast cancer tumours with decitabine alone, we were surprised to see cancer growth significantly reduced in mice,"" says co-first author Associate Professor Clare Stirzaker, Head of the Epigenetic Biomarker Group. ""This highlights the importance of studying fundamental molecular mechanisms to best guide targeted treatments.""
Decitabine is an FDA- and TGA-approved epigenetic therapy currently used to successfully treat certain blood cell cancers, including myelodysplastic syndromes, but there are limited studies in other cancers. While the current study focused on ER+ breast cancer, the researchers say the drug may also have potential for other endocrine-resistant cancers driven by epigenetic changes.
""The next stage of our research will be to test decitabine together with endocrine therapy, which could be even more effectively target this difficult-to-treat cancer,"" says Professor Clark. ""We hope that such a combination approach is a turning point that enables significantly better clinical outcomes.""
This research was supported by Australia's National Health and Medical Research Council (Project Grant #1128916), the National Breast Cancer Foundation (IIRS-21-047), Cancer Council NSW (RG20-04 and RG16-02) and the Van Andel Institute Stand Up To Cancer Epigenetics Dream Team.
Professor Susan Clark is a Conjoint Professor, Dr Joanna Achinger-Kawecka is a Conjoint Lecturer and Associate Professor Clare Stirzaker is a Conjoint Associate Professor at St Vincent's Clinical School, Faculty of Medicine and Health, UNSW Sydney. 

","score: 19.12227414330218, grade_level: '19'","score: 21.501792916871615, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41594-023-01181-7,"Three-dimensional (3D) epigenome remodeling is an important mechanism of gene deregulation in cancer. However, its potential as a target to counteract therapy resistance remains largely unaddressed. Here, we show that epigenetic therapy with decitabine (5-Aza-mC) suppresses tumor growth in xenograft models of pre-clinical metastatic estrogen receptor positive (ER+) breast tumor. Decitabine-induced genome-wide DNA hypomethylation results in large-scale 3D epigenome deregulation, including de-compaction of higher-order chromatin structure and loss of boundary insulation of topologically associated domains. Significant DNA hypomethylation associates with ectopic activation of ER-enhancers, gain in ER binding, creation of new 3D enhancer–promoter interactions and concordant up-regulation of ER-mediated transcription pathways. Importantly, long-term withdrawal of epigenetic therapy partially restores methylation at ER-enhancer elements, resulting in a loss of ectopic 3D enhancer–promoter interactions and associated gene repression. Our study illustrates the potential of epigenetic therapy to target ER+ endocrine-resistant breast cancer by DNA methylation-dependent rewiring of 3D chromatin interactions, which are associated with the suppression of tumor growth."
"
It may sound strange, but we can actually learn more about ourselves by studying pigs.

Pigs and humans are pretty similar. Our organs, our skin and the way many diseases develop are largely the same.
Pigs have therefore long been used to develop and test new medicines, even though pigs are larger, more expensive and more difficult to use in experiments than rats and mice.
And now pigs may become even more valuable as laboratory animals, because researchers from the Center for Quantitative Genetics and Genomics at Aarhus University have mapped the most important genetic similarities between pigs and humans.
The researchers have not only identified the genes that are the same in humans and pigs; they have also identified the so-called 'transcriptome' across a number of tissue types. Where the genome includes all the genes found in the DNA of our cells, whether active or inactive, the transcriptome includes the genes that are active in the different types of cells in our body, says Lingzhao Fang, one of the main researchers behind the new findings.
""We examined which genes are active and how they are regulated in 34 different types of tissue in pigs, and compared this with similar studies in humans. We looked at everything from testicular tissue to skin cells and various brain cells,"" he says and continues:
""No one has ever conducted a study at this scale and comprehensiveness, and we hope the new knowledge can make a difference in agriculture as well as in the pharmaceutical industry.""
More useful knowledge from RNA

A little more than 20 years ago, a group of more than 1,000 researchers succeeded in mapping the entire human genome. After completing the project, the researchers hoped they could now develop treatments for nearly all diseases, because they now knew the code and could identify the errors.
But that is not how the story went.
The researchers soon discovered that there is a big difference between the genes in an individual's recipe book and the recipes that are actually used and translated in the various cell types.
This is what is also referred to as genotype and phenotype, with phenotype referring to the traits or symptoms that can be observed in an individual. Because of the greater role played by the transcriptome, a person can have the genetic disposition for a disease without actually suffering from the disease.
In other words, two people who, on paper, have the same disease mutation do not necessarily become ill to the same extent. With greater knowledge about the role of the transcriptome in various diseases, it is possible to develop better and more targeted medicines.
And this is one area in which the results from Lingzhao Fang's study can be useful when it comes to pigs as laboratory animals.

""Pigs become more suited as animals for testing new medicines. As the various tissue types in pigs and humans are very similar, in fact more similar than we thought, the pharmaceutical industry can test the safety of new medicines in pigs with much higher accuracy,"" he says.
Can also help agriculture become greener
The pharmaceutical industry is not the only industry to potentially benefit from the new results. Agriculture can also use the results in their efforts to breed pigs with a reduced climate impact, according to Lingzhao Fang.
""There's never before been such a comprehensive mapping of the genes that are active in various tissue types. Our results make it possible to more precisely pinpoint the genetic mechanisms that lead to different desirable traits in pigs,"" he says and continues:
""For example, traits that make them more climate-friendly. Our mapping also paves the way for researchers to edit pig genes far more precisely and in this way develop entirely new properties in the future. Because we now know more about a wide range of traits in pigs, other researchers can more easily use gene-editing techniques such as CRISPR to change genes or insert new sequences with greener properties.""
Mapping other animals as well
Pigs are actually not the first animal whose transcriptome Lingzhao Fang and his colleagues have mapped. They started with cows a few years ago, and they plan to map a number of other animals in the coming years.
""We already have a study on chickens in the pipeline. It's currently being peer-reviewed, but we hope to publish it early next year,"" he says.
In addition to chickens, pigs and cows, the research team is studying goats, sheep, horses and ducks using the same method. He explains that the ultimate objective is not only to make agriculture greener but also to obtain a better understanding of fundamental animal and human biology.
""Once we've completed the project, we'll have gained a greater basic understanding of the biology and evolution of a number of animals. This knowledge can be useful in other areas,"" he says and continues:
""For example, we have problems with disease transmission between humans and farm animals. Our mapping may provide us with the necessary knowledge to limit and prevent outbreaks in the future.
One of the reasons why Lingzhao Fang is studying farm animals and not wild animals is that it is easy to access tissue samples and large amounts of data. However, the knowledge obtained can also be used in relation to wild and even extinct animals.
""We will gain a fundamental understanding of the biology of several different animals, and these all have wild cousins who basically function in the same way,"" he concludes.
DNA, RNA and transcriptomes
In the centre of every human and pig cell, inside a small nucleus, are the long, two-stranded DNA molecules that make up the chromosomes. The strands consist of almost endless rows of four small molecules that we abbreviate to A, C, G and T.
The sequence of the four molecules is what forms our genes. A gene is a sequence of the four molecules and it serves as a recipe for a protein.
However, before the cell can produce one of the many different proteins for which it has recipes in its DNA, the sequence must be translated. This happens when the two strands of DNA unwind where the recipe is located and a so-called RNA strand binds to this place and copies the part of the code that makes up the gene. In simple terms, RNA is single-stranded DNA.
RNA leaves the cell nucleus and transports the code to the cell's protein factories, the ribosomes, where the code is then translated into a protein.
All cells in our body have the same DNA, but the parts of the DNA code that are translated and activated differ from cell to cell. Liver cells have other active genes than skin cells, for example. Not all RNA sequences transport code to the protein factories. Instead, some bits attach themselves to other RNA sequences to stop them from being translated into proteins, or to ensure that the body produces even more of the protein in question.
The RNA sequences that are active in a specific type of cell are called the transcriptome. This is what the researchers have been studying in this research project.

","score: 11.851220657276993, grade_level: '12'","score: 12.665595139464237, grade_levels: ['college'], ages: [18, 24]",10.1038/s41588-023-01585-7,"The Farm Animal Genotype-Tissue Expression (FarmGTEx) project has been established to develop a public resource of genetic regulatory variants in livestock, which is essential for linking genetic polymorphisms to variation in phenotypes, helping fundamental biological discovery and exploitation in animal breeding and human biomedicine. Here we show results from the pilot phase of PigGTEx by processing 5,457 RNA-sequencing and 1,602 whole-genome sequencing samples passing quality control from pigs. We build a pig genotype imputation panel and associate millions of genetic variants with five types of transcriptomic phenotypes in 34 tissues. We evaluate tissue specificity of regulatory effects and elucidate molecular mechanisms of their action using multi-omics data. Leveraging this resource, we decipher regulatory mechanisms underlying 207 pig complex phenotypes and demonstrate the similarity of pigs to humans in gene expression and the genetic regulation behind complex phenotypes, supporting the importance of pigs as a human biomedical model."
"
Researchers from Binghamton University, State University of New York are unraveling the workings of Group B Strep (GBS) infections in pregnant women, which could someday lead to a vaccine.

One in five pregnant women carry Streptococcus agalactiae (Group B Strep or GBS) in the vaginal tract, which is typically harmless -- except when it isn't.
The bacterial infection poses serious and even fatal consequences for newborns, including pneumonia, sepsis and meningitis, which can have long-term effects on the child's cognitive function.
Researchers from Binghamton University's Biofilm Research Center and the School of Pharmacy and Pharmaceutical Sciences (SOPPS) are unraveling the workings of GBS infections, which could someday lead to a vaccine. Their article, ""In silico and experimental analysis of the repeated domains in BvaP, a protein important for GBS vaginal colonization,"" was recently published in Infection and Immunity.
""This research has identified and characterized a novel protein that could serve as a vaccine candidate to fight a bacterium that impacts women's reproductive health and neonatal outcomes,"" said first author Lamar Thomas PhD '23, now a postdoctoral fellow at the University of California, San Diego, in the Department of Pediatrics. ""I hope this work will inspire others to explore other novel proteins and microbial agents that may potentially aid in improving global health.""
When most people think of ""strep,"" they have in mind Streptococcus pyogenes --  Group A Strep or GAS, which causes strep throat and necrotizing fasciitis, a ""flesh-eating"" infection, explained Assistant Professor of Biological Sciences Laura Cook, a co-author of the paper along with Nicholas Faiola of the Biofilm Research Center and Emily Canessa and Yetrib Hathout of SOPPS.
""There are many other pathogenic species of Streptococcus as well, including GBS and Streptococcus pneumoniae, which also causes many diseases, especially in the elderly,"" she said.

GBS can pass from mother to child in utero, potentially causing preterm birth, or after birth via close contact like breastfeeding, but these infections are rare. Most commonly, the infection is transmitted from mother to child during the birthing process, likely due to the aspiration of contaminated bodily fluids. Because of the risks, pregnant women in the United States are tested during their last trimester and treated with antibiotics if they are found to be positive. While antibiotics have decreased the rates of neonatal GBS disease in developed countries, the World Health Organization has placed a high priority on developing a vaccine.
To successfully colonize, the bacteria create a biofilm that allows them to stick to each other and the human host. Key to that biofilm is a protein known as BvaP, which Cook's lab established in previously published research.
Blocking surface proteins such as BvaP could be key to developing a successful vaccine, protecting newborns from infection. Cook's lab is now looking at the regulation of this protein, how this affects its function and how it may interact with other GBS proteins and the host.
""Even if BvaP does not prove to be a viable vaccine candidate, the process of host colonization is essential to understand for developing treatment strategies against bacterial pathogens,"" Cook said.

","score: 16.077184054283297, grade_level: '16'","score: 17.853055555555557, grade_levels: ['college_graduate'], ages: [24, 100]",10.1128/iai.00387-23,"Streptococcus agalactiae (group B strep, GBS) infections in neonates are often fatal and strongly associated with maternal GBS vaginal colonization. Previously, we highlighted the importance of a formerly uncharacterized protein, BvaP, in GBS vaginal colonization. BvaP is highly conserved across GBS and is made up of repeated domains, with a variable number of repeats between strains. Here, we evaluate the prevalence of BvaP repeated domains and their relevance in phenotypes previously associated with vaginal colonization. Using in silico analysis, we found that the number of repeats in the BvaP protein does not generally appear to be associated with serotype, isolation site, or host. Using BvaP truncations in GBS strain A909, we determined that a smaller number of repeats was correlated with decreased bacterial chain length, but adherence to vaginal epithelial cells was complemented using BvaP containing one, two, three, or five repeats. Future research will be geared toward understanding the host immune response to BvaP in vivo and whether vaginal carriage or host response is dependent on the BvaP repeated domains."
"
From a wartime spread of antimicrobial resistant disease in Ukraine, to superbugs in China causing ""white lung"" pneumonia in children, 2023 brought no shortage of new evidence that antimicrobial resistance (AMR) continues to be a pressing problem globally, and this pattern shows no sign of abating in 2024 unless a radical shift occurs.

To truly tackle the issue of AMR, York University researchers with the Global Strategy Lab (GSL) argue it needs to be understood as a socio-ecological challenge that accepts AMR as a phenomenon stemming from natural evolutionary processes. In other words, the war on bugs can't be won; what's needed is a major change in how people live with it.
""For the past hundred years, we've tried to address AMR like a medical problem. But we haven't really made much progress in actually mitigating the deeper drivers of the issue,"" says Isaac Weldon, a recent York PhD political science graduate and lead author of a new peer-reviewed article published today in the journal Perspectives on Politics journal. ""We argue that there's a lot of potential to make progress by instead looking at it as a problem with our relationship with the microbial world and sustainability.""
AMR stems from both the natural tendency of bacteria, viruses and fungi to evolve as well as the acceleration of that process through human interventions such as an over-reliance or misuse of antibiotics in medical settings, to the routine use of antimicrobials in the livestock industry. Global data from 2019 showed more than a million deaths a year directly related to AMR, and the COVID-19 pandemic seems to have accelerated this process.
Last year, GSL set up the AMR Policy Accelerator with $8.7 million from Wellcome Trust to deal with this urgent threat. While Weldon acknowledges that medical and technological innovation will be a crucial component in managing the issue, new antimicrobial drugs alone will not be the solution.
""What we're currently doing is treating the symptoms and not the causes of AMR,"" says Weldon, also an investigator with GSL. ""Without addressing the underlying social relationships that drive our use, innovation would have to operate at an unsustainable speed as these microbes evolve faster than we can make new drugs.""
Weldon and co-author Steven J. Hoffman, director of GSL and Dahdaleh Distinguished Chair in Global Governance & Legal Epidemiology with York's Faculty of Health and Osgoode Hall Law School, outline major problems with the current governance approach to AMR. They introduce five principles for designing institutions for a better ecological fit of human-microbial ecosystems to minimize drug resistance: There's no silver bullet. Recognizing that there is no easy fit or one-fits all solution for AMR means problem-solving must always be tailored to specific ecological situations and health challenges of diverse populations. Create institutions that can adapt over time. Future proofing doesn't mean creating institutions that are strong enough to withstand change, but ones flexible enough to evolve with the changing nature of AMR and our relationship to it. Diversify practices. As the best way to tackle AMR is still unknown, diversifying practices can help us discover what works, when, and where. Create records. As practices are diversified, records need to be kept of what works to enable learning and adjustments in policy. Involve stakeholders. This involves everyone from the public at large, to government and decision makers.""What we are proposing is a completely different way of looking at the issue,"" says Hoffman. ""We are hoping this journal article will be a foundational piece that will inspire further AMR research in this direction.""

","score: 13.537488741721855, grade_level: '14'","score: 14.582102649006622, grade_levels: ['college_graduate'], ages: [24, 100]",10.1017/S1537592723002906,"Antimicrobial resistance (AMR) is a natural process where microbes develop the ability to survive the antimicrobial drugs we depend upon to treat and prevent deadly infections, such as antibiotics. This microscopic evolution is further propelled by human activities, where each use of an antimicrobial drug potentially induces AMR. As microbes can spread quickly from animals to humans and travel around the world through humanity’s global circuits of movement, the use of any antimicrobial drug has potentially global consequences. As human-induced AMR occurs, mortality and morbidity increase due to increasingly or sometimes completely ineffective antimicrobial treatments. This article considers AMR as a product of the evolving and complex interplay between human societies and invisible microbial worlds. It argues that as a political challenge, AMR requires robust institutions that can manage human–microbial interactions to minimize the emergence of drug resistance and maximize the likelihood of achieving effective antimicrobial use for all. Yet, current governance systems for AMR are ill-equipped to meet these goals. We propose a conceptual paradigm shift for global AMR governance efforts, arguing that global governance could better address AMR if approached as a socioecological problem in need of sustainable management rather than solely as a medical problem to be solved. In biodiversity governance, institutions are designed to fit the biological features of the ecosystems that they are attempting to manage. We consider how a similar approach can improve global AMR governance. Employing the concept of ecological fit, which is defined as the alignment between human social systems and biological ecosystems, we diagnose 18 discrepancies between the social institutions that currently govern AMR and the ecological nature of this problem. Drawing from lessons learned in biodiversity governance, the article proposes five institutional design principles for improving the fit and effectiveness of global AMR governance."
"
Leukemia is a common term used to refer to a form of blood cancer. However, there are different types of leukemia depending on the cell type involved. One unique form is myeloid/natural killer (NK) cell precursor acute leukemia (MNKPL). Because of its rarity, there is no consensus on the specific characteristics needed to clinically identify this disease. In a recent article published in Science Advances, a team led by researchers at Tokyo Medical and Dental University (TMDU) used various approaches to better assess the molecular profile and drug sensitivity characteristics of MNKPL.

MNKPL was only first proposed as a leukemia subtype in 1997. Extramedullary involvement is one of the hallmarks of MNKPL. It is prevalent in East Asian countries. Although the immunological phenotype of MNKPL was explored previously, a full genetic characterization of this cancer type had not been performed. These details would help support more accurate diagnoses for patients, which would lead to more appropriate therapeutic decisions. Therefore, the TMDU group aimed to investigate MNKPL on a single-cell level.
""A single-cell exploration of MNKPL would not only help us better understand its clinical and genomic features, but also clarify the specific cellular origin of this disease,"" says Dr. Akira Nishimura, lead author of the study.
The team first used what is known as a multiomics approach to investigate MNKPL patient samples. They used various sequencing technologies to determine if there were any relevant mutations in specific genes, look for expression differences in certain signaling pathways at the RNA level, and examine any unique DNA methylation patterns.
""Our results demonstrate that MNKPL has molecular qualities that are distinct from other similar cancers, such as acute myeloid leukemia, T-cell acute lymphoblastic leukemia, and mixed-phenotype acute leukemia,"" explains Dr. Masatoshi Takagi, senior author. ""Specific hallmarks of MNKPL include activation of the NOTCH1 and RUNX3, as well as lower expression of the BCL11B.""
Further work at the single-cell level in MNKPL cells showed that NK cells and myeloid cells come from a common progenitor cell type.
The researchers also conducted in vitro drug sensitivity assays where they measured MNKPL cell responses to 79 individual anti-cancer drugs.
""We observed that MNKPL cells were highly sensitive to a drug called L-asparaginase, which has already shown clinical effectiveness for this disease,"" says Dr. Nishimura. ""Mechanistically, we found that this was from low expression of asparagine synthetase, a quality that was distinct from other similar types of leukemia.""
Overall, the robust and comprehensive analysis performed in this study provides crucial molecular details for characterizing MNKPL. This work will undoubtedly help clinicians more effectively diagnose MNKPL and choice of therapeutic option. Additionally, this work provides data that will assist with novel therapeutic target identification and drug development in this leukemia.

","score: 13.531448031349132, grade_level: '14'","score: 14.170821048703111, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adj4407,"Myeloid/natural killer (NK) cell precursor acute leukemia (MNKPL) has been described on the basis of its unique immunophenotype and clinical phenotype. However, there is no consensus on the characteristics for identifying this disease type because of its rarity and lack of defined distinctive molecular characteristics. In this study, multiomics analysis revealed that MNKPL is distinct from acute myeloid leukemia, T cell acute lymphoblastic leukemia, and mixed-phenotype acute leukemia (MPAL), and NOTCH1 and RUNX3 activation and BCL11B down-regulation are hallmarks of MNKPL. Although NK cells have been classically considered to be lymphoid lineage–derived, the results of our single-cell analysis using MNKPL cells suggest that NK cells and myeloid cells share common progenitor cells. Treatment outcomes for MNKPL are unsatisfactory, even when hematopoietic cell transplantation is performed. Multiomics analysis and in vitro drug sensitivity assays revealed increased sensitivity to l -asparaginase and reduced levels of asparagine synthetase (ASNS), supporting the clinically observed effectiveness of l -asparaginase."
"
Just as healthy organs are vital to our well-being, healthy organelles are vital to the proper functioning of the cell. These subcellular structures carry out specific jobs within the cell, for example, mitochondria power the cell and lysosomes keep the cell tidy.

Although damage to these two organelles has been linked to aging, cellular senescence, and many diseases, the regulation and maintenance of these organelles has remained poorly understood. Now, researchers at Osaka University have identified a protein, HKDC1, that plays a key role in maintaining these two organelles, thereby acting to prevent cellular aging.
There was evidence that a protein called TFEB is involved in maintaining the function of both organelles, but no targets of this protein were known. By comparing all the genes of the cell that are active under particular conditions, and by using a method called chromatin immunoprecipitation, which can identify the DNA targets of proteins, the team were the first to show that the gene encoding HKDC1 is a direct target of TFEB, and that HKDC1 becomes upregulated under conditions of mitochondrial or lysosomal stress.
One way that mitochondria are protected from damage is through the process of ""mitophagy,"" the controlled removal of damaged mitochondria. There are various mitophagy pathways, and the most well-characterized of these depends on proteins called PINK1 and Parkin.
""We observed that HKDC1 co-localizes with a protein called TOM20, which is located in the outer membrane of the mitochondria,"" explains lead author Mengying Cui, ""and through our experiments, we found that HKDC1, and its interaction with TOM20, are critical for PINK1/Parkin-dependent mitophagy.""
So, put simply, HKDC1 is brought in by TFEB to help take out the mitochondrial trash. But what about lysosomes? Well, TFEB and KHDC1 are key players here, too. Reducing HKDC1 in the cell was shown to interfere with lysosomal repair, indicating that HKDC1 and TFEB help lysosomes to recover from damage.
""HKDC1 is localized to the mitochondria, right? Well, this turns out to also be critical for the process of lysosomal repair,"" explains senior author Shuhei Nakamura. ""You see, lysosomes and mitochondria contact each other via proteins called VDACs. Specifically, HKDC1 is responsible for interacting with the VDACs; this protein is essential for mitochondria-lysosome contact, and thus, lysosomal repair.""
These two diverse functions of HKDC1, with key roles in both the lysosome and the mitochondria, help to prevent cellular senescence by simultaneously maintaining the stability of these two organelles. As dysfunction of these organelles is linked to aging and age-related diseases, this discovery opens new avenues for therapeutic approaches to these diseases.

","score: 13.57949227373069, grade_level: '14'","score: 14.35297316138027, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2306454120,"Mitochondrial and lysosomal functions are intimately linked and are critical for cellular homeostasis, as evidenced by the fact that cellular senescence, aging, and multiple prominent diseases are associated with concomitant dysfunction of both organelles. However, it is not well understood how the two important organelles are regulated. Transcription factor EB (TFEB) is the master regulator of lysosomal function and is also implicated in regulating mitochondrial function; however, the mechanism underlying the maintenance of both organelles remains to be fully elucidated. Here, by comprehensive transcriptome analysis and subsequent chromatin immunoprecipitation-qPCR, we identified hexokinase domain containing 1 (HKDC1), which is known to function in the glycolysis pathway as a direct TFEB target. Moreover, HKDC1 was upregulated in both mitochondrial and lysosomal stress in a TFEB-dependent manner, and its function was critical for the maintenance of both organelles under stress conditions. Mechanistically, the TFEB–HKDC1 axis was essential for PINK1 (PTEN-induced kinase 1)/Parkin-dependent mitophagy via its initial step, PINK1 stabilization. In addition, the functions of HKDC1 and voltage-dependent anion channels, with which HKDC1 interacts, were essential for the clearance of damaged lysosomes and maintaining mitochondria–lysosome contact. Interestingly, HKDC1 regulated mitophagy and lysosomal repair independently of its prospective function in glycolysis. Furthermore, loss function of HKDC1 accelerated DNA damage–induced cellular senescence with the accumulation of hyperfused mitochondria and damaged lysosomes. Our results show that HKDC1, a factor downstream of TFEB, maintains both mitochondrial and lysosomal homeostasis, which is critical to prevent cellular senescence."
"
For decades, a substantial number of proteins, vital for treating various diseases, have remained elusive to oral drug therapy. Traditional small molecules often struggle to bind to proteins with flat surfaces or require specificity for particular protein homologs. Typically, larger biologics that can target these proteins demand injection, limiting patient convenience and accessibility.

In a new study published in Nature Chemical Biology, scientists from the laboratory of Professor Christian Heinis at EPFL have achieved a significant milestone in drug development. Their research opens the door to a new class of orally available drugs, addressing a long-standing challenge in the pharmaceutical industry.
""There are many diseases for which the targets were identified but drugs binding and reaching them could not be developed,"" says Heinis. ""Most of them are types of cancer, and many targets in these cancers are protein-protein interactions that are important for the tumor growth but cannot be inhibited.""
The study focused on cyclic peptides, which are versatile molecules known for their high affinity and specificity in binding challenging disease targets. At the same time, developing cyclic peptides as oral drugs has proven difficult because they are rapidly digested or poorly absorbed by the gastrointestinal tract.
""Cyclic peptides are of great interest for drug development as these molecules can bind to difficult targets for which it has been challenging to generate drugs using established methods,"" says Heinis. ""But the cyclic peptides cannot usually be administered orally -- as a pill -- which limits their application enormously.""
Cyclizing Breakthrough
The research team targeted the enzyme thrombin, which is a critical disease target because of its central role in blood coagulation; regulating thrombin is key to preventing and treating thrombotic disorders like strokes and heart attacks.

To generate cyclic peptides that can target thrombin and are sufficiently stable, the scientists developed a two-step combinatorial synthesis strategy to synthesize a vast library of cyclical peptides with thioether bonds, which enhance their metabolic stability when taken orally.
""We have now succeeded in generating cyclic peptides that bind to a disease target of our choice and can also be administered orally,"" says Heinis. ""To this end, we have developed a new method in which thousands of small cyclic peptides with random sequences are chemically synthesized on a nanoscale and examined in a high-throughput process.""
Two steps, one pot
The new method process involves two steps, and takes place in the same reactive container, a feature that chemists refer to as ""one pot.""
The first step is to synthesize linear peptides, which then undergo a chemical process of forming a ring-like structure -- in technical terms, being ""cyclized."" This is done with using ""bis-electrophilic linkers"" -- chemical compounds used to connect two molecular groups together -- to form stable thioether bonds.
In the second phase, the cyclized peptides undergo acylation, a process that attaches carboxylic acids to them, further diversifying their molecular structure.

The technique eliminates the need for intermediate purification steps, allowing for high-throughput screening directly in the synthesis plates, combining the synthesis and screening of thousands of peptides to identify candidates with high affinity for specific disease targets -- in this case, thrombin.
Using the method, the PhD student leading the project, Manuel Merz, was able to generate a comprehensive library of 8,448 cyclic peptides with an average molecular mass of about 650 Daltons (Da), only slightly above the maximum limit of 500 Da recommended for orally available small molecules.
The cyclic peptides also showed a high affinity for thrombin.
When tested on rats, the peptides showed oral bioavailability up to 18%, which means that when the cyclic peptide drug is taken orally, 18% of it successfully enters the bloodstream and to have a therapeutic effect. Considering that orally administered cyclic peptides generally show a bioavailability below 2%, increasing that number to 18% is a substantial advance for drugs in the biologics category -- which includes peptides.
Setting targets
By enabling the oral availability of cyclic peptides, the team has opened up possibilities for treating a range of diseases that have been challenging to address with conventional oral drugs. The method's versatility means it can be adapted to target a wide array of proteins, potentially leading to breakthroughs in areas where medical needs are currently unmet.
""To apply the method to more challenging disease targets, such as protein-protein interactions, larger libraries will likely need to be synthesized and studied,"" says Manuel Merz. ""By automating further steps of the methods, libraries with more than one million molecules seem to be within reach.""
In the next step of this project, the researchers will target several intracellular protein-protein interaction targets for which it has been difficult to develop inhibitors based on classical small molecules. They are confident that orally applicable cyclic peptides can be developed for at least some of them.

","score: 16.215925925925927, grade_level: '16'","score: 17.521444444444448, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41589-023-01496-y,"Cyclic peptides can bind challenging disease targets with high affinity and specificity, offering enormous opportunities for addressing unmet medical needs. However, as with biological drugs, most cyclic peptides cannot be applied orally because they are rapidly digested and/or display low absorption in the gastrointestinal tract, hampering their development as therapeutics. In this study, we developed a combinatorial synthesis and screening approach based on sequential cyclization and one-pot peptide acylation and screening, with the possibility of simultaneously interrogating activity and permeability. In a proof of concept, we synthesized a library of 8,448 cyclic peptides and screened them against the disease target thrombin. Our workflow allowed multiple iterative cycles of library synthesis and yielded cyclic peptides with nanomolar affinities, high stabilities and an oral bioavailability (%F) as high as 18% in rats. This method for generating orally available peptides is general and provides a promising push toward unlocking the full potential of peptides as therapeutics."
"
Women with autoimmune disease are more likely to suffer from depression during pregnancy and after childbirth; conversely, women with a history of perinatal depression are at higher risk of developing autoimmune disease, a new study from Karolinska Institutet published in the journal Molecular Psychiatry reports.

In autoimmune disease, the immune system mistakenly attacks the body's own healthy tissue. Some of the most common autoimmune diseases are gluten intolerance (coeliac disease), autoimmune thyroiditis, rheumatoid arthritis, type 1 diabetes, and multiple sclerosis (MS).
In the present study, researchers used data from the Swedish Medical Birth Register and identified all women who had given birth in Sweden between 2001 and 2013. Out of the resulting group of approximately 815,000 women and 1.3 million pregnancies, just over 55,000 women had been diagnosed with depression during their pregnancy or within a year after delivery.
The researchers then compared the incidence of 41 autoimmune diseases in women with and without perinatal depression, controlling for familial factors such as genes and childhood environment by also including the affected women's sisters.
Strongest association for MS
The results reveal a bidirectional association between perinatal depression and autoimmune thyroiditis, psoriasis, MS, ulcerative colitis, and coeliac disease. Overall, women with autoimmune disease were 30 per cent more likely to suffer perinatal depression. Conversely, women with perinatal depression were 30 per cent more likely to develop a subsequent autoimmune disease.
The association was strongest for the neurological disease MS, for which the risk was double in both directions. It was also strongest in women who had not had a previous psychiatric diagnosis.

""Our study suggests that there's an immunological mechanism behind perinatal depression and that autoimmune diseases should be seen as a risk factor for this kind of depression,"" says the study's first author Emma Bränn, researcher at the Institute of Environmental Medicine at Karolinska Institutet.
Can have serious consequences
The researchers will now continue to examine the long-term effects of depression during pregnancy and in the first year following childbirth.
""Depression during this sensitive period can have serious consequences for both the mother and the baby,"" says Dr Bränn. ""We hope that our results will help decision-makers to steer funding towards maternal healthcare so that more women can get help and support in time.""
Since this was an observational study, no conclusions on causality can be drawn.
The study was financed by Karolinska Institutet, Forte (the Swedish Research Council for Health, Working Life and Welfare), the Swedish Research Councill and the Icelandic Research Fund. The researchers report no conflicts of interest.

","score: 15.202863849765262, grade_level: '15'","score: 16.70636150234742, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41380-023-02351-1,"Although major depression, characterized by a pro-inflammatory profile, genetically overlap with autoimmune disease (AD) and the perinatal period involve immune system adaptations and AD symptom alterations, the bidirectional link between perinatal depression (PND) and AD is largely unexplored. Hence, the objective of this study was to investigate the bidirectional association between PND and AD. Using nationwide Swedish population and health registers, we conducted a nested case-control study and a matched cohort study. From 1,347,901 pregnancies during 2001–2013, we included 55,299 incident PND, their unaffected full sisters, and 10 unaffected matched women per PND case. We identified 41 subtypes of AD diagnoses recorded in the registers and compared PND with unaffected population-matched women and full sisters, using multivariable regressions. Women with an AD had a 30% higher risk of subsequent PND (95% CI 1.2–1.5) and women exposed to PND had a 30% higher risk of a subsequent AD (95% CI 1.3–1.4). Comparable associations were found when comparing exposed women with their unaffected sisters (nested case-control OR: 1.3, 95% CI 1.2–1.5, matched cohort HR: 1.3, 95% CI 1.1–1.6), and when studying antepartum and postpartum depression. The bidirectional association was more pronounced among women without psychiatric comorbidities (nested case-control OR: 1.5, 95% CI 1.4–1.6, matched cohort HR: 1.4, 95% CI 1.4–1.5) and strongest for multiple sclerosis (nested case-control OR: 2.0, 95% CI 1.6–2.3, matched cohort HR: 1.8, 95% CI 1.0–3.1). These findings demonstrate a bidirectional association between AD and PND independent of psychiatric comorbidities, suggesting possibly shared biological mechanisms. If future translational science confirms the underlying mechanisms, healthcare providers need to be aware of the increased risk of PND among women with ADs and vice versa."
"
Ethanol -- the compound found in alcoholic beverages -- interferes with the normal functioning of a long list of biological molecules, but how each of these interactions contributes to the behavioral effects of alcohol is not fully understood. A guiding, but elusive, goal of researchers is to identify the protein (or proteins) to which ethanol binds that makes some people vulnerable to excessive drinking. Solving this question would point the way to effective therapies for alcohol use disorder, which affects more than 10% of the U.S. adult population and is responsible for a myriad of health and societal issues.

Previous studies identified one such molecule, a protein widely expressed in the brain, called the BK channel. Ethanol can directly interact with a component of BK channels, known as the α subunit, to facilitate their opening. However, scientists at Scripps Research found that this interaction may not drive behaviors related to alcohol abuse as much as previously thought. Their study, appearing in the journal Molecular Psychiatry on December 22, 2023, demonstrates that preventing ethanol from interacting with the BK α subunit does not reduce or increase the motivation to consume alcohol in mice.
The relationship between the BK α subunit and ethanol had previously been explored in vitro, ex vivo and in live invertebrates. Previous studies suggested that the BK α subunit was involved in an animal's response to alcohol exposure, but there was a gap in understanding its role in mammals, particularly for the control of alcohol drinking.
""Knowing what a molecule does from in vitro experiments really doesn't tell you much about what the behavioral consequences of that action might be,"" says senior author Candice Contet, PhD, associate professor in the Department of Molecular Medicine at Scripps Research. ""Things get complicated in vivo, because there are many layers of modulation that may occur in a cell-type specific manner. Moreover, the initial effect often changes with repeated or prolonged exposure to alcohol. We thus sought to determine whether the ability of ethanol to alter BK channel activity was in any way influencing the motivation to drink alcohol.""
Tackling this question didn't lend itself well to conventional pharmacological testing: blocking BK channels with a drug causes tremors, which then interfere with drinking behavior. However, Contet's collaborator Alex Dopico, MD, PhD, of the University of Tennessee, had identified a residue in the mouse BK α subunit that is required for ethanol to activate BK channels but is dispensable for normal BK channel activity, as shown in frog eggs. In the new study, Contet and her colleagues leveraged this discovery to unlock the significance of ethanol's interaction with BK channels for alcohol drinking in mice.
Accordingly, the team tested mice that had a mutation in this particular BK α subunit residue. First, they found that the mutation prevented alcohol from altering the firing properties of neurons in the medial habenula, a brain region with high levels of BK channels, thereby demonstrating that it also confers resistance to ethanol in mouse brain cells, not just in frog eggs. At the behavioral level, the mice harboring the mutation did not display any anomalies when compared to control littermates. Notably, they exhibited the standard signs of intoxication upon alcohol injection, such as loss of balance and hypothermia, and they consumed the same amount of alcohol when tested under various conditions of moderate or excessive drinking.
""The lack of effect of the mutation was surprising, especially in light of our previous results showing that other BK channel subunits, β1 and β4, influence alcohol intake escalation in the same model of alcohol dependence,"" says Contet. ""However, these negative results, which were replicated in multiple cohorts and both sexes, are just as important as positive ones, because they encourage the field to study other targets rather than focusing on the wrong culprit.""
While the study does not point to a critical role of the BK α subunit in the motivation to drink alcohol or several physiological responses related to ethanol intoxication and withdrawal, the group will continue to explore whether the molecular target plays a role in other aspects of alcohol use disorder.
""Ethanol is highly pleiotropic. Beyond its reinforcing effects, it alters the functioning of multiple organs and cell types,"" Contet says. ""It is likely that ethanol's interaction with BK channels contribute to some of these effects, but we've only explored the tip of the iceberg so far; the next challenge will be to find the right experimental readout.""
This work was supported by funding from the National Institutes of Health (AA020913, AA006420, AA026685, AA027636, AA027372, AA020889, AA010422, AA021491, AA013498, AA011560, AA007456)

","score: 16.25289127837515, grade_level: '16'","score: 17.32269056152927, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41380-023-02346-y,"Large conductance potassium (BK) channels are among the most sensitive molecular targets of ethanol and genetic variations in the channel-forming α subunit have been nominally associated with alcohol use disorders. However, whether the action of ethanol at BK α influences the motivation to drink alcohol remains to be determined. To address this question, we first tested the effect of systemically administered BK channel modulators on voluntary alcohol consumption in C57BL/6J males. Penitrem A (blocker) exerted dose-dependent effects on moderate alcohol intake, while paxilline (blocker) and BMS-204352 (opener) were ineffective. Because pharmacological manipulations are inherently limited by non-specific effects, we then sought to investigate the behavioral relevance of ethanol’s direct interaction with BK α by introducing in the mouse genome a point mutation known to render BK channels insensitive to ethanol while preserving their physiological function. The BK α K361N substitution prevented ethanol from reducing spike threshold in medial habenula neurons. However, it did not alter acute responses to ethanol in vivo, including ataxia, sedation, hypothermia, analgesia, and conditioned place preference. Furthermore, the mutation did not have reproducible effects on alcohol consumption in limited, continuous, or intermittent access home cage two-bottle choice paradigms conducted in both males and females. Notably, in contrast to previous observations made in mice missing BK channel auxiliary β subunits, the BK α K361N substitution had no significant impact on ethanol intake escalation induced by chronic intermittent alcohol vapor inhalation. It also did not affect the metabolic and locomotor consequences of chronic alcohol exposure. Altogether, these data suggest that the direct interaction of ethanol with BK α does not mediate the alcohol-related phenotypes examined here in mice."
"
A study of seriously ill patients from academic medical centers across the country has found that nearly a quarter had a delayed or missed diagnosis.

All the patients had either been transferred to the intensive care unit (ICU) after being admitted or died in the hospital. The researchers concluded that three-quarters of these diagnostic errors contributed to temporary or permanent harm, and that diagnostic errors played a role in about one in 15 of the deaths.
The most common errors identified in the study involved delayed rather than missed diagnoses, for example because a specialist was consulted too late or an alternate diagnosis was not considered soon enough, or because of problems ordering the correct test and interpreting the results.
Using statistical methods, they estimated that eliminating these problems with assessment and testing would reduce the risk for diagnostic errors by approximately 40%.
The study represents the largest assessment of diagnostic errors in which physicians reviewed each medical record. It appears Jan. 8, 2024, in JAMA Internal Medicine.
Academic medical centers often see the most challenging cases, and the data can help them increase patient safety by coaching physicians, improving communication between healthcare teams and patients, and developing more accurate diagnostic tools and techniques.
""Our study is similar to studies from the '90s describing the prevalence and impact of common patient safety events, such as medication errors, studies which catalyzed the patient safety movement,"" the paper's first author, Andrew Auerbach, MD, MPH, a professor in the UCSF in the Division of Hospital Medicine, said in reference to the groundbreaking 1999 Institute of Medicine report, ""To Err is Human."" ""We hope our work provides a similar call to action to academic medical centers, researchers and policymakers.""
The data may also be useful in designing artificial intelligence (AI) that can summarize lengthy medical records, suggest alternative diagnoses when patients fail to improve and ensure that the correct tests are ordered.

A national collaboration to improve safety
The study involved the 29 academic medical centers that are participating in the Hospital Medicine ReEngineering Network, a quality improvement collaborative that includes Beth Israel Deaconess Medical Center, Brigham and Women's Hospital, Johns Hopkins Hospital, Massachusetts General Hospital, the Mayo Clinic, UCSF Medical Center, Yale New Haven Hospital and Zuckerberg San Francisco General Hospital and Trauma Center.
While the study centered on some of the most respected medical centers in the country, the authors cautioned that the results may not generalize to all acute care hospitals.
The research was drawn from a pool of more than 24,000 hospitalized adults who were transferred to the ICU on their second hospital day or died in the hospital between Jan. 1, 2019, and Dec. 31, 2019. Patients who had been transferred to the ICU from the emergency department were excluded to eliminate cases that had been misdiagnosed there.
The researchers randomly selected cases from this large pool, settling on a final group of 2,428. The patients were extremely ill, and three-quarters (1,863) died in the hospital. The physicians first examined every chart for the presence or absence of diagnostic errors, then evaluated whether the mistake had caused harm. Two physicians who had been trained to identify errors reviewed each record, and a third was on hand to settle any disagreements.
Of the reviewed cases, 550 patients, or 23%, experienced a diagnostic error. The errors caused temporary or permanent injury or death in 436 of those patients. The researchers concluded that diagnostic error was a contributing factor in 121 of the deaths.

""We know diagnostic errors are dangerous, and hospitals are obviously interested in reducing their frequency, but it's much harder to do this when we don't know what's causing these errors or what their direct impact is on individual patients,"" said senior author Jeffrey L. Schnipper, MD, MPH, of the Brigham's Division of General Internal Medicine and Primary Care. ""We found that diagnostic errors can largely be attributed to either errors in testing, or errors in assessing patients, and this knowledge gives us new opportunities to solve these problems.""
How AI can help physicians
The researchers say the study highlights the need to improve clinician training, evaluate physician workloads and develop more accurate diagnostic tools and techniques. This could include using AI to evaluate patients, select the most appropriate tests and reduce delays, although care must be taken to ensure the models are performing correctly without introducing errors or widening health disparities.
""In the end, helping physicians become better diagnosticians means coaching and training physicians, and helping physicians clearly explain diagnoses to patients,"" Auerbach said. ""I suspect AI will help with many tasks, but we still have work to improve communication between patients and healthcare team members to fully advance the field.""
This study was supported by the U.S. Department of Health and Human Services' Agency for Healthcare Research and Quality (AHRQ). Since 2019, AHRQ has received dedicated funding from Congress to support diagnostic excellence. This includes 10 Diagnostic Safety Centers of Excellence funded in 2022, one of which was awarded to UCSF.
Preventing diagnostic errors is also the focus of UCSF's new Coordinating Center for Diagnostic Excellence.
Authors: Additional UCSF co-authors include Tiffany M. Lee, Colin C. Hubbard, PhD, Sumant R. Ranji, MD, Armond M. Esmaili, MD, Peter Barish, MD, Cynthia Fenton, MD, and Molly Kantor, MD.
Funding: The Agency for Healthcare Research and Quality (R01HS027369).

","score: 15.358166894664844, grade_level: '15'","score: 16.891172562048077, grade_levels: ['college_graduate'], ages: [24, 100]",10.1001/jamainternmed.2023.7347,"Diagnostic errors contribute to patient harm, though few data exist to describe their prevalence or underlying causes among medical inpatients. To determine the prevalence, underlying cause, and harms of diagnostic errors among hospitalized adults transferred to an intensive care unit (ICU) or who died. Retrospective cohort study conducted at 29 academic medical centers in the US in a random sample of adults hospitalized with general medical conditions and who were transferred to an ICU, died, or both from January 1 to December 31, 2019. Each record was reviewed by 2 trained clinicians to determine whether a diagnostic error occurred (ie, missed or delayed diagnosis), identify diagnostic process faults, and classify harms. Multivariable models estimated association between process faults and diagnostic error. Opportunity for diagnostic error reduction associated with each fault was estimated using the adjusted proportion attributable fraction (aPAF). Data analysis was performed from April through September 2023. Whether or not a diagnostic error took place, the frequency of underlying causes of errors, and harms associated with those errors. Of 2428 patient records at 29 hospitals that underwent review (mean [SD] patient age, 63.9 [17.0] years; 1107 [45.6%] female and 1321 male individuals [54.4%]), 550 patients (23.0%; 95% CI, 20.9%-25.3%) had experienced a diagnostic error. Errors were judged to have contributed to temporary harm, permanent harm, or death in 436 patients (17.8%; 95% CI, 15.9%-19.8%); among the 1863 patients who died, diagnostic error was judged to have contributed to death in 121 (6.6%; 95% CI, 5.3%-8.2%). In multivariable models examining process faults associated with any diagnostic error, patient assessment problems (aPAF, 21.4%; 95% CI, 16.4%-26.4%) and problems with test ordering and interpretation (aPAF, 19.9%; 95% CI, 14.7%-25.1%) had the highest opportunity to reduce diagnostic errors; similar ranking was seen in multivariable models examining harmful diagnostic errors. In this cohort study, diagnostic errors in hospitalized adults who died or were transferred to the ICU were common and associated with patient harm. Problems with choosing and interpreting tests and the processes involved with clinician assessment are high-priority areas for improvement efforts."
"
In recent years, there has been rising concern that tiny particles known as microplastics are showing up basically everywhere on Earth, from polar ice to soil, drinking water and food. Formed when plastics break down into progressively smaller bits, these particles are being consumed by humans and other creatures, with unknown potential health and ecosystem effects. One big focus of research: bottled water, which has been shown to contain tens of thousands of identifiable fragments in each container.

Now, using newly refined technology, researchers have entered a whole new plastic world: the poorly known realm of nanoplastics, the spawn of microplastics that have broken down even further. For the first time, they counted and identified these minute particles in bottled water. They found that on average, a liter contained some 240,000 detectable plastic fragments -- 10 to 100 times greater than previous estimates, which were based mainly on larger sizes.
The study was just published in the journal Proceedings of the National Academy of Sciences.
Nanoplastics are so tiny that, unlike microplastics, they can pass through intestines and lungs directly into the bloodstream and travel from there to organs including the heart and brain. They can invade individual cells, and cross through the placenta to the bodies of unborn babies. Medical scientists are racing to study the possible effects on a wide variety of biological systems.
""Previously this was just a dark area, uncharted. Toxicity studies were just guessing what's in there,"" said study coauthor Beizhan Yan, an environmental chemist at Columbia University's Lamont-Doherty Earth Observatory. ""This opens a window where we can look into a world that was not exposed to us before.""
Worldwide plastic production is approaching 400 million metric tons a year. More than 30 million tons are dumped yearly in water or on land, and many products made with plastics including synthetic textiles shed particles while still in use. Unlike natural organic matter, most plastics do not break down into relatively benign substances; they simply divide and redivide into smaller and smaller particles of the same chemical composition. Beyond single molecules, there is no theoretical limit to how small they can get.
Microplastics are defined as fragments ranging from 5 millimeters (less than a quarter inch) down to 1 micrometer, which is 1 millionth of a meter, or 1/25,000th of an inch. (A human hair is about 70 micrometers across.) Nanoplastics, which are particles below 1 micrometer, are measured in billionths of a meter.

Plastics in bottled water became a public issue largely after a 2018 study detected an average of 325 particles per liter; later studies multiplied that number many times over. Scientists suspected there were even more than they had yet counted, but good estimates stopped at sizes below 1 micrometer -- the boundary of the nano world.
""People developed methods to see nano particles, but they didn't know what they were looking at,"" said the new study's lead author, Naixin Qian, a Columbia graduate student in chemistry. She noted that previous studies could provide bulk estimates of nano mass, but for the most part could not count individual particles, nor identify which were plastics or something else.
The new study uses a technique called stimulated Raman scattering microscopy, which was co-invented by study coauthor Wei Min, a Columbia biophysicist. This involves probing samples with two simultaneous lasers that are tuned to make specific molecules resonate. Targeting seven common plastics, the researchers created a data-driven algorithm to interpret the results. ""It is one thing to detect, but another to know what you are detecting,"" said Min.
The researchers tested three popular brands of bottled water sold in the United States (they declined to name which ones), analyzing plastic particles down to just 100 nanometers in size. They spotted 110,000 to 370,000 particles in each liter, 90% of which were nanoplastics; the rest were microplastics. They also determined which of the seven specific plastics they were, and charted their shapes -- qualities that could be valuable in biomedical research.
One common one was polyethylene terephthalate or PET. This was not surprising, since that is what many water bottles are made of. (It is also used for bottled sodas, sports drinks and products such as ketchup and mayonnaise.) It probably gets into the water as bits slough off when the bottle is squeezed or gets exposed to heat. One recent study suggests that many particles enter the water when you repeatedly open or close the cap, and tiny bits abrade.
However, PET was outnumbered by polyamide, a type of nylon. Ironically, said Beizhan Yan, that probably comes from plastic filters used to supposedly purify the water before it is bottled. Other common plastics the researchers found: polystyrene, polyvinyl chloride and polymethyl methacrylate, all used in various industrial processes.

A somewhat disturbing thought: the seven plastic types the researchers searched for accounted for only about 10% of all the nanoparticles they found in samples; they have no idea what the rest are. If they are all nanoplastics, that means they could number in the tens of millions per liter. But they could be almost anything, ""indicating the complicated particle composition inside the seemingly simple water sample,"" the authors write. ""The common existence of natural organic matter certainly requires prudent distinguishment.""
The researchers are now reaching beyond bottled water. ""There is a huge world of nanoplastics to be studied,"" said Min. He noted that by mass, nanoplastics comprise far less than microplastics, but ""it's not size that matters. It's the numbers, because the smaller things are, the more easily they can get inside us.""
Among other things, the team plans to look at tap water, which also has been shown to contain microplastics, though far less than bottled water. Beizhan Yan is running a project to study microplastics and nanoplastics that end up in wastewater when people do laundry -- by his count so far, millions per 10-pound load, coming off synthetic materials that comprise many items. (He and colleagues are designing filters to reduce the pollution from commercial and residential washing machines.) The team will soon identify particles in snow that British collaborators trekking by foot across western Antarctica are currently collecting. They also are collaborating with environmental health experts to measure nanoplastics in various human tissues and examine their developmental and neurologic effects.
""It is not totally unexpected to find so much of this stuff,"" said Qian. ""The idea is that the smaller things get, the more of them there are.""
The study was coauthored by Xin Gao and Xiaoqi Lang of the Columbia chemistry department; Huipeng Deng and Teodora Maria Bratu of Lamont-Doherty; Qixuan Chen of Columbia's Mailman School of Public Health; and Phoebe Stapleton of Rutgers University.

","score: 12.224712322160599, grade_level: '12'","score: 12.95985531709669, grade_levels: ['college'], ages: [18, 24]",10.1073/pnas.2300582121,"Plastics are now omnipresent in our daily lives. The existence of microplastics (1 µm to 5 mm in length) and possibly even nanoplastics (<1 μm) has recently raised health concerns. In particular, nanoplastics are believed to be more toxic since their smaller size renders them much more amenable, compared to microplastics, to enter the human body. However, detecting nanoplastics imposes tremendous analytical challenges on both the nano-level sensitivity and the plastic-identifying specificity, leading to a knowledge gap in this mysterious nanoworld surrounding us. To address these challenges, we developed a hyperspectral stimulated Raman scattering (SRS) imaging platform with an automated plastic identification algorithm that allows micro-nano plastic analysis at the single-particle level with high chemical specificity and throughput. We first validated the sensitivity enhancement of the narrow band of SRS to enable high-speed single nanoplastic detection below 100 nm. We then devised a data-driven spectral matching algorithm to address spectral identification challenges imposed by sensitive narrow-band hyperspectral imaging and achieve robust determination of common plastic polymers. With the established technique, we studied the micro-nano plastics from bottled water as a model system. We successfully detected and identified nanoplastics from major plastic types. Micro-nano plastics concentrations were estimated to be about 2.4 ± 1.3 × 10 5 particles per liter of bottled water, about 90% of which are nanoplastics. This is orders of magnitude more than the microplastic abundance reported previously in bottled water. High-throughput single-particle counting revealed extraordinary particle heterogeneity and nonorthogonality between plastic composition and morphologies; the resulting multidimensional profiling sheds light on the science of nanoplastics."
"
In social media posts on the community network Reddit, users reported reduced cravings for alcohol when taking drugs intended to treat Type 2 diabetes and obesity.

Across a number of threads -- with titles such as ""Did scientists accidentally invent an anti-addiction drug?"" and ""I don't know if this is a side effect but ... Mounjaro makes me drink less!!!!!"" -- users reported a changing relationship with beer, wine, and liquor.
An analysis of those posts, together with a remote study of individuals with obesity who reported using semaglutide and tirzepatide, found that the drugs decreased cravings and reduced alcohol consumption, according to a study by Virginia Tech researchers published Nov. 28 in Scientific Reports.
""These findings add to a growing literature that these medications may curb dangerous drinking habits,"" said Warren Bickel, Virginia Tech Carilion Behavioral Health Research Professor at the Fralin Biomedical Research Institute at VTC and corresponding author.
What they did
Scientists with the Fralin Biomedical Research Institute's Addiction Recovery Research Center combined two different studies to build on existing research, including studies that showed the drugs were effective in reducing alcohol consumption in animal models.
The first was an analysis of more than 68,000 Reddit posts from 2009-23 that included terms linked to GLP-1 approved medications. Semaglutide is a GLP-1 agonist, a class of drugs that reduce blood sugar and energy intake by mimicking the actions of hormones released after eating.

Among the keywords included in the search were Mounjaro, Wegovy, Ozempic, and Trulicity. After cleaning the resulting data -- such as eliminating comments with fewer than 100 characters -- the set was narrowed to 33,609 posts from 14,595 unique users. The study was unique in using Reddit to analyze the reported experience of thousands of users.
On examining alcohol-related discussions, researchers found that 962 individuals made 1,580 alcohol-related posts. Of those, 71.7 percent addressed reduced cravings, reduced usage, and other negative effects due to drinking.
In a second study, 153 participants who self-reported having obesity were recruited from various social media platforms. Roughly a third of these participants represented the control group, a third were taking either a semaglutide injection or tablet, and a third were using tirzepatide.
Participants on semaglutide or tirzepatide reported drinking significantly fewer drinks, on average, than those in the control group who were not on any medication for diabetes or weight loss. In addition, researchers found that both the average number of drinks and the odds of binge drinking were found to be significantly lower.
Results also found that the stimulative and sedative effects of alcohol intoxication are reduced when taking these medications. ""Participants reported drinking less, experienced fewer effects of alcohol when they did drink it, and decreased odds of binge drinking,"" said Alexandra DiFeliceantonio, assistant professor at Fralin Biomedical Research Institute and one of the study's co-authors.
Researchers believe theirs is the first published report following tirezepatide, sold under the brand name Mounjaro, which was approved in 2022 and is used for treatment of Type 2 diabetes and weight loss.

Why this matters
Case studies and reports in the popular press hint at the drugs' unexpected side effect of reducing addictive behaviors, including the desire to consume alcohol.
The U.S. Food and Drug Administration has approved only three medications to treat alcohol use disorder: disulfiram, naltrexone, and acamprosate. They have shown only modest success, have poor compliance, and are underprescribed.
The authors suggest further randomized controlled trials to explore the therapeutic potential of GLP-1 agonists and GIP/GLP-1 combination drugs to treat alcohol use disorder, which affects 5.9 percent of individuals in the United States ages 12 and older. In addition, the participants identified as mostly white and female, and further studies in more diverse populations are needed to examine sex and race differences.
""Although evidence supporting the use of these medications for alcohol use disorder is growing, the field still needs to learn considerably more about them, particularly in identifying the underlying mechanisms. We plan to contribute to that effort,"" Bickel said.
The drugs are a promising development in the study of alcohol use disorder. Data from the National Survey on Drug Use and Health indicate 15.7 million people in the United States meet the criteria for the chronic, relapsing brain disorder that is a significant contributor to global mortality yet remains one of the most undertreated conditions, Bickel said.

","score: 15.12054421768708, grade_level: '15'","score: 16.292448979591832, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41598-023-48267-2,"Alcohol Use Disorder (AUD) contributes significantly to global mortality. GLP-1 (Glucagon-like peptide-1) and GLP-1/GIP (Glucose-dependent Insulinotropic Polypeptide) agonists, FDA-approved for managing type 2 diabetes and obesity, where the former has shown to effectively reduce the consumption of alcohol in animal models but no reports exist on the latter. In this report, we conducted two studies. In the first study, we conducted an analysis of abundant social media texts. Specifically, a machine-learning based attribution mapping of ~ 68,250 posts related to GLP-1 or GLP-1/GIP agonists on the Reddit platform. Secondly, we recruited participants (n = 153; current alcohol drinkers; BMI ≥ 30) who self-reported either taking Semaglutide (GLP-1 agonist), Tirzepatide (the GLP-1/GIP combination) for ≥ 30 days or, as a control group; no medication to manage diabetes or weight loss for a within and between subject remote study. In the social media study, we report 8 major themes including effects of medications (30%); diabetes (21%); and Weight loss and obesity (19%). Among the alcohol-related posts (n = 1580), 71% were identified as craving reduction, decreased desire to drink, and other negative effects. In the remote study, we observe a significantly lower self-reported intake of alcohol, drinks per drinking episode, binge drinking odds, Alcohol Use Disorders Identification Test (AUDIT) scores, and stimulating, and sedative effects in the Semaglutide or Tirzepatide group when compared to prior to starting medication timepoint (within-subjects) and the control group (between-subjects). In summary, we provide initial real-world evidence of reduced alcohol consumption in people with obesity taking Semaglutide or Tirzepatide medications, suggesting potential efficacy for treatment in AUD comorbid with obesity."
"
Researchers have developed a groundbreaking Artificial Intelligence (AI) system that can rapidly detect COVID-19 from chest X-rays with more than 98% accuracy. The study results have just been published in Nature Scientific Reports.

Corresponding author Professor Amir H Gandomi, from the University of Technology Sydney (UTS) Data Science Institute, said there was a pressing need for effective automated tools to detect COVID-19, given the significant impact on public health and the global economy.
""The most widely used COVID-19 test, real time polymerase chain reaction (PCR), can be slow and costly, and produce false-negatives. To confirm a diagnosis, radiologists need to manually examine a CT scans or X-rays, which can be time consuming and prone to error,"" said Professor Gandomi.
""The new AI system could be particularly beneficial in countries experiencing high levels of COVID-19 where there is a shortage of radiologists. Chest X-rays are portable, widely available and provide lower exposure to ionizing radiation than CT scans,"" he said.
Common symptoms of COVID-19 include fever, cough, difficulty breathing and a sore throat, however it can be difficult to distinguish COVID-19 from Flu and other types of pneumonia.
The new AI system uses a deep learning-based algorithm called a Custom Convolutional Neural Network (Custom-CNN) that is able to quickly and accurately distinguish between COVID-19 cases, normal cases, and pneumonia in X-ray images.
""Deep learning offers an end-to-end solution, eliminating the need to manually search for biomarkers. The Custom-CNN model streamlines the detection process, providing a faster and more accurate diagnosis of COVID-19,"" said Professor Gandomi.

""If a PCR test or rapid antigen test shows a negative or inconclusive result, due to low sensitivity, patients may require further examination via radiological imaging to confirm or rule out the virus's presence. In this situation the new AI system could prove beneficial.
""While radiologists play a crucial role in medical diagnosis, AI technology can assist them in making accurate and efficient diagnoses,"" said Professor Gandomi.
The performance of the Custom-CNN model was evaluated via a comprehensive comparative analysis, with accuracy as the performance criterion. The results showed that the new model outperforms the other AI diagnostic models.
Fast and accurate diagnosis of COVID-19 can ensure patients get the correct treatment, including COVID-19 antivirals, which work best if taken within five days of the onset of symptoms. It could also help them isolate and protect others from getting infected, reducing pandemic outbreaks.
This breakthrough represents a significant step in combatting the ongoing challenges posed by the pandemic, potentially transforming the landscape of COVID-19 diagnosis and management.

","score: 14.662653061224493, grade_level: '15'","score: 15.316623702112416, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41598-023-47038-3,"The most widely used method for detecting Coronavirus Disease 2019 (COVID-19) is real-time polymerase chain reaction. However, this method has several drawbacks, including high cost, lengthy turnaround time for results, and the potential for false-negative results due to limited sensitivity. To address these issues, additional technologies such as computed tomography (CT) or X-rays have been employed for diagnosing the disease. Chest X-rays are more commonly used than CT scans due to the widespread availability of X-ray machines, lower ionizing radiation, and lower cost of equipment. COVID-19 presents certain radiological biomarkers that can be observed through chest X-rays, making it necessary for radiologists to manually search for these biomarkers. However, this process is time-consuming and prone to errors. Therefore, there is a critical need to develop an automated system for evaluating chest X-rays. Deep learning techniques can be employed to expedite this process. In this study, a deep learning-based method called Custom Convolutional Neural Network (Custom-CNN) is proposed for identifying COVID-19 infection in chest X-rays. The Custom-CNN model consists of eight weighted layers and utilizes strategies like dropout and batch normalization to enhance performance and reduce overfitting. The proposed approach achieved a classification accuracy of 98.19% and aims to accurately classify COVID-19, normal, and pneumonia samples."
"
Certain populations of mosquitoes are more heat tolerant and better equipped to survive heat waves than others, according to new research from Washington University in St. Louis.

This is bad news in a world where vector-borne diseases are an increasingly global health concern. Most models that scientists use to estimate vector-borne disease risk currently assume that mosquito heat tolerances do not vary. As a result, these models may underestimate mosquitoes' ability to spread diseases in a warming world.
Researchers led by Katie M. Westby, a senior scientist at Tyson Research Center, Washington University's environmental field station, conducted a new study that measured the critical thermal maximum (CTmax), an organism's upper thermal tolerance limit, of eight populations of the globally invasive tiger mosquito, Aedes albopictus. The tiger mosquito is a known vector for many viruses including West Nile, chikungunya and dengue.
""We found significant differences across populations for both adults and larvae, and these differences were more pronounced for adults,"" Westby said. The new study is published Jan. 8 in Frontiers in Ecology and Evolution.
Westby's team sampled mosquitoes from eight different populations spanning four climate zones across the eastern United States, including mosquitoes from locations in New Orleans; St. Augustine, Fla.; Huntsville, Ala.; Stillwater, Okla.; St. Louis; Urbana, Ill.; College Park, Md.; and Allegheny County, Pa.
The scientists collected eggs in the wild and raised larvae from the different geographic locations to adult stages in the lab, tending the mosquito populations separately as they continued to breed and grow. The scientists then used adults and larvae from subsequent generations of these captive-raised mosquitoes in trials to determine CTmax values, ramping up air and water temperatures at a rate of 1 degree Celsius per minute using established research protocols.
The team then tested the relationship between climatic variables measured near each population source and the CTmax of adults and larvae. The scientists found significant differences among the mosquito populations.

The differences did not appear to follow a simple latitudinal or temperature-dependent pattern, but there were some important trends. Mosquito populations from locations with higher precipitation had higher CTmax values. Overall, the results reveal that mean and maximum seasonal temperatures, relative humidity and annual precipitation may all be important climatic factors in determining CTmax.
""Larvae had significantly higher thermal limits than adults, and this likely results from different selection pressures for terrestrial adults and aquatic larvae,"" said Benjamin Orlinick, first author of the paper and a former undergraduate research fellow at Tyson Research Center. ""It appears that adult Ae. albopictus are experiencing temperatures closer to their CTmax than larvae, possibly explaining why there are more differences among adult populations.""
""The overall trend is for increased heat tolerance with increasing precipitation,"" Westby said. ""It could be that wetter climates allow mosquitoes to endure hotter temperatures due to decreases in desiccation, as humidity and temperature are known to interact and influence mosquito survival.""
Little is known about how different vector populations, like those of this kind of mosquito, are adapted to their local climate, nor the potential for vectors to adapt to a rapidly changing climate. This study is one of the few to consider the upper limits of survivability in high temperatures -- akin to heat waves -- as opposed to the limits imposed by cold winters.
""Standing genetic variation in heat tolerance is necessary for organisms to adapt to higher temperatures,"" Westby said. ""That's why it was important for us to experimentally determine if this mosquito exhibits variation before we can begin to test how, or if, it will adapt to a warmer world.""
Future research in the lab aims to determine the upper limits that mosquitoes will seek out hosts for blood meals in the field, where they spend the hottest parts of the day when temperatures get above those thresholds, and if they are already adapting to higher temperatures. ""Determining this is key to understanding how climate change will impact disease transmission in the real world,"" Westby said. ""Mosquitoes in the wild experience fluctuating daily temperatures and humidity that we cannot fully replicate in the lab.""

","score: 14.91197927048037, grade_level: '15'","score: 15.936395754434919, grade_levels: ['college_graduate'], ages: [24, 100]",10.3389/fevo.2023.1248673,"Vector-borne diseases (VBDs) are an increasingly important global health concern in the face of climate change. Understanding the ecology and evolution of vector species is critical to predicting and combating VBD. Vectorial capacity models, used to forecast disease transmission, traditionally assume traits are constant among populations, and little is known about whether different vector populations vary in thermal tolerance. To test for geographic variation in upper thermal tolerance, we determined the critical thermal maximum (CTmax) of Aedes albopictus, a globally distributed mosquito and competent vector for many viruses including West Nile, chikungunya, and dengue. We studied CTmax for eight different populations spanning four climate zones across the Eastern United States using common garden experiments to isolate genetic variation. To explore potential drivers of this variation we then tested the relationship between climatic variables measured near each population source and CTmax. We found significant differences across populations for both adults and larvae, and these differences were more pronounced for adults. Larvae had higher CTmax values compared to adults. Several climatic variables improved models of CTmax for both adults and larvae including mean and max seasonal temperature, annual precipitation, and relative humidity. Annual precipitation appears to be particularly important and has a positive linear relationship with CTmax. The differences between life stages likely result from different selection pressures experienced in their terrestrial and aquatic habitats. Importantly, the assumption that mosquito populations within a species have the same upper thermal limits does not hold in this case, thus it is important to use population-specific CTmax values, among other important physiological parameters that may vary, to more accurately model and forecast VBDs."
"
Early symptoms can be subtle. A child's personality and behavior may change, and clumsiness or stumbling develops between the ages of five and ten. Over time, cognitive impairment sets in, seizures emerge or worsen, vision loss begins, and motor skills decline. This is the course of Batten disease, a progressive inherited disorder of the nervous system that results from mutations to the CLN3 gene.

""It is a devastating neurodegenerative disorder of childhood,"" said John Foxe, PhD, director of the Del Monte Institute for Neuroscience and co-director of the University of Rochester Intellectual and Developmental Disabilities Research Center (UR-IDDRC), ""and while it is very rare, it is important to study and understand because it could inform what we know and how we treat it and other related rare diseases.""
A possible neuromarker
In a new study, out today in theJournal of Neurodevelopmental Disorders, Foxe and a team of researchers from the University of Rochester Medical Center may be closer to that goal of understanding. The paper describes how they measured changes in brain function of participants with CLN3 disease, also known as 'juvenile-onset' Batten disease. Researchers found that the functioning of the auditory sensory memory system -- the brain system required for short-term memory recall -- appears to decrease as the disease progresses. They revealed this by utilizing electroencephalographic recordings (EEG) to measure the brain activity of participants with and without Batten disease as they passively listened to simple auditory beeps. The participants simultaneously watched a video of their favorite movie while the brain responses to these beeps were being measured. In the participants with Batten disease, the EEG revealed a decline in the response from the auditory sensory memory system as the disease progressed. There were no significant changes among the other participants. This finding suggests that this easy-to-measure brain process may be a target or biomarker in measuring treatment outcomes in clinical trials.
""We needed to find a task that did not require explicit engagement or attention, and this is one of those kinds of tasks,"" Foxe said. ""The brain produces the signal that we're looking at, regardless of whether the participant is paying attention to the beeps or not. It is an objective method that provides new insight into the brain function of a population with varying communication abilities.""
Leading Batten disease research & treatment
There are 12 currently known childhood-onset forms of Batten disease, each genetically distinct from one another, and all significantly impact neurodevelopment. The University of Rochester Batten Center (URBC) is a recognized leader in research and treatment of this condition. URBC is designated a Center of Excellence by the Batten Disease Support and Research Association (BDSRA). The University is a designated Intellectual and Developmental Research Center (IDDRC), and its current principal project is aimed at neuromarker discovery in Batten disease. With several potential gene therapies for Batten disease currently in advanced stages of development, this recent finding continues the mission at URMC to identify biomarkers to evaluate the effectiveness of these experimental treatments.
Progressing scientific findings
Researchers in the Frederick J. and Marion A. Schindler Cognitive Neurophysiology Lab, where Foxe is co-principal investigator with Edward Freedman, PhD, are using these findings to leverage a Batten disease mouse model. They aim to measure the impact pharmaceuticals have on the auditory perceptual system. Researchers are starting with treatments already on the market for other conditions. ""We think this potential biomarker is key to the possibility for us to screen these treatments in the mouse models. The auditory sensory memory marker provides a sensitive measure,"" Foxe said. ""We'll be able to tell you pretty quickly if a treatment is having an impact and know if it is actually changing dynamics -- i.e., whether the system in the brain is improving, what the speed of improvement is, etc. I think that is a big deal.""
Additional authors include first author Tufikameni Brima, PhD, Edward Freedman, PhD, Kevin Prinsloo, PhD, Heather Adams, PhD, Kuan Hong Wang, PhD, Luke Shaw, and Emma Mantel of the University of Rochester School of Medicine and Dentistry, Erika Augustine, MD, of the Kennedy Krieger Institute, and Jonathan Mink, MD, PhD. This research is supported by the Schmitt Program in Integrative Neuroscience (SPIN) through the Del Monte Institute for Neuroscience pilot program, the National Institute of Neurological Disorders and Stroke, and the Eunice Kennedy Shriver National Institute of Child Health and Human Development.

","score: 15.087310780333784, grade_level: '15'","score: 16.093770861524582, grade_levels: ['college_graduate'], ages: [24, 100]",10.1186/s11689-023-09515-8,"We interrogated auditory sensory memory capabilities in individuals with CLN3 disease (juvenile neuronal ceroid lipofuscinosis), specifically for the feature of “duration” processing. Given decrements in auditory processing abilities associated with later-stage CLN3 disease, we hypothesized that the duration-evoked mismatch negativity (MMN) of the event related potential (ERP) would be a marker of progressively atypical cortical processing in this population, with potential applicability as a brain-based biomarker in clinical trials. We employed three stimulation rates (fast: 450 ms, medium: 900 ms, slow: 1800 ms), allowing for assessment of the sustainability of the auditory sensory memory trace. The robustness of MMN directly relates to the rate at which the regularly occurring stimulus stream is presented. As presentation rate slows, robustness of the sensory memory trace diminishes. By manipulating presentation rate, the strength of the sensory memory trace is parametrically varied, providing greater sensitivity to detect auditory cortical dysfunction. A secondary hypothesis was that duration-evoked MMN abnormalities in CLN3 disease would be more severe at slower presentation rates, resulting from greater demand on the sensory memory system. Data from individuals with CLN3 disease (N = 21; range 6–28 years of age) showed robust MMN responses (i.e., intact auditory sensory memory processes) at the medium stimulation rate. However, at the fastest rate, MMN was significantly reduced, and at the slowest rate, MMN was not detectable in CLN3 disease relative to neurotypical controls (N = 41; ages 6–26 years). Results reveal emerging insufficiencies in this critical auditory perceptual system in individuals with CLN3 disease."
"
Babies and toddlers exposed to television or video viewing may be more likely to exhibit atypical sensory behaviors, such as being disengaged and disinterested in activities, seeking more intense stimulation in an environment, or being overwhelmed by sensations like loud sounds or bright lights, according to data from researchers at Drexel's College of Medicine published today in the journal JAMA Pediatrics.

According to the researchers, children exposed to greater TV viewing by their second birthday were more likely to develop atypical sensory processing behaviors, such as ""sensation seeking"" and ""sensation avoiding,"" as well as ""low registration"" -- being less sensitive or slower to respond to stimuli, such as their name being called, by 33 months old.
Sensory processing skills reflect the body's ability to respond efficiently and appropriately to information and stimuli received by its sensory systems, such as what the toddler hears, sees, touches, and tastes.
The team pulled 2011-2014 data on television or DVD-watching by babies and toddlers at 12- 18- and 24-months from the National Children's Study of 1,471 children (50% male) nationwide.
Sensory processing outcomes were assessed at 33 months using the Infant/Toddler Sensory Profile (ITSP), a questionnaire completed by parents/caregivers, designed to give insights on how children process what they see, hear and smell, etc.
ITSP subscales examine children's patterns of low registration, sensation seeking, such as excessively touching or smelling objects; sensory sensitivity, such as being overly upset or irritated by lights and noise; and sensation avoiding -- actively trying to control their environment to avoid things like having their teeth brushed. Children score in ""typical,"" ""high"" or ""low"" groups based on how often they display various sensory-related behaviors. Scores were considered ""typical"" if they were within one standard deviation from the average of the ITSP norm.
Measurements of screen exposure at 12-months were based on caregiver responses to the question: ""Does your child watch TV and/or DVDs? (yes/no),"" and at 18- and 24- months based on the question: ""Over the past 30 days, on average, how many hours per day did your child watch TV and/or DVDs?""
The findings suggest: At 12 months, any screen exposure compared to no screen viewing was associated with a 105% greater likelihood of exhibiting ""high"" sensory behaviors instead of ""typical"" sensory behaviors related to low registration at 33 months At 18 months, each additional hour of daily screen time was associated with 23% increased odds of exhibiting ""high"" sensory behaviors related to later sensation avoiding and low registration. At 24 months, each additional hour of daily screen time was associated with a 20% increased odds of ""high"" sensation seeking, sensory sensitivity, and sensation avoiding at 33 months.

The researchers adjusted for age, whether the child was born prematurely, caregiver education, race/ethnicity and other factors, such as how often the child engages in play or walks with the caregiver.
The findings add to a growing list of concerning health and developmental outcomes linked to screen time in infants and toddlers, including language delay, autism spectrum disorder, behavioral issues, sleep struggles, attention problems and problem-solving delays.
""This association could have important implications for attention deficit hyperactivity disorder and autism, as atypical sensory processing is much more prevalent in these populations,"" said lead author Karen Heffler, MD, an associate professor of Psychiatry in Drexel's College of Medicine. ""Repetitive behavior, such as that seen in autism spectrum disorder, is highly correlated with atypical sensory processing. Future work may determine whether early life screen time could fuel the sensory brain hyperconnectivity seen in autism spectrum disorders, such as heightened brain responses to sensory stimulation.""
Atypical sensory processing in kids with autism spectrum disorder (ASD) and ADHD manifests in a range of detrimental behaviors. In children with ASD, greater sensation seeking or sensation avoiding, heightened sensory sensitivity and low registration have been associated with irritability, hyperactivity, eating and sleeping struggles, as well as social problems. In kids with ADHD, atypical sensory processing is linked to trouble with executive function, anxiety and lower quality of life.
""Considering this link between high screen time and a growing list of developmental and behavioral problems, it may be beneficial for toddlers exhibiting these symptoms to undergo a period of screen time reduction, along with sensory processing practices delivered by occupational therapists,"" said Heffler.
The American Academy of Pediatrics (AAP) discourages screen time for babies under 18-24 months. Live video chat is considered by the AAP to be okay, as there may be benefit from the interaction that takes place. AAP recommends time limitations on digital media use for children 2 to 5 years to typically no more than 1 hour per day.

""Parent training and education are key to minimizing, or hopefully even avoiding, screen time in children younger than two years,"" said senior author David Bennett, PhD, a professor of Psychiatry in Drexel's College of Medicine.""
Despite the evidence, many toddlers view screens more often. As of 2014, children age 2 and under in the United States averaged 3 hours, 3 minutes a day of screen time, up from 1 hour, 19 minutes a day in 1997, according to a 2019 research letter in JAMA Pediatrics. Some parents cite exhaustion and inability for affordable alternatives as reasons for the screen time, according to a July 2015 study in the Journal of Nutrition and Behavior.
Although the current paper looked strictly at television or DVD watching, and not media viewed on smartphones or tablets, it does provide some of the earliest data linking early-life digital media exposure with later atypical sensory processing across multiple behaviors. The authors said future research is needed to better understand the mechanisms that drive the association between early-life screen time and atypical sensory processing.
In addition to Heffler and Bennett, authors on this paper include Binod Acharya, who completed the work while at Drexel's Dornsife School of Public Health's Urban Health Collaborative, and Keshab Subedi from Christiana Care Health Systems. 

","score: 17.82107642728508, grade_level: '18'","score: 19.681052415405517, grade_levels: ['college_graduate'], ages: [24, 100]",10.1001/jamapediatrics.2023.5923,"Atypical sensory processing is challenging for children and families, yet there is limited understanding of its associated risk factors. To determine the association between early-life digital media exposure and sensory processing outcomes among toddlers. This multicenter US study used data that were analyzed from the National Children’s Study (NCS), a cohort study of environmental influences on child health and development, with enrollment from 2011 to 2014. Data analysis was performed in 2023. The study included children enrolled in the NCS at birth whose caregivers completed reports of digital media exposure and sensory processing. Children’s viewing of television or video at 12 months (yes or no), 18 months, and 24 months of age (hours per day). Sensory processing was reported at approximately 33 months of age on the Infant/Toddler Sensory Profile. Quadrant scores (low registration, sensation seeking, sensory sensitivity, and sensation avoiding) were categorized into groups representing typical, high, and low sensory-related behaviors, and multinomial regression analyses were performed. A total of 1471 children (50% male) were included. Screen exposure at 12 months of age was associated with a 2-fold increased odds of being in the high category of low registration (odds ratio [OR], 2.05; 95% CI, 1.31-3.20), while the odds of being in the low category instead of the typical category decreased for sensation seeking (OR, 0.55; 95% CI, 0.35-0.87), sensation avoiding (OR, 0.69; 95% CI, 0.50-0.94), and low registration (OR, 0.64; 95% CI, 0.44-0.92). At 18 months of age, greater screen exposure was associated with increased risk of high sensation avoiding (OR, 1.23; 95% CI, 1.03-1.46) and low registration (OR, 1.23; 95% CI, 1.04-1.44). At 24 months of age, greater screen exposure was associated with increased risk of high sensation seeking (OR, 1.20; 95% CI, 1.02-1.42), sensory sensitivity (OR, 1.25; 95% CI, 1.05-1.49), and sensation avoiding (OR, 1.21; 95% CI, 1.03-1.42). In this cohort study, early-life digital media exposure was associated with atypical sensory processing outcomes in multiple domains. These findings suggest that digital media exposure might be a potential risk factor for the development of atypical sensory profiles. Further research is needed to understand the relationship between screen time and specific sensory-related developmental and behavioral outcomes, and whether minimizing early-life exposure can improve subsequent sensory-related outcomes."
"
Scientists have solved a cellular murder mystery nearly 25 years after the case went cold. Following a trail of evidence from fruit flies to mice to humans revealed that cannibalistic cells likely cause a rare human immunodeficiency. Now the discovery shows promise for enhancing an up-and-coming cancer treatment.

""This paper takes us from very fundamental cell biology in a fly, to explaining a human disease and harnessing that knowledge for a cancer therapy,"" said UC Santa Barbara's Denise Montell. ""Each one of those steps feels like a major discovery, but here they are, all in one paper.""
Researchers in Montell's lab published their findings in the Proceedings of the National Academy of Sciences and are now investigating the mechanisms and implications.
An ancient gene
The primary character in this story is a gene, Rac2, and the protein it encodes. Rac2 is one of three Rac genes in humans. ""Rac is very ancient in evolution, so it must serve a fundamental function,"" said senior author Montell, Duggan Professor and Distinguished Professor of Molecular, Cellular, and Developmental Biology.
Rac proteins help build a cell's scaffolding, called the cytoskeleton. The cytoskeleton is made of dynamic filaments that allow cells to maintain their shape or deform, as needed. In 1996, while studying a small group of cells in the fruit fly ovary, Montell determined that Rac proteins are instrumental in cell movement. Since then, it has become clear that Rac is a nearly universal regulator of cell motility in animal cells.
Back in the '90s, she noticed that a hyperactive form of the Rac1 protein, expressed in only a few cells in a fly's egg chamber, destroyed the whole tissue. ""Just expressing this active Rac in six to eight cells kills the entire tissue, which is composed of about 900 cells,"" explained lead author Abhinava Mishra, a project scientist in Montell's lab.

Why did this happen? How does it work? ""This was our 25-year-old cold case,"" Montell said.
A few years ago, evidence began to mount implicating cell eating, also known as cannibalism, in tissue destruction. There's a step in normal fly egg development where certain cells similar to the border cells consume their neighbors because they are no longer needed. Indeed, cellular cannibalism is not as rare as you might expect: Millions of old red blood cells are eliminated from the human body this way every second.
Rac2 is one component of the complex eating process. Rac helps the eating cell to envelop its target. The team was curious if a hyperactive form of the protein was causing border cells to prematurely consume their neighbors.
For this to occur, the border cells need to recognize their targets, which requires a particular receptor. Indeed, when Mishra blocked this receptor, the border cells expressing activated Rac didn't consume their neighbors, and the egg chamber remained alive and healthy.
""Our 25-year-old cold case was solved, and that was very satisfying for us,"" Montell exclaimed. ""But this is a fairly niche area of Drosophila egg development."" The implications would soon grow, though.
A mysterious immune condition
Around the time that her lab made their breakthrough, Montell caught wind of an intriguing study in the journal Blood. This paper found that three unrelated people suffering from recurrent infections had the exact same mutation, which hyperactivates Rac2, a Rac protein produced in blood cells. She suspected her lab's recent revelation in fruit flies might shed light on this enigma.

The patients' mutation was just mildly activating, and yet it was enough that they all suffered from multiple infections and ultimately needed bone marrow transplants. Blood tests revealed that these patients had nearly no T cells, a specialized kind of white blood cells crucial to the immune system. The team at the National Institutes of Health inserted the Rac2 mutation into mice and found the same mysterious loss of T cells. They also found that the T cells with hyperactive Rac developed normally in the animals' bone marrow, and migrated to the thymus, where they continued to mature without incident. But then they just seemed to disappear. So, the paper ended with a mystery: what was causing the T cells to disappear?
The authors of that journal study had noticed that many of the patients' neutrophils -- another type of white blood cell -- were enlarged. They seemed to be consuming quite a lot of material, unusual behavior in an otherwise healthy person.
Montell wondered if the patients' T cells were disappearing because their innate immune cells like neutrophils with active Rac2 were eating them, much like the fruit fly border cells with active Rac were eating the egg chamber. Her team turned their attention to macrophages -- the neutrophil's more voracious counterpart -- to investigate. Mishra cultured human macrophages with and without hyperactive Rac2 together with T cells. He observed that macrophages with hyperactive Rac consumed more cells, confirming the group's hypothesis from their work with fruit flies.
To test whether this might cause the observed immunodeficiency, co-author Melanie Rodriguez (a graduate student in Montell's lab) took bone marrow samples from mice with the same hyperactive Rac2 mutation found in the patients. She then grew the marrow stem cells into macrophages, and performed a similar experiment to Mishra, but this time mixing both macrophages and T cells with and without the Rac2 mutation.
She found that macrophages with active Rac2 consumed significantly more T-cells than their normal counterparts. However, T-cells with active Rac2 were also more vulnerable to consumption from either kind of macrophage. So the most likely explanation for the patients' missing T cells was a combination of increased consumption by macrophages as well as increased vulnerability of the T cells themselves. A human medical mystery was solved based on fundamental observations in fruit flies.
Harnessing haywire cells
The implications of these insights expanded in January 2020, when co-author Meghan Morrissey interviewed for a faculty position at UCSB. In her talk she described programming macrophages to eat cancer cells as a novel treatment for the disease, an approach called CAR-M. Morrissey had found that adding a CAR receptor to macrophages promoted this behavior. But it was also clear that inducing the macrophages to eat more would make the approach more effective -- especially if they would specifically consume, and kill, entire cancer cells .
Well, if there was one thing that Montell and her lab had learned, it was how to make macrophages eat and kill whole, living cells. So they collaborated with Morrissey, now an assistant professor of molecular, cellular and developmental biology, to determine if adding activated Rac2 would increase the effectiveness of the CAR-M approach.
Rodriguez grew macrophages from the bone marrow of normal and mutant mice with activated Rac2. In each of these groups, Morrissey expressed either a dummy receptor or the CAR receptor, which recognizes B cells (another type of white blood cell). They found that the normal and hyperactive Rac cells with the dummy receptors did not eat many B cell targets. The normal macrophages with CAR receptors consumed far more B cells, as Morrissey had previously shown. However the macrophages with both hyperactive Rac and the CAR receptors ate twice-again as many B cells as the CAR-only group. Activated Rac2 also seemed to increase the number of so-called ""super eaters"" -- ravenous macrophages that eat and kill multiple cancer cells.
The results made it clear that activated Rac and the receptor were both necessary for the enhanced effect. ""If you add active Rac without the right receptor, it doesn't do anything,"" Montell explained.
This level of control is good news for any potential treatments, because it would give doctors a way to focus the modified macrophages' attack on cancerous cells. Clinicians hopefully won't need to worry about the engineered cells eating the patient's T-cells either, because the T-cells wouldn't have the active Rac2 mutation making them more vulnerable to this, as Rodriguez had previously discovered.
There is a current cancer treatment called CAR-T, which uses the CAR receptor and a patient's own T-cells to attack and destroy cancers. It is highly effective against some cancers, but there are many that do not respond. CAR-M,a newer cousin to CAR-T, has recently entered into clinical trials in humans and so far seems safe. Montell and her group are interested in harnessing Rac-enhanced CAR macrophages to increase the efficacy of CAR-M treatments. They've filed a provisional patent for the technique -- which they call RaceCAR-M -- and are inviting biotech companies to partner in further developing the approach.
This new multifaceted paper raises both basic science and practical questions, which the lab has begun to tackle. They're investigating whether the technique, which is so effective in the lab, will also work in freshly collected human immune cells and in animal cancer models, in mice and zebrafish. The team is also exploring how Rac2 is making this all happen at the molecular level, deep inside the cells.
Further down the line, Montell wants to know how many kinds of cancer the RaceCAR-M treatment might successfully target. For comparison, CAR-T has been effective against cancers like leukemia and lymphoma, but not against solid-tumor cancers like breast, lung or colon.
The results have amazed Montell, an esteemed cell biologist with well over 100 papers to her name. ""This is my favorite paper so far,"" she said.
""We had this 25-year-old cold case in fruit flies, and we solved it,"" Montell added. ""And that helped us solve the mystery of an unexplained human immunodeficiency. And then we harnessed that knowledge to enhance a potential cancer immunotherapy.
""It was just one mystery after another, and Rac turned out to be the answer to each of them.""
You can hear more about the path from fruit flies to potential cancer treatment in Montell's SNPets interview with the Genetics Society of America, episodes 4-6 (https://genetics-gsa.org/snpets/full-season-snpets/#montell).

","score: 11.629807092694584, grade_level: '12'","score: 12.35826689395926, grade_levels: ['college'], ages: [18, 24]",10.1073/pnas.2310221120,"The 21kD GTPase Rac is an evolutionarily ancient regulator of cell shape and behavior. Rac2 is predominantly expressed in hematopoietic cells where it is essential for survival and motility. The hyperactivating mutation Rac2E62Kalso causes human immunodeficiency, although the mechanism remains unexplained. Here, we report that in Drosophila, hyperactivating Rac stimulates ovarian cells to cannibalize neighboring cells, destroying the tissue. We then show that hyperactive Rac2E62Kstimulates human HL60-derived macrophage-like cells to engulf and kill living T cell leukemia cells. Primary mouse Rac2+/E62Kbone-marrow-derived macrophages also cannibalize primary Rac2+/E62KT cells due to a combination of macrophage hyperactivity and T cell hypersensitivity to engulfment. Additionally, Rac2+/E62Kmacrophages non-autonomously stimulate wild-type macrophages to engulf T cells. Rac2E62Kalso enhances engulfment of target cancer cells by chimeric antigen receptor-expressing macrophages (CAR-M) in a CAR-dependent manner. We propose that Rac-mediated cell cannibalism may contribute to Rac2+/E62Khuman immunodeficiency and enhance CAR-M cancer immunotherapy."
"
Researchers at the University of Michigan Health Rogel Cancer Center have identified a mechanism that causes severe gastrointestinal problems with immune-based cancer treatment.

They also found a way to deliver immunotherapy's cancer-killing impact without the unwelcome side effect.
The findings are published in Science.
""This is a good example of how understanding a mechanism helps you to develop an alternative therapy that's more beneficial. Once we identified the mechanism causing the colitis, we could then develop ways to overcome this problem and prevent colitis while preserving the anti-tumor effect,"" said senior study author Gabriel Nunez, M.D., Paul de Kruif Professor of Pathology at Michigan Medicine.
Immunotherapy has emerged as a promising treatment for several types of cancer. But immune checkpoint inhibitors can also cause severe side effects, including colitis, which is inflammation in the digestive tract.
Colitis can cause severe gastrointestinal discomfort, and some patients will discontinue their cancer treatment because of it.
The problem facing researchers was that while patients were developing colitis, the laboratory mice were not. So researchers couldn't study what was causing this side effect.

To get past this, the Rogel team, led by first author Bernard C. Lo, Ph.D., created a new mouse model, injecting microbiota from wild-caught mice into the traditional mouse model.
In this model, the mice did develop colitis after administration of antibodies used for tumor immunotherapy. Now, researchers could trace back the mechanism to see what was causing this reaction.
In fact, colitis developed because of the composition of the gut microbiota, which caused immune T cells to be hyper-activated while regulatory T cells that put the brakes on T cell activation were deleted in the gut.
This was happening within a specific domain of the immune checkpoint antibodies.
Researchers then removed that domain, which they found still resulted in a strong anti-tumor response but without inducing colitis.
""Previously, there were some data that suggested the presence of certain bacteria correlated with response to therapy. But it was not proven that microbiota were critical to develop colitis. This work for the first time shows that microbiota are essential to develop colitis from immune checkpoint inhibition,"" Nunez said.

To follow up what they saw in mice, researchers reanalyzed previously reported data from studies of human cells from patients treated with immune checkpoint antibodies, which reinforced the role of regulatory T cells in inducing colitis.
The antibody they used to stop the colitis was developed by Takeda Pharmaceuticals.
The Rogel team plans additional studies to further understand the mechanisms causing colitis and seeks clinical partners to move this knowledge to a clinical trial.
Additional authors are Ilona Kryczek, Jiali Yu, Linda Vatan, Roberta Caruso, Masanori Matsumoto, Yosuke Sato, Michael H. Shaw, Naohiro Inohara, Yuying Xie, Yu Leo Lei and Weiping Zou.
Funding for this work is from National Institutes of Health grants R01 DK121504, R01 DK095782, R01 DE026728, R01 DE030691, P30 CA046592; Takeda Millennium Pharmaceuticals, Canadian Institutes of Health, Crohn's and Colitis Foundation, National Science Foundation grant IOS-2107215.
This work was supported by these Rogel Cancer Center Shared Resources: Single Cell Spatial Analysis, Tissue and Molecular Pathology

","score: 14.162597312859887, grade_level: '14'","score: 14.890479846449132, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/science.adh8342,"Immune checkpoint inhibitors can stimulate antitumor immunity but can also induce toxicities termed immune-related adverse events (irAEs). Colitis is a common and severe irAE that can lead to treatment discontinuation. Mechanistic understanding of gut irAEs has been hampered because robust colitis is not observed in laboratory mice treated with checkpoint inhibitors. We report here that this limitation can be overcome by using mice harboring the microbiota of wild-caught mice, which develop overt colitis following treatment with anti-CTLA-4 antibodies. Intestinal inflammation is driven by unrestrained activation of IFNγ-producing CD4 + T cells and depletion of peripherally induced regulatory T cells through Fcγ receptor signaling. Accordingly, anti-CTLA-4 nanobodies that lack an Fc domain can promote antitumor responses without triggering colitis. This work suggests a strategy for mitigating gut irAEs while preserving antitumor stimulating effects of CTLA-4 blockade."
"
Technological advancements have enabled scientists to comprehensively explore genetic control elements, unraveling the complexities of gene activation mechanisms in our genetic code. New evidence challenges the simplistic view that cis-regulatory elements (CREs) are mere on/off switches for genes, emphasizing their ability to exhibit complex behaviors, such as the simultaneous enhancement of gene activity and initiation of gene transcription, e.g., simultaneous enhancer and promoter activities. These switches aren't only important for the enhancement of specific genes but are crucial for the basic functions that keep our cells healthy.

Now, a study conducted in Japan has revealed the existence of around 11,000 vital genetic switches active in every cell type -- housekeeping cis-regulatory elements (HK-CREs) -- that play a role in maintaining the stability and function of our cells, far beyond the regulation of housekeeping genes. This study was performed by scientists from the Laboratory of Functional Analysis in silico (Nakai-lab) at The Institute of Medical Science, The University of Tokyo, Japan: Professor Kenta Nakai, head of the laboratory, and Dr. Martin Loza, Assistant Professor, in collaboration with Dr. Alexis Vandenbon, Associate Professor, from the Institute of Life and Medical Sciences, Kyoto University, Japan. Their work was published in Nucleic Acids Research on December 12, 2023.

Discussing his motivation behind this study, Dr. Loza states, ""Given the significant association between cancer and mutations in epigenetic components, every small insight we gain could be key in the ongoing battle against this disease, which has tragically claimed innumerable lives. Through extensive bioinformatics analyses, we aimed to emphasize HK-CREs profound impact on fundamental cellular processes, including their potential as essential housekeeping tumor suppressors."" The research team found that HK-CREs were not solely confined to regulating the well-studied housekeeping genes (HKGs), which only constituted less than 20% of the genes associated with these elements. Instead, these elements predominantly resided within core promoter regions of many more genes (around 8,000), indicating a broader regulatory role beyond typical housekeeping gene functions. By employing bioinformatics analyses and levering diverse public datasets, the team validated the robustness of HK-CREs across 50 randomly selected healthy cell types, confirming the location of HK-CREs within the genome. These elements were highly conserved, residing in unmethylated CpG-rich regions, a trait strongly associated with their housekeeping regulatory function.
Sharing his concerns about the analysis, Dr. Lozastates, ""By leveraging bioinformatics analyses of multiomics data, we offer an approach to harnessing publicly available datasets for exploring diverse biological mechanisms. We anticipate that employing similar workflows can significantly streamline analyses, cutting back both time and financial investments needed for comprehensive studies involving new data.""
The team remarked on the intricate cooperative interactions among housekeeping core promoters (HK-CPs), forming complex regulatory networks through promoter-promoter interactions. These observations hint at the significant influence of such interactions not only on HKGs but also on genes specific to various cell types. Turning their attention to cancer cells, researchers discovered a subset of HK-CREs displaying reduced activity in diverse cancer subtypes due to aberrant methylation, particularly those linked to zinc finger genes clustered in sub-telomere regions of chromosome 19. Identifying genes such as ZNF135, ZNF154, ZNF667, and ZNF667-AS1 under the influence of these foundational core promoters, the research suggests their potential as housekeeping tumor suppressor genes.
""Genes detected in our study have exhibited decreased activity in multiple cancer cell lines, and survival analysis across various cancer projects have revealed significant increases in survival probability in diverse cancer types like pancreas adenocarcinoma and uveal melanoma,"" states Dr. Loza.
In essence, the results of this research have uncovered a previously unknown class of HK-CREs critical for cellular stability, extending their influence beyond housekeeping gene regulation. ""Our discovery on housekeeping tumor suppressor genes unveils a novel avenue in cancer therapy, harnessing the intrinsic elements within the DNA of every cell. Future approaches to cancer treatment, focusing on these housekeeping tumor suppressor genes, offer a unique solution that could potentially target a broad range of cancers, sidestepping the challenges associated with personalized medicine,"" remarks Dr. Loza. He further adds, ""Our findings on housekeeping cis-regulatory elements fill a big gap in the current knowledge regarding gene regulatory processes. We anticipate that our findings will enhance the understanding of these processes and serve as a valuable resource for researchers striving to uncover elements inherent in the genome for combating various diseases.""
Technological advancements have enabled scientists to comprehensively explore genetic control elements, unraveling the complexities of gene activation mechanisms in our genetic code. New evidence challenges the simplistic view that cis-regulatory elements (CREs) are mere on/off switches for genes, emphasizing their ability to exhibit complex behaviors, such as the simultaneous enhancement of gene activity and initiation of gene transcription, e.g., simultaneous enhancer and promoter activities. These switches aren't only important for the enhancement of specific genes but are crucial for the basic functions that keep our cells healthy. Now, a study conducted in Japan has revealed the existence of around 11,000 vital genetic switches active in every cell type -- housekeeping cis-regulatory elements (HK-CREs) -- that play a role in maintaining the stability and function of our cells, far beyond the regulation of housekeeping genes. This study was performed by scientists from the Laboratory of Functional Analysis in silico (Nakai-lab) at The Institute of Medical Science, The University of Tokyo, Japan: Professor Kenta Nakai, head of the laboratory, and Dr. Martin Loza, Assistant Professor, in collaboration with Dr. Alexis Vandenbon, Associate Professor, from the Institute of Life and Medical Sciences, Kyoto University, Japan. Their work was published in Nucleic Acids Research on December 12, 2023.
Discussing his motivation behind this study, Dr. Loza states, ""Given the significant association between cancer and mutations in epigenetic components, every small insight we gain could be key in the ongoing battle against this disease, which has tragically claimed innumerable lives. Through extensive bioinformatics analyses, we aimed to emphasize HK-CREs profound impact on fundamental cellular processes, including their potential as essential housekeeping tumor suppressors."" The research team found that HK-CREs were not solely confined to regulating the well-studied housekeeping genes (HKGs), which only constituted less than 20% of the genes associated with these elements. Instead, these elements predominantly resided within core promoter regions of many more genes (around 8,000), indicating a broader regulatory role beyond typical housekeeping gene functions. By employing bioinformatics analyses and levering diverse public datasets, the team validated the robustness of HK-CREs across 50 randomly selected healthy cell types, confirming the location of HK-CREs within the genome. These elements were highly conserved, residing in unmethylated CpG-rich regions, a trait strongly associated with their housekeeping regulatory function.
Sharing his concerns about the analysis, Dr. Lozastates, ""By leveraging bioinformatics analyses of multiomics data, we offer an approach to harnessing publicly available datasets for exploring diverse biological mechanisms. We anticipate that employing similar workflows can significantly streamline analyses, cutting back both time and financial investments needed for comprehensive studies involving new data.""
The team remarked on the intricate cooperative interactions among housekeeping core promoters (HK-CPs), forming complex regulatory networks through promoter-promoter interactions. These observations hint at the significant influence of such interactions not only on HKGs but also on genes specific to various cell types. Turning their attention to cancer cells, researchers discovered a subset of HK-CREs displaying reduced activity in diverse cancer subtypes due to aberrant methylation, particularly those linked to zinc finger genes clustered in sub-telomere regions of chromosome 19. Identifying genes such as ZNF135, ZNF154, ZNF667, and ZNF667-AS1 under the influence of these foundational core promoters, the research suggests their potential as housekeeping tumor suppressor genes.
""Genes detected in our study have exhibited decreased activity in multiple cancer cell lines, and survival analysis across various cancer projects have revealed significant increases in survival probability in diverse cancer types like pancreas adenocarcinoma and uveal melanoma,"" states Dr. Loza.
In essence, the results of this research have uncovered a previously unknown class of HK-CREs critical for cellular stability, extending their influence beyond housekeeping gene regulation. ""Our discovery on housekeeping tumor suppressor genes unveils a novel avenue in cancer therapy, harnessing the intrinsic elements within the DNA of every cell. Future approaches to cancer treatment, focusing on these housekeeping tumor suppressor genes, offer a unique solution that could potentially target a broad range of cancers, sidestepping the challenges associated with personalized medicine,"" remarks Dr. Loza. He further adds, ""Our findings on housekeeping cis-regulatory elements fill a big gap in the current knowledge regarding gene regulatory processes. We anticipate that our findings will enhance the understanding of these processes and serve as a valuable resource for researchers striving to uncover elements inherent in the genome for combating various diseases.""

","score: 19.569526593305827, grade_level: '20'","score: 21.742600871160015, grade_levels: ['college_graduate'], ages: [24, 100]",10.1093/nar/gkad1164,"In this research, we elucidate the presence of around 11,000 housekeeping cis-regulatory elements (HK-CREs) and describe their main characteristics. Besides the trivial promoters of housekeeping genes, most HK-CREs reside in promoter regions and are involved in a broader role beyond housekeeping gene regulation. HK-CREs are conserved regions rich in unmethylated CpG sites. Their distribution highly correlates with that of protein-coding genes, and they interact with many genes over long distances. We observed reduced activity of a subset of HK-CREs in diverse cancer subtypes due to aberrant methylation, particularly those located in chromosome 19 and associated with zinc finger genes. Further analysis of samples from 17 cancer subtypes showed a significantly increased survival probability of patients with higher expression of these genes, suggesting them as housekeeping tumor suppressor genes. Overall, our work unravels the presence of housekeeping CREs indispensable for the maintenance and stability of cells."
"
Using a new technology developed at MIT, diagnosing lung cancer could become as easy as inhaling nanoparticle sensors and then taking a urine test that reveals whether a tumor is present.

The new diagnostic is based on nanosensors that can be delivered by an inhaler or a nebulizer. If the sensors encounter cancer-linked proteins in the lungs, they produce a signal that accumulates in the urine, where it can be detected with a simple paper test strip.
This approach could potentially replace or supplement the current gold standard for diagnosing lung cancer, low-dose computed tomography (CT). It could have an especially significant impact in low- and middle-income countries that don't have widespread availability of CT scanners, the researchers say.
""Around the world, cancer is going to become more and more prevalent in low- and middle-income countries. The epidemiology of lung cancer globally is that it's driven by pollution and smoking, so we know that those are settings where accessibility to this kind of technology could have a big impact,"" says Sangeeta Bhatia, the John and Dorothy Wilson Professor of Health Sciences and Technology and of Electrical Engineering and Computer Science at MIT, and a member of MIT's Koch Institute for Integrative Cancer Research and the Institute for Medical Engineering and Science.
Bhatia is the senior author of the paper, which appears today in Science Advances. Qian Zhong, an MIT research scientist, and Edward Tan, a former MIT postdoc, are the lead authors of the study.
Inhalable particles
To help diagnose lung cancer as early as possible, the U.S. Preventive Services Task Force recommends that heavy smokers over the age of 50 undergo annual CT scans. However, not everyone in this target group receives these scans, and the high false-positive rate of the scans can lead to unnecessary, invasive tests.

Bhatia has spent the last decade developing nanosensors for use in diagnosing cancer and other diseases, and in this study, she and her colleagues explored the possibility of using them as a more accessible alternative to CT screening for lung cancer.
These sensors consist of polymer nanoparticles coated with a reporter, such as a DNA barcode, that is cleaved from the particle when the sensor encounters enzymes called proteases, which are often overactive in tumors. Those reporters eventually accumulate in the urine and are excreted from the body.
Previous versions of the sensors, which targeted other cancer sites such as the liver and ovaries, were designed to be given intravenously. For lung cancer diagnosis, the researchers wanted to create a version that could be inhaled, which could make it easier to deploy in lower resource settings.
""When we developed this technology, our goal was to provide a method that can detect cancer with high specificity and sensitivity, and also lower the threshold for accessibility, so that hopefully we can improve the resource disparity and inequity in early detection of lung cancer,"" Zhong says.
To achieve that, the researchers created two formulations of their particles: a solution that can be aerosolized and delivered with a nebulizer, and a dry powder that can be delivered using an inhaler.
Once the particles reach the lungs, they are absorbed into the tissue, where they encounter any proteases that may be present. Human cells can express hundreds of different proteases, and some of them are overactive in tumors, where they help cancer cells to escape their original locations by cutting through proteins of the extracellular matrix. These cancerous proteases cleave DNA barcodes from the sensors, allowing the barcodes to circulate in the bloodstream until they are excreted in the urine.

In the earlier versions of this technology, the researchers used mass spectrometry to analyze the urine sample and detect DNA barcodes. However, mass spectrometry requires equipment that might not be available in low-resource areas, so for this version, the researchers created a lateral flow assay, which allows the barcodes to be detected using a paper test strip.
The researchers designed the strip to detect up to four different DNA barcodes, each of which indicates the presence of a different protease. No pre-treatment or processing of the urine sample is required, and the results can be read about 20 minutes after the sample is obtained.
""We were really pushing this assay to be point-of-care available in a low-resource setting, so the idea was to not do any sample processing, not do any amplification, just to be able to put the sample right on the paper and read it out in 20 minutes,"" Bhatia says.
Accurate diagnosis
The researchers tested their diagnostic system in mice that are genetically engineered to develop lung tumors similar to those seen in humans. The sensors were administered 7.5 weeks after the tumors started to form, a time point that would likely correlate with stage 1 or 2 cancer in humans.
In their first set of experiments in the mice, the researchers measured the levels of 20 different sensors designed to detect different proteases. Using a machine learning algorithm to analyze those results, the researchers identified a combination of just four sensors that was predicted to give accurate diagnostic results. They then tested that combination in the mouse model and found that it could accurately detect early-stage lung tumors.
For use in humans, it's possible that more sensors might be needed to make an accurate diagnosis, but that could be achieved by using multiple paper strips, each of which detects four different DNA barcodes, the researchers say.
The researchers now plan to analyze human biopsy samples to see if the sensor panels they are using would also work to detect human cancers. In the longer term, they hope to perform clinical trials in human patients. A company called Sunbird Bio has already run phase 1 trials on a similar sensor developed by Bhatia's lab, for use in diagnosing liver cancer and a form of hepatitis known as nonalcoholic steatohepatitis (NASH).
In parts of the world where there is limited access to CT scanning, this technology could offer a dramatic improvement in lung cancer screening, especially since the results can be obtained during a single visit.
""The idea would be you come in and then you get an answer about whether you need a follow-up test or not, and we could get patients who have early lesions into the system so that they could get curative surgery or lifesaving medicines,"" Bhatia says.
The research was funded by the Johnson & Johnson Lung Cancer Initiative, the Howard Hughes Medical Institute, the Koch Institute Support (core) Grant from the National Cancer Institute, and the National Institute of Environmental Health Sciences.

","score: 15.38934664246824, grade_level: '15'","score: 16.79950998185118, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/sciadv.adj9591,"Although low-dose computed tomography screening improves lung cancer survival in at-risk groups, inequality remains in lung cancer diagnosis due to limited access to and high costs of medical imaging infrastructure. We designed a needleless and imaging-free platform, termed PATROL (point-of-care aerosolizable nanosensors with tumor-responsive oligonucleotide barcodes), to reduce resource disparities for early detection of lung cancer. PATROL formulates a set of DNA-barcoded, activity-based nanosensors (ABNs) into an inhalable format. Lung cancer–associated proteases selectively cleave the ABNs, releasing synthetic DNA reporters that are eventually excreted via the urine. The urinary signatures of barcoded nanosensors are quantified within 20 min at room temperature using a multiplexable paper-based lateral flow assay. PATROL detects early-stage tumors in an autochthonous lung adenocarcinoma mouse model with high sensitivity and specificity. Tailoring the library of ABNs may enable not only the modular PATROL platform to lower the resource threshold for lung cancer early detection tools but also the rapid detection of chronic pulmonary disorders and infections."
"
People who are hard of hearing spend more energy listening. That energy comes at the expense of other cognitive functions. Cognitive functions are the mental processes in the brain that enable us to think and solve problems, among other things.

In a new study featuring data from 573,088 people, researchers from the Department of Clinical Research at the University of Southern Denmark have found a link between hearing loss and the development of dementia. The study is the largest of its kind to date.
There is already an increase in the number of people with dementia. This is mainly due to the ageing of the population as a whole, but there are also other risk factors, such as lifestyle and hearing.
""Previous studies have suggested that there could be a link between hearing loss and dementia. Our study is larger than the previous studies, and we have demonstrated a link between hearing loss and dementia, ""says Assistant Professor Manuella Lech Cantuaria from the Department of Clinical Research at the University of Southern Denmark.
Good news for hearing aid users
The results of the study show that people affected by hearing loss have up to a 13% higher risk of developing dementia compared to people with normal hearing. The high risk is especially seen in people with severe hearing loss.
The researchers also studied whether there was a difference in the risk depending on whether or not people wear hearing aids.

""We found that the risk of developing dementia was 20% higher for people who didn't wear hearing aids compared to people with normal hearing. People who used hearing aids had a 6% increased risk of developing dementia. This suggests that wearing a hearing aid can prevent or delay the development of dementia,"" explains Manuella Lech Cantuaria.
About the study
The study is a so-called cohort study that follows a group of people with common characteristics over a longer period of time. In this study, all of the people were above 50 years of age and from the Region of Southern Denmark between 2003-2017. People diagnosed with dementia before the commencement of the study were excluded. The researchers compared data on people's hearing with data on the development of dementia during the period. The researchers have found a significant -- that is, clear -- correlation between hearing loss and the development of dementia. The greatest risk of developing dementia was especially seen in people with severe hearing loss Hearing loss causes a 7% increased risk of developing dementia People with severe hearing loss have up to a 20% increased risk of developing dementia compared to people without hearing lossHearing loss and dementia
Hearing loss -- a national scourge
Around 800,000 Danes suffer from hearing loss. And that number is only likely to get higher in the future because we are getting older in general, and we are exposed to more and more noise. Hearing loss is measured in decibels (dB). There are different degrees of hearing loss. For example, hearing loss above 60-70 dB means you can't hear normal speech. Above 90-100 dB means you can't hear shouting.
Dementia
Dementia is a term used to describe the weakening of mental abilities due to illness in the brain. Dementia is characterised by an impairment of cognitive functions such as: Impaired memory and concentration, impaired orientation, language disorders, personality and behavioural changes. Alzheimer's, for example, is a type of dementia.

","score: 11.401702282661489, grade_level: '11'","score: 11.805304152501215, grade_levels: ['12'], ages: [17, 18]",10.1001/jamaoto.2023.3509,"Hearing loss has been suggested as a risk factor for dementia, but there is still a need for high-quality research to better understand the association between these 2 conditions and the underlying causal mechanisms and treatment benefits using larger cohorts and detailed data. To investigate the association between hearing loss and incident dementia, as well as how hearing aid use contributes to this association. This population-based cohort study was conducted in Southern Denmark between January 2003 and December 2017 and included all residents 50 years and older. We excluded all persons with dementia before baseline as well as those who did not live in the region 5 years before baseline, with incomplete address history, or who had missing covariate information. Individual hearing status based on the Hearing Examinations in Southern Denmark database, which contains data on all pure-tone audiometry examinations performed at public hearing rehabilitation clinics in Southern Denmark. Incident cases of dementia and Alzheimer disease as identified from national registries. The study population comprised 573 088 persons (298 006 women [52%]; mean [SD] age, 60.8 [11.3] years) with 23 023 cases of dementia and mean (SD) follow-up of 8.6 (4.3) years. Having a hearing loss was associated with an increased risk of dementia, with an adjusted hazard ratio (HR) of 1.07 (95% CI, 1.04-1.11) compared with having no hearing loss. Severe hearing loss in the better and worse ear was associated with a higher dementia risk, with an HR of 1.20 (95% CI, 1.09-1.32) and 1.13 (95% CI, 1.06-1.20), respectively, compared with having no hearing loss in the corresponding ear. Compared with people without hearing loss, the risk of dementia was higher among people with hearing loss who were not using hearing aids than those who had hearing loss and were using hearing aids, with HRs of 1.20 (95% CI, 1.13-1.27) and 1.06 (95% CI, 1.01-1.10), respectively. The results of this cohort study suggest that hearing loss was associated with increased dementia risk, especially among people not using hearing aids, suggesting that hearing aids might prevent or delay the onset and progression of dementia. The risk estimates were lower than in previous studies, highlighting the need for more high-quality longitudinal studies."
"
Creating a functional lung using interspecies chimeric animals is an attractive albeit challenging option for lung transplantation, requiring more research on the viable conditions needed for organ generation. A new study uses reverse-blastocyst complementation and tetraploid-based organ complementation methods to first determine these conditions in lung-deficient mice and then to generate rat-derived lungs in these mice. It provides useful insights on the intrinsic species-specific barriers and factors associated with lung development in interspecies chimeric animals.

Chronic obstructive pulmonary disease (COPD) is the third leading cause of death worldwide. It is marked by lung damage that is lasting and incurable, leaving lung transplantation as the only viable treatment option. Unfortunately, finding suitable lung donors is difficult. To compensate for this shortage of donors, regenerative medicine is making strides in developing lungs from pluripotent stem cells (PSCs), using interspecies animal models.
Through a biological technique known as blastocyst complementation, PSCs, and embryonic stem cells (ESCs) from one species can be injected into blastocysts of a different organ-deficient species, creating interspecies chimeric animals. This technique has enabled successful regeneration of the pancreas, heart, and kidney in rat-mouse chimeras. However, functional lung formation has still not been achieved successfully, warranting further research into the viable conditions required to generate PSC-derived organs.
Now, scientists from Nara Institute of Science and Technology (NAIST), Japan have used the reverse-blastocyst complementation (rBC) method to understand the conditions required to form lungs in rat-mouse chimeric models. In addition, they used the tetraploid-based organ complementation (TOC) method to successfully create a rat-derived lung in their mouse model. The study, published in Development, was led by Shunsuke Yuri and Ayako Isotani from NAIST.
The fibroblast growth factor 10 (Fgf10) and its interaction with the Fgf receptor 2 isoform IIIb (Fgfr2b) in the lungs are crucial for lung development. In this study, the rBC method involved injecting mutant ESCs which fail to show lung formation into wild-type (WT) embryos. This method allows for efficient detection of mutant PSCs in the recipient tissue, aiding the determination of the conditions necessary for successful lung formation in the organ-deficient animal.
The research team also found that WT ESCs provide uniform contributions across target and non-target organs in the chimeras. This helped ascertain that a certain number of WT or normal cells are required to overcome the lung development failure in Fgf10-deficient or Fgfr2b-deficient animals.
With this knowledge, they successfully produced rat-derived lungs in the Fgfr2b-deficient mouse embryos with the TOC method, without needing to produce a mutant mouse line. ""Interestingly, we found that the rat epithelial cells conserved intrinsic species-specific timing in the interspecies model, resulting in an underdeveloped lung,"" notes Yuri. Consequently, these lungs remained nonfunctional post-birth.
The findings of this study clearly identify the factors required and barriers to overcome for successful generation of functional lungs in rat-mouse interspecies chimeras. Speaking of the significance of these findings, Yuri concludes, ""We believe that our study makes an important contribution to the literature by presenting a faster and more efficient method of exploring blastocyst complementation. These novel results can significantly advance the progress toward developing in-vivo chimeric lungs for the purpose of transplantation, which could transform the practical application of regenerative medicine.""

","score: 15.931179653679653, grade_level: '16'","score: 17.665938466295607, grade_levels: ['college_graduate'], ages: [24, 100]",10.1242/dev.202081,"Regenerative medicine is a tool to compensate for the shortage of lungs for transplantation, but it remains difficult to construct a lung in vitro due to the complex three-dimensional structures and multiple cell types required. A blastocyst complementation method using interspecies chimeric animals has been attracting attention as a way to create complex organs in animals, although successful lung formation using interspecies chimeric animals has not yet been achieved. Here, we applied a reverse-blastocyst complementation method to clarify the conditions required to form lungs in an Fgfr2b-deficient mouse model. We then successfully formed a rat-derived lung in the mouse model by applying a tetraploid-based organ-complementation method. Importantly, rat lung epithelial cells retained their developmental timing even in the mouse body. These findings provide useful insights to overcome the barrier of species-specific developmental timing to generate functional lungs in interspecies chimeras."
"
The cycling of water across membrane transporters is an hallmark of the cell metabolism and is potentially of high diagnostic significance for the characterization of tumors and other diseases. In the journal Angewandte Chemie, an Italian research team has now introduced a new MRI-based method for assessing this water exchange. By this method, they were able to estimate the degree of malignancy and the success of treatments in mice tumor models.

Not all cancers are equal. Depending on the type of tumor, a given treatment may be spot on or fail completely. For targeted, effective, treatment that is as gentle as possible, it is important to precisely locate the tumor and determine its malignancy. Magnetic resonance imaging (MRI) provides excellent time- and spatially resolved images for the characterization of tumors. During this procedure, the patient lies in a ""tube"" in which there is a very strong magnetic field. The spins of protons (the nuclei of hydrogen atoms) align themselves in this magnetic field. Radio waves are beamed in and synchronize the precessions of the spins, temporarily flipping some of them. Depending on the composition of the tissue, this ""magnetization"" is lost at different times (relaxation). This can be used to compute 3D images. Gadolinium contrast agents reduce the relaxation times. These agents are more concentrated in tumors because their blood vessels are particularly permeable. This increases the contrast and makes it easier to define the tumor.
Contrast agents only spread through the extracellular compartments of the tumor; they do not enter tumor cells. A team led by Giuseppe Ferrauto and Silvio Aime wanted to exploit this feature to determine the degree of water exchange through the cell membrane. Tumor cells are more metabolically active than healthy cells and have more transport proteins and channels in their cell membranes. These proteins also allow water to enter and exit the cell, and the degree of water exchange is a measure of the aggressiveness of a tumor. Yet, classic MRI cannot show this.
The team from the University of Torino and IRCCS SDN SynLab in Naples decided to work with a new MRI method called CEST (Chemical Exchange Saturation Transfer). There is constant proton exchange between free water and hydrogen-containing groups in biomolecules, such as the amine groups in creatine. The radio frequencies at which a proton can be ""magnetized"" depends on the chemical environment of that proton, so frequencies are different for protons in free water and those bound to creatine, for example. With a matching pulse, the creatine-bound protons can be saturated. These protons are exchanged and bind to nearby free water. They keep their ""saturated magnetization state"" as they do this. If radio waves with the right frequency for free water protons are then pulsed, an increasing number of these protons are already magnetized and cannot absorb the energy (the CEST signal in MR images). Absorption decreases until the proton exchange reaches equilibrium. This makes it possible to draw conclusions about the concentration of creatine and other proton exchanging molecules in a cell, which can be used for cancer phenotyping.
If a contrast agent is then administered and enters the extracellular compartment, the magnetization of the water protons there decreases significantly faster. Because water is exchanged through the membrane, the number of magnetized water protons within the cells also decreases more quickly. This in turn changes the CEST signals. The changes after addition of contrast agent reflect the permeability of the tumor cell membrane to water.
The team tested this method in mouse models for breast cancer with different degrees of malignancy. As expected, the observable water exchange increase as the tumors grew more aggressive. Within the tumors, it was also possible to differentiate between areas of differing malignancy. The cytostatic drug Doxorubicin immediately reduced the water permeability.
Hence, the developed method sheds light into tumor phenotype and provides a new tool to assess the outcome of chemotherapy.

","score: 11.45810975609756, grade_level: '11'","score: 11.692142971758663, grade_levels: ['12'], ages: [17, 18]",10.1002/anie.202313485,"Water cycling across the membrane transporters is considered a hallmark of cellular metabolism and it could be of high diagnostic relevance in the characterization of tumors and other diseases. The method relies on the response of intracellular proton exchanging molecules to the presence of extracellular Gd‐based contrast agents (GBCAs). Paramagnetic GBCAs enhances the relaxation rate of water molecules in the extracellular compartment and, through membrane exchange, the relaxation enhancement is transferred to intracellular molecules. The effect is detected at the MRI‐CEST (Magnetic Resonance Imaging ‐ Chemical Exchange Saturation Transfer) signal of intracellular proton exchanging molecules. The magnitude of the change in the CEST response reports on water cycling across the membrane. The method has been tested on Red Blood Cells and on orthotopic murine models of breast cancer with different degree of malignancy (4T1, TS/A and 168FARN). The distribution of voxels reporting on membrane permeability fits well with the cells’ aggressiveness and acts as an early reporter to monitor therapeutic treatments."
"
A new study in Advanced Science unlocks the secrets of how high blood pressure (hypertension) fuels the progression of arterial disease. Led by Professor Thomas Iskratsch, Professor of Cardiovascular Mechanobiology & Bioengineering at Queen Mary University of London, the research team exposes a novel mechanism by which elevated pressure transforms muscle cells in the arterial wall into ""foam cells"" -- the building blocks of plaque buildup that cripples arteries.

The study focuses on vascular smooth muscle cells (VSMCs), the workhorses responsible for maintaining blood vessel tone and flow. Under the chronic stress of hypertension, VSMCs undergo a dramatic makeover. The researchers discovered that pressure alone triggers these cells to fill with lipid droplets, morphing them into foam cells -- culprits in the formation of atherosclerotic lesions, the hallmark of arterial disease.
""This finding is pivotal because VSMCs make up over half of the foam cells found in arterial blockages,"" explains Professor Iskratsch. ""Understanding how pressure flips this switch from muscle to foam cell is crucial for developing new therapies to control or reverse the buildup of these dangerous lesions.""
The study goes deeper, identifying the molecular machinery behind pressure's impact. Using advanced imaging techniques, researchers pinpointed a ""mechanosignalling"" pathway involving Piezo1, a pressure-sensitive protein, as well as changes in lipid metabolism and gene activity. This paves the way for novel therapies targeting specific pressure-sensitive points in the cell.
This breakthrough research offers not only a deeper understanding of arterial disease but also exciting possibilities for future treatment strategies. By targeting the mechanisms that drive VSMC transformation into foam cells, researchers might be able to develop medications that prevent or even shrink atherosclerotic lesions.
""Our findings provide a vital blueprint for developing next-generation therapies that could benefit millions suffering from the life-threatening consequences of arterial disease,"" concludes Professor Iskratsch. ""This is a significant step forward in our journey towards a future where high blood pressure doesn't have to steal away life.""

","score: 15.143506493506496, grade_level: '15'","score: 17.316896103896106, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/advs.202308686,"Arterial Vascular smooth muscle cells (VSMCs) play a central role in the onset and progression of atherosclerosis. Upon exposure to pathological stimuli, they can take on alternative phenotypes that, among others, have been described as macrophage like, or foam cells. VSMC foam cells make up >50% of all arterial foam cells and have been suggested to retain an even higher proportion of the cell stored lipid droplets, further leading to apoptosis, secondary necrosis, and an inflammatory response. However, the mechanism of VSMC foam cell formation is still unclear. Here, it is identified that mechanical stimulation through hypertensive pressure alone is sufficient for the phenotypic switch. Hyperspectral stimulated Raman scattering imaging demonstrates rapid lipid droplet formation and changes to lipid metabolism and changes are confirmed in ABCA1, KLF4, LDLR, and CD68 expression, cell proliferation, and migration. Further, a mechanosignaling route is identified involving Piezo1, phospholipid, and arachidonic acid signaling, as well as epigenetic regulation, whereby CUT&Tag epigenomic analysis confirms changes in the cells (lipid) metabolism and atherosclerotic pathways. Overall, the results show for the first time that VSMC foam cell formation can be triggered by mechanical stimulation alone, suggesting modulation of mechanosignaling can be harnessed as potential therapeutic strategy."
"
Scientists at St. Jude Children's Research Hospital are tackling Mycobacterium abscessus (Mab) antibiotic resistance. This naturally antibiotic-resistant pathogen is becoming more prevalent, highlighting the urgent need for novel therapeutics. To address this, the scientists designed new versions of the drug spectinomycin that overcome efflux, the main mechanism driving resistance. The work was published today in Proceedings of the National Academy of Science.

Mab infections are increasingly found in health care settings. Such infections can be hazardous for patients with compromised lung function, such as in cystic fibrosis, or who are immunologically compromised, such as in childhood cancer. These infections are treated with long courses of antibiotics and can result in poor outcomes. The emergence of Mab and other similar pathogens presents a growing and deeply concerning public health threat because there are few effective therapeutic options and a limited drug development pipeline.
""We chemists are in a race against the pathogens. We make stronger antibiotics, and the pathogens become more resistant,"" said corresponding author Richard Lee, PhD, St. Jude Department of Chemical Biology and Therapeutics.
Scientists at St. Jude modified the naturally occurring antibiotic spectinomycin to create analogs, comparable but structurally distinct N-ethylene linked aminomethyl spectinomycins (eAmSPCs). These synthetically created eAmSPCs are up to 64 times more potent against Mab than standard spectinomycin.
""By re-engineering the molecule through structure-based drug design, we and our collaborators have adapted the antibiotic to increase its activity,"" Lee added.
Overcoming efflux to make a more effective antibiotic
Through their work, the scientists unraveled the mechanism of action by which eAmSPCs are more effective: they circumvent efflux. Efflux is the process that cells use to get rid of a drug -- imagine pumping water out of a flooded basement -- and is a significant mechanism by which cells become resistant to therapy.

The N-ethylene linkage structure of the eAmSPCs plays a critical role in how the compounds avoid efflux, suggesting that longer linkages modify how the compound is pumped out of the cell. This ultimately shifts the balance toward higher concentrations of eAmSPC within the cell and thus enhances antimicrobial efficacy.
""Over the past two decades, we've seen a massive increase in the number of infections caused by non-tuberculous mycobacteria like Mab,"" said co-first author Gregory Phelps, PharmD, St. Jude Graduate School of Biomedical Sciences. ""We had a place to start with this naturally occurring antibiotic, which, through modification, we've made much more efficacious against this clinically relevant pathogen.""
The researchers also found that eAmSPCs work well with various classes of antibiotics used to treat Mab and retain their activity against other mycobacterial strains. Collectively, this work demonstrates that eAmSPCs should be further studied and developed because once issues of tolerability and safety are addressed, these compounds could become next-generation therapeutics.
""It is challenging to attract pharmaceutical companies to develop new antibiotics for several economic reasons,"" said Phelps. ""If we can boost the drug pipeline against this hard-to-treat bacteria, we can potentially make a difference for patients like the ones we have here at St. Jude who are increasingly faced with limited or no therapeutic options.""

","score: 14.964467161812571, grade_level: '15'","score: 16.474589835600433, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2314101120,"Mycobacterium abscessus ( Mab ), a nontuberculous mycobacterial (NTM) species, is an emerging pathogen with high intrinsic drug resistance. Current standard-of-care therapy results in poor outcomes, demonstrating the urgent need to develop effective antimycobacterial regimens. Through synthetic modification of spectinomycin (SPC), we have identified a distinct structural subclass of N-ethylene linked aminomethyl SPCs (eAmSPCs) that are up to 64-fold more potent against Mab over the parent SPC. Mechanism of action and crystallography studies demonstrate that the eAmSPCs display a mode of ribosomal inhibition consistent with SPC. However, they exert their increased antimicrobial activity through enhanced accumulation, largely by circumventing efflux mechanisms. The N-ethylene linkage within this series plays a critical role in avoiding TetV-mediated efflux, as lead eAmSPC 2593 displays a mere fourfold susceptibility improvement against Mab Δ tetV, in contrast to the 64-fold increase for SPC. Even a minor shortening of the linkage by a single carbon, akin to 1st generation AmSPC 1950, results in a substantial increase in MICs and a 16-fold rise in susceptibility against Mab Δ tetV . These shifts suggest that longer linkages might modify the kinetics of drug expulsion by TetV, ultimately shifting the equilibrium towards heightened intracellular concentrations and enhanced antimicrobial efficacy. Furthermore, lead eAmSPCs were also shown to synergize with various classes of anti- Mab antibiotics and retain activity against clinical isolates and other mycobacterial strains. Encouraging pharmacokinetic profiles coupled with robust efficacy in Mab murine infection models suggest that eAmSPCs hold the potential to be developed into treatments for Mab and other NTM infections."
"
A new study published in the journal Diabetes demonstrates that a glucagon-like peptide-1 receptor (GLP-1R) agonist, a member of a class of medication used to treat Type 2 diabetes and obesity, can lead to a rapid improvement in insulin sensitivity.

Insulin sensitivity is how responsive cells are to insulin, an essential hormone that controls blood glucose levels. An increase in insulin sensitivity means insulin can more effectively lower the blood glucose. Reduced insulin sensitivity or insulin resistance is a feature of Type 2 diabetes. Thus, improved insulin sensitivity can reduce the risk of developing Type 2 diabetes or improve its treatment.
GLP-1R agonists are medications that influence metabolism, such as decreasing blood sugar levels by promoting insulin secretion. Dipeptidyl peptidase 4 (DPP-4) inhibitors block the degradation of the body's own endogenous GLP-1, as well as other peptide hormones such as glucose-dependent insulinotropic peptide (GIP).
""We know that GLP-1R agonists promote weight loss, but we were surprised to find that the GLP-1R agonist liraglutide also has rapid effects on insulin sensitivity, independent from weight loss,"" said Mona Mashayekhi MD, PhD, assistant professor of Medicine in the Division of Diabetes, Endocrinology and Metabolism. ""This effect requires activation of the GLP-1 receptor, but increasing the body's own endogenous GLP-1 through the use of the DPP4 inhibitor sitagliptin does not achieve similar effects.""
""Our research suggests that liraglutide, and presumably other GLP-1R agonists, are having important metabolic effects in a way that's different from increasing endogenous GLP-1 levels, even though they're using the same receptor. Future research will focus on potential mechanisms of how GLP-1R agonists are improving insulin sensitivity independent of weight loss.""
Eighty-eight individuals with obesity and pre-diabetes were randomized for 14 weeks to receive the GLP-1R agonist liraglutide, the dipeptidyl peptidase 4 (DPP-4) inhibitor sitagliptin, or weight loss without drug using a low-calorie diet.
To further investigate the GLP-1R-dependent effects of the treatments, the GLP-1R antagonist exendin and a placebo were given in a two-by-two crossover study during mixed meal tests. Crossover studies allow the response of a subject to treatment A to be compared with the same subject's response to treatment B.

Liraglutide was shown to rapidly improve insulin sensitivity as well as decrease blood glucose within two weeks of beginning treatment and before any weight loss.
""GLP-1R agonists are an exciting class of medications, given their strong glucose-lowering effects combined with tremendous weight-loss benefits, and they have transformed how we manage diabetes and obesity in the clinic,"" Mashayekhi said. ""Since the number of medications in this class is rapidly expanding, a deeper understanding of the mechanisms of benefit is crucial so we can design the right drugs for the desired effects in the right patients.""
The investigators' prior research demonstrated that liraglutide, but not sitagliptin or diet, improves measures of heart disease and inflammation. This matches the clinical findings of reduced cardiovascular disease with GLP-1R agonist treatment.
Future studies will continue to explore both receptor- and weight loss-dependent effects of GLP-1R agonists in humans.
This research was supported by the American Heart Association (17SFRN33520017), National Center for Advancing Translational Sciences (5UL1TR002243), and the National Institute of Diabetes and Digestive and Kidney Diseases (T32DK007061) This work utilized the cores of the Vanderbilt Diabetes Research and Training Center funded by grant DK020593 from the National Institute of Diabetes and Digestive and Kidney Disease. Novo Nordisk provided liraglutide and matching placebo.

","score: 16.886190476190475, grade_level: '17'","score: 18.251195318805486, grade_levels: ['college_graduate'], ages: [24, 100]",10.2337/db23-0356,"Metabolic effects of glucagon-like peptide 1 (GLP-1) receptor agonists are confounded by weight loss and not fully recapitulated by increasing endogenous GLP-1. We tested the hypothesis that GLP-1 receptor (GLP-1R) agonists exert weight loss–independent, GLP-1R–dependent effects that differ from effects of increasing endogenous GLP-1. Individuals with obesity and prediabetes were randomized to receive for 14 weeks the GLP-1R agonist liraglutide, a hypocaloric diet, or the dipeptidyl peptidase 4 (DPP-4) inhibitor sitagliptin. The GLP-1R antagonist exendin(9-39) and placebo were administered in a two-by-two crossover study during mixed-meal tests. Liraglutide and diet, but not sitagliptin, caused weight loss. Liraglutide improved insulin sensitivity measured by HOMA for insulin resistance (HOMA-IR), the updated HOMA model (HOMA2), and the Matsuda index after 2 weeks, prior to weight loss. Liraglutide decreased fasting and postprandial glucose levels, and decreased insulin, C-peptide, and fasting glucagon levels. In contrast, diet-induced weight loss improved insulin sensitivity by HOMA-IR and HOMA2, but not the Matsuda index, and did not decrease glucose levels. Sitagliptin increased endogenous GLP-1 and GIP values without altering insulin sensitivity or fasting glucose levels, but decreased postprandial glucose and glucagon levels. Notably, sitagliptin increased GIP without altering weight. Acute GLP-1R antagonism increased glucose levels in all groups, increased the Matsuda index and fasting glucagon level during liraglutide treatment, and increased endogenous GLP-1 values during liraglutide and sitagliptin treatments. Thus, liraglutide exerts rapid, weight loss–independent, GLP-1R–dependent effects on insulin sensitivity that are not achieved by increasing endogenous GLP-1. Metabolic benefits of glucagon-like peptide 1 (GLP-1) receptor agonists are confounded by weight loss and are not fully achieved by increasing endogenous GLP-1 through dipeptidyl peptidase 4 (DPP-4) inhibition. We investigated weight loss–independent, GLP-1 receptor (GLP-1R)–dependent metabolic effects of liraglutide versus a hypocaloric diet or the DPP-4 inhibitor sitagliptin. GLP-1R antagonism with exendin(9-39) was used to assess GLP-1R–dependent effects during mixed meals. Liraglutide improved insulin sensitivity and decreased fasting and postprandial glucose prior to weight loss, and these benefits were reversed by exendin(9-39). GLP-1R agonists exert rapid, weight loss–independent, GLP-1R–dependent effects on insulin sensitivity not achieved by increasing endogenous GLP-1."
"
Assessing how seriously injured a person is, involves weighing up lots of different parameters fast. If healthcare professionals could get support making fast-paced, life-critical decisions from an AI tool, more lives could be saved. This is shown by research from Chalmers University of Technology in Sweden, along with the University of Gothenburg and the University of Borås.

""If severely injured people are transported directly to a university hospital, the chances of survival increase, as there are resources to take care of all types of injuries. Therefore, we need to be able to better say who is severely injured, and who is not, so that everyone receives the right care and that resources are used in the best way,"" says Anna Bakidou, doctoral student in the research group Care@Distance -- Remote and Prehospital Digital Health at the Department of Electrical Engineering at Chalmers University of Technology.
In a recently published study, Anna Bakidou and her co-authors have developed five different mathematical models based on the data of adults who came into contact with ambulance care between 2013 and 2020. This data is from over 47,000 real events, retrieved from the Swedish Trauma Registry, which also showed where the people had been transported. By weighing up a number of complex variables, such as respiratory rate, injury type, blood pressure, age and gender, it turned out that all AI models could perform better than the clinical outcome -- which were the transport decisions made by the ambulance staff at the time of the incident.
Many severely injured taken to regular hospitals
It turned out that 40 percent of the severely injured patients were not sent directly to a university hospital. At the same time, 45 percent of the non-severely injured were sent to university hospitals unnecessarily, as their injuries could have been taken care of in a regular hospital.
""Ambulance personnel are constantly faced with difficult and quick decisions. Our hope is that a more objective decision support system will be able to function as an 'extra colleague' that makes staff see more complex connections and think twice in cases where injuries can be difficult to perceive or assess,"" says Anna Bakidou.
As an example, she mentions that younger people -- who are often involved in traffic accidents -- are frequently judged to be more severely injured than they are. On the other hand; older people, who are involved in events such as fall accidents, are often assessed as mildly injured -- despite the fact that their condition can suddenly become life-threatening, due to consequences such as internal bleeding.

Several steps before the technology can be put into use
Although the mathematical models show that many human lives could potentially be saved, there is still a long way to go before ambulance staff can use the technology. A crucial step is to find methods to input all of the information quickly and easily into the AI tool, and for the service to be able to interact with the users in a good way.
""For example, can you talk to the tool to be able to have both hands free? How can existing routines and protocols be used to work together with the AI, and how can the advice to staff be updated when new data is added? We need to test and take these things into account when we proceed with more studies and prototype work,"" says Anna Bakidou.
Before AI services could become part of everyday life for ambulance staff, large-scale clinical trials over time are also required.
""The regulations mean that it takes time and there is also a fear of AI. There can be serious consequences if things go wrong. Everything that is to be introduced into healthcare must be validated. At the same time, we know that some of the methods used today are not always the best. When it comes to ambulance care, there is not much research on AI, and we hope that our mathematical models will be able to contribute with support that is adapted to the work environment and that in the long run provides more equal care,"" says co-author Stefan Candefjord, Associate Professor at the Department of Electrical Engineering at Chalmers.

","score: 14.60000967283073, grade_level: '15'","score: 15.302318634423898, grade_levels: ['college_graduate'], ages: [24, 100]",10.1186/s12911-023-02290-5,"Providing optimal care for trauma, the leading cause of death for young adults, remains a challenge e.g., due to field triage limitations in assessing a patient’s condition and deciding on transport destination. Data-driven On Scene Injury Severity Prediction (OSISP) models for motor vehicle crashes have shown potential for providing real-time decision support. The objective of this study is therefore to evaluate if an Artificial Intelligence (AI) based clinical decision support system can identify severely injured trauma patients in the prehospital setting. The Swedish Trauma Registry was used to train and validate five models – Logistic Regression, Random Forest, XGBoost, Support Vector Machine and Artificial Neural Network – in a stratified 10-fold cross validation setting and hold-out analysis. The models performed binary classification of the New Injury Severity Score and were evaluated using accuracy metrics, area under the receiver operating characteristic curve (AUC) and Precision-Recall curve (AUCPR), and under- and overtriage rates. There were 75,602 registrations between 2013–2020 and 47,357 (62.6%) remained after eligibility criteria were applied. Models were based on 21 predictors, including injury location. From the clinical outcome, about 40% of patients were undertriaged and 46% were overtriaged. Models demonstrated potential for improved triaging and yielded AUC between 0.80–0.89 and AUCPR between 0.43–0.62. AI based OSISP models have potential to provide support during assessment of injury severity. The findings may be used for developing tools to complement field triage protocols, with potential to improve prehospital trauma care and thereby reduce morbidity and mortality for a large patient population."
"
How deeply someone can be hypnotized -- known as hypnotizability -- appears to be a stable trait that changes little throughout adulthood, much like personality and IQ. But now, for the first time, Stanford Medicine researchers have demonstrated a way to temporarily heighten hypnotizablity -- potentially allowing more people to access the benefits of hypnosis-based therapy.

In the new study, to be published Jan. 4 in Nature Mental Health, the researchers found that less than two minutes of electrical stimulation targeting a precise area of the brain could boost participants' hypnotizability for about one hour.
""We know hypnosis is an effective treatment for many different symptoms and disorders, in particular pain,"" said Afik Faerman, PhD, a postdoctoral scholar in psychiatry and lead author of the study. ""But we also know that not everyone benefits equally from hypnosis.""
Focused attention
Approximately two-thirds of adults are at least somewhat hypnotizable, and 15% are considered highly hypnotizable, meaning they score 9 or 10 on a standard 10-point measure of hypnotizability.
""Hypnosis is a state of highly focused attention, and higher hypnotizability improves the odds of your doing better with techniques using hypnosis,"" said David Spiegel, MD, a professor of psychiatry and behavioral sciences and a senior author of the study.
Spiegel, the Jack, Lulu, and Sam Willson Professor in Medicine, has devoted decades to studying hypnotherapy and using it to help patients control pain, lower stress, stop smoking and more. Several years ago, Spiegel led a team that used brain imaging to uncover the neurobiological basis of the practice. They found that highly hypnotizable people had stronger functional connectivity between the left dorsolateral prefrontal cortex, which is involved in information processing and decision making; and the dorsal anterior cingulate cortex, involved in detecting stimuli.

""It made sense that people who naturally coordinate activity between these two regions would be able to concentrate more intently,"" Spiegel said. ""It's because you're coordinating what you are focusing on with the system that distracts you.""
Shifting a stable trait
With these insights, Spiegel teamed up with Nolan Williams, MD, associate professor of psychiatry and behavioral sciences, who has pioneered non-invasive neurostimulation techniques to treat conditions such as depression, obsessive-compulsive disorder and suicidal ideation.
The hope was that neurostimulation could alter even a stable trait like hypnotizability.
In the new study, the researchers recruited 80 participants with fibromyalgia, a chronic pain condition that can be treated with hypnotherapy. They excluded those who were already highly hypnotizable.
Half of the participants received transcranial magnetic stimulation, in which paddles applied to the scalp deliver electrical pulses to the brain. Specifically, they received two 46-second applications that delivered 800 pulses of electricity to a precise location in the left dorsolateral prefrontal cortex. The exact locations depended on the unique structure and activity of each person's brain.

""A novel aspect of this trial is that we used the person's own brain networks, based on brain imaging, to target the right spot,"" said Williams, also a senior author of the study.
The other half of participants received a sham treatment with the same look and feel, but without electrical stimulation.
Hypnotizability was assessed by clinicians immediately before and after the treatments, with neither patients nor clinicians knowing who was in which group.
The researchers found that participants who received the neurostimulation showed a statistically significant increase in hypnotizability, scoring roughly one point higher. The sham group experienced no effect.
When the participants were assessed again one hour later, the effect had worn off and there was no longer a statistically significant difference between the two groups.
""We were pleasantly surprised that we were able to, with 92 seconds of stimulation, change a stable brain trait that people have been trying to change for 100 years,"" Williams said. ""We finally cracked the code on how to do it.""
The researchers plan to test whether different dosages of neurostimulation could enhance hypnotizability even more.
""It's unusual to be able to change hypnotizability,"" Spiegel said. A study of Stanford University students that began in the 1950s, for example, found that the trait remained relatively consistent when the students were tested 25 years later, as consistent as IQ over that time period. Recent research by Spiegel's lab also suggests that hypnotizability may have a genetic basis.
Bigger implications
Clinically, a transient bump in hypnotizability may be enough to allow more people living with chronic pain to choose hypnosis as an alternative to long-term opioid use. Spiegel will follow up with the study participants to see how they fare in hypnotherapy.
The new results could have implications beyond hypnosis. Faerman noted that neurostimulation may be able to temporarily shift other stable traits or enhance people's response to other forms of psychotherapy.
""As a clinical psychologist, my personal vision is that, in the future, patients come in, they go into a quick, non-invasive brain stimulation session, then they go in to see their psychologist,"" he said. ""Their benefit from treatment could be much higher.""
The study was supported by funding from the National Institute of Health (grant R33AT009305-03).

","score: 14.591660859465744, grade_level: '15'","score: 15.133825417201543, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s44220-023-00184-z,"Hypnotizability, one’s ability to experience cognitive, emotional, behavioral and physical changes in response to suggestions in the context of hypnosis, is a stable neurobehavioral trait associated with improved treatment outcomes from hypnosis-based therapy. Increasing hypnotizability in people who are low-to-medium hypnotizable individuals could improve both the efficacy and effectiveness of therapeutic hypnosis as a clinical intervention. Hypnotizability is associated with dorsolateral prefrontal cortex (DLPFC) functions and connectivity with the salience network, yet there is conflicting evidence as to whether unilateral inhibition of the DLPFC changes hypnotizability. We hypothesized that using personalized neuroimaging-guided targeting to non-invasively stimulate the left DLPFC with transcranial magnetic stimulation (TMS) would temporarily increase hypnotizability. In a preregistered, double-blinded, randomized controlled trial, we recruited a sample of 80 patients with fibromyalgia syndrome, a functional pain disorder for which hypnosis has been a demonstrated beneficial non-pharmacological treatment option. All participants were TMS-naive. Participants were randomly assigned to active or sham continuous theta-burst stimulation over a personalized neuroimaging-derived left-DLPFC target, a technique termed SHIFT (Stanford Hypnosis Integrated with Functional Connectivity-targeted Transcranial Stimulation). We tested our hypothesis using the hypnotic induction profile scores, a standardized measure of hypnotizability. Pre-to-post SHIFT change in the hypnotic induction profile scores was significantly greater in the active versus sham group after 92 s of stimulation (P = 0.046). Only the active SHIFT group showed a significant increase in hypnotizability following stimulation (active: P < 0.001; sham: P = 0.607). As such, modulation of trait hypnotizability is possible in humans using non-invasive neuromodulation. Our findings support a relationship between the inhibition of the left DLPFC and an increase in hypnotizability. Dose–response optimization of spaced SHIFT should be explored to understand the optimal dose–response relationship. ClinicalTrials.gov registration: NCT02969707."
"
When experiencing new things, the structure and function of our neurons and their connections are rapidly being remodeled. This process, known as synaptic plasticity, is critical for us to learn and adapt. However, these changes require a lot of energy.

Fortunately, our neurons are well-adapted to support these changes. Biological batteries known as mitochondria are strategically stabilized near sites of synaptic remodeling to ensure a local and efficient energy supply. However, how mitochondria are anchored near synapses was not known.
A team of scientists at Max Planck Florida Institute for Neuroscience has now identified a molecular anchor called VAP (vesicle-associated membrane protein-associated protein) that stabilizes mitochondria near synapses to support these remodeling projects. The identification of VAP as a molecular anchor has particular significance because a mutation in VAP leads to ALS (amyotrophic lateral sclerosis), a progressive motor neuron degeneration disease. This discovery, published in Nature Communications, not only sheds light on how memories are powered but opens up new research directions into ALS pathology.
Lead scientist of the work and Max Planck Florida Institute Research Group Leader, Dr. Vidhya Rangaraju, describes the implications, ""While we started this study to understand fundamental properties of how memories are powered, our findings open important new directions for our research. We will investigate the cellular mechanisms of the cognitive symptoms that often occur with motor symptoms in ALS but have been severely understudied. We believe the tools and approaches that we have established will begin to shine light into this area.""
Stable mitochondria support the plasticity of synapses in dendrites
Neurons have an extensive, complex morphology and are constantly being remodeled. In order to energetically support these changes, mitochondria are anchored locally near synapses. This local stabilization allows the energy produced by the mitochondria to efficiently power local structural and functional changes in synapses during memory formation.
""This stability, however, is a unique feature of neuronal dendrites,"" explains Ojasee Bapat, the study's first author. ""In neuronal axons, where mitochondria have been primarily studied, they are very mobile. We were interested in understanding how mitochondria are stabilized in dendrites and what this means for plasticity.""
The search for a molecular anchor

To address this knowledge gap, the team took an unbiased approach to identify proteins that might serve as an anchor to stabilize dendritic mitochondria. The team used a chemogenetic tool that chemically marked all proteins present near the outer shell of the mitochondria. They then took advantage of advanced proteomics to determine the identity of the marked proteins. This screen identified over 100 proteins that might be responsible for anchoring the mitochondria.
To narrow their search, they selected proteins for their ability to interact with the actin cytoskeleton. The actin cytoskeleton is a network of protein filaments localized near synapses in dendrites that help to define and remodel synaptic structure. Previous work of Dr. Rangaraju and others has shown that mitochondrial stability in dendrites depends on actin. Only a handful of the initially identified candidate proteins could bind to actin.
To determine if these proteins were essential to mitochondrial stabilization, the authors genetically removed them one by one from neurons and looked at the stability of mitochondria in dendrites. What they found was striking.
ALS-linked protein VAP stabilizes mitochondria to support plasticity
The team discovered that when they removed one particular protein, named VAP, the interaction of mitochondria with actin was reduced. Additionally, dendritic mitochondria were shorter and destabilized. Without VAP to anchor the mitochondria by tethering it to the actin cytoskeleton, the mitochondria drifted away from synapses over time.
Finally, the researchers investigated if mitochondrial instability caused by removing VAP affected synaptic plasticity, the structural and functional remodeling of synapses during memory formation. To test this question, the team induced remodeling in a cluster of synapses and compared the structural changes to neurons that lacked VAP. In neurons in which VAP was removed, the remodeling was dramatically impaired. Induced changes in the structure of synapses could not be maintained in the absence of VAP.

A link to ALS leads to new research directions
The discovery that VAP serves as a mitochondrial anchor and supports memory formation holds particular significance. A single mutation in VAP causes a familial form of ALS, a fatal progressive motor neuron degeneration disease. Although VAP is associated with this specific and rare familial cause of the disease, the discovery suggests that mitochondrial stability and energetic support of plasticity are key cellular pathways that might contribute to disease pathology.
""The fact that our unbiased screen for mitochondrial tethering to the cytoskeleton identified a protein linked to neurodegenerative disease suggests that mitochondrial stabilization is a critical element in neuronal function and health,"" described Dr. Rangaraju. ""We are motivated to expand our research focus to understand what happens in the brain when mitochondrial energy availability is disrupted. We think this focus has the potential to find common mechanisms of neurodegeneration in ALS as well as other neurological disorders.""

","score: 15.047066682395968, grade_level: '15'","score: 15.400420267201461, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44233-8,"Synapses are pivotal sites of plasticity and memory formation. Consequently, synapses are energy consumption hotspots susceptible to dysfunction when their energy supplies are perturbed. Mitochondria are stabilized near synapses via the cytoskeleton and provide the local energy required for synaptic plasticity. However, the mechanisms that tether and stabilize mitochondria to support synaptic plasticity are unknown. We identified proteins exclusively tethering mitochondria to actin near postsynaptic spines. We find that VAP, the vesicle-associated membrane protein-associated protein implicated in amyotrophic lateral sclerosis, stabilizes mitochondria via actin near the spines. To test if the VAP-dependent stable mitochondrial compartments can locally support synaptic plasticity, we used two-photon glutamate uncaging for spine plasticity induction and investigated the induced and adjacent uninduced spines. We find VAP functions as a spatial stabilizer of mitochondrial compartments for up to ~60 min and as a spatial ruler determining the ~30 μm dendritic segment supported during synaptic plasticity."
"
Stress during pregnancy is known to influence health outcomes, but a new study from Mass General Brigham researchers suggests that stress levels before pregnancy are also important to evaluate. Investigators at Massachusetts General Hospital and Brigham and Women's Hospital analyzed the link between self-reported stress immediately before conception among women seeking fertility care and blood glucose levels, a marker of heart health. The team found that maternal stress during preconception was associated with higher blood glucose levels, especially among women using intrauterine insemination to conceive and women of higher socioeconomic status. Results are published in the Journal of the Endocrine Society. 

""Stress prevalence has increased over the years, particularly for couples who are not able to conceive naturally,"" said corresponding author Lidia Mínguez-Alarcón, PhD, MPH, Bpharm, a reproductive epidemiologist in the Brigham's Channing Division of Network Medicine and co-investigator of the Environment and Reproductive Health (EARTH) study. ""We wanted to evaluate how this stress affects health during pregnancy, which can affect both the mother and child in the long term.""
Mínguez-Alarcón and colleagues analyzed data from the EARTH study conducted at the Massachusetts General Hospital Fertility Center from 2004 to 2019 for 398 women between 18 and 45 years of age. The women self-reported preconception-perceived stress at study entry. Additional clinical characteristics and sociodemographic information, including family and medical history, consumer products use and smoking history, were either collected by the study staff through medical records or questionnaires.
Women had a median age of 35 years at study entry, and most were of white ethnic background (83 percent), reported never smoking (78 percent), and were at least college educated (64 percent). Three hundred of the women conceived using medically assisted technologies like intrauterine insemination (IUI) or in vitro fertilization (IVF). During IUI, sperm is injected directly into the uterus while IVF is a multi-step technology that involves retrieving an egg for fertilization in a lab before transfer back to the uterus. Glucose testing was done at a median of 26 weeks into pregnancy and taken one hour after the women drank a 50 gram glucose solution. A blood sugar that was equal to or less than 140 mg/dL was considered normal.
Researchers found that blood sugar levels, a measure of cardiovascular health, were abnormally high in 82 of the women involved. Previous studies have shown that women with a history of gestational diabetes (GD) during pregnancy are at increased risk of developing type 2 diabetes as well as cardiovascular problems later in life, including heart artery calcification.
The team found that women who experienced higher preconception stress had higher mean glucose levels. In addition, women who conceived through IUI had both higher stress and blood sugar levels than those who conceived through IVF. The study also found that women of higher socioeconomic status had higher levels of preconception stress and blood glucose levels during their pregnancy. Median family income was used to measure socioeconomic status.
""Professional women with higher incomes and attained education levels may be employed in demanding, time-intensive jobs and are often also responsible for balancing demands in the workplace with household duties and childcare,"" Mínguez-Alarcón said. ""It has previously been shown that women with a higher education level experience greater levels of job stress. Given that education level is positively associated with salary, it is possible that this explanation applies to women with higher incomes as well.""
Still, findings are limited since the study comprises a group of mostly white women of high socioeconomic status seeking fertility care. Self-reporting perceived stress may also result in participant bias. Future research can investigate additional variables like sleep quality or neighborhood safety as well as the effect of preconception stress on the baby's health.
""Our results are of public health importance given the increasing rates of stress over the years and its effect on cardiovascular health,"" Mínguez-Alarcón said. ""Women can try to lower their stress levels through a variety of strategies like being more active, avoiding alcohol and drugs, eating healthy and avoiding isolation. Given the scarce literature in this field, our study has the potential to start important discussions.""
Authorship: The other authors of this study are Olivia Chagnon, Aya Tanaka, Paige Williams, Tamarra James Todd and Jennifer Ford of Harvard T.H. Chan School of Public Health; Irene Souter of Massachusetts General Hospital and Harvard Medical School in Boston, Mass.; Kathryn Rexrode of Brigham and Women's Hospital and Harvard Medical School; and Russ Hauser of Harvard T.H. Chan School of Public Health and Harvard Medical School.

","score: 14.7082493347631, grade_level: '15'","score: 15.810291512768579, grade_levels: ['college_graduate'], ages: [24, 100]",10.1210/jendso/bvad152,"The association between women's stress and pregnancy glucose levels remain unclear, specifically when considering the preconception period as a sensitive window of exposure. We investigated whether preconception perceived stress was associated with glucose levels during pregnancy among women attending a fertility center (2004-2019). Before conception, women completed a psychological stress survey using the short version of the validated Perceived Stress Scale 4 (PSS-4), and blood glucose was measured using a 50-gram glucose load test during late pregnancy as a part of screening for gestational diabetes. Linear and log-binomial regression models were used to assess associations of total PSS-4 scores with mean glucose levels and abnormal glucose levels ( ≥ 140 mg/dL), adjusting for age, body mass index, race, smoking, education, physical activity, primary infertility diagnosis, number of babies, and mode of conception. Psychological stress was positively associated with mean abnormal glucose levels. The adjusted marginal means (95% CI) of mean glucose levels for women in the first, second, and third tertiles of psychological stress were 115 (110, 119), 119 (115, 123), and 124 (119, 128), and mg/dL, respectively (P for trend = .007). Also, women in the second and third tertiles of psychological stress had 4% and 13% higher probabilities of having abnormal glucose compared with women in the first tertile of psychological stress (P trend = .01). These results highlight the importance of considering preconception when evaluating the relationship between women's stress and pregnancy glucose levels."
"
A team of researchers from UC San Francisco has found that Paxlovid (Nirmatrelvir-ritonavir) did not reduce the risk of developing long COVID for vaccinated, non-hospitalized individuals during their first COVID-19 infection. They also found a higher proportion of individuals with acute symptoms rebound and test-positivity than previously reported.

The study appears Jan. 4, 2024, in the Journal of Medical Virology.
Paxlovid treatment for acute COVID-19 has been shown to be effective for high-risk unvaccinated individuals. But the effect of the treatment on long COVID risk, including whether it protects vaccinated people from getting long COVID, has been less clear.
The research team selected a group of vaccinated people from the UCSF Covid-19 Citizen Science study who had reported their first positive test for COVID-19 between March and August of 2022 and who were not hospitalized. Some of these participants reported taking oral Paxlovid treatment during the acute phase of their COVID infection, while others did not. In December of 2022, they were invited to answer a follow-up survey with questions about long COVID, COVID rebound symptoms and how long they continued to test positive.
Researchers found the two groups were similar. About 16% of those treated with Paxlovid had long COVID symptoms compared to 14% of those who were not treated with the medication. Commonly reported symptoms included fatigue, shortness of breath, confusion, headache, and altered taste and smell. Those who took Paxlovid and then went on to develop long COVID reported as many long COVID symptoms as those who were not treated with Paxlovid. A small percentage of people developed severe long COVID, and those who had received Paxlovid were just as likely to have severe Long COVID symptoms as those who did not.
Among individuals who experienced symptomatic improvement during Paxlovid treatment, 21% reported rebound symptoms. And among those with rebound symptoms, 10.8% reported one or more Long COVID symptom compared to 8.3% without rebound symptoms. For participants who repeated antigen testing after testing negative and completing treatment, 25.7% reported rebound test positivity. In total, 26.1% reported rebound symptoms or test positivity.
""We found a higher proportion with clinical rebound than previously reported but did not identify an effect of post-treatment rebound on long COVID symptoms,"" said study first author Matthew Durstenfeld, MD, MAS, a cardiologist and UCSF assistant professor of Medicine. ""Our finding that Paxlovid treatment during acute infection is not associated with lower odds of long COVID surprised us, but it is consistent with two other rigorously conducted studies finding no difference in post-COVID conditions between 4 and 6 months after infection.""
The authors note that the study may have been impacted by limitations arising from its observational nature with researchers relying on patient self-reporting of treatment and Long COVID symptoms.
Authors: Other UCSF authors include Michael J. Peluso, Feng Lin, Noah D. Peyser, Carmen Isasi, Thomas W. Carton, Timothy J. Henrich, Steven G. Deeks, Jeffrey E. Olgin, Mark J. Pletcher, Alexis L. Beatty, Gregory M. Marcus, Priscilla Y. Hsue
Funding: This work (Eureka Research Platform) was supported by NIH/NIBIB 3U2CEB021881-05S1. The COVID-19 Citizen Science Study is supported by Patient-Centered Outcomes Research Institute (PCORI) contract COVID-2020C2-10761 and Bill and Melinda Gates Foundation contract INV-017206. Dr. Durstenfeld is supported by NIH/NHLBI grant K12HL143961.

","score: 14.222371182829637, grade_level: '14'","score: 15.782235461216764, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/jmv.29333,"Oral nirmatrelvir/ritonavir is approved as treatment for acute COVID‐19, but the effect of treatment during acute infection on risk of Long COVID is unknown. We hypothesized that nirmatrelvir treatment during acute SARS‐CoV‐2 infection reduces risk of developing Long COVID and rebound after treatment is associated with Long COVID. We conducted an observational cohort study within the Covid Citizen Science (CCS) study, an online cohort study with over 100 000 participants. We included vaccinated, nonhospitalized, nonpregnant individuals who reported their first SARS‐CoV‐2 positive test March–August 2022. Oral nirmatrelvir/ritonavir treatment was ascertained during acute SARS‐CoV‐2 infection. Patient‐reported Long COVID symptoms, symptom rebound and test‐positivity rebound were asked on subsequent surveys at least 3 months after SARS‐CoV‐2 infection. A total of 4684 individuals met the eligibility criteria, of whom 988 (21.1%) were treated and 3696 (78.9%) were untreated; 353/988 (35.7%) treated and 1258/3696 (34.0%) untreated responded to the Long COVID survey (n = 1611). Among 1611 participants, median age was 55 years and 66% were female. At 5.4 ± 1.3 months after infection, nirmatrelvir treatment was not associated with subsequent Long COVID symptoms (odds ratio [OR]: 1.15; 95% confidence interval [CI]: 0.80–1.64; p = 0.45). Among 666 treated who answered rebound questions, rebound symptoms or test positivity were not associated with Long COVID symptoms (OR: 1.34; 95% CI: 0.74–2.41; p = 0.33). Within this cohort of vaccinated, nonhospitalized individuals, oral nirmatrelvir treatment during acute SARS‐CoV‐2 infection and rebound after nirmatrelvir treatment were not associated with Long COVID symptoms more than 90 days after infection."
"
New research indicates that the eating disorder anorexia nervosa is associated with being an early riser, unlike many other disorders that tend to be evening-based such as depression, binge eating disorder and schizophrenia.

The study, which is published in JAMA Network Open and led by investigators at Massachusetts General Hospital (MGH), in collaboration with University College London and the University of the Republic in Uruguay, also revealed a link between anorexia nervosa and insomnia risk.
Previous research has suggested a possible connection between eating disorders and the body's internal clock, or circadian clock, which controls a wide range of biological functions such as sleep and affects nearly every organ in the body.
This study aimed to further understand this relationship by assessing genes associated with anorexia nervosa, the circadian clock and several sleep traits including insomnia.
The investigators used a statistical method called Mendelian Randomization to see how genes that are associated with a certain trait affect other traits of interest. For example, examining the sleep patterns of people with genetic differences that makes them more likely to have anorexia nervosa, this provides evidence on the relationship between anorexia nervosa and sleep.
They found a two-way association between genes associated with anorexia nervosa and genes associated with morning chronotype (waking early and going to bed early).
In other words, the findings suggest that being an early riser could increase the risk for having anorexia nervosa, and having anorexia nervosa could lead to an earlier wake time. The team also found an association between anorexia nervosa and insomnia.

When they further assessed the insomnia connection using the Mass General Brigham Biobank by developing a ""genetic risk score"" for anorexia nervosa, the scientists found that the genetic risk score was indeed associated with higher insomnia risk.
""Our findings implicate anorexia nervosa as a morning disorder in contrast to most other evening-based psychiatric diseases and support the association between anorexia nervosa and insomnia as seen in earlier studies,"" says senior author Hassan S Dashti, PhD, RD, an assistant investigator in the Department of Anesthesia, Critical Care and Pain Medicine at MGH and an assistant professor of anesthesia at Harvard Medical School.
Treatments for anorexia nervosa are limited and current treatments have relapse rates of up to 52%. In addition, the cause of the disease is still unclear.
With anorexia nervosa having the second highest mortality rate of psychiatric diseases, more research is desperately needed into new prevention strategies and treatments.
""The clinical implications of our new findings are currently unclear; however, our results could direct future investigations into circadian-based therapies for anorexia nervosa prevention and treatment,"" says Hannah Wilcox, lead author of the study and researcher at MGH.
Additional authors include Valentina Paz, MSc, Richa Saxena, PhD, John W. Winkelman, MD, PhD, and Victoria Garfield, PhD.
This research was supported by the National Institutes of Health.

","score: 17.756307257767407, grade_level: '18'","score: 18.69598059683164, grade_levels: ['college_graduate'], ages: [24, 100]",10.1001/jamanetworkopen.2023.50358,"Observational studies have associated anorexia nervosa with circadian rhythms and sleep traits. However, the direction of causality and the extent of confounding by psychosocial comorbidities in these associations are unknown. To investigate the association between anorexia nervosa and circadian and sleep traits through mendelian randomization and to test the associations between a polygenic risk score (PRS) for anorexia nervosa and sleep disorders in a clinical biobank. This genetic association study used bidirectional 2-sample mendelian randomization with summary-level genetic associations between anorexia nervosa (from the Psychiatric Genomics Consortium) and chronotype and sleep traits (primarily from the UK Biobank). The inverse-variance weighted method, in addition to other sensitivity approaches, was used. From the clinical Mass General Brigham (MGB) Biobank (n = 47 082), a PRS for anorexia nervosa was calculated for each patient and associations were tested with prevalent sleep disorders derived from electronic health records. Patients were of European ancestry. All analyses were performed between February and August 2023. Genetic instruments for anorexia nervosa, chronotype, daytime napping, daytime sleepiness, insomnia, and sleep duration. Chronotype, sleep traits, risk of anorexia nervosa, and sleep disorders derived from a clinical biobank. The anorexia nervosa genome-wide association study included 16 992 cases (87.7%-97.4% female) and 55 525 controls (49.6%-63.4% female). Genetic liability for anorexia nervosa was associated with a more morning chronotype (β = 0.039; 95% CI, 0.006-0.072), and conversely, genetic liability for morning chronotype was associated with increased risk of anorexia nervosa (β = 0.178; 95% CI, 0.042-0.315). Associations were robust in sensitivity and secondary analyses. Genetic liability for insomnia was associated with increased risk of anorexia nervosa (β = 0.369; 95% CI, 0.073-0.666); however, sensitivity analyses indicated bias due to horizontal pleiotropy. The MGB Biobank analysis included 47 082 participants with a mean (SD) age of 60.4 (17.0) years and 25 318 (53.8%) were female. A PRS for anorexia nervosa was associated with organic or persistent insomnia in the MGB Biobank (odds ratio, 1.10; 95% CI, 1.03-1.17). No associations were evident for anorexia nervosa with other sleep traits. The results of this study suggest that in contrast to other metabo-psychiatric diseases, anorexia nervosa is a morningness eating disorder and further corroborate findings implicating insomnia in anorexia nervosa. Future studies in diverse populations and with subtypes of anorexia nervosa are warranted."
"
Medical technology innovations achieved by integrating science and medicine have improved the quality of life for patients. Especially noteworthy is the emergence of electronic devices implanted in the body, such as in the heart or brain, which enable real-time measurement and regulation of physiological signals, presenting new solutions for challenging conditions like Parkinson's disease. However, technical constraints have hindered the semi-permanent use of electronic devices after their implantation.

A collaborative research team led by Professor Sung-Min Park from the Departments of Convergence IT Engineering, Mechanical Engineering, and Electrical Engineering, and the School of Interdisciplinary Bioscience and Bioengineering at POSTECH, alongside Jiho Lee, enrolled in the MS/Ph.D. program, and Professor Sang-Woo Kim from Yonsei University's Department of Materials Science and Engineering, together with Dr. Young-Jun Kim and MS/Ph.D. student Joon-Ha Hwang from Sungkyunkwan University, has achieved a groundbreaking development. They've created electrostatic materials that function even with extremely weak ultrasound, heralding the era of permanent implantable electronic devices in biomedicine. This research has been published in the international academic journal Advanced Materials.
Patients with implanted devices need to undergo periodic surgeries for battery replacement. This process carries a significant risk of complications and imposes both economic and physical burdens on patients. Recent research explores implantable medical devices that operate wirelessly, yet finding a safe energy source and protective materials remains challenging. Presently, titanium (Ti) is used due to its biocompatibility and durability. However, radio waves cannot pass through this metal, necessitating a separate antenna for wireless power transmission. Consequently, this enlarges the device size, creating more discomfort for patients.
The research team addresses this issue by opting for ultrasound, a safety-validated method in various medical fields for diagnoses and treatments, instead of radio waves. They developed an electrostatic material capable of responding to weak ultrasound by utilizing a composite of high dielectric polymers (P(VDF-TrFE)) and a high dielectric constant ceramic material known as calcium copper titanate (CCTO, CaCu3Ti4O12). This material generates static electricity through friction between its material layers, producing effective electrical energy, and possesses an extremely low output impedence, facilitating efficient transmission of the generated electricity.
Using this technology, the research team created an implantable neurological stimulator powered by ultrasound-based energy transmission, eliminating the need for batteries. This was confirmed through experimental validation. In animal model trials, the device was activated even at standard imaging ultrasound levels (500 mW/cm2), imposing minimal strain on the human body. Furthermore, it effectively mitigated symptoms related to abnormal urination caused by overactive bladder disorders through nerve stimulation.
Professor Sung-Min Park stated: ""We have addressed the challenges in the field of implantable medical devices using ultrasound-based energy transmission technology that is harmless to the human body. This research serves as a case of introducing advanced material technology into medical devices, and we anticipate that it will promote the emergence of a next-generation medical industry, including the treatment of intractable diseases using implantable devices.""
Professor Sang-Woo Kim remarked: ""Devices manufactured based on highly biocompatible materials exhibit excellent mechanical and chemical stability, making them suitable for treating various diseases requiring long-term therapy. Non-battery, miniaturized components with established long-term stability are expected to bring forth new innovations in the market of human-insertable medical devices.""
The research was conducted with support from the Research Leader Program, Pioneer Program of Future Technology, and Bio & Medical Technology Development Program by the National Research Foundation of Korea and the Ministry of Science and ICT, along with Yonsei Fellowship.

","score: 18.181378482868954, grade_level: '18'","score: 19.23221970403946, grade_levels: ['college_graduate'], ages: [24, 100]",10.1002/adma.202307194,"In implantable bioelectronics, which aim for semipermanent use of devices, biosafe energy sources and packaging materials to protect devices are essential elements. However, research so far has been conducted in a direction where they cannot coexist. Here, the development of capacitance‐matched triboelectric implants driven is reported by ultrasound under 500 mW cm−2 safe intensity and realize a battery‐free, miniatured, and wireless neurostimulator with full titanium (Ti) packaging. The triboelectric implant with high dielectric composite, which has ultralow output impedance, can efficiently deliver sufficient power to generate the stimulation pulse without an energy‐storing battery, despite ultrasound attenuation due to the Ti, and has the highest energy transmission efficiency among those reported so far. In vivo study using a rat model demonstrated that the proposed device system is an effective solution for relieving urinary symptoms. These achievements provide a significant step toward permanently implantable devices for controlling human organs and treating various diseases."
"
We have two copies of each chromosome in every cell in our bodies except in our reproductive cells. Sperm and egg cells contain a single copy of each chromosome with a unique mix of genes from our parents, an evolutionary trick to give our offspring genetic variability. The sperm and egg are made during meiosis, the process by which cells with two chromosome copies reduce their chromosome numbers to one. For meiosis to work, the two chromosomes must align perfectly and exchange the correct amount of genetic information. Any deviation puts fertility at risk.

Enter the synaptonemal complex (SC), a zipper-like protein structure that lines up and anchors the two parental chromosomes together, end-to-end, to facilitate successful genetic exchanges. Failure to regulate this exchange is a leading cause of age-related infertility in humans and could compromise fertility across the tree of life. Humans, fungi, plants, worms and anything that reproduces sexually uses the SC to make reproductive cells, known as gametes. Despite its importance, we don't understand how proteins within the SC regulate chromosomal interactions because this multi-step process happens in internal organs and has been impossible to recreate in a lab.
In a new study, University of Utah biologists developed a method for illuminating the intricate interactions of the SC in the nematode C. elegans. The authors identified a trio of protein segments that guide chromosomal interactions, and pinpointed the location where they interact with each other. Their novel method uses a technique known as genetic suppressor screening, which can serve as a blueprint for research on large cellular assemblies that resist traditional structural analysis.
""This is a way to lock in on systems in cells that are too 'loosie-goosey' to use methods that rely on crystallization,"" said Ofer Rog, associate professor of biology at the U and senior author of the study. ""A lot of the interactions in cells are loosely bonded together. The problem is that you can't look at it under an electron microscope because nothing is stable enough -- everything is constantly moving. Our approach allows you to study even the interactions that are relatively weak or transient.""
The study published on Dec. 6, 2023, in the journal Proceedings of the National Academy of Sciences (PNAS).
The birds and the bees… and the nematodes
Let's dig into meiosis. Chromosomes are thread-like structures made of DNA that carry genetic information when cells divide and from generation to generation. Regular cells have a certain number of chromosomes; humans have 46 and C. elegans have 12. Chromosomes come in pairs called homologous chromosomes that carry the genes we inherited from each of our parents -- one from our mom, one from our dad. When meiosis begins, homologous chromosomes arrange themselves into elongated structures organized along a backbone called the axis. The axes of homologous pairs are aligned lengthwise to each other while at the same time, the synaptonemal complex (SC) forms between the parallel axes. The homologous pairs have matching genes arranged in the same order, with small variations within the genes -- these are the variations that make each individual unique.

""You can think of it like a zipper,"" Rog explained. ""The axes of the chromosomes are like the two sides of your shirt. The synaptonemal complex is kind of like the teeth of the zippers that lock onto each other and can pull and align the two sides of the shirt correctly.""
Scientist previously knew that the SC of C. elegans formed between homologs, but the U biologists are the first to pinpoint the exact position where the SC interacts with itself to facilitate genetic exchanges.
""When you exchange information between the chromosomes, you want to make sure that at the end you still have two complete chromosomes,"" said Rog. ""The way the cell does it is that the two chromosomes are perfectly aligned. So, when you exchange segments between them, you're not losing any information in the process.
How to analyze loosie-goosey structures
The researchers bred 50,000 nematodes that had temperature-sensitive defects in the SC. At high temperatures, the worms were unable to form the SC protein zipper needed to join the chromosomes together. Without the zipper, the gene exchanges during meiosis either didn't happen at all or didn't occur at the right number. Lisa Kursel, postdoctoral researcher and lead author of the study ran the experiments.
""We grew the worms at the permissive, cooler temperature, then exposed them to a chemical that caused millions of mutations along their chromosomes and watched to see if any of the mutated worms could reproduce at the warmer temperature,"" Kursel said. The chemically induced mutations that corrected the nematode's infertility are known as suppressor mutations. ""Then we'd know if the suppressor mutations restored their fertility.""
To identify the animals with mutations that made them fertile again, the researchers put the nematodes on agar plates filled with yummy bacteria. The agar plates that had fertile nematodes were soon empty as their progeny ate the food. The agar plates with sterile worms died off before they could clean their plate, allowing the bacteria to flourish.

Once they had fertile nematodes, they could test if the mutation ""fixed"" the protein zipper. They then screened every single base pair on the DNA -- 100 million base pairs -- and identified which mutations restored the worms' ability to reproduce. They found that all the helpful mutations occurred in short segments of three proteins, SYP-1, SYP-3, SYP-4. Moreover, the mutations carried distinct signatures of interaction. For example, while the original mutations changed the electric charge from positive to negative, the helpful mutations flipped the charge back.
""This was a strong indication that SYP-1, SYP-3 and SYP-4 interact with each other like magnets, with positive and negative regions attracted to each other,"" said Rog. Such ""sticky"" interactions could also help tether the chromosomes together.
Jesus Aguayo Martinez, a senior biology major and co-author of the study, looked at the behavior of the suppressor mutation in nematodes without the original SC-disrupting mutation.
""We thought that since the original mutation alone produced a fertility defect, then the nematodes with the suppressor mutation alone would also have a fertility defect. That wasn't the case,"" said Aguayo Martinez. ""Surprisingly, normal worms and worms with only the suppressor mutations produced similar numbers of progeny.""
Next steps
Uncovering the SC's role in meiosis may help to better understand fertility in humans. The SC has a similar role across all eukaryotes, from nematodes to fungi to plants to humans. Previous research by the Rog Lab at the U showed that the structure itself looks the same and acts similarly to bring in parental chromosomes to facilitate exchanges. However, the actual sequences of the protein components are different between organisms. Such a pattern is unusual: Most cellular structures that carry essential, basic functions like cell division, genome duplication or metabolism are highly conserved, and could in fact be swapped between different organisms.
""A question that we think a lot about is what is special about the SC? Why can it do the same thing and look the same way, but consist of different building blocks?"" Rog asked.
Kursel, Aguayo Martinez, Rog and other members of the lab are doing more analysis on the evolution of the SC across species, and of other cellular structures that defy the common wisdom of evolution.
This work was funded by the National Institute for General Medical Sciences grant R35GM128804. Kursel was supported by the Developmental Biology Training Grant from the U.S. National Institute of Child Health and Human Development, and Aguayo Martinez was supported by a University of Utah Biology Research Scholar Award.

","score: 12.266479076479076, grade_level: '12'","score: 12.639306870154329, grade_levels: ['college'], ages: [18, 24]",10.1073/pnas.2314335120,"Successful chromosome segregation into gametes depends on tightly regulated interactions between the parental chromosomes. During meiosis, chromosomes are aligned end-to-end by an interface called the synaptonemal complex, which also regulates exchanges between them. However, despite the functional and ultrastructural conservation of this essential interface, how protein–protein interactions within the synaptonemal complex regulate chromosomal interactions remains poorly understood. Here, we describe a genetic interaction in the C. elegans synaptonemal complex, comprised of short segments of three proteins, SYP-1, SYP-3, and SYP-4. We identified the interaction through a saturated suppressor screen of a mutant that destabilizes the synaptonemal complex. The specificity and tight distribution of suppressors suggest a charge-based interface that promotes interactions between synaptonemal complex subunits and, in turn, allows intimate interactions between chromosomes. Our work highlights the power of genetic studies to illuminate the mechanisms that underlie meiotic chromosome interactions."
"
Pregnancy weight and biochemical markers measured in blood from women with gestational diabetes mellitus (GDM) were related to increased risk of poor pregnancy outcomes, suggesting a new direction for precision diagnostics, according to researchers.

The study led by Ellen C. Francis, an assistant professor in the Department of Biostatistics and Epidemiology at Rutgers School of Public Health, and published in Communications Medicine, evaluated the diagnostic value of these markers before or at the time of screening for GDM, a type of diabetes that can develop during pregnancy.
""Although we found that obesity is a risk factor for offspring born larger for their gestational age, evidence suggests that the metabolic alterations that accompany obesity increase the risk of adverse outcomes,"" said Francis. GDM, characterized by elevated blood sugar (glucose) levels during pregnancy, is the most common metabolic condition among pregnant women and poses risks to both mother and child. While standard treatments are applied, clinical outcomes can differ among individuals.
Francis said the research demonstrates the need for a more nuanced approach to diagnose GDM, which may help improve outcomes. It is the first systematic review of the literature to assess the potential of subtypes in GDM and to examine whether nonglycemic markers could refine risk stratification. Francis said some of the literature suggested insulin profiles and triglyceride levels may serve as promising non-glucose indicators of risk.
""To really assess the clinical implications of precision diagnostics in GDM, we first need to understand if insulin resistance or higher triglycerides are causally linked to adverse outcomes, and whether we can safely target them in pregnancy,"" Francis said.
Overall, researchers found a critical gap in the existing literature in which most studies hadn't focused on comparing clinical, biochemical or sociocultural differences among women who develop GDM.
""In our full text screening of 775 studies, we found that only recently has there been a focus on clinical, biochemical, or sociocultural markers that could improve who is at greatest risk of poor outcomes, and on comparing clinical outcomes between different subtypes of GDM,"" said Francis. ""The data from these studies indicate that in the future, we may be able to refine how we diagnose GDM by using anthropometric or biochemical information in combination with current diagnostic approaches.""
Future research should delve into mechanistic studies on precision biomarkers, large diverse population studies for replication, and multinational studies focusing on environmental and behavioral factors, Francis said. It should also explore potential insights on casual pathways of heterogeneity within GDM and its outcomes from genetic and multi-omics data using advanced analytical approaches.
Study co-authors include researchers from collaborating institutions in the United States, the United Kingdom, Singapore, South Korea and Australia.

","score: 18.048637102734663, grade_level: '18'","score: 20.014841093865485, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s43856-023-00393-8,"Perinatal outcomes vary for women with gestational diabetes mellitus (GDM). The precise factors beyond glycemic status that may refine GDM diagnosis remain unclear. We conducted a systematic review and meta-analysis of potential precision markers for GDM. Systematic literature searches were performed in PubMed and EMBASE from inception to March 2022 for studies comparing perinatal outcomes among women with GDM. We searched for precision markers in the following categories: maternal anthropometrics, clinical/sociocultural factors, non-glycemic biochemical markers, genetics/genomics or other -omics, and fetal biometry. We conducted post-hoc meta-analyses of a subset of studies with data on the association of maternal body mass index (BMI, kg/m2) with offspring macrosomia or large-for-gestational age (LGA). A total of 5905 titles/abstracts were screened, 775 full-texts reviewed, and 137 studies synthesized. Maternal anthropometrics were the most frequent risk marker. Meta-analysis demonstrated that women with GDM and overweight/obesity vs. GDM with normal range BMI are at higher risk of offspring macrosomia (13 studies [n = 28,763]; odds ratio [OR] 2.65; 95% Confidence Interval [CI] 1.91, 3.68), and LGA (10 studies [n = 20,070]; OR 2.23; 95% CI 2.00, 2.49). Lipids and insulin resistance/secretion indices were the most studied non-glycemic biochemical markers, with increased triglycerides and insulin resistance generally associated with greater risk of offspring macrosomia or LGA. Studies evaluating other markers had inconsistent findings as to whether they could be used as precision markers. Maternal overweight/obesity is associated with greater risk of offspring macrosomia or LGA in women with GDM. Pregnancy insulin resistance or hypertriglyceridemia may be useful in GDM risk stratification. Future studies examining non-glycemic biochemical, genetic, other -omic, or sociocultural precision markers among women with GDM are warranted."
"
The blood-brain barrier blocks the entry of antibodies into the brain. This limits the potential use of antibody therapeutics to treat brain diseases, such as brain tumors.

Elsewhere in the body, more than 100 United States Food and Drug Administration-approved therapeutic antibodies are used by medical teams to treat cancers and autoimmune, infectious and metabolic diseases. Finding ways to transport therapeutic antibodies across the blood-brain barrier -- from the peripheral blood stream into the central nervous system -- could create effective treatments that act in the brain.
In a study published in the journal Frontiers in Cell and Developmental Biology, researchers at the University of Alabama at Birmingham report that the site-directed addition of an FDA-approved, biodegradable polymer at the hinge and near hinge regions of the therapeutic antibody trastuzumab effectively facilitated the brain delivery of this human monoclonal IgG1 antibody. Trastuzumab is used to treat breast cancer and several other cancers.
Preliminary work on this novel platform included in vitro and mouse-model experiments. Researchers say the delivery system still needs to be optimized and tested further, yet note their simple methodology converts antibody therapeutics to a brain-deliverable form that maintains the antibody's medical functionality.
""The concerns of brain-entry haunt the development of brain-disease-targeting antibody therapeutics, impeding the medical translations of laboratory-generated antibodies to clinical practices,"" said Masakazu Kamata, Ph.D., leader of the study and an associate professor in the UAB Department of Microbiology. ""In this context, this simple methodology has great potential to serve as the platform to not only repurpose the current antibody therapeutics, but also encourage the design of novel antibodies, for the treatment of brain diseases.""
The biocompatible polymer used was poly 2-methacryloyloxyethyl phosphorylcholine, or PMPC, with chain lengths of 50, 100 or 200 monomers. The researchers had already discovered that this non-immunogenic polymer, which the FDA has approved as a coating material for transplantable devices, could bind to two receptors on brain microvascular endothelial cells composing the blood-brain barrier, and those cells could then move the polymer across the blood-brain barrier by transcytosis. Transcytosis is a specialized transport whereby extracellular cargo is brought inside the cell, shuttled across the cytoplasm to the other side of the cell, and then released.
The UAB researchers were able to cleave four interchain disulfide bonds in the trastuzumab IgG1 hinge and near hinge regions, creating thiol groups. Each thiol group was then conjugated to a chain of the PMPC to create trastuzumab molecules with one of the three chain lengths, which they denoted as Tmab-PMPC50, Tmab-PMPC100 and Tmab-PMPC200.

Each of these modified antibodies still maintained trastuzumab-specific binding to cells expressing the HER2 antigen, the target of trastuzumab. Both the Tmab-PMPC50 and the Tmab-PMPC100 were internalized into HER2-positive cells and promoted antibody-dependent cell death, which is the medical functionality by which trastuzumab kills HER2+ breast cancer cells.
The researchers then showed that PMPC conjugation of trastuzumab enhanced blood-brain barrier penetration through the epithelial cells on the blood-brain barrier via the transcytosis pathway. The translocatable Tmab-PMPC100 was the best at efficient blood-brain barrier penetration while retaining trastuzumab's epitope recognition, the ability of the antibody to bind to its antigen target.
In a mouse model, both Tmab-PMPC100 and Tmab-PMPC200 were about fivefold better at brain penetration than native trastuzumab. In preliminary in vitro and mouse-model experiments, the polymer-modified trastuzumab did not induce neurotoxicity, did not show adverse effects in the liver, and did not disrupt the integrity of the blood-brain barrier.
""Those findings collectively indicate that PMPC conjugation achieves effective brain delivery of therapeutic antibodies, such as trastuzumab, without induction of adverse effects, at least in the liver, the blood-brain barrier or the brain,"" Kamata said.
Others have also investigated ways to get cargos like antibodies across the blood-brain barrier, the researchers noted.
In work that led to the current study, the UAB researchers for the current study had shown they could wrap various macromolecular cargos within PMPC shells, and these nanocapsules demonstrated prolonged blood circulation, reduced immunogenicity and enhanced brain delivery in mice and non-human primates.

Yet this system had drawbacks. The nanocapsules required the addition of targeting ligands to bring them to their disease target and degradable crosslinkers that would allow release of the cargo at that site. Unfortunately, disease-associated microenvironments often lack conditions that can trigger degradation of the crosslinkers.
Other researchers seeking to breech the blood-brain barrier have investigated various ligands other than PMPC to boost transport, such as ligands derived from microbes and toxins, or endogenous proteins like lipoproteins. These generally have had undesirable surface properties -- such as being highly immunogenic, highly hydrophobic or charged. PMPC does not exhibit those undesirable traits.
Co-authors with Kamata in the study, ""Site-oriented conjugation of poly(2-methacryloyloxyethyl phosphorylcholine) for enhanced brain delivery of antibody,"" are Jie Ren, Chloe E. Jepson, Charles J. Kuhlmann, Stella Uloma Azolibe and Madison T. Blucas, UAB Department of Microbiology; Sarah L. Nealy and Eugenia Kharlampieva, UAB Department of Chemistry; Satoru Osuka, UAB Department of Neurosurgery; and Yoshiko Nagaoka-Kamata, UAB Department of Pathology.
Support came from National Institutes of Health grants CA232015 and MH130183, an O'Neal Comprehensive Cancer Center at UAB Pre-R01 award, and National Science Foundation grant DMR-2208831.
At UAB, Microbiology, Neurosurgery and Pathology are departments in the Marnix E. Heersink School of Medicine, and Chemistry is a department in the College of Arts and Sciences.

","score: 17.635221753963474, grade_level: '18'","score: 19.517537627934978, grade_levels: ['college_graduate'], ages: [24, 100]",10.3389/fcell.2023.1214118,"Antibody therapeutics are limited in treating brain diseases due to poor blood-brain barrier (BBB) penetration. We have discovered that poly 2-methacryloyloxyethyl phosphorylcholine (PMPC), a biocompatible polymer, effectively facilitates BBB penetration via receptor-mediated transcytosis and have developed a PMPC-shell-based platform for brain delivery of therapeutic antibodies, termed nanocapsule. Yet, the platform results in functional loss of antibodies due to epitope masking by the PMPC polymer network, which necessitates the incorporation of a targeting moiety and degradable crosslinker to enable on-site antibody release. In this study, we developed a novel platform based on site-oriented conjugation of PMPC to the antibody, allowing it to maintain key functionalities of the original antibody. With an optimized PMPC chain length, the PMPC-antibody conjugate exhibited enhanced brain delivery while retaining epitope recognition, cellular internalization, and antibody-dependent cellular phagocytic activity. This simple formula incorporates only the antibody and PMPC without requiring additional components, thereby addressing the issues of the nanocapsule platform and paving the way for PMPC-based brain delivery strategies for antibodies."
"
Researchers have created a new brain imaging method that allows mild traumatic brain injuries (mTBIs) to be diagnosed, even when existing imaging techniques like magnetic resonance imaging (MRI) don't show any structural abnormalities. The technique involves loading gadolinium, a standard MRI contrast agent, into hydrogel-based micropatches that are attached to immune cells called macrophages. mTBIs cause inflammation in the brain, which produces signals that attract macrophages to migrate there. Coupling the gadolinium contrast agent to these cells enables MRI to reveal brain inflammation and increase the number of correctly diagnosed mTBI cases, improving patient care. The method is described in a new paper in Science Translational Medicine.

""70-90% of reported TBI cases are categorized as 'mild,' yet as many as 90% of mTBI cases go undiagnosed, even though their effects can last for years and they are known to increase the risk of a host of neurological disorders including depression, dementia, and Parkinson's disease,"" said senior author Samir Mitragotri, Ph.D., in whose lab the research was performed. ""Our cell-based imaging approach exploits immune cells' innate ability to travel into the brain in response to inflammation, enabling us to identify mTBIs that standard MRI imaging would miss.""
Mitragotri is a Core Faculty member of the Wyss Institute at Harvard University and the Hiller Professor of Bioengineering and Hansjörg Wyss Professor of Biologically Inspired Engineering at Harvard's John A. Paulson School of Engineering and Applied Sciences (SEAS).
Using immune cells to identify inflammation
Most of us know someone who has had a concussion (another name for an mTBI), sometimes even more than one. But the vast majority of people who experience an mTBI are never properly diagnosed. Without that diagnosis, they can exacerbate their injuries by returning to normal activity before they're fully recovered, which can lead to further damage. Some studies even suggest that repeated mTBIs can lead to chronic traumatic encephalopathy (CTE), the neurodegenerative disease that has been found to afflict more than 90% of professional American football players.
Because the effects of mTBI are believed to be caused by ""invisible"" brain inflammation, members of the Mitragotri lab decided to leverage their experience with immune cells to create a better diagnostic. ""Our previous projects have focused on controlling the behavior of immune cells or using them to deliver drugs to a specific tissue. We wanted to exploit another innate ability of immune cells -- homing to sites of inflammation in the body -- to carry imaging agents into the brain, where they can provide a visible detection signal for mTBI,"" said first author Lily Li-Wen Wang, Ph.D.. Wang is a former Research Fellow in the Mitragotri Lab at the Wyss Institute and SEAS who is now a scientist at Landmark Bio.
The team planned to use their cellular backpack technology to attach gadolinium molecules to macrophages, a type of white blood cell that is known to infiltrate the brain in response to inflammation. But right away, they ran into a problem: in order to function as a contrast agent for MRI scans, gadolinium needs to interact with water. Their original backpack microparticles are compost of a polymer called PLGA, which is hydrophobic (meaning it repels water). So Wang and her co-authors started developing a new backpack made out of a hydrogel material that could be manufactured at a large scale in the lab.

After years of hard work, they finally created a new hydrogel backpack that could produce a strong gadolinium-mediated MRI signal, attach stably to both mouse and pig macrophages, and maintain their cargo for a sustained period of time in vitro. They named their new microparticles M-GLAMs, short for ""macrophage-hitchhiking Gd(III)-Loaded Anisotropic Micropatches."" Now, it was time to test them in a more realistic setting, for which they partnered with researchers and clinicians at Boston Children's Hospital.
First, they injected mouse M-GLAMs macrophages into mice to see if they could visualize them in vivo. They were especially interested to see if they accumulated in the kidney, as existing gadolinium-based contrast agents like Gadavist® can cause health risks for patients with kidney disease. Their M-GLAMs did not accumulate in the mice's kidneys, but persisted in their bodies for over 24 hours with no negative side effects. In contrast, mice injected with Gadavist® showed substantial accumulation of the contrast agent in their kidneys within 15 minutes of injection, and the substance was fully cleared from their bodies within 24 hours.
Then, they tested porcine M-GLAMs in a pig model of mTBI. They injected the M-GLAMs into the animals' blood two days after a mock mTBI, then used MRI to evaluate the concentration of gadolinium in the brain. They focused on a small region called the choroid plexus, which is known as a major conduit of immune cells into the brain. Pigs that received the M-GLAMs displayed a significant increase in the intensity of gadolinium present in the choroid plexus, while those injected with Gadavist® did not, despite confirmation of increased inflammation macrophage density in the brains of both groups. The animals showed no toxicity in any of their major organs following administration of the treatments.
""Another important aspect of our M-GLAMs is that we are able to achieve better imaging at a much lower dose of gadolinium than current contrast agents -- 500-1000-fold lower in the case of Gadavist®,"" said Wang. ""This could allow the use of MRI for patients who are currently unable to tolerate existing contrast agents, including those who have existing kidney problems.""
The authors note that while M-GLAMs can indicate the presence of inflammation in the brain via the high concentration of macrophages entering it through the choroid plexus, their technique cannot pinpoint the exact location of injuries or inflammatory responses in brain tissue. However, if coupled with new treatment modalities like one they developed in , M-GLAMS could offer a more rapid and effective way to identify and reduce inflammation in mTBI patients to minimize damage and speed their recovery.
The researchers have submitted a patent application for their technology, and hope to be able to bring it to the market in the near future. They are currently exploring collaborations with biotech and pharmaceutical companies to accelerate it to clinical trials .
""This work demonstrates just how much potential is waiting to be unlocked within the human body for a variety of functions: monitoring health, diagnosing problems, treating diseases, and preventing their recurrence. I'm impressed with this team's ingenuity in leveraging immune cells to improve medical imaging, and hope to see it in clinicians' hands soon,"" said Wyss Founding Director Donald Ingber, M.D., Ph.D. Ingber is also the Judah Folkman Professor of Vascular Biology at Harvard Medical School and Boston Children's Hospital, and the Hansjörg Wyss Professor of Bioinspired Engineering at SEAS.
Additional authors of the paper include Yongsheng Gao, Vineeth Chandran Suja, Suyong Shaha, Rick Liao, Ninad Kumbhojkar, Supriya Prakash, Kyung Soo Park, and Michael Dunne from the Wyss Institute and SEAS; Masen Boucher, Kaitlyn Warren, Camilo Jaimes, and Rebekah Mannix from Boston Children's Hospital; Neha Kapate and Morgan Janes from the Wyss Institute, SEAS, and MIT; Bolu Ilelaboye, Andrew Lu, and Solomina Darko from SEAS; and former SEAS members Tao Sun and John Clegg.
This research was supported by the US Department of Defense under Grant No. W81XWH-19-2-0011 and the National Science Foundation Graduate Research Fellowship under Grant Nos. 1122374 and 1745302.

","score: 15.59818290585508, grade_level: '16'","score: 17.387785089359156, grade_levels: ['college_graduate'], ages: [24, 100]",10.1126/scitranslmed.adk5413,"The choroid plexus (ChP) of the brain plays a central role in orchestrating the recruitment of peripheral leukocytes into the central nervous system (CNS) through the blood-cerebrospinal fluid (BCSF) barrier in pathological conditions, thus offering a unique niche to diagnose CNS disorders. We explored whether magnetic resonance imaging of the ChP could be optimized for mild traumatic brain injury (mTBI). mTBI induces subtle, yet influential, changes in the brain and is currently severely underdiagnosed. We hypothesized that mTBI induces sufficient alterations in the ChP to cause infiltration of circulating leukocytes through the BCSF barrier and developed macrophage-adhering gadolinium [Gd(III)]–loaded anisotropic micropatches (GLAMs), specifically designed to image infiltrating immune cells. GLAMs are hydrogel-based discoidal microparticles that adhere to macrophages without phagocytosis. We present a fabrication process to prepare GLAMs at scale and demonstrate their loading with Gd(III) at high relaxivities, a key indicator of their effectiveness in enhancing image contrast and clarity in medical imaging. In vitro experiments with primary murine and porcine macrophages demonstrated that GLAMs adhere to macrophages also under shear stress and did not affect macrophage viability or functions. Studies in a porcine mTBI model confirmed that intravenously administered macrophage-adhering GLAMs provide a differential signal in the ChP and lateral ventricles at Gd(III) doses 500- to 1000-fold lower than those used in the current clinical standard Gadavist. Under the same mTBI conditions, Gadavist did not offer a differential signal at clinically used doses. Our results suggest that macrophage-adhering GLAMs could facilitate mTBI diagnosis."
"
A new study from researchers at the University of Colorado Anschutz Medical Campus finds that older adult drivers who are recently diagnosed with migraines are three times as likely to experience a motor vehicle crash. Older adult drivers who reported having ever had migraines in the past were no more likely to have a motor vehicle crash than those without migraines.

Additionally, study results, published in the Journal of the American Geriatrics Society, explored the relationships medications commonly prescribed for migraine management have with increased crash risk.
""Migraine headaches affect more than 7% of U.S. adults over the age of 60,"" says Carolyn DiGuiseppi, MPH, PhD, MD, professor with the Colorado School of Public Health and study lead author. ""The US population is aging, which means increasing numbers of older adult drivers could see their driving abilities affected by migraine symptoms previously not experienced. These symptoms include sleepiness, decreased concentration, dizziness, debilitating head pain and more.""
Researchers conducted a five-year longitudinal study of more than 2,500 active drivers aged 65-79 in five sites across the United States. Participants were categorized as having previously been diagnosed with migraine symptoms (12.5%), no previous diagnosis but experienced symptoms during the study timeframe (1.3%) or never migraine respondents. Results indicate those with previous diagnosis did not have a different likelihood of having crashes after baseline, while those with new onset migraines were three times as likely to experience a crash within one year of diagnosis. However, previously diagnosed drivers experienced more hard braking events compared to adults who had never experienced a migraine.
Additionally, researchers examined the role medications commonly prescribed for migraines have in motor vehicle events and found that there was no impact on the relationship between migraines and either crashes or driving habits. However, few participants in the study sample were using acute migraine medications.
""These results have potential implications for the safety of older patients that should be addressed,"" says DiGuiseppi. ""Patients with a new migraine diagnosis would benefit from talking with their clinicians about driving safety, including being extra careful about other risks, such as distracted driving, alcohol, pain medication and other factors that affect driving.""

","score: 16.428985167837627, grade_level: '16'","score: 17.94536299765808, grade_levels: ['college_graduate'], ages: [24, 100]",10.1111/jgs.18719,"Migraine headache is common in older adults, often causing symptoms that may affect driving safety. This study examined associations of migraine with motor vehicle crashes (MVCs) and driving habits in older drivers and assessed modification of associations by medication use. In a multi‐site, prospective cohort study of active drivers aged 65–79 (53% female), we assessed prevalent migraine (i.e., ever had migraine, reported at enrollment), incident migraine (diagnosis first reported at a follow‐up visit), and medications typically used for migraine prophylaxis and treatment. During 2‐year follow‐up, we recorded self‐reported MVCs and measured driving habits using in‐vehicle GPS devices. Associations of prevalent migraine with driving outcomes were estimated in multivariable mixed models. Using a matched design, associations of incident migraine with MVCs in the subsequent year were estimated with conditional logistic regression. Interactions between migraine and medications were tested in all models. Of 2589 drivers, 324 (12.5%) reported prevalent migraine and 34 (1.3%) incident migraine. Interactions between migraine and medications were not statistically significant in any models. Prevalent migraine was not associated with MVCs in the subsequent 2 years (adjusted OR [aOR] = 0.98; 95% CI: 0.72, 1.35), whereas incident migraine significantly increased the odds of having an MVC within 1 year (aOR = 3.27; 1.21, 8.82). Prevalent migraine was associated with small reductions in driving days and trips per month and increases in hard braking events in adjusted models. Our results suggest substantially increased likelihood of MVCs in the year after newly diagnosed migraine, indicating a potential need for driving safety interventions in these patients. We found little evidence for MVC risk or substantial changes in driving habits associated with prevalent migraine. Future research should examine timing, frequency, and severity of migraine diagnosis and symptoms, and use of medications specifically prescribed for migraine, in relation to driving outcomes."
"
Like mail carriers who manage to deliver their parcels through snow, rain, heat and gloom, a critical group of mammalian proteins helps cells function properly even under less-than-ideal conditions.

Using state-of-the-art cell imaging and genome editing technology, University of Wisconsin-Madison scientists have begun to unravel how this collection of proteins performs its essential service. The discovery could eventually help researchers better understand and develop new treatments for diseases like cancer, diabetes and those that cause immune dysfunction.
Led by Anjon Audhya, a professor in the Department of Biomolecular Chemistry, the research team sought to better understand how the Coat Protein Complex II, or COPII, functions. COPII is an enormously important group of proteins responsible for transporting roughly a third of all proteins that function in mammalian cells.
COPII was a subject of the 2013 Nobel Prize in Physiology or Medicine, which was awarded to a trio of scientists for their work defining how proteins are sorted and transported around cells. This new research builds on some of those discoveries.
There are millions of proteins inside mammalian cells, and they perform a wide variety of duties. Cells must ensure that proteins are moved efficiently to their proper places, so they can perform their cellular roles -- an intricate task requiring precision. Previous research identified COPII as an essential part of this process, but no one had recorded exactly how this set of proteins goes about packaging and transporting other proteins around cells.
To do so, Audhya and his colleagues used the CRISPR/Cas9 genome editing tool to add a tag, which could be chemically linked to a bright, fluorescent dye, to individual proteins involved in controlling the traffic flow within cells, including some that make up the COPII complex. With the tag, the scientists could follow the proteins as they moved about living cells.
Using a technique called lattice light-sheet imaging, the team tracked how COPII helps get cellular proteins, including molecules destined for other places, where they're supposed to go -- something that had never been done before.

The team described their advance in a paper recently published in the journal Nature Communications. Audhya described it in terms of the postal system. Researchers knew that COPII functions like postal workers who pick up and deliver parcels, but they had never tracked these workers as they sorted packages through the cell's distribution and delivery systems.
""We can now see that envelope in the mailbox, see how the mail carrier comes to the mailbox to pick up the letter and then drive away,"" says Audhya, who is the senior associate dean for basic research, biotechnology and graduate studies at the School of Medicine and Public Health.
The researchers discovered that, on average, this delivery process takes between 45 and 60 seconds under normal conditions. However, when cells receive subpar nutrition, as they sometimes do thanks to certain diseases and environmental conditions, this process slows down significantly, at least until cells can adapt over time.
Through a series of experiments, Audhya and his colleagues were able to identify a single protein named Sec23 that was capable of helping restore COPII's trafficking system after disruption. When the scientists increased how much Sec23 was produced inside cells, they saw a change in the rate in which cells transported proteins, ""something we never anticipated when we started this work,"" Audhya says. ""Sec23 seems to be the central player in regulating the function of the COPII complex.""
Identifying what triggers Sec23 to promote COPII function has potential implications for a number of diseases. For instance, cancer cells often grow prodigiously in nutrient-starved environments, in part by producing more of certain proteins that promote growth. Understanding the molecular mechanisms that underlie this property could identify new targets for therapies.
Beyond that, a more precise picture of the process by which cells correctly prepare and deliver proteins can help inform our basic understanding of proper cell function and what can go awry in diseases such as cancer, Type 2 diabetes, neurodegenerative conditions and immune disorders.
""Understanding these fundamental processes and the regulatory systems that exist in cells can ultimately pave the way to developing more rational approaches to disease intervention,"" says Audhya.
This work was supported in part by National Institutes of Health grants GM134865 and GM008688, as well as shared resources available in the UWCCC Flow Cytometry Laboratory and the UW Optical Imaging Core.

","score: 14.60183078115914, grade_level: '15'","score: 16.72502907540221, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41467-023-44002-7,"Co-assembly of the multilayered coat protein complex II (COPII) with the Sar1 GTPase at subdomains of the endoplasmic reticulum (ER) enables secretory cargoes to be concentrated efficiently within nascent transport intermediates, which subsequently deliver their contents to ER-Golgi intermediate compartments. Here, we define the spatiotemporal accumulation of native COPII subunits and secretory cargoes at ER subdomains under differing nutrient availability conditions using a combination of CRISPR/Cas9-mediated genome editing and live cell imaging. Our findings demonstrate that the rate of inner COPII coat recruitment serves as a determinant for the pace of cargo export, irrespective of COPII subunit expression levels. Moreover, increasing inner COPII coat recruitment kinetics is sufficient to rescue cargo trafficking deficits caused by acute nutrient limitation. Our findings are consistent with a model in which the rate of inner COPII coat addition acts as an important control point to regulate cargo export from the ER."
"
Many bacterial pathogens use small injection apparatuses to manipulate the cells of their hosts, such as humans, so that they can spread throughout the body. To do this, they need to fill their syringes with the relevant injection agent. A technique that tracks the individual movement of proteins revealed how bacteria accomplish this challenging task.

Disease-causing bacteria of the genus Salmonella or Yersinia can use tiny injection apparatuses to inject harmful proteins into host cells, much to the discomfort of the infected person. However, it is not only with a view to controlling disease that researchers are investigating the injection mechanism of these so-called type III secretion systems, also known as ""injectisomes.""
If the structure and function of the injectisome were fully understood, researchers would be able to hijack it to deliver specific drugs into cells, such as cancer cells. In fact, the structure of the injectisome has already been elucidated. However, it remained unclear how the bacteria load their syringes so that the right proteins are injected at the right time.
Mobile components of the injectisome search for proteins
A team of scientists led by Andreas Diepold from the Max Planck Institute for Terrestrial Microbiology in Marburg and Ulrike Endesfelder from the University of Bonn has now been able to answer this question: mobile components of the injectisome comb through the bacterial cell in search of the proteins to be injected, so-called effectors. When they encounter an effector, they transport it like a shuttle bus to the gate of the injection needle.
""How proteins of the sorting platform in the cytosol bind to effectors and deliver the cargo to the export gate of the membrane-bound injectisome is comparable to the processes at a freight terminal,"" explains Stephan Wimmi, first author of the study as a postdoctoral researcher in Andreas Diepold's laboratory. ""We think that this shuttle mechanism helps to make the injection efficient and specific at the same time -- after all, the bacteria have to inject the right proteins quickly to avoid being recognized and eliminated by the immune system, for example.""
To gain this insight into the important loading mechanism of the injectisome, the researchers had to apply new techniques. ""Conventional methods, which are normally used to detect that proteins bind to each other, did not work to answer this question -- possibly because the effectors are only bound for a short time and then immediately injected,"" explains Andreas Diepold, research group leader at the Max Planck Institute and co-leader of the study. ""That's why we had to analyse this binding in situ in the living bacteria.""
""To measure these transient interactions we made use of two novel approaches that work in living cells, proximity labeling and single-particle tracking,"" adds Ulrike Endesfelder, whose group worked on the study in three different locations -- the Max Planck Institute in Marburg, Carnogie Mellon University in Pittsburgh, PA, USA, and at the University in Bonn. Proximity labeling, in which a protein marks its immediate neighbors like a paintbrush, enabled them to show that the effectors in the bacterium bind to the mobile injectisome components. This binding was examined in more detail using single particle tracking, a high-resolution microscopy method that can follow individual proteins in cells. These methods, which the team refers to as ""in situ biochemistry,"" i.e. biochemical investigations on site, made the breakthrough possible.
The researchers next want to use their method to investigate other mechanisms that bacteria use to cause infections. ""The more we know about how bacteria use these systems during an infection, the better we can understand how we can influence them -- be it to prevent infections or to modify the systems in order to use them in the fields of medicine or biotechnology,"" says Andreas Diepold.

","score: 15.563064608347627, grade_level: '16'","score: 17.070724699828475, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41564-023-01545-1,"Bacteria use type III secretion injectisomes to inject effector proteins into eukaryotic target cells. Recruitment of effectors to the machinery and the resulting export hierarchy involve the sorting platform. These conserved proteins form pod structures at the cytosolic interface of the injectisome but are also mobile in the cytosol. Photoactivated localization microscopy in Yersinia enterocolitica revealed a direct interaction of the sorting platform proteins SctQ and SctL with effectors in the cytosol of live bacteria. These proteins form larger cytosolic protein complexes involving the ATPase SctN and the membrane connector SctK. The mobility and composition of these mobile pod structures are modulated in the presence of effectors and their chaperones, and upon initiation of secretion, which also increases the number of injectisomes from ~5 to ~18 per bacterium. Our quantitative data support an effector shuttling mechanism, in which sorting platform proteins bind to effectors in the cytosol and deliver the cargo to the export gate at the membrane-bound injectisome."
"
Mutations of the tumor suppressor p53 not only have a growth-promoting effect on the cancer cells themselves, but also influence the cells in the tumor's microenvironment. Scientists at the German Cancer Research Center (DKFZ) and the Weizmann Institute in Israel have now shown that p53-mutated mouse breast cancer cells reprogram fat cells. The manipulated fat cells create an inflammatory microenvironment, impairing the immune response against the tumor and thus promoting cancer growth.

No other gene is mutated as frequently in human tumors as the gene for the tumor suppressor p53. In around 30 percent of all cases of breast cancer, the cancer cells show mutations or losses in the p53 gene. These mutations restrict the ability of p53 to acta as a ""cancer brake"" p53 and to prevent the development and progression of cancer.
The effects of p53 mutations in the cancer cells themselves have already been intensively researched. However, the understanding that p53 mutations in cancer cells can also affect cells in the tumor's microenvironment -- and thus additionally drive cancer growth -- is only slowly growing.
A team of researchers led by Almut Schulze from the DKZF and Moshe Oren from the Weizmann Institute in Israel investigated the effects of p53 mutations in breast cancer cells on fat cells, known as adipocytes. During the progression of breast cancer, adipocytes, one of the main cell types in breast tissue, undergo a transformation. Research results indicate that this increases the aggressiveness and resistance to therapy of the surrounding breast cancer cells.
Schulze and Oren's team have now demonstrated this in adipocytes from mouse breast tissue: The cancer-promoting properties of adipocytes are potentiated when the breast cancer cells carry p53 mutations.
The researchers treated immature adipocytes with culture medium in which breast cancer cells with or without p53 mutations had previously grown. This treatment triggered profound changes in metabolism and gene activity in the adipocytes and increased the production of pro-inflammatory messengers. The maturation of the adipocytes was prevented, while mature fat cells were returned to an immature stage. These effects were only mild after treatment with cell culture media from breast cancer cells with functioning p53, but were very clear in the case of medium from cancer cells with mutated p53.
The researchers then transferred breast cancer cells with mutated or functional p53 together with pre-treated fat cells to mice and compared the resulting tumors. If p53 was mutated in the cancer cells, the number of immunosuppressive myeloid cells in the tumor increased. The migrated immune cells carried more PD-L1 on their surface, which acts as a potent brake on the immune defense of tumors.
A particularly surprising result was that breast cancer cells with certain p53 mutations were able to reprogram neighboring precursor fat cells -- directly or indirectly -- to be even more pro-inflammatory than breast cancer cells that had completely lost the tumor suppressor p53.
""p53 defects in breast cancer cells appear to be the central driver of tumor-promoting reprogramming of fat cells,"" summarizes Almut Schulze, who led the study together with Moshe Oren. ""Fat cells are an essential component of breast tissue and can therefore have a massive influence on tumor progression. A detailed understanding of the interaction between p53-mutated cancer cells and adipocytes could therefore provide new clues as to how the progression of breast cancer can be halted.""

","score: 13.63599206657852, grade_level: '14'","score: 15.645572839698218, grade_levels: ['college_graduate'], ages: [24, 100]",10.1073/pnas.2311460120,"The TP53 gene is mutated in approximately 30% of all breast cancer cases. Adipocytes and preadipocytes, which constitute a substantial fraction of the stroma of normal mammary tissue and breast tumors, undergo transcriptional, metabolic, and phenotypic reprogramming during breast cancer development and play an important role in tumor progression. We report here that p53 loss in breast cancer cells facilitates the reprogramming of preadipocytes, inducing them to acquire a unique transcriptional and metabolic program that combines impaired adipocytic differentiation with augmented cytokine expression. This, in turn, promotes the establishment of an inflammatory tumor microenvironment, including increased abundance of Ly6C+ and Ly6G+ myeloid cells and elevated expression of the immune checkpoint ligand PD-L1. We also describe a potential gain-of-function effect of common p53 missense mutations on the inflammatory reprogramming of preadipocytes. Altogether, our study implicates p53 deregulation in breast cancer cells as a driver of tumor-supportive adipose tissue reprogramming, expanding the network of non-cell autonomous mechanisms whereby p53 dysfunction may promote cancer. Further elucidation of the interplay between p53 and adipocytes within the tumor microenvironment may suggest effective therapeutic targets for the treatment of breast cancer patients."
"
A UC Riverside study to motivate your new year's resolutions: it demonstrates that high-fat diets affect genes linked not only to obesity, colon cancer and irritable bowels, but also to the immune system, brain function, and potentially COVID-19 risk.

While other studies have examined the effects of a high-fat diet, this one is unusual in its scope. UCR researchers fed mice three different diets over the course of 24 weeks where at least 40% of the calories came from fat. Then, they looked not only at the microbiome, but also at genetic changes in all four parts of the intestines.
One group of mice ate a diet based on saturated fat from coconut oil, another got a monounsaturated, modified soybean oil, a third got an unmodified soybean oil high in polyunsaturated fat. Compared to a low-fat control diet, all three groups experienced concerning changes in gene expression, the process that turns genetic information into a functional product, such as a protein.
""Word on the street is that plant-based diets are better for you, and in many cases that's true. However, a diet high in fat, even from a plant, is one case where it's just not true,"" said Frances Sladek, a UCR cell biology professor and senior author of the new study.
A new Scientific Reports paper about the study documents the many impacts of high-fat diets. Some of the intestinal changes did not surprise the researchers, such as major changes in genes related to fat metabolism and the composition of gut bacteria. For example, they observed an increase in pathogenic E. coli and a suppression of Bacteroides, which helps protect the body against pathogens.
Other observations were more surprising, such as changes in genes regulating susceptibility to infectious diseases. ""We saw pattern recognition genes, ones that recognize infectious bacteria, take a hit. We saw cytokine signaling genes take a hit, which help the body control inflammation,"" Sladek said. 'So, it's a double whammy. These diets impair immune system genes in the host, and they also create an environment in which harmful gut bacteria can thrive.""
The team's previous work with soybean oil documents its link to obesity and diabetes, both major risk factors for COVID. This paper now shows that all three high-fat diets increase the expression of ACE2 and other host proteins that are used by COVID spike proteins to enter the body.

Additionally, the team observed that high-fat food increased signs of stem cells in the colon. ""You'd think that would be a good thing, but actually they can be precursors to cancer,"" Sladek said.
In terms of effects on gene expression, coconut oil showed the greatest number of changes, followed by the unmodified soybean oil. Differences between the two soybean oils suggest that polyunsaturated fatty acids in unmodified soybean oil, primarily linoleic acid, play a role in altering gene expression.
Negative changes to the microbiome in this study were more pronounced in mice fed the soybean oil diet. This was unsurprising, as the same research team previously documented other negative health effects of high soybean oil consumption.
In 2015, the team found that soybean oil induces obesity, diabetes, insulin resistance, and fatty liver in mice. In 2020, the researchers team demonstrated the oil could also affect genes in the brain related to conditions like autism, Alzheimer's disease, anxiety, and depression.
Interestingly, in their current work they also found the expression of several neurotransmitter genes were changed by the high fat diets, reinforcing the notion of a gut-brain axis that can be impacted by diet.
The researchers have noted that these findings only apply to soybean oil, and not to other soy products, tofu, or soybeans themselves. ""There are some really good things about soybeans. But too much of that oil is just not good for you,"" said UCR microbiologist Poonamjot Deol, who was co-first author of the current study along with UCR postdoctoral researcher Jose Martinez-Lomeli.

Also, the studies were conducted using mice, and mouse studies do not always translate to the same results in humans. However, humans and mice share 97.5% of their working DNA. Therefore, the findings are concerning, as soybean oil is the most commonly consumed oil in the United States, and is increasingly being used in other countries, including Brazil, China, and India.
By some estimates, Americans tend to get nearly 40% of their calories from fat, which mirrors what the mice were fed in this study. ""Some fat is necessary in the diet, perhaps 10 to 15%. Most people though, at least in this country, are getting at least three times the amount that they need,"" Deol said.
Readers should not panic about a single meal. It is the long-term high-fat habit that caused the observed changes. Recall that the mice were fed these diets for 24 weeks. ""In human terms, that is like starting from childhood and continuing until middle age. One night of indulgence is not what these mice ate. It's more like a lifetime of the food,"" Deol said.
That said, the researchers hope the study will cause people to closely examine their eating habits.
""Some people think, 'Oh, I'll just exercise more and be okay. But regularly eating this way could be impacting your immune system and how your brain functions,"" Deol said. ""You may not be able to just exercise away these effects.""

","score: 10.37580477972934, grade_level: '10'","score: 11.068455226029371, grade_levels: ['12'], ages: [17, 18]",10.1038/s41598-023-49555-7,"High fat diets (HFDs) have been linked to several diseases including obesity, diabetes, fatty liver, inflammatory bowel disease (IBD) and colon cancer. In this study, we examined the impact on intestinal gene expression of three isocaloric HFDs that differed only in their fatty acid composition—coconut oil (saturated fats), conventional soybean oil (polyunsaturated fats) and a genetically modified soybean oil (monounsaturated fats). Four functionally distinct segments of the mouse intestinal tract were analyzed using RNA-seq—duodenum, jejunum, terminal ileum and proximal colon. We found considerable dysregulation of genes in multiple tissues with the different diets, including those encoding nuclear receptors and genes involved in xenobiotic and drug metabolism, epithelial barrier function, IBD and colon cancer as well as genes associated with the microbiome and COVID-19. Network analysis shows that genes involved in metabolism tend to be upregulated by the HFDs while genes related to the immune system are downregulated; neurotransmitter signaling was also dysregulated by the HFDs. Genomic sequencing also revealed a microbiome altered by the HFDs. This study highlights the potential impact of different HFDs on gut health with implications for the organism as a whole and will serve as a reference for gene expression along the length of the intestines."
"
Yale researchers have identified a drug target that may alleviate joint degeneration associated with osteoarthritis, a debilitating condition that afflicts as many as 30 million people in the United States alone, which they report on Jan. 3 in the journal Nature.

Pain relievers and lifestyle changes, such as exercise and reduced excess weight, have long been the therapies most commonly used to treat the joint stiffness and pain caused by degenerative disease, but there is a pressing need for therapies that can prevent joint breakdown that occurs in osteoarthritis.
It is known that specialized proteins known as sodium channels found in cell membranes produce electrical impulses in ""excitable"" cells within muscles, the nervous system, and the heart. And in previous research, Yale's Stephen G. Waxmanidentified the key role of one particular sodium channel, called Nav1.7, in the transmission of pain signals.
Now, the labs of Chuan-Ju Liu, the Charles W. Ohse Professor of Orthopedics, and Waxman, the Bridget M. Flaherty Professor of Neurology and professor of neuroscience and pharmacology, both at Yale School of Medicine, have found that the same Nav1.7 channels are also present in non-excitable cells that produce collagen and help maintain the joints in the body.
Osteoarthritis, the most common form of arthritis, is a degenerative disease caused by the breakdown of cartilage that eases friction between the joints. It occurs most commonly in the hands, hips, and knees.
In the new study, the researchers deleted Nav1.7 genes from these collagen-producing cells and significantly reduced joint damage in two osteoarthritis models in mice.
They also demonstrated that drugs used to block Nav1.7 -- including carbamazepine, a sodium channel blocker currently used to treat epilepsy and trigeminal neuralgia -- also provided substantial protection from joint damage in the mice.
""The function of sodium channels in non-excitable cells has been a mystery,"" Waxman said. ""This new study provides a window on how small numbers of sodium channels can powerfully regulate the behavior of non-excitable cells.""
""The findings open new avenues for disease-modifying treatments,"" added Wenyu Fu, a research scientist in the Liu laboratory and first author of the study.

","score: 16.427222222222223, grade_level: '16'","score: 18.17975, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41586-023-06888-7,"Osteoarthritis (OA) is the most common joint disease. Currently there are no effective methods that simultaneously prevent joint degeneration and reduce pain1. Although limited evidence suggests the existence of voltage-gated sodium channels (VGSCs) in chondrocytes2, their expression and function in chondrocytes and in OA remain essentially unknown. Here we identify Nav1.7 as an OA-associated VGSC and demonstrate that human OA chondrocytes express functional Nav1.7 channels, with a density of 0.1 to 0.15 channels per µm2 and 350 to 525 channels per cell. Serial genetic ablation of Nav1.7 in multiple mouse models demonstrates that Nav1.7 expressed in dorsal root ganglia neurons is involved in pain, whereas Nav1.7 in chondrocytes regulates OA progression. Pharmacological blockade of Nav1.7 with selective or clinically used pan-Nav channel blockers significantly ameliorates the progression of structural joint damage, and reduces OA pain behaviour. Mechanistically, Nav1.7 blockers regulate intracellular Ca2+ signalling and the chondrocyte secretome, which in turn affects chondrocyte biology and OA progression. Identification of Nav1.7 as a novel chondrocyte-expressed, OA-associated channel uncovers a dual target for the development of disease-modifying and non-opioid pain relief treatment for OA."
"
A previously unidentified genetic mutation in a small protein provides significant protection against Parkinson's disease and offers a new direction for exploring potential treatments, according to a new USC Leonard Davis School of Gerontology study.

The variant, located in a mitochondrial microprotein dubbed SHLP2, was found to be highly protective against Parkinson's disease; individuals with this mutation are half as likely to develop the disease as those who do not carry it. The variant form of the protein is relatively rare and is found primarily in people of European descent.
The findings appear on January 3, 2024, in the journal Molecular Psychiatry.
First discovered by Pinchas Cohen at the USC Leonard Davis School in 2016, SHLP2 is made within the cell's mitochondria. Previous research from the Cohen Lab established that SHLP2 is associated with protection from aging-related diseases including cancer and that levels of the microprotein change in patients with Parkinson's disease; they rise as the body attempts to counteract the pathology of Parkinson's disease but often fail to mount additional production as the disease progresses.
This latest finding builds upon the USC team's prior mitochondrial research and represents an advance at the intersection of longevity science, precision health, and microprotein discovery.
""This study advances our understanding of why people might get Parkinson's and how we might develop new therapies for this devastating disease,"" said Cohen, professor of gerontology, medicine and biological sciences and senior author of the study. ""Also, because most research is done on well-established protein-coding genes in the nucleus, it underscores the relevance of exploring mitochondrial-derived microproteins as a new approach to the prevention and treatment of diseases of aging.""
For this study, first author Su-Jeong Kim, an adjunct research assistant professor of gerontology at the USC Leonard Davis School, led a series of experiments that leveraged the Lab-developed microprotein discovery pipeline that begins with a big data-driven analysis to identify variants involved in disease. Thousands of human study subjects from the Health & Retirement Study, Cardiovascular Health Study, and Framingham Heart Study were screened for the SHLP2 variant. By comparing genetic variants in the mitochondrial DNA in patients with Parkinson's disease and in controls, researchers found a highly protective variant found in 1% of Europeans, that reduced risk of Parkinson's disease by twofold, to 50% of average.

Next, they demonstrated that this naturally occurring variant results in a change to the amino acid sequence and protein structure of SHLP2. The mutation -- a single nucleotide polymorphism (SNP), or a change to a single letter of the protein's genetic code -- is essentially a ""gain-of-function"" variant that is associated with higher expression of SHLP2 and also makes the microprotein more stable. According to their findings, the SHLP2 variant has high stability compared to the more common type and provides enhanced protection against mitochondrial dysfunction.
The research team was able to use targeted mass spectrometry techniques to identify the tiny peptide's presence in neurons and found that SHLP2 specifically binds to an enzyme in mitochondria called mitochondrial complex 1. This enzyme is essential for life, and declines in its function have been linked not only to Parkinson's disease but also to strokes and heart attacks.
The increased stability of the SHLP2 variant means that the microprotein binds to mitochondrial complex 1 more stably, prevents the decline of the enzyme's activity, and thus reduces mitochondrial dysfunction. The benefits of the mutant form of SHLP2 were observed in both in vitro experiments in human tissue samples as well as in mouse models of Parkinson's disease, according to the study.
""Our data highlights the biological effects of a particular gene variant and the potential molecular mechanisms by which this mutation may reduce the risk for Parkinson's disease,"" said Kim. ""These findings may guide the development of therapies and provide a roadmap for understanding other mutations found in mitochondrial microproteins.""
Coauthors included Brendan Miller, Nicolas G. Hartel, Ricardo Ramirez II, Regina Gonzalez Braniff, Naphada Leelaprachakul, Amy Huang, Yuzhu Wang, Thalida Em Arpawong, Eileen M. Crimmins, Kelvin Yen, Giselle M. Petzinger, Michael W. Jakowec, and Nicholas A. Graham of USC; Penglong Wang and Chunyu Liu of the National Heart, Lung, and Blood Institute, National Institutes of Health; and Xianbang Sun and Daniel Levy of Boston University.
This work was supported by Department of Defense grant W81XWH2110625 to Kim and by NIH grants P01AG034906, R01AG068405 and P30AG068345 to Cohen. Pinchas Cohen is a consultant of CohBar Inc.

","score: 17.304733333333335, grade_level: '17'","score: 19.641560000000005, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s41380-023-02344-0,"Mitochondrial DNA single nucleotide polymorphisms (mtSNPs) have been associated with a reduced risk of developing Parkinson’s disease (PD), yet the underlying mechanisms remain elusive. In this study, we investigate the functional role of a PD-associated mtSNP that impacts the mitochondrial-derived peptide (MDP) Small Humanin-like Peptide 2 (SHLP2). We identify m.2158 T > C, a mtSNP associated with reduced PD risk, within the small open reading frame encoding SHLP2. This mtSNP results in an alternative form of SHLP2 (lysine 4 replaced with arginine; K4R). Using targeted mass spectrometry, we detect specific tryptic fragments of SHLP2 in neuronal cells and demonstrate its binding to mitochondrial complex 1. Notably, we observe that the K4R variant, associated with reduced PD risk, exhibits increased stability compared to WT SHLP2. Additionally, both WT and K4R SHLP2 show enhanced protection against mitochondrial dysfunction in in vitro experiments and confer protection against a PD-inducing toxin, a mitochondrial complex 1 inhibitor, in a mouse model. This study sheds light on the functional consequences of the m.2158 T > C mtSNP on SHLP2 and provides insights into the potential mechanisms by which this mtSNP may reduce the risk of PD."
"
Farmers in sub-Saharan Africa need to diversify away from growing maize and switch to crops that are resilient to climate change and supply key micronutrients for the population, say researchers.

Maize is a staple crop across the region where it is grown and consumed in vast quantities. 
Led by Dr Stewart Jennings from the University of Leeds, the study argues that diversification towards fruits, vegetables and crops such as cassava, millet and sorghum will improve nutrition security in the country, with people getting sufficient micronutrients essential for good health.
The study also says the quantity of food produced must increase -- and unless yields are boosted to an unprecedented level, more land will have to be brought into agricultural production.
Sub-Saharan Africa is home to around 1.2 billion people, and according to figures from the World Bank, the population will grow by an additional 740 million people by 2050. 
Farmers will have to boost the amount of food grown at a time when climate change will result in increasingly extreme conditions, affecting what crops can be grown.
The researchers say the population is at risk of ""food and nutrition insecurity"" unless effective ways of adapting to climate change are identified. Integral to any decisions is a requirement that crops need to be nutritious and provide sufficient energy for the population. 
Professor Jennie Macdiarmid, from the Rowett Institute at the University of Aberdeen and one of the authors of the paper, said: ""The study has highlighted the need to place nutrition at the heart of agricultural policy to avoid the long-term unintended consequence of failing to produce food that can deliver the nutritional needs of the population.

""If policy solutions focus only on increasing production of calories and adapting to be climate smart, it is likely there will be negative consequences for health through nutritionally poor diets.""
The study -- Stakeholder-driven transformative adaptation is needed for climate-smart nutrition security in sub-Saharan Africa - is published in the scientific journal Nature Food. 
More than 50 researchers contributed to the investigation, which involved talking to policymakers and other stakeholders in the food and agriculture sectors in four countries in sub-Saharan Africa: Malawi, South Africa, Tanzania and Zambia.
'Agriculture and nutrition policies can sit in siloes'
The researchers used the iFEED assessment framework to investigate policy options to create an agricultural system that is resilient to climate change and would supply enough nutritionally-adequate food to meet the food and nutritional needs of the population.
""Too often food, agriculture and nutrition policies sit in siloes across different government departments,"" said Dr Jennings, a Research Fellow in the School of Earth and Environment at the University of Leeds. 
""This study provides holistic evidence that combines information on environmental impacts of food system changes and the changes needed for population level nutrition security. The research shows that action can be taken to adapt to climate change and improve nutrition security in sub-Saharan Africa."" 

Stakeholders in each country identified key uncertainties in the future of the food system. iFEED explores these uncertain futures and identifies key policy issues that decision makers working in the agriculture and food sectors need to consider. 
The scientists say there needs to be a fundamental shift - or ""transformative approach"" - in agriculture to incorporate nutritional needs. 
Diversifying into soybean production is one option. Soybean crops are more likely to withstand the impacts of climate change compared to maize. Dr Ndashe Kapulu, from the Zambia Agriculture Research Institute and contributing author to the study has been involved in studies to assess how soybean could improve the income of commercial and small-scale farmers.
He said: ""Many countries in sub-Saharan Africa will be better able to handle climate change and other stresses if they have more diverse food systems, such as the transition to soybean production in Zambia.
""As scientists, we need to generate enough evidence in our research to help make changes that support and guide actions to make the agrifood system more resilient.""
Increasing the production and consumption of animal-based products in sub-Saharan Africa could also improve nutritional quality of diets but the scientists warn that it should not reach the unsustainable production levels seen in some higher income countries. 
More animal-based products would cause a rise in greenhouse gas emissions, although the researchers say that this could be tolerable given sub-Saharan Africa's need to reduce the risk of nutritionally-inadequate diets -- and that its greenhouse gas emissions are relatively low.
The study involved researchers from a number of organisation including the University of Leeds, University of Aberdeen, the Met Office, Chatham House and FANRPAN.
iFEED is a database - developed in part by the University of Leeds under the GCRF AFRICAP programme and the CGIAR Initiative on Climate Resilience -- to help decision makers deliver food system policies which are resilient to climate change and deliver nutritious food -- reducing the risk of food and nutrition insecurity. 

","score: 16.994425087108016, grade_level: '17'","score: 18.69280836236934, grade_levels: ['college_graduate'], ages: [24, 100]",10.1038/s43016-023-00901-y,"Improving nutrition security in sub-Saharan Africa under increasing climate risks and population growth requires a strong and contextualized evidence base. Yet, to date, few studies have assessed climate-smart agriculture and nutrition security simultaneously. Here we use an integrated assessment framework (iFEED) to explore stakeholder-driven scenarios of food system transformation towards climate-smart nutrition security in Malawi, South Africa, Tanzania and Zambia. iFEED translates climate–food–emissions modelling into policy-relevant information using model output implication statements. Results show that diversifying agricultural production towards more micronutrient-rich foods is necessary to achieve an adequate population-level nutrient supply by mid-century. Agricultural areas must expand unless unprecedented rapid yield improvements are achieved. While these transformations are challenging to accomplish and often associated with increased greenhouse gas emissions, the alternative for a nutrition-secure future is to rely increasingly on imports, which would outsource emissions and be economically and politically challenging given the large import increases required."
"
Throughout the day and night, cerebrospinal fluid (CSF) pulses through small fluid-filled channels surrounding blood vessels in the brain, called perivascular spaces, to flush out neuroinflammation and other neurological waste. A disruption to this vital process can lead to neurological dysfunction, cognitive decline, or developmental delays.

For the first time, researchers Dea Garic, PhD, and Mark Shen, PhD, both at the UNC School of Medicine's Department of Psychiatry, discovered that infants with abnormally enlarged perivascular spaces have a 2.2 times greater chance of developing autism compared to infants with the same genetic risk. Their research also indicated that enlarged perivascular spaces in infancy are associated with sleep problems seven to 10 years after diagnosis.
""These results suggest that perivascular spaces could serve as an early marker for autism,"" said Garic, assistant professor of psychiatry and a member of the Carolina Institute for Developmental Disabilities (CIDD).
The researchers studied infants at increased likelihood for developing autism, because they had an older sibling with autism. They followed these infants from 6-24 months of age, before the age of autism diagnosis. Their study, published in JAMA Network Open, found that thirty percent of infants who later developed autism had enlarged perivascular spaces by 12 months. By 24 months of age, nearly half of the infants diagnosed with autism had enlarged perivascular spaces.
The Importance of Cerebrospinal Fluid and Sleep
Starting ten years ago, there has been a resurgence of research on the important functions of CSF in regulating brain health and development. Shen's lab was the first to report that excessive volume of CSF was evident at 6 months of age in infants who would later develop autism. The current study showed that excessive CSF volume at 6 months was linked to enlarged perivascular spaces at 24 months.
Every six hours, the brain expels a wave of CSF that flows through perivascular spaces to remove potentially harmful neuroinflammatory proteins, such as amyloid beta, from building up in the brain. The CSF cleansing process is especially efficient when we are asleep, as the majority of CSF circulation and clearance occurs during sleep.

Disrupted sleep, however, can reduce CSF clearance from perivascular spaces, leading to dilation or enlargement, but this has previously only been studied in animal studies or in human studies of adults. This is the first study of its kind in children.
Shen, senior author of the JAMA Network Open paper, and Garic hypothesized that CSF abnormalities in infancy would be related to later sleep problems, based on Shen's earlier research. The current sleep analysis revealed children who had enlarged perivascular spaces at two years of age had higher rates of sleep disturbances at school age.
""Since autism is so highly linked with sleep problems, we were in this unique position to examine CSF dynamics and sleep,"" said Garic, who is first author of the paper. ""It was really striking to observe such a strong association separated by such a long period of time over childhood. But it really shows how perivascular spaces not only have an effect early in life, but they can have long term effects, too.""
New Clinical Relevance in Infancy
The research was done in conjunction with the Infant Brain Imaging Study (IBIS), a nationwide network of researchers investigating brain development, autism, and related developmental disabilities. The network consists of five universities, of which the University of North Carolina-Chapel Hill is the lead site.
For their study, Garic and Shen analyzed 870 MRIs from IBIS to measure excessive CSF volume and enlarged perivascular spaces. MRIs were obtained from babies during natural sleep at six, 12, and 24 months of age to observe changes over time.

The infant brain undergoes rapid development over this period. Previously, measurement of perivascular spaces was only thought to be clinically relevant for disorders of aging in older adults, such as in dementia. These findings suggest that younger populations may need to be considered and monitored for these types of brain abnormalities.
""Our findings were striking, given that neuroradiologists typically view enlarged perivascular spaces as a sign of neurodegeneration in adults, but this study reported it in toddlers,"" said Garic. ""This is an important aspect of brain development in the first years of life that should be monitored.""
Future Studies and Possibilities
Garic and Shen hypothesize that excess CSF volume is stagnant, or clogged, and not circulating through the brain as efficiently as it should. For their next research endeavor, the researchers are planning to once again use MRIs to measure CSF in a sleeping infant's brain, but this time focusing on the physiology and speed of CSF flow throughout the brain.
The research team is also working with other collaborators to quantify the size of perivascular spaces and the severity of behavioral outcomes. The team also plans to extend their research to neurogenetic syndromes associated with autism, such as Fragile X syndrome and Down syndrome.
""Collectively our research has shown that CSF abnormalities in the first year of life could have downstream effects on a variety of outcomes, including later autism diagnosis, sleep problems, neuroinflammation, and possibly, other developmental disabilities,"" said Shen.
This work was supported the National Institutes of Health, Eunice Kennedy Shriver National Institute of Child Health and Human Development (NICHD), National Institute of Mental Health (NIMH), National Institute of Environmental Health Sciences (NIEHS), and the Simons Foundation.
Other researchers on this project include Joseph Piven, MD; Heather C. Hazlett, PhD; Martin Styner, PhD; Sun Hyung Kim, PhD; Joshua Rutsohn, PhD; and Leigh Anne Weisenfeld, MA; of the University of North Carolina -- Chapel Hill; Robert C. McKinstry, MD, PhD; and Kelly N. Botteron, MD; of Washington University in St. Louis; Rebecca Slomowitz, MA; of the University of Denver; Jason Wolff, PhD; of the University of Minnesota; Leigh C. MacIntyre, BSc; of McGill University; Juhi Pandey, PhD; of University of Pennsylvania; and Tanya St. John, PhD; Annette M. Estes, PhD; Robert T. Schultz, PhD; and Stephen R. Dager, MD; of the University of Washington.

","score: 15.346375198728143, grade_level: '15'","score: 16.697762927433914, grade_levels: ['college_graduate'], ages: [24, 100]",10.1001/jamanetworkopen.2023.48341,"Perivascular spaces (PVS) and cerebrospinal fluid (CSF) are essential components of the glymphatic system, regulating brain homeostasis and clearing neural waste throughout the lifespan. Enlarged PVS have been implicated in neurological disorders and sleep problems in adults, and excessive CSF volume has been reported in infants who develop autism. Enlarged PVS have not been sufficiently studied longitudinally in infancy or in relation to autism outcomes or CSF volume. To examine whether enlarged PVS are more prevalent in infants who develop autism compared with controls and whether they are associated with trajectories of extra-axial CSF volume (EA-CSF) and sleep problems in later childhood. This prospective, longitudinal cohort study used data from the Infant Brain Imaging Study. Magnetic resonance images were acquired at ages 6, 12, and 24 months (2007-2017), with sleep questionnaires performed between ages 7 and 12 years (starting in 2018). Data were collected at 4 sites in North Carolina, Missouri, Pennsylvania, and Washington. Data were analyzed from March 2021 through August 2022. PVS (ie, fluid-filled channels that surround blood vessels in the brain) that are enlarged (ie, visible on magnetic resonance imaging). Outcomes of interest were enlarged PVS and EA-CSF volume from 6 to 24 months, autism diagnosis at 24 months, sleep problems between ages 7 and 12 years. A total of 311 infants (197 [63.3%] male) were included: 47 infants at high familial likelihood for autism (ie, having an older sibling with autism) who were diagnosed with autism at age 24 months, 180 high likelihood infants not diagnosed with autism, and 84 low likelihood control infants not diagnosed with autism. Sleep measures at school-age were available for 109 participants. Of infants who developed autism, 21 (44.7%) had enlarged PVS at 24 months compared with 48 infants (26.7%) in the high likelihood but no autism diagnosis group (P = .02) and 22 infants in the control group (26.2%) (P = .03). Across all groups, enlarged PVS at 24 months was associated with greater EA-CSF volume from ages 6 to 24 months (β = 4.64; 95% CI, 0.58-8.72; P = .002) and more frequent night wakings at school-age (F = 7.76; η2 = 0.08; P = .006). These findings suggest that enlarged PVS emerged between ages 12 and 24 months in infants who developed autism. These results add to a growing body of evidence that, along with excessive CSF volume and sleep dysfunction, the glymphatic system could be dysregulated in infants who develop autism."
